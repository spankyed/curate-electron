[
  {
    "id": "2308.05713",
    "title": "Testing GPT-4 with Wolfram Alpha and Code Interpreter plug-ins on math and science problems",
    "abstract": "This report describes a test of the large language model GPT-4 with the\nWolfram Alpha and the Code Interpreter plug-ins on 105 original problems in\nscience and math, at the high school and college levels, carried out in\nJune-August 2023. Our tests suggest that the plug-ins significantly enhance\nGPT's ability to solve these problems. Having said that, there are still often\n\"interface\" failures; that is, GPT often has trouble formulating problems in a\nway that elicits useful answers from the plug-ins. Fixing these interface\nfailures seems like a central challenge in making GPT a reliable tool for\ncollege-level calculation problems.",
    "pdfLink": "https://arxiv.org/pdf/2308.05713.pdf"
  },
  {
    "id": "2308.05701",
    "title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving",
    "abstract": "In recent years there have been remarkable advancements in autonomous\ndriving. While autonomous vehicles demonstrate high performance in closed-set\nconditions, they encounter difficulties when confronted with unexpected\nsituations. At the same time, world models emerged in the field of model-based\nreinforcement learning as a way to enable agents to predict the future\ndepending on potential actions. This led to outstanding results in sparse\nreward and complex control tasks. This work provides an overview of how world\nmodels can be leveraged to perform anomaly detection in the domain of\nautonomous driving. We provide a characterization of world models and relate\nindividual components to previous works in anomaly detection to facilitate\nfurther research in the field.",
    "pdfLink": "https://arxiv.org/pdf/2308.05701.pdf"
  },
  {
    "id": "2308.05665",
    "title": "Exploring Deep Learning Approaches to Predict Person and Vehicle Trips: An Analysis of NHTS Data",
    "abstract": "Modern transportation planning relies heavily on accurate predictions of\nperson and vehicle trips. However, traditional planning models often fail to\naccount for the intricacies and dynamics of travel behavior, leading to\nless-than-optimal accuracy in these predictions. This study explores the\npotential of deep learning techniques to transform the way we approach trip\npredictions, and ultimately, transportation planning. Utilizing a comprehensive\ndataset from the National Household Travel Survey (NHTS), we developed and\ntrained a deep learning model for predicting person and vehicle trips. The\nproposed model leverages the vast amount of information in the NHTS data,\ncapturing complex, non-linear relationships that were previously overlooked by\ntraditional models. As a result, our deep learning model achieved an impressive\naccuracy of 98% for person trip prediction and 96% for vehicle trip estimation.\nThis represents a significant improvement over the performances of traditional\ntransportation planning models, thereby demonstrating the power of deep\nlearning in this domain. The implications of this study extend beyond just more\naccurate predictions. By enhancing the accuracy and reliability of trip\nprediction models, planners can formulate more effective, data-driven\ntransportation policies, infrastructure, and services. As such, our research\nunderscores the need for the transportation planning field to embrace advanced\ntechniques like deep learning. The detailed methodology, along with a thorough\ndiscussion of the results and their implications, are presented in the\nsubsequent sections of this paper.",
    "pdfLink": "https://arxiv.org/pdf/2308.05665.pdf"
  },
  {
    "id": "2308.05658",
    "title": "Automatic Extraction of Relevant Road Infrastructure using Connected vehicle data and Deep Learning Model",
    "abstract": "In today's rapidly evolving urban landscapes, efficient and accurate mapping\nof road infrastructure is critical for optimizing transportation systems,\nenhancing road safety, and improving the overall mobility experience for\ndrivers and commuters. Yet, a formidable bottleneck obstructs progress - the\nlaborious and time-intensive manual identification of intersections. Simply\nconsidering the shear number of intersections that need to be identified, and\nthe labor hours required per intersection, the need for an automated solution\nbecomes undeniable. To address this challenge, we propose a novel approach that\nleverages connected vehicle data and cutting-edge deep learning techniques. By\nemploying geohashing to segment vehicle trajectories and then generating image\nrepresentations of road segments, we utilize the YOLOv5 (You Only Look Once\nversion 5) algorithm for accurate classification of both straight road segments\nand intersections. Experimental results demonstrate an impressive overall\nclassification accuracy of 95%, with straight roads achieving a remarkable 97%\nF1 score and intersections reaching a 90% F1 score. This approach not only\nsaves time and resources but also enables more frequent updates and a\ncomprehensive understanding of the road network. Our research showcases the\npotential impact on traffic management, urban planning, and autonomous vehicle\nnavigation systems. The fusion of connected vehicle data and deep learning\nmodels holds promise for a transformative shift in road infrastructure mapping,\npropelling us towards a smarter, safer, and more connected transportation\necosystem.",
    "pdfLink": "https://arxiv.org/pdf/2308.05658.pdf"
  },
  {
    "id": "2308.05617",
    "title": "A Neural Network Based Choice Model for Assortment Optimization",
    "abstract": "Discrete-choice models are used in economics, marketing and revenue\nmanagement to predict customer purchase probabilities, say as a function of\nprices and other features of the offered assortment. While they have been shown\nto be expressive, capturing customer heterogeneity and behaviour, they are also\nhard to estimate, often based on many unobservables like utilities; and\nmoreover, they still fail to capture many salient features of customer\nbehaviour. A natural question then, given their success in other contexts, is\nif neural networks can eliminate the necessity of carefully building a\ncontext-dependent customer behaviour model and hand-coding and tuning the\nestimation. It is unclear however how one would incorporate assortment effects\ninto such a neural network, and also how one would optimize the assortment with\nsuch a black-box generative model of choice probabilities. In this paper we\ninvestigate first whether a single neural network architecture can predict\npurchase probabilities for datasets from various contexts and generated under\nvarious models and assumptions. Next, we develop an assortment optimization\nformulation that is solvable by off-the-shelf integer programming solvers. We\ncompare against a variety of benchmark discrete-choice models on simulated as\nwell as real-world datasets, developing training tricks along the way to make\nthe neural network prediction and subsequent optimization robust and comparable\nin performance to the alternates.",
    "pdfLink": "https://arxiv.org/pdf/2308.05617.pdf"
  },
  {
    "id": "2308.05585",
    "title": "Proximal Policy Optimization Actual Combat: Manipulating Output Tokenizer Length",
    "abstract": "The Reinforcement Learning from Human Feedback (RLHF) plays a pivotal role in\nshaping the impact of large language models (LLMs), contributing significantly\nto controlling output toxicity and selecting output styles, particularly as\nLLMs often harbor misleading content, highlighting the urgency to align them\nwith human values for secure AI systems. The RLHF, characterized by complexity,\ninstability, and sensitivity to hyperparameters, makes the evaluation of the\nreward model for complex tasks challenging, thereby further complicating the\nuse of Proximal Policy Optimization (PPO). In this paper, we introduce a simple\ntask designed to employ Gloden as a reward model that validates the\neffectiveness of PPO and inspires it, primarily explaining the task of\nutilizing PPO to manipulate the tokenizer length of the output generated by the\nmodel. Experiments confirm that PPO is not only effective in manipulating the\noutput tokenizer length to a certain extent in this type of task but also\nexhibits facilitated training once the influence of the reward model effect is\nexcluded, making it an exciting development.",
    "pdfLink": "https://arxiv.org/pdf/2308.05585.pdf"
  },
  {
    "id": "2308.05583",
    "title": "Generative Diffusion Models for Radio Wireless Channel Modelling and Sampling",
    "abstract": "Channel modelling is essential to designing modern wireless communication\nsystems. The increasing complexity of channel modelling and the cost of\ncollecting high-quality wireless channel data have become major challenges. In\nthis paper, we propose a diffusion model based channel sampling approach for\nrapidly synthesizing channel realizations from limited data. We use a diffusion\nmodel with a U Net based architecture operating in the frequency space domain.\nTo evaluate how well the proposed model reproduces the true distribution of\nchannels in the training dataset, two evaluation metrics are used: i)i) the\napproximate 22-Wasserstein distance between real and generated distributions\nof the normalized power spectrum in the antenna and frequency domains and ii)ii)\nprecision and recall metric for distributions. We show that, compared to\nexisting GAN based approaches which suffer from mode collapse and unstable\ntraining, our diffusion based approach trains stably and generates diverse and\nhigh-fidelity samples from the true channel distribution. We also show that we\ncan pretrain the model on a simulated urban macro-cellular channel dataset and\nfine-tune it on a smaller, out-of-distribution urban micro-cellular dataset,\ntherefore showing that it is feasible to model real world channels using\nlimited data with this approach.",
    "pdfLink": "https://arxiv.org/pdf/2308.05583.pdf"
  },
  {
    "id": "2308.05567",
    "title": "C5: Towards Better Conversation Comprehension and Contextual Continuity for ChatGPT",
    "abstract": "Large language models (LLMs), such as ChatGPT, have demonstrated outstanding\nperformance in various fields, particularly in natural language understanding\nand generation tasks. In complex application scenarios, users tend to engage in\nmulti-turn conversations with ChatGPT to keep contextual information and obtain\ncomprehensive responses. However, human forgetting and model contextual\nforgetting remain prominent issues in multi-turn conversation scenarios, which\nchallenge the users' conversation comprehension and contextual continuity for\nChatGPT. To address these challenges, we propose an interactive conversation\nvisualization system called C5, which includes Global View, Topic View, and\nContext-associated Q\\&A View. The Global View uses the GitLog diagram metaphor\nto represent the conversation structure, presenting the trend of conversation\nevolution and supporting the exploration of locally salient features. The Topic\nView is designed to display all the question and answer nodes and their\nrelationships within a topic using the structure of a knowledge graph, thereby\ndisplay the relevance and evolution of conversations. The Context-associated\nQ\\&A View consists of three linked views, which allow users to explore\nindividual conversations deeply while providing specific contextual information\nwhen posing questions. The usefulness and effectiveness of C5 were evaluated\nthrough a case study and a user study.",
    "pdfLink": "https://arxiv.org/pdf/2308.05567.pdf"
  },
  {
    "id": "2308.05563",
    "title": "Recent Advancements In The Field Of Deepfake Detection",
    "abstract": "A deepfake is a photo or video of a person whose image has been digitally\naltered or partially replaced with an image of someone else. Deepfakes have the\npotential to cause a variety of problems and are often used maliciously. A\ncommon usage is altering videos of prominent political figures and celebrities.\nThese deepfakes can portray them making offensive, problematic, and/or untrue\nstatements. Current deepfakes can be very realistic, and when used in this way,\ncan spread panic and even influence elections and political opinions. There are\nmany deepfake detection strategies currently in use but finding the most\ncomprehensive and universal method is critical. So, in this survey we will\naddress the problems of malicious deepfake creation and the lack of universal\ndeepfake detection methods. Our objective is to survey and analyze a variety of\ncurrent methods and advances in the field of deepfake detection.",
    "pdfLink": "https://arxiv.org/pdf/2308.05563.pdf"
  },
  {
    "id": "2308.05522",
    "title": "Models Matter: The Impact of Single-Step Retrosynthesis on Synthesis Planning",
    "abstract": "Retrosynthesis consists of breaking down a chemical compound recursively\nstep-by-step into molecular precursors until a set of commercially available\nmolecules is found with the goal to provide a synthesis route. Its two primary\nresearch directions, single-step retrosynthesis prediction, which models the\nchemical reaction logic, and multi-step synthesis planning, which tries to find\nthe correct sequence of reactions, are inherently intertwined. Still, this\nconnection is not reflected in contemporary research. In this work, we combine\nthese two major research directions by applying multiple single-step\nretrosynthesis models within multi-step synthesis planning and analyzing their\nimpact using public and proprietary reaction data. We find a disconnection\nbetween high single-step performance and potential route-finding success,\nsuggesting that single-step models must be evaluated within synthesis planning\nin the future. Furthermore, we show that the commonly used single-step\nretrosynthesis benchmark dataset USPTO-50k is insufficient as this evaluation\ntask does not represent model performance and scalability on larger and more\ndiverse datasets. For multi-step synthesis planning, we show that the choice of\nthe single-step model can improve the overall success rate of synthesis\nplanning by up to +28% compared to the commonly used baseline model. Finally,\nwe show that each single-step model finds unique synthesis routes, and differs\nin aspects such as route-finding success, the number of found synthesis routes,\nand chemical validity, making the combination of single-step retrosynthesis\nprediction and multi-step synthesis planning a crucial aspect when developing\nfuture methods.",
    "pdfLink": "https://arxiv.org/pdf/2308.05522.pdf"
  },
  {
    "id": "2308.05501",
    "title": "More Than Meets the Eye: Analyzing Anesthesiologists' Visual Attention in the Operating Room Using Deep Learning Models",
    "abstract": "Patient's vital signs, which are displayed on monitors, make the\nanesthesiologist's visual attention (VA) a key component in the safe management\nof patients under general anesthesia; moreover, the distribution of said VA and\nthe ability to acquire specific cues throughout the anesthetic, may have a\ndirect impact on patient's outcome. Currently, most studies employ wearable\neye-tracking technologies to analyze anesthesiologists' visual patterns. Albeit\nbeing able to produce meticulous data, wearable devices are not a sustainable\nsolution for large-scale or long-term use for data collection in the operating\nroom (OR). Thus, by utilizing a novel eye-tracking method in the form of deep\nlearning models that process monitor-mounted webcams, we collected continuous\nbehavioral data and gained insight into the anesthesiologist's VA distribution\nwith minimal disturbance to their natural workflow. In this study, we collected\nOR video recordings using the proposed framework and compared different visual\nbehavioral patterns. We distinguished between baseline VA distribution during\nuneventful periods to patterns associated with active phases or during\ncritical, unanticipated incidents. In the future, such a platform may serve as\na crucial component of context-aware assistive technologies in the OR.",
    "pdfLink": "https://arxiv.org/pdf/2308.05501.pdf"
  },
  {
    "id": "2308.05496",
    "title": "Exploring XAI for the Arts: Explaining Latent Space in Generative Music",
    "abstract": "Explainable AI has the potential to support more interactive and fluid\nco-creative AI systems which can creatively collaborate with people. To do\nthis, creative AI models need to be amenable to debugging by offering\neXplainable AI (XAI) features which are inspectable, understandable, and\nmodifiable. However, currently there is very little XAI for the arts. In this\nwork, we demonstrate how a latent variable model for music generation can be\nmade more explainable; specifically we extend MeasureVAE which generates\nmeasures of music. We increase the explainability of the model by: i) using\nlatent space regularisation to force some specific dimensions of the latent\nspace to map to meaningful musical attributes, ii) providing a user interface\nfeedback loop to allow people to adjust dimensions of the latent space and\nobserve the results of these changes in real-time, iii) providing a\nvisualisation of the musical attributes in the latent space to help people\nunderstand and predict the effect of changes to latent space dimensions. We\nsuggest that in doing so we bridge the gap between the latent space and the\ngenerated musical outcomes in a meaningful way which makes the model and its\noutputs more explainable and more debuggable.",
    "pdfLink": "https://arxiv.org/pdf/2308.05496.pdf"
  },
  {
    "id": "2308.05411",
    "title": "Explainable AI applications in the Medical Domain: a systematic review",
    "abstract": "Artificial Intelligence in Medicine has made significant progress with\nemerging applications in medical imaging, patient care, and other areas. While\nthese applications have proven successful in retrospective studies, very few of\nthem were applied in practice.The field of Medical AI faces various challenges,\nin terms of building user trust, complying with regulations, using data\nethically.Explainable AI (XAI) aims to enable humans understand AI and trust\nits results. This paper presents a literature review on the recent developments\nof XAI solutions for medical decision support, based on a representative sample\nof 198 articles published in recent years. The systematic synthesis of the\nrelevant articles resulted in several findings. (1) model-agnostic XAI\ntechniques were mostly employed in these solutions, (2) deep learning models\nare utilized more than other types of machine learning models, (3)\nexplainability was applied to promote trust, but very few works reported the\nphysicians participation in the loop, (4) visual and interactive user interface\nis more useful in understanding the explanation and the recommendation of the\nsystem. More research is needed in collaboration between medical and AI\nexperts, that could guide the development of suitable frameworks for the\ndesign, implementation, and evaluation of XAI solutions in medicine.",
    "pdfLink": "https://arxiv.org/pdf/2308.05411.pdf"
  },
  {
    "id": "2308.05391",
    "title": "Enhancing Trust in LLM-Based AI Automation Agents: New Considerations and Future Challenges",
    "abstract": "Trust in AI agents has been extensively studied in the literature, resulting\nin significant advancements in our understanding of this field. However, the\nrapid advancements in Large Language Models (LLMs) and the emergence of\nLLM-based AI agent frameworks pose new challenges and opportunities for further\nresearch. In the field of process automation, a new generation of AI-based\nagents has emerged, enabling the execution of complex tasks. At the same time,\nthe process of building automation has become more accessible to business users\nvia user-friendly no-code tools and training mechanisms. This paper explores\nthese new challenges and opportunities, analyzes the main aspects of trust in\nAI agents discussed in existing literature, and identifies specific\nconsiderations and challenges relevant to this new generation of automation\nagents. We also evaluate how nascent products in this category address these\nconsiderations. Finally, we highlight several challenges that the research\ncommunity should address in this evolving landscape.",
    "pdfLink": "https://arxiv.org/pdf/2308.05391.pdf"
  },
  {
    "id": "2308.05385",
    "title": "Adaptive Taxonomy Learning and Historical Patterns Modelling for Patent Classification",
    "abstract": "Patent classification aims to assign multiple International Patent\nClassification (IPC) codes to a given patent. Recent methods for automatically\nclassifying patents mainly focus on analyzing the text descriptions of patents.\nHowever, apart from the texts, each patent is also associated with some\nassignees, and the knowledge of their applied patents is often valuable for\nclassification. Furthermore, the hierarchical taxonomy formulated by the IPC\nsystem provides important contextual information and enables models to leverage\nthe correlations between IPC codes for more accurate classification. However,\nexisting methods fail to incorporate the above aspects. In this paper, we\npropose an integrated framework that comprehensively considers the information\non patents for patent classification. To be specific, we first present an IPC\ncodes correlations learning module to derive their semantic representations via\nadaptively passing and aggregating messages within the same level and across\ndifferent levels along the hierarchical taxonomy. Moreover, we design a\nhistorical application patterns learning component to incorporate the\ncorresponding assignee's previous patents by a dual channel aggregation\nmechanism. Finally, we combine the contextual information of patent texts that\ncontains the semantics of IPC codes, and assignees' sequential preferences to\nmake predictions. Experiments on real-world datasets demonstrate the\nsuperiority of our approach over the existing methods. Besides, we present the\nmodel's ability to capture the temporal patterns of assignees and the semantic\ndependencies among IPC codes.",
    "pdfLink": "https://arxiv.org/pdf/2308.05385.pdf"
  },
  {
    "id": "2308.05374",
    "title": "Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models' Alignment",
    "abstract": "Ensuring alignment, which refers to making models behave in accordance with\nhuman intentions [1,2], has become a critical task before deploying large\nlanguage models (LLMs) in real-world applications. For instance, OpenAI devoted\nsix months to iteratively aligning GPT-4 before its release [3]. However, a\nmajor challenge faced by practitioners is the lack of clear guidance on\nevaluating whether LLM outputs align with social norms, values, and\nregulations. This obstacle hinders systematic iteration and deployment of LLMs.\nTo address this issue, this paper presents a comprehensive survey of key\ndimensions that are crucial to consider when assessing LLM trustworthiness. The\nsurvey covers seven major categories of LLM trustworthiness: reliability,\nsafety, fairness, resistance to misuse, explainability and reasoning, adherence\nto social norms, and robustness. Each major category is further divided into\nseveral sub-categories, resulting in a total of 29 sub-categories.\nAdditionally, a subset of 8 sub-categories is selected for further\ninvestigation, where corresponding measurement studies are designed and\nconducted on several widely-used LLMs. The measurement results indicate that,\nin general, more aligned models tend to perform better in terms of overall\ntrustworthiness. However, the effectiveness of alignment varies across the\ndifferent trustworthiness categories considered. This highlights the importance\nof conducting more fine-grained analyses, testing, and making continuous\nimprovements on LLM alignment. By shedding light on these key dimensions of LLM\ntrustworthiness, this paper aims to provide valuable insights and guidance to\npractitioners in the field. Understanding and addressing these concerns will be\ncrucial in achieving reliable and ethically sound deployment of LLMs in various\napplications.",
    "pdfLink": "https://arxiv.org/pdf/2308.05374.pdf"
  },
  {
    "id": "2308.05295",
    "title": "Multimodal Pretrained Models for Sequential Decision-Making: Synthesis, Verification, Grounding, and Perception",
    "abstract": "Recently developed pretrained models can encode rich world knowledge\nexpressed in multiple modalities, such as text and images. However, the outputs\nof these models cannot be integrated into algorithms to solve sequential\ndecision-making tasks. We develop an algorithm that utilizes the knowledge from\npretrained models to construct and verify controllers for sequential\ndecision-making tasks, and to ground these controllers to task environments\nthrough visual observations. In particular, the algorithm queries a pretrained\nmodel with a user-provided, text-based task description and uses the model's\noutput to construct an automaton-based controller that encodes the model's\ntask-relevant knowledge. It then verifies whether the knowledge encoded in the\ncontroller is consistent with other independently available knowledge, which\nmay include abstract information on the environment or user-provided\nspecifications. If this verification step discovers any inconsistency, the\nalgorithm automatically refines the controller to resolve the inconsistency.\nNext, the algorithm leverages the vision and language capabilities of\npretrained models to ground the controller to the task environment. It collects\nimage-based observations from the task environment and uses the pretrained\nmodel to link these observations to the text-based control logic encoded in the\ncontroller (e.g., actions and conditions that trigger the actions). We propose\na mechanism to ensure the controller satisfies the user-provided specification\neven when perceptual uncertainties are present. We demonstrate the algorithm's\nability to construct, verify, and ground automaton-based controllers through a\nsuite of real-world tasks, including daily life and robot manipulation tasks.",
    "pdfLink": "https://arxiv.org/pdf/2308.05295.pdf"
  },
  {
    "id": "2308.05260",
    "title": "AI4GCC -- Track 3: Consumption and the Challenges of Multi-Agent RL",
    "abstract": "The AI4GCC competition presents a bold step forward in the direction of\nintegrating machine learning with traditional economic policy analysis. Below,\nwe highlight two potential areas for improvement that could enhance the\ncompetition's ability to identify and evaluate proposed negotiation protocols.\nFirstly, we suggest the inclusion of an additional index that accounts for\nconsumption/utility as part of the evaluation criteria. Secondly, we recommend\nfurther investigation into the learning dynamics of agents in the simulator and\nthe game theoretic properties of outcomes from proposed negotiation protocols.\nWe hope that these suggestions can be of use for future iterations of the\ncompetition/simulation.",
    "pdfLink": "https://arxiv.org/pdf/2308.05260.pdf"
  },
  {
    "id": "2308.05201",
    "title": "\"Generate\" the Future of Work through AI: Empirical Evidence from Online Labor Markets",
    "abstract": "With the advent of general-purpose Generative AI, the interest in discerning\nits impact on the labor market escalates. In an attempt to bridge the extant\nempirical void, we interpret the launch of ChatGPT as an exogenous shock, and\nimplement a Difference-in-Differences (DID) approach to quantify its influence\non text-related jobs and freelancers within an online labor marketplace. Our\nresults reveal a significant decrease in transaction volume for gigs and\nfreelancers directly exposed to ChatGPT. Additionally, this decline is\nparticularly marked in units of relatively higher past transaction volume or\nlower quality standards. Yet, the negative effect is not universally\nexperienced among service providers. Subsequent analyses illustrate that\nfreelancers proficiently adapting to novel advancements and offering services\nthat augment AI technologies can yield substantial benefits amidst this\ntransformative period. Consequently, even though the advent of ChatGPT could\nconceivably substitute existing occupations, it also unfolds immense\nopportunities and carries the potential to reconfigure the future of work. This\nresearch contributes to the limited empirical repository exploring the profound\ninfluence of LLM-based generative AI on the labor market, furnishing invaluable\ninsights for workers, job intermediaries, and regulatory bodies navigating this\nevolving landscape.",
    "pdfLink": "https://arxiv.org/pdf/2308.05201.pdf"
  },
  {
    "id": "2308.05741",
    "title": "Neural Progressive Meshes",
    "abstract": "The recent proliferation of 3D content that can be consumed on hand-held\ndevices necessitates efficient tools for transmitting large geometric data,\ne.g., 3D meshes, over the Internet. Detailed high-resolution assets can pose a\nchallenge to storage as well as transmission bandwidth, and level-of-detail\ntechniques are often used to transmit an asset using an appropriate bandwidth\nbudget. It is especially desirable for these methods to transmit data\nprogressively, improving the quality of the geometry with more data. Our key\ninsight is that the geometric details of 3D meshes often exhibit similar local\npatterns even across different shapes, and thus can be effectively represented\nwith a shared learned generative space. We learn this space using a\nsubdivision-based encoder-decoder architecture trained in advance on a large\ncollection of surfaces. We further observe that additional residual features\ncan be transmitted progressively between intermediate levels of subdivision\nthat enable the client to control the tradeoff between bandwidth cost and\nquality of reconstruction, providing a neural progressive mesh representation.\nWe evaluate our method on a diverse set of complex 3D shapes and demonstrate\nthat it outperforms baselines in terms of compression ratio and reconstruction\nquality.",
    "pdfLink": "https://arxiv.org/pdf/2308.05741.pdf"
  },
  {
    "id": "2308.05734",
    "title": "AudioLDM 2: Learning Holistic Audio Generation with Self-supervised Pretraining",
    "abstract": "Although audio generation shares commonalities across different types of\naudio, such as speech, music, and sound effects, designing models for each type\nrequires careful consideration of specific objectives and biases that can\nsignificantly differ from those of other types. To bring us closer to a unified\nperspective of audio generation, this paper proposes a framework that utilizes\nthe same learning method for speech, music, and sound effect generation. Our\nframework introduces a general representation of audio, called language of\naudio (LOA). Any audio can be translated into LOA based on AudioMAE, a\nself-supervised pre-trained representation learning model. In the generation\nprocess, we translate any modalities into LOA by using a GPT-2 model, and we\nperform self-supervised audio generation learning with a latent diffusion model\nconditioned on LOA. The proposed framework naturally brings advantages such as\nin-context learning abilities and reusable self-supervised pretrained AudioMAE\nand latent diffusion models. Experiments on the major benchmarks of\ntext-to-audio, text-to-music, and text-to-speech demonstrate new\nstate-of-the-art or competitive performance to previous approaches. Our demo\nand code are available at this https URL.",
    "pdfLink": "https://arxiv.org/pdf/2308.05734.pdf"
  },
  {
    "id": "2308.05732",
    "title": "PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers",
    "abstract": "Time-dependent partial differential equations (PDEs) are ubiquitous in\nscience and engineering. Recently, mostly due to the high computational cost of\ntraditional solution techniques, deep neural network based surrogates have\ngained increased interest. The practical utility of such neural PDE solvers\nrelies on their ability to provide accurate, stable predictions over long time\nhorizons, which is a notoriously hard problem. In this work, we present a\nlarge-scale analysis of common temporal rollout strategies, identifying the\nneglect of non-dominant spatial frequency information, often associated with\nhigh frequencies in PDE solutions, as the primary pitfall limiting stable,\naccurate rollout performance. Based on these insights, we draw inspiration from\nrecent advances in diffusion models to introduce PDE-Refiner; a novel model\nclass that enables more accurate modeling of all frequency components via a\nmultistep refinement process. We validate PDE-Refiner on challenging benchmarks\nof complex fluid dynamics, demonstrating stable and accurate rollouts that\nconsistently outperform state-of-the-art models, including neural, numerical,\nand hybrid neural-numerical architectures. We further demonstrate that\nPDE-Refiner greatly enhances data efficiency, since the denoising objective\nimplicitly induces a novel form of spectral data augmentation. Finally,\nPDE-Refiner's connection to diffusion models enables an accurate and efficient\nassessment of the model's predictive uncertainty, allowing us to estimate when\nthe surrogate becomes inaccurate.",
    "pdfLink": "https://arxiv.org/pdf/2308.05732.pdf"
  },
  {
    "id": "2308.05731",
    "title": "Rethinking Integration of Prediction and Planning in Deep Learning-Based Automated Driving Systems: A Review",
    "abstract": "Automated driving has the potential to revolutionize personal, public, and\nfreight mobility. Besides the enormous challenge of perception, i.e. accurately\nperceiving the environment using available sensor data, automated driving\ncomprises planning a safe, comfortable, and efficient motion trajectory. To\npromote safety and progress, many works rely on modules that predict the future\nmotion of surrounding traffic. Modular automated driving systems commonly\nhandle prediction and planning as sequential separate tasks. While this\naccounts for the influence of surrounding traffic on the ego-vehicle, it fails\nto anticipate the reactions of traffic participants to the ego-vehicle's\nbehavior. Recent works suggest that integrating prediction and planning in an\ninterdependent joint step is necessary to achieve safe, efficient, and\ncomfortable driving. While various models implement such integrated systems, a\ncomprehensive overview and theoretical understanding of different principles\nare lacking. We systematically review state-of-the-art deep learning-based\nprediction, planning, and integrated prediction and planning models. Different\nfacets of the integration ranging from model architecture and model design to\nbehavioral aspects are considered and related to each other. Moreover, we\ndiscuss the implications, strengths, and limitations of different integration\nmethods. By pointing out research gaps, describing relevant future challenges,\nand highlighting trends in the research field, we identify promising directions\nfor future research.",
    "pdfLink": "https://arxiv.org/pdf/2308.05731.pdf"
  },
  {
    "id": "2308.05697",
    "title": "SSLRec: A Self-Supervised Learning Library for Recommendation",
    "abstract": "Self-supervised learning (SSL) has gained significant interest in recent\nyears as a solution to address the challenges posed by sparse and noisy data in\nrecommender systems. Despite the growing number of SSL algorithms designed to\nprovide state-of-the-art performance in various recommendation scenarios (e.g.,\ngraph collaborative filtering, sequential recommendation, social\nrecommendation, KG-enhanced recommendation), there is still a lack of unified\nframeworks that integrate recommendation algorithms across different domains.\nSuch a framework could serve as the cornerstone for self-supervised\nrecommendation algorithms, unifying the validation of existing methods and\ndriving the design of new ones. To address this gap, we introduce SSLRec, a\nnovel benchmark platform that provides a standardized, flexible, and\ncomprehensive framework for evaluating various SSL-enhanced recommenders. The\nSSLRec library features a modular architecture that allows users to easily\nevaluate state-of-the-art models and a complete set of data augmentation and\nself-supervised toolkits to help create SSL recommendation models with specific\nneeds. Furthermore, SSLRec simplifies the process of training and evaluating\ndifferent recommendation models with consistent and fair settings. Our SSLRec\nplatform covers a comprehensive set of state-of-the-art SSL-enhanced\nrecommendation models across different scenarios, enabling researchers to\nevaluate these cutting-edge models and drive further innovation in the field.\nOur implemented SSLRec framework is available at the source code repository\nthis https URL.",
    "pdfLink": "https://arxiv.org/pdf/2308.05697.pdf"
  },
  {
    "id": "2308.05681",
    "title": "Hard No-Box Adversarial Attack on Skeleton-Based Human Action Recognition with Skeleton-Motion-Informed Gradient",
    "abstract": "Recently, methods for skeleton-based human activity recognition have been\nshown to be vulnerable to adversarial attacks. However, these attack methods\nrequire either the full knowledge of the victim (i.e. white-box attacks),\naccess to training data (i.e. transfer-based attacks) or frequent model queries\n(i.e. black-box attacks). All their requirements are highly restrictive,\nraising the question of how detrimental the vulnerability is. In this paper, we\nshow that the vulnerability indeed exists. To this end, we consider a new\nattack task: the attacker has no access to the victim model or the training\ndata or labels, where we coin the term hard no-box attack. Specifically, we\nfirst learn a motion manifold where we define an adversarial loss to compute a\nnew gradient for the attack, named skeleton-motion-informed (SMI) gradient. Our\ngradient contains information of the motion dynamics, which is different from\nexisting gradient-based attack methods that compute the loss gradient assuming\neach dimension in the data is independent. The SMI gradient can augment many\ngradient-based attack methods, leading to a new family of no-box attack\nmethods. Extensive evaluation and comparison show that our method imposes a\nreal threat to existing classifiers. They also show that the SMI gradient\nimproves the transferability and imperceptibility of adversarial samples in\nboth no-box and transfer-based black-box settings.",
    "pdfLink": "https://arxiv.org/pdf/2308.05681.pdf"
  },
  {
    "id": "2308.05619",
    "title": "Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance",
    "abstract": "As data shift or new data become available, updating clinical machine\nlearning models may be necessary to maintain or improve performance over time.\nHowever, updating a model can introduce compatibility issues when the behavior\nof the updated model does not align with user expectations, resulting in poor\nuser-model team performance. Existing compatibility measures depend on model\ndecision thresholds, limiting their applicability in settings where models are\nused to generate rankings based on estimated risk. To address this limitation,\nwe propose a novel rank-based compatibility measure, CRC^R, and a new loss\nfunction that aims to optimize discriminative performance while encouraging\ngood compatibility. Applied to a case study in mortality risk stratification\nleveraging data from MIMIC, our approach yields more compatible models while\nmaintaining discriminative performance compared to existing model selection\ntechniques, with an increase in CRC^R of 0.0190.019 (95%95\\% confidence interval:\n0.0050.005, 0.0350.035). This work provides new tools to analyze and update risk\nstratification models used in clinical care.",
    "pdfLink": "https://arxiv.org/pdf/2308.05619.pdf"
  },
  {
    "id": "2308.05612",
    "title": "A Smart Robotic System for Industrial Plant Supervision",
    "abstract": "In today's chemical production plants, human field operators perform frequent\nchecks on the plant's integrity to guarantee high safety standards, and thus\nare possibly the first to encounter dangerous operating conditions. To\nalleviate their tasks of failure detection and monitoring by audio, visual, and\nolfactory perceptions, we present a robotic system that consists of an\nautonomously navigating robot integrated with various sensors and data\nprocessing. We aim to resemble the human sensing and interpretation\ncapabilities of sight, smell, and hearing, for providing automated inspection.\nWe evaluate our system extensively at a wastewater facility in full working\nconditions. Our results demonstrate that the system is able to robustly\nnavigate a plant and to provide useful information about critical operating\nconditions.",
    "pdfLink": "https://arxiv.org/pdf/2308.05612.pdf"
  },
  {
    "id": "2308.05601",
    "title": "Multi-graph Spatio-temporal Graph Convolutional Network for Traffic Flow Prediction",
    "abstract": "Inter-city highway transportation is significant for urban life. As one of\nthe key functions in intelligent transportation system (ITS), traffic\nevaluation always plays significant role nowadays, and daily traffic flow\nprediction still faces challenges at network-wide toll stations. On the one\nhand, the data imbalance in practice among various locations deteriorates the\nperformance of prediction. On the other hand, complex correlative\nspatio-temporal factors cannot be comprehensively employed in long-term\nduration. In this paper, a prediction method is proposed for daily traffic flow\nin highway domain through spatio-temporal deep learning. In our method, data\nnormalization strategy is used to deal with data imbalance, due to long-tail\ndistribution of traffic flow at network-wide toll stations. And then, based on\ngraph convolutional network, we construct networks in distinct semantics to\ncapture spatio-temporal features. Beside that, meteorology and calendar\nfeatures are used by our model in the full connection stage to extra external\ncharacteristics of traffic flow. By extensive experiments and case studies in\none Chinese provincial highway, our method shows clear improvement in\npredictive accuracy than baselines and practical benefits in business.",
    "pdfLink": "https://arxiv.org/pdf/2308.05601.pdf"
  },
  {
    "id": "2308.05548",
    "title": "Learning (With) Distributed Optimization",
    "abstract": "This paper provides an overview of the historical progression of distributed\noptimization techniques, tracing their development from early duality-based\nmethods pioneered by Dantzig, Wolfe, and Benders in the 1960s to the emergence\nof the Augmented Lagrangian Alternating Direction Inexact Newton (ALADIN)\nalgorithm. The initial focus on Lagrangian relaxation for convex problems and\ndecomposition strategies led to the refinement of methods like the Alternating\nDirection Method of Multipliers (ADMM). The resurgence of interest in\ndistributed optimization in the late 2000s, particularly in machine learning\nand imaging, demonstrated ADMM's practical efficacy and its unifying potential.\nThis overview also highlights the emergence of the proximal center method and\nits applications in diverse domains. Furthermore, the paper underscores the\ndistinctive features of ALADIN, which offers convergence guarantees for\nnon-convex scenarios without introducing auxiliary variables, differentiating\nit from traditional augmentation techniques. In essence, this work encapsulates\nthe historical trajectory of distributed optimization and underscores the\npromising prospects of ALADIN in addressing non-convex optimization challenges.",
    "pdfLink": "https://arxiv.org/pdf/2308.05548.pdf"
  },
  {
    "id": "2308.05547",
    "title": "Enhancing AUV Autonomy With Model Predictive Path Integral Control",
    "abstract": "Autonomous underwater vehicles (AUVs) play a crucial role in surveying marine\nenvironments, carrying out underwater inspection tasks, and ocean exploration.\nHowever, in order to ensure that the AUV is able to carry out its mission\nsuccessfully, a control system capable of adapting to changing environmental\nconditions is required. Furthermore, to ensure the robotic platform's safe\noperation, the onboard controller should be able to operate under certain\nconstraints. In this work, we investigate the feasibility of Model Predictive\nPath Integral Control (MPPI) for the control of an AUV. We utilise a non-linear\nmodel of the AUV to propagate the samples of the MPPI, which allow us to\ncompute the control action in real time. We provide a detailed evaluation of\nthe effect of the main hyperparameters on the performance of the MPPI\ncontroller. Furthermore, we compared the performance of the proposed method\nwith a classical PID and Cascade PID approach, demonstrating the superiority of\nour proposed controller. Finally, we present results where environmental\nconstraints are added and show how MPPI can handle them by simply incorporating\nthose constraints in the cost function.",
    "pdfLink": "https://arxiv.org/pdf/2308.05547.pdf"
  },
  {
    "id": "2308.05515",
    "title": "Mono-hydra: Real-time 3D scene graph construction from monocular camera input with IMU",
    "abstract": "The ability of robots to autonomously navigate through 3D environments\ndepends on their comprehension of spatial concepts, ranging from low-level\ngeometry to high-level semantics, such as objects, places, and buildings. To\nenable such comprehension, 3D scene graphs have emerged as a robust tool for\nrepresenting the environment as a layered graph of concepts and their\nrelationships. However, building these representations using monocular vision\nsystems in real-time remains a difficult task that has not been explored in\ndepth. This paper puts forth a real-time spatial perception system Mono-Hydra,\ncombining a monocular camera and an IMU sensor setup, focusing on indoor\nscenarios. However, the proposed approach is adaptable to outdoor applications,\noffering flexibility in its potential uses. The system employs a suite of deep\nlearning algorithms to derive depth and semantics. It uses a robocentric\nvisual-inertial odometry (VIO) algorithm based on square-root information,\nthereby ensuring consistent visual odometry with an IMU and a monocular camera.\nThis system achieves sub-20 cm error in real-time processing at 15 fps,\nenabling real-time 3D scene graph construction using a laptop GPU (NVIDIA\n3080). This enhances decision-making efficiency and effectiveness in simple\ncamera setups, augmenting robotic system agility. We make Mono-Hydra publicly\navailable at: this https URL",
    "pdfLink": "https://arxiv.org/pdf/2308.05515.pdf"
  },
  {
    "id": "2308.05508",
    "title": "Multi-domain Recommendation with Embedding Disentangling and Domain Alignment",
    "abstract": "Multi-domain recommendation (MDR) aims to provide recommendations for\ndifferent domains (e.g., types of products) with overlapping users/items and is\ncommon for platforms such as Amazon, Facebook, and LinkedIn that host multiple\nservices. Existing MDR models face two challenges: First, it is difficult to\ndisentangle knowledge that generalizes across domains (e.g., a user likes cheap\nitems) and knowledge specific to a single domain (e.g., a user likes blue\nclothing but not blue cars). Second, they have limited ability to transfer\nknowledge across domains with small overlaps. We propose a new MDR method named\nEDDA with two key components, i.e., embedding disentangling recommender and\ndomain alignment, to tackle the two challenges respectively. In particular, the\nembedding disentangling recommender separates both the model and embedding for\nthe inter-domain part and the intra-domain part, while most existing MDR\nmethods only focus on model-level disentangling. The domain alignment leverages\nrandom walks from graph processing to identify similar user/item pairs from\ndifferent domains and encourages similar user/item pairs to have similar\nembeddings, enhancing knowledge transfer. We compare EDDA with 12\nstate-of-the-art baselines on 3 real datasets. The results show that EDDA\nconsistently outperforms the baselines on all datasets and domains. All\ndatasets and codes are available at this https URL.",
    "pdfLink": "https://arxiv.org/pdf/2308.05508.pdf"
  },
  {
    "id": "2308.05503",
    "title": "EFX Allocations Exist for Binary Valuations",
    "abstract": "We study the fair division problem and the existence of allocations\nsatisfying the fairness criterion envy-freeness up to any item (EFX). The\nexistence of EFX allocations is a major open problem in the fair division\nliterature. We consider binary valuations where the marginal gain of the value\nby receiving an extra item is either 00 or 11. Babaioff et al. [2021] proved\nthat EFX allocations always exist for binary and submodular valuations. In this\npaper, by using completely different techniques, we extend this existence\nresult to general binary valuations that are not necessarily submodular, and we\npresent a polynomial time algorithm for computing an EFX allocation.",
    "pdfLink": "https://arxiv.org/pdf/2308.05503.pdf"
  },
  {
    "id": "2308.05502",
    "title": "Bringing order into the realm of Transformer-based language models for artificial intelligence and law",
    "abstract": "Transformer-based language models (TLMs) have widely been recognized to be a\ncutting-edge technology for the successful development of deep-learning-based\nsolutions to problems and applications that require natural language processing\nand understanding. Like for other textual domains, TLMs have indeed pushed the\nstate-of-the-art of AI approaches for many tasks of interest in the legal\ndomain. Despite the first Transformer model being proposed about six years ago,\nthere has been a rapid progress of this technology at an unprecedented rate,\nwhereby BERT and related models represent a major reference, also in the legal\ndomain. This article provides the first systematic overview of TLM-based\nmethods for AI-driven problems and tasks in the legal sphere. A major goal is\nto highlight research advances in this field so as to understand, on the one\nhand, how the Transformers have contributed to the success of AI in supporting\nlegal processes, and on the other hand, what are the current limitations and\nopportunities for further research development.",
    "pdfLink": "https://arxiv.org/pdf/2308.05502.pdf"
  },
  {
    "id": "2308.05481",
    "title": "LLM As DBA",
    "abstract": "Database administrators (DBAs) play a crucial role in managing, maintaining\nand optimizing a database system to ensure data availability, performance, and\nreliability. However, it is hard and tedious for DBAs to manage a large number\nof database instances (e.g., millions of instances on the cloud databases).\nRecently large language models (LLMs) have shown great potential to understand\nvaluable documents and accordingly generate reasonable answers. Thus, we\npropose D-Bot, a LLM-based database administrator that can continuously acquire\ndatabase maintenance experience from textual sources, and provide reasonable,\nwell-founded, in-time diagnosis and optimization advice for target databases.\nThis paper presents a revolutionary LLM-centric framework for database\nmaintenance, including (i) database maintenance knowledge detection from\ndocuments and tools, (ii) tree of thought reasoning for root cause analysis,\nand (iii) collaborative diagnosis among multiple LLMs. Our preliminary\nexperimental results that D-Bot can efficiently and effectively diagnose the\nroot causes and our code is available at\nthis http URL.",
    "pdfLink": "https://arxiv.org/pdf/2308.05481.pdf"
  },
  {
    "id": "2308.05478",
    "title": "Reviewing 3D Object Detectors in the Context of High-Resolution 3+1D Radar",
    "abstract": "Recent developments and the beginning market introduction of high-resolution\nimaging 4D (3+1D) radar sensors have initialized deep learning-based radar\nperception research. We investigate deep learning-based models operating on\nradar point clouds for 3D object detection. 3D object detection on lidar point\ncloud data is a mature area of 3D vision. Many different architectures have\nbeen proposed, each with strengths and weaknesses. Due to similarities between\n3D lidar point clouds and 3+1D radar point clouds, those existing 3D object\ndetectors are a natural basis to start deep learning-based 3D object detection\non radar data. Thus, the first step is to analyze the detection performance of\nthe existing models on the new data modality and evaluate them in depth. In\norder to apply existing 3D point cloud object detectors developed for lidar\npoint clouds to the radar domain, they need to be adapted first. While some\ndetectors, such as PointPillars, have already been adapted to be applicable to\nradar data, we have adapted others, e.g., Voxel R-CNN, SECOND, PointRCNN, and\nPV-RCNN. To this end, we conduct a cross-model validation (evaluating a set of\nmodels on one particular data set) as well as a cross-data set validation\n(evaluating all models in the model set on several data sets). The\nhigh-resolution radar data used are the View-of-Delft and Astyx data sets.\nFinally, we evaluate several adaptations of the models and their training\nprocedures. We also discuss major factors influencing the detection performance\non radar data and propose possible solutions indicating potential future\nresearch avenues.",
    "pdfLink": "https://arxiv.org/pdf/2308.05478.pdf"
  },
  {
    "id": "2308.05407",
    "title": "A Comparative Assessment of Multi-view fusion learning for Crop Classification",
    "abstract": "With a rapidly increasing amount and diversity of remote sensing (RS) data\nsources, there is a strong need for multi-view learning modeling. This is a\ncomplex task when considering the differences in resolution, magnitude, and\nnoise of RS data. The typical approach for merging multiple RS sources has been\ninput-level fusion, but other - more advanced - fusion strategies may\noutperform this traditional approach. This work assesses different fusion\nstrategies for crop classification in the CropHarvest dataset. The fusion\nmethods proposed in this work outperform models based on individual views and\nprevious fusion methods. We do not find one single fusion method that\nconsistently outperforms all other approaches. Instead, we present a comparison\nof multi-view fusion methods for three different datasets and show that,\ndepending on the test region, different methods obtain the best performance.\nDespite this, we suggest a preliminary criterion for the selection of fusion\nmethods.",
    "pdfLink": "https://arxiv.org/pdf/2308.05407.pdf"
  },
  {
    "id": "2308.05379",
    "title": "Beyond Semantics: Learning a Behavior Augmented Relevance Model with Self-supervised Learning",
    "abstract": "Relevance modeling aims to locate desirable items for corresponding queries,\nwhich is crucial for search engines to ensure user experience. Although most\nconventional approaches address this problem by assessing the semantic\nsimilarity between the query and item, pure semantic matching is not\neverything. In reality, auxiliary query-item interactions extracted from user\nhistorical behavior data of the search log could provide hints to reveal users'\nsearch intents further. Drawing inspiration from this, we devise a novel\nBehavior Augmented Relevance Learning model for Alipay Search (BARL-ASe) that\nleverages neighbor queries of target item and neighbor items of target query to\ncomplement target query-item semantic matching. Specifically, our model builds\nmulti-level co-attention for distilling coarse-grained and fine-grained\nsemantic representations from both neighbor and target views. The model\nsubsequently employs neighbor-target self-supervised learning to improve the\naccuracy and robustness of BARL-ASe by strengthening representation and logit\nlearning. Furthermore, we discuss how to deal with the long-tail query-item\nmatching of the mini apps search scenario of Alipay practically. Experiments on\nreal-world industry data and online A/B testing demonstrate our proposal\nachieves promising performance with low latency.",
    "pdfLink": "https://arxiv.org/pdf/2308.05379.pdf"
  },
  {
    "id": "2308.05364",
    "title": "Machine Learning aided Computer Architecture Design for CNN Inferencing Systems",
    "abstract": "Efficient and timely calculations of Machine Learning (ML) algorithms are\nessential for emerging technologies like autonomous driving, the Internet of\nThings (IoT), and edge computing. One of the primary ML algorithms used in such\nsystems is Convolutional Neural Networks (CNNs), which demand high\ncomputational resources. This requirement has led to the use of ML accelerators\nlike GPGPUs to meet design constraints. However, selecting the most suitable\naccelerator involves Design Space Exploration (DSE), a process that is usually\ntime-consuming and requires significant manual effort. Our work presents\napproaches to expedite the DSE process by identifying the most appropriate\nGPGPU for CNN inferencing systems. We have developed a quick and precise\ntechnique for forecasting the power and performance of CNNs during inference,\nwith a MAPE of 5.03% and 5.94%, respectively. Our approach empowers computer\narchitects to estimate power and performance in the early stages of\ndevelopment, reducing the necessity for numerous prototypes. This saves time\nand money while also improving the time-to-market period.",
    "pdfLink": "https://arxiv.org/pdf/2308.05364.pdf"
  },
  {
    "id": "2308.05342",
    "title": "Metacognitive Prompting Improves Understanding in Large Language Models",
    "abstract": "In Large Language Models (LLMs), there have been consistent advancements in\ntask-specific performance, largely influenced by effective prompt design. While\nrecent research on prompting has enhanced the reasoning capabilities of LLMs, a\ngap remains in further improving their understanding abilities. In this study,\nwe introduce metacognitive prompting (MP), a strategy inspired by human\nintrospective reasoning processes. Using MP, LLMs undergo a systematic series\nof structured, self-aware evaluations, drawing on both their vast inherent\nknowledge and new insights. Our experiments involve five prevalent LLMs:\nLlama2, Vicuna, PaLM, GPT-3.5, and GPT-4, all of which span various general\nnatural language understanding (NLU) tasks from the GLUE and SuperGLUE\nbenchmarks. Results indicate that, although GPT-4 consistently excels in most\ntasks, PaLM, when equipped with MP, approaches its performance level.\nFurthermore, across models and datasets, MP consistently outperforms existing\nprompting methods, including standard and chain-of-thought prompting. This\nstudy underscores the potential to amplify the understanding abilities of LLMs\nand highlights the benefits of mirroring human introspective reasoning in NLU\ntasks.",
    "pdfLink": "https://arxiv.org/pdf/2308.05342.pdf"
  },
  {
    "id": "2308.05341",
    "title": "Classification of Human- and AI-Generated Texts: Investigating Features for ChatGPT",
    "abstract": "Recently, generative AIs like ChatGPT have become available to the wide\npublic. These tools can for instance be used by students to generate essays or\nwhole theses. But how does a teacher know whether a text is written by a\nstudent or an AI? In our work, we explore traditional and new features to (1)\ndetect text generated by AI from scratch and (2) text rephrased by AI. Since we\nfound that classification is more difficult when the AI has been instructed to\ncreate the text in a way that a human would not recognize that it was generated\nby an AI, we also investigate this more advanced case. For our experiments, we\nproduced a new text corpus covering 10 school topics. Our best systems to\nclassify basic and advanced human-generated/AI-generated texts have F1-scores\nof over 96%. Our best systems for classifying basic and advanced\nhuman-generated/AI-rephrased texts have F1-scores of more than 78%. The systems\nuse a combination of perplexity, semantic, list lookup, error-based,\nreadability, AI feedback, and text vector features. Our results show that the\nnew features substantially help to improve the performance of many classifiers.\nOur best basic text rephrasing detection system even outperforms GPTZero by\n183.8% relative in F1-score.",
    "pdfLink": "https://arxiv.org/pdf/2308.05341.pdf"
  },
  {
    "id": "2308.05320",
    "title": "Adv-Inpainting: Generating Natural and Transferable Adversarial Patch via Attention-guided Feature Fusion",
    "abstract": "The rudimentary adversarial attacks utilize additive noise to attack facial\nrecognition (FR) models. However, because manipulating the total face is\nimpractical in the physical setting, most real-world FR attacks are based on\nadversarial patches, which limit perturbations to a small area. Previous\nadversarial patch attacks often resulted in unnatural patterns and clear\nboundaries that were easily noticeable. In this paper, we argue that generating\nadversarial patches with plausible content can result in stronger\ntransferability than using additive noise or directly sampling from the latent\nspace. To generate natural-looking and highly transferable adversarial patches,\nwe propose an innovative two-stage coarse-to-fine attack framework called\nAdv-Inpainting. In the first stage, we propose an attention-guided StyleGAN\n(Att-StyleGAN) that adaptively combines texture and identity features based on\nthe attention map to generate high-transferable and natural adversarial\npatches. In the second stage, we design a refinement network with a new\nboundary variance loss to further improve the coherence between the patch and\nits surrounding area. Experiment results demonstrate that Adv-Inpainting is\nstealthy and can produce adversarial patches with stronger transferability and\nimproved visual quality than previous adversarial patch attacks.",
    "pdfLink": "https://arxiv.org/pdf/2308.05320.pdf"
  },
  {
    "id": "2308.05309",
    "title": "Homophily-enhanced Structure Learning for Graph Clustering",
    "abstract": "Graph clustering is a fundamental task in graph analysis, and recent advances\nin utilizing graph neural networks (GNNs) have shown impressive results.\nDespite the success of existing GNN-based graph clustering methods, they often\noverlook the quality of graph structure, which is inherent in real-world graphs\ndue to their sparse and multifarious nature, leading to subpar performance.\nGraph structure learning allows refining the input graph by adding missing\nlinks and removing spurious connections. However, previous endeavors in graph\nstructure learning have predominantly centered around supervised settings, and\ncannot be directly applied to our specific clustering tasks due to the absence\nof ground-truth labels. To bridge the gap, we propose a novel method called\n\\textbf{ho}mophily-enhanced structure \\textbf{le}arning for graph clustering\n(HoLe). Our motivation stems from the observation that subtly enhancing the\ndegree of homophily within the graph structure can significantly improve GNNs\nand clustering outcomes. To realize this objective, we develop two\nclustering-oriented structure learning modules, i.e., hierarchical correlation\nestimation and cluster-aware sparsification. The former module enables a more\naccurate estimation of pairwise node relationships by leveraging guidance from\nlatent and clustering spaces, while the latter one generates a sparsified\nstructure based on the similarity matrix and clustering assignments.\nAdditionally, we devise a joint optimization approach alternating between\ntraining the homophily-enhanced structure learning and GNN-based clustering,\nthereby enforcing their reciprocal effects. Extensive experiments on seven\nbenchmark datasets of various types and scales, across a range of clustering\nmetrics, demonstrate the superiority of HoLe against state-of-the-art\nbaselines.",
    "pdfLink": "https://arxiv.org/pdf/2308.05309.pdf"
  },
  {
    "id": "2308.05298",
    "title": "Double-chain Constraints for 3D Human Pose Estimation in Images and Videos",
    "abstract": "Reconstructing 3D poses from 2D poses lacking depth information is\nparticularly challenging due to the complexity and diversity of human motion.\nThe key is to effectively model the spatial constraints between joints to\nleverage their inherent dependencies. Thus, we propose a novel model, called\nDouble-chain Graph Convolutional Transformer (DC-GCT), to constrain the pose\nthrough a double-chain design consisting of local-to-global and global-to-local\nchains to obtain a complex representation more suitable for the current human\npose. Specifically, we combine the advantages of GCN and Transformer and design\na Local Constraint Module (LCM) based on GCN and a Global Constraint Module\n(GCM) based on self-attention mechanism as well as a Feature Interaction Module\n(FIM). The proposed method fully captures the multi-level dependencies between\nhuman body joints to optimize the modeling capability of the model. Moreover,\nwe propose a method to use temporal information into the single-frame model by\nguiding the video sequence embedding through the joint embedding of the target\nframe, with negligible increase in computational cost. Experimental results\ndemonstrate that DC-GCT achieves state-of-the-art performance on two\nchallenging datasets (Human3.6M and MPI-INF-3DHP). Notably, our model achieves\nstate-of-the-art performance on all action categories in the Human3.6M dataset\nusing detected 2D poses from CPN, and our code is available at:\nthis https URL.",
    "pdfLink": "https://arxiv.org/pdf/2308.05298.pdf"
  },
  {
    "id": "2308.05275",
    "title": "Cross-heterogeneity Graph Few-shot Learning",
    "abstract": "In recent years, heterogeneous graph few-shot learning has been proposed to\naddress the label sparsity issue in heterogeneous graphs (HGs), which contain\nvarious types of nodes and edges. The existing methods have achieved good\nperformance by transferring generalized knowledge extracted from rich-labeled\nclasses in source HG(s) to few-labeled classes in a target HG. However, these\nmethods only consider the single-heterogeneity scenario where the source and\ntarget HGs share a fixed set of node/edge types, ignoring the more general\nscenario of cross-heterogeneity, where each HG can have a different and\nnon-fixed set of node/edge types. To this end, we focus on the unexplored\ncross-heterogeneity scenario and propose a novel model for Cross-heterogeneity\nGraph Few-shot Learning, namely CGFL. In CGFL, we first extract meta-patterns\nto capture heterogeneous information and propose a multi-view heterogeneous\ngraph neural network (MHGN) to learn meta-patterns across HGs. Then, we propose\na score module to measure the informativeness of labeled samples and determine\nthe transferability of each source HG. Finally, by integrating MHGN and the\nscore module into a meta-learning mechanism, CGFL can effectively transfer\ngeneralized knowledge to predict new classes with few-labeled data. Extensive\nexperiments on four real-world datasets have demonstrated the superior\nperformance of CGFL over the state-of-the-art methods.",
    "pdfLink": "https://arxiv.org/pdf/2308.05275.pdf"
  },
  {
    "id": "2308.05242",
    "title": "Vector quantization loss analysis in VQGANs: a single-GPU ablation study for image-to-image synthesis",
    "abstract": "This study performs an ablation analysis of Vector Quantized Generative\nAdversarial Networks (VQGANs), concentrating on image-to-image synthesis\nutilizing a single NVIDIA A100 GPU. The current work explores the nuanced\neffects of varying critical parameters including the number of epochs, image\ncount, and attributes of codebook vectors and latent dimensions, specifically\nwithin the constraint of limited resources. Notably, our focus is pinpointed on\nthe vector quantization loss, keeping other hyperparameters and loss components\n(GAN loss) fixed. This was done to delve into a deeper understanding of the\ndiscrete latent space, and to explore how varying its size affects the\nreconstruction. Though, our results do not surpass the existing benchmarks,\nhowever, our findings shed significant light on VQGAN's behaviour for a smaller\ndataset, particularly concerning artifacts, codebook size optimization, and\ncomparative analysis with Principal Component Analysis (PCA). The study also\nuncovers the promising direction by introducing 2D positional encodings,\nrevealing a marked reduction in artifacts and insights into balancing clarity\nand overfitting.",
    "pdfLink": "https://arxiv.org/pdf/2308.05242.pdf"
  },
  {
    "id": "2308.05234",
    "title": "Leveraging the Edge and Cloud for V2X-Based Real-Time Object Detection in Autonomous Driving",
    "abstract": "Environmental perception is a key element of autonomous driving because the\ninformation received from the perception module influences core driving\ndecisions. An outstanding challenge in real-time perception for autonomous\ndriving lies in finding the best trade-off between detection quality and\nlatency. Major constraints on both computation and power have to be taken into\naccount for real-time perception in autonomous vehicles. Larger object\ndetection models tend to produce the best results, but are also slower at\nruntime. Since the most accurate detectors cannot run in real-time locally, we\ninvestigate the possibility of offloading computation to edge and cloud\nplatforms, which are less resource-constrained. We create a synthetic dataset\nto train object detection models and evaluate different offloading strategies.\nUsing real hardware and network simulations, we compare different trade-offs\nbetween prediction quality and end-to-end delay. Since sending raw frames over\nthe network implies additional transmission delays, we also explore the use of\nJPEG and H.265 compression at varying qualities and measure their impact on\nprediction metrics. We show that models with adequate compression can be run in\nreal-time on the cloud while outperforming local detection performance.",
    "pdfLink": "https://arxiv.org/pdf/2308.05234.pdf"
  },
  {
    "id": "2308.05221",
    "title": "Alexa, play with robot: Introducing the First Alexa Prize SimBot Challenge on Embodied AI",
    "abstract": "The Alexa Prize program has empowered numerous university students to\nexplore, experiment, and showcase their talents in building conversational\nagents through challenges like the SocialBot Grand Challenge and the TaskBot\nChallenge. As conversational agents increasingly appear in multimodal and\nembodied contexts, it is important to explore the affordances of conversational\ninteraction augmented with computer vision and physical embodiment. This paper\ndescribes the SimBot Challenge, a new challenge in which university teams\ncompete to build robot assistants that complete tasks in a simulated physical\nenvironment. This paper provides an overview of the SimBot Challenge, which\nincluded both online and offline challenge phases. We describe the\ninfrastructure and support provided to the teams including Alexa Arena, the\nsimulated environment, and the ML toolkit provided to teams to accelerate their\nbuilding of vision and language models. We summarize the approaches the\nparticipating teams took to overcome research challenges and extract key\nlessons learned. Finally, we provide analysis of the performance of the\ncompeting SimBots during the competition.",
    "pdfLink": "https://arxiv.org/pdf/2308.05221.pdf"
  },
  {
    "id": "2308.05189",
    "title": "Hierarchical Representations for Spatio-Temporal Visual Attention Modeling and Understanding",
    "abstract": "This PhD. Thesis concerns the study and development of hierarchical\nrepresentations for spatio-temporal visual attention modeling and understanding\nin video sequences. More specifically, we propose two computational models for\nvisual attention. First, we present a generative probabilistic model for\ncontext-aware visual attention modeling and understanding. Secondly, we develop\na deep network architecture for visual attention modeling, which first\nestimates top-down spatio-temporal visual attention, and ultimately serves for\nmodeling attention in the temporal domain.",
    "pdfLink": "https://arxiv.org/pdf/2308.05189.pdf"
  },
  {
    "id": "2308.05184",
    "title": "PromptPaint: Steering Text-to-Image Generation Through Paint Medium-like Interactions",
    "abstract": "While diffusion-based text-to-image (T2I) models provide a simple and\npowerful way to generate images, guiding this generation remains a challenge.\nFor concepts that are difficult to describe through language, users may\nstruggle to create prompts. Moreover, many of these models are built as\nend-to-end systems, lacking support for iterative shaping of the image. In\nresponse, we introduce PromptPaint, which combines T2I generation with\ninteractions that model how we use colored paints. PromptPaint allows users to\ngo beyond language to mix prompts that express challenging concepts. Just as we\niteratively tune colors through layered placements of paint on a physical\ncanvas, PromptPaint similarly allows users to apply different prompts to\ndifferent canvas areas and times of the generative process. Through a set of\nstudies, we characterize different approaches for mixing prompts, design\ntrade-offs, and socio-technical challenges for generative models. With\nPromptPaint we provide insight into future steerable generative tools.",
    "pdfLink": "https://arxiv.org/pdf/2308.05184.pdf"
  },
  {
    "id": "2308.05176",
    "title": "Comparative Analysis of Epileptic Seizure Prediction: Exploring Diverse Pre-Processing Techniques and Machine Learning Models",
    "abstract": "Epilepsy is a prevalent neurological disorder characterized by recurrent and\nunpredictable seizures, necessitating accurate prediction for effective\nmanagement and patient care. Application of machine learning (ML) on\nelectroencephalogram (EEG) recordings, along with its ability to provide\nvaluable insights into brain activity during seizures, is able to make accurate\nand robust seizure prediction an indispensable component in relevant studies.\nIn this research, we present a comprehensive comparative analysis of five\nmachine learning models - Random Forest (RF), Decision Tree (DT), Extra Trees\n(ET), Logistic Regression (LR), and Gradient Boosting (GB) - for the prediction\nof epileptic seizures using EEG data. The dataset underwent meticulous\npreprocessing, including cleaning, normalization, outlier handling, and\noversampling, ensuring data quality and facilitating accurate model training.\nThese preprocessing techniques played a crucial role in enhancing the models'\nperformance. The results of our analysis demonstrate the performance of each\nmodel in terms of accuracy. The LR classifier achieved an accuracy of 56.95%,\nwhile GB and DT both attained 97.17% accuracy. RT achieved a higher accuracy of\n98.99%, while the ET model exhibited the best performance with an accuracy of\n99.29%. Our findings reveal that the ET model outperformed not only the other\nmodels in the comparative analysis but also surpassed the state-of-the-art\nresults from previous research. The superior performance of the ET model makes\nit a compelling choice for accurate and robust epileptic seizure prediction\nusing EEG data.",
    "pdfLink": "https://arxiv.org/pdf/2308.05176.pdf"
  },
  {
    "id": "2308.05170",
    "title": "FPGA Resource-aware Structured Pruning for Real-Time Neural Networks",
    "abstract": "Neural networks achieve state-of-the-art performance in image classification,\nspeech recognition, scientific analysis and many more application areas. With\nthe ever-increasing need for faster computation and lower power consumption,\ndriven by real-time systems and Internet-of-Things (IoT) devices, FPGAs have\nemerged as suitable devices for deep learning inference. Due to the high\ncomputational complexity and memory footprint of neural networks, various\ncompression techniques, such as pruning, quantization and knowledge\ndistillation, have been proposed in literature. Pruning sparsifies a neural\nnetwork, reducing the number of multiplications and memory. However, pruning\noften fails to capture properties of the underlying hardware, causing\nunstructured sparsity and load-balance inefficiency, thus bottlenecking\nresource improvements. We propose a hardware-centric formulation of pruning, by\nformulating it as a knapsack problem with resource-aware tensor structures. The\nprimary emphasis is on real-time inference, with latencies in the order of\n1\\mus, accelerated with hls4ml, an open-source framework for deep learning\ninference on FPGAs. Evaluated on a range of tasks, including real-time particle\nclassification at CERN's Large Hadron Collider and fast image classification,\nthe proposed method achieves a reduction ranging between 55% and 92% in the\nutilization of digital signal processing blocks (DSP) and up to 81% in block\nmemory (BRAM) utilization.",
    "pdfLink": "https://arxiv.org/pdf/2308.05170.pdf"
  },
  {
    "id": "2308.05127",
    "title": "Data-Free Model Extraction Attacks in the Context of Object Detection",
    "abstract": "A significant number of machine learning models are vulnerable to model\nextraction attacks, which focus on stealing the models by using specially\ncurated queries against the target model. This task is well accomplished by\nusing part of the training data or a surrogate dataset to train a new model\nthat mimics a target model in a white-box environment. In pragmatic situations,\nhowever, the target models are trained on private datasets that are\ninaccessible to the adversary. The data-free model extraction technique\nreplaces this problem when it comes to using queries artificially curated by a\ngenerator similar to that used in Generative Adversarial Nets. We propose for\nthe first time, to the best of our knowledge, an adversary black box attack\nextending to a regression problem for predicting bounding box coordinates in\nobject detection. As part of our study, we found that defining a loss function\nand using a novel generator setup is one of the key aspects in extracting the\ntarget model. We find that the proposed model extraction method achieves\nsignificant results by using reasonable queries. The discovery of this object\ndetection vulnerability will support future prospects for securing such models.",
    "pdfLink": "https://arxiv.org/pdf/2308.05127.pdf"
  },
  {
    "id": "2308.05106",
    "title": "Balancing Accuracy and Training Time in Federated Learning for Violence Detection in Surveillance Videos: A Study of Neural Network Architectures",
    "abstract": "This paper presents an investigation into machine learning techniques for\nviolence detection in videos and their adaptation to a federated learning\ncontext. The study includes experiments with spatio-temporal features extracted\nfrom benchmark video datasets, comparison of different methods, and proposal of\na modified version of the \"Flow-Gated\" architecture called \"Diff-Gated.\"\nAdditionally, various machine learning techniques, including super-convergence\nand transfer learning, are explored, and a method for adapting centralized\ndatasets to a federated learning context is developed. The research achieves\nbetter accuracy results compared to state-of-the-art models by training the\nbest violence detection model in a federated learning context.",
    "pdfLink": "https://arxiv.org/pdf/2308.05106.pdf"
  },
  {
    "id": "2305.19069",
    "title": "Multi-source adversarial transfer learning for ultrasound image segmentation with limited similarity",
    "abstract": "Lesion segmentation of ultrasound medical images based on deep learning\ntechniques is a widely used method for diagnosing diseases. Although there is a\nlarge amount of ultrasound image data in medical centers and other places,\nlabeled ultrasound datasets are a scarce resource, and it is likely that no\ndatasets are available for new tissues/organs. Transfer learning provides the\npossibility to solve this problem, but there are too many features in natural\nimages that are not related to the target domain. As a source domain, redundant\nfeatures that are not conducive to the task will be extracted. Migration\nbetween ultrasound images can avoid this problem, but there are few types of\npublic datasets, and it is difficult to find sufficiently similar source\ndomains. Compared with natural images, ultrasound images have less information,\nand there are fewer transferable features between different ultrasound images,\nwhich may cause negative transfer. To this end, a multi-source adversarial\ntransfer learning network for ultrasound image segmentation is proposed.\nSpecifically, to address the lack of annotations, the idea of adversarial\ntransfer learning is used to adaptively extract common features between a\ncertain pair of source and target domains, which provides the possibility to\nutilize unlabeled ultrasound data. To alleviate the lack of knowledge in a\nsingle source domain, multi-source transfer learning is adopted to fuse\nknowledge from multiple source domains. In order to ensure the effectiveness of\nthe fusion and maximize the use of precious data, a multi-source domain\nindependent strategy is also proposed to improve the estimation of the target\ndomain data distribution, which further increases the learning ability of the\nmulti-source adversarial migration learning network in multiple domains.",
    "pdfLink": "https://arxiv.org/pdf/2305.19069.pdf"
  }
]