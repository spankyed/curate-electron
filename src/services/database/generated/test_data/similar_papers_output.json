[
    [
        {
            "id": "2307.02390",
            "title": "Causal Discovery with Language Models as Imperfect Experts",
            "abstract": "Understanding the causal relationships that underlie a system is a\nfundamental prerequisite to accurate decision-making. In this work, we explore\nhow expert knowledge can be used to improve the data-driven identification of\ncausal graphs, beyond Markov equivalence classes. In doing so, we consider a\nsetting where we can query an expert about the orientation of causal\nrelationships between variables, but where the expert may provide erroneous\ninformation. We propose strategies for amending such expert knowledge based on\nconsistency properties, e.g., acyclicity and conditional independencies in the\nequivalence class. We then report a case study, on real data, where a large\nlanguage model is used as an imperfect expert.",
            "pdfLink": "https://arxiv.org/pdf/2307.02390.pdf",
            "semantic_relevancy_score": 0.3901698589324951
        },
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.38583460450172424
        },
        {
            "id": "2308.05481",
            "title": "LLM As DBA",
            "abstract": "Database administrators (DBAs) play a crucial role in managing, maintaining and optimizing a database system to ensure data availability, performance, and reliability. However, it is hard and tedious for DBAs to manage a large number of database instances (e.g., millions of instances on the cloud databases). Recently large language models (LLMs) have shown great potential to understand valuable documents and accordingly generate reasonable answers. Thus, we propose D-Bot, a LLM-based database administrator that can continuously acquire database maintenance experience from textual sources, and provide reasonable, well-founded, in-time diagnosis and optimization advice for target databases. This paper presents a revolutionary LLM-centric framework for database maintenance, including (i) database maintenance knowledge detection from documents and tools, (ii) tree of thought reasoning for root cause analysis, and (iii) collaborative diagnosis among multiple LLMs. Our preliminary experimental results that D-Bot can efficiently and effectively diagnose the root causes and our code is available at this http URL.",
            "pdfLink": "https://arxiv.org/pdf/2308.05481.pdf",
            "semantic_relevancy_score": 0.36437588930130005
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.33609136939048767
        }
    ],
    [
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.5811617374420166
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.5026471614837646
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.4859332740306854
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.45685696601867676
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.44847285747528076
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.44035351276397705
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.43264880776405334
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.4272693395614624
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.41814184188842773
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.4174119830131531
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.4120801091194153
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.40635937452316284
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.4046540856361389
        },
        {
            "id": "2307.05082",
            "title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning",
            "abstract": "This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.",
            "pdfLink": "https://arxiv.org/pdf/2307.05082.pdf",
            "semantic_relevancy_score": 0.37353792786598206
        },
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.3593021035194397
        },
        {
            "id": "2307.06159",
            "title": "Reflective Hybrid Intelligence for Meaningful Human Control in Decision-Support Systems",
            "abstract": "With the growing capabilities and pervasiveness of AI systems, societies must\ncollectively choose between reduced human autonomy, endangered democracies and\nlimited human rights, and AI that is aligned to human and social values,\nnurturing collaboration, resilience, knowledge and ethical behaviour. In this\nchapter, we introduce the notion of self-reflective AI systems for meaningful\nhuman control over AI systems. Focusing on decision support systems, we propose\na framework that integrates knowledge from psychology and philosophy with\nformal reasoning methods and machine learning approaches to create AI systems\nresponsive to human values and social norms. We also propose a possible\nresearch approach to design and develop self-reflective capability in AI\nsystems. Finally, we argue that self-reflective AI systems can lead to\nself-reflective hybrid systems (human + AI), thus increasing meaningful human\ncontrol and empowering human moral reasoning by providing comprehensible\ninformation and insights on possible human moral blind spots.",
            "pdfLink": "https://arxiv.org/pdf/2307.06159.pdf",
            "semantic_relevancy_score": 0.35389578342437744
        },
        {
            "id": "2307.02276",
            "title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
            "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.",
            "pdfLink": "https://arxiv.org/pdf/2307.02276.pdf",
            "semantic_relevancy_score": 0.32995229959487915
        }
    ],
    [
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.5346760749816895
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.5015479326248169
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.451782763004303
        },
        {
            "id": "2307.06159",
            "title": "Reflective Hybrid Intelligence for Meaningful Human Control in Decision-Support Systems",
            "abstract": "With the growing capabilities and pervasiveness of AI systems, societies must\ncollectively choose between reduced human autonomy, endangered democracies and\nlimited human rights, and AI that is aligned to human and social values,\nnurturing collaboration, resilience, knowledge and ethical behaviour. In this\nchapter, we introduce the notion of self-reflective AI systems for meaningful\nhuman control over AI systems. Focusing on decision support systems, we propose\na framework that integrates knowledge from psychology and philosophy with\nformal reasoning methods and machine learning approaches to create AI systems\nresponsive to human values and social norms. We also propose a possible\nresearch approach to design and develop self-reflective capability in AI\nsystems. Finally, we argue that self-reflective AI systems can lead to\nself-reflective hybrid systems (human + AI), thus increasing meaningful human\ncontrol and empowering human moral reasoning by providing comprehensible\ninformation and insights on possible human moral blind spots.",
            "pdfLink": "https://arxiv.org/pdf/2307.06159.pdf",
            "semantic_relevancy_score": 0.41081473231315613
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.40682297945022583
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.3926759362220764
        },
        {
            "id": "2307.05082",
            "title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning",
            "abstract": "This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.",
            "pdfLink": "https://arxiv.org/pdf/2307.05082.pdf",
            "semantic_relevancy_score": 0.38927605748176575
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.38895806670188904
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.3851926624774933
        },
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.330748975276947
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.31953123211860657
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.3153720200061798
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.3125286400318146
        },
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.3093109130859375
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.30514761805534363
        }
    ],
    [
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.5732019543647766
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.5393369197845459
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.4601675868034363
        },
        {
            "id": "2307.02276",
            "title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
            "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.",
            "pdfLink": "https://arxiv.org/pdf/2307.02276.pdf",
            "semantic_relevancy_score": 0.45110684633255005
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.38235971331596375
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.35643720626831055
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.3279738128185272
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.3049623966217041
        }
    ],
    [
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.5807385444641113
        },
        {
            "id": "2307.02390",
            "title": "Causal Discovery with Language Models as Imperfect Experts",
            "abstract": "Understanding the causal relationships that underlie a system is a\nfundamental prerequisite to accurate decision-making. In this work, we explore\nhow expert knowledge can be used to improve the data-driven identification of\ncausal graphs, beyond Markov equivalence classes. In doing so, we consider a\nsetting where we can query an expert about the orientation of causal\nrelationships between variables, but where the expert may provide erroneous\ninformation. We propose strategies for amending such expert knowledge based on\nconsistency properties, e.g., acyclicity and conditional independencies in the\nequivalence class. We then report a case study, on real data, where a large\nlanguage model is used as an imperfect expert.",
            "pdfLink": "https://arxiv.org/pdf/2307.02390.pdf",
            "semantic_relevancy_score": 0.5617326498031616
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.4723946452140808
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.47173839807510376
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.44579148292541504
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.43293696641921997
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.40850478410720825
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.40012818574905396
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.39469635486602783
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.38774991035461426
        },
        {
            "id": "2307.05082",
            "title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning",
            "abstract": "This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.",
            "pdfLink": "https://arxiv.org/pdf/2307.05082.pdf",
            "semantic_relevancy_score": 0.37464892864227295
        },
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.3723308742046356
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.3691972494125366
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.3665863573551178
        },
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.36467495560646057
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.3560834527015686
        },
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.35197684168815613
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.3344765603542328
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.3193002939224243
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.3099987506866455
        },
        {
            "id": "2307.06159",
            "title": "Reflective Hybrid Intelligence for Meaningful Human Control in Decision-Support Systems",
            "abstract": "With the growing capabilities and pervasiveness of AI systems, societies must\ncollectively choose between reduced human autonomy, endangered democracies and\nlimited human rights, and AI that is aligned to human and social values,\nnurturing collaboration, resilience, knowledge and ethical behaviour. In this\nchapter, we introduce the notion of self-reflective AI systems for meaningful\nhuman control over AI systems. Focusing on decision support systems, we propose\na framework that integrates knowledge from psychology and philosophy with\nformal reasoning methods and machine learning approaches to create AI systems\nresponsive to human values and social norms. We also propose a possible\nresearch approach to design and develop self-reflective capability in AI\nsystems. Finally, we argue that self-reflective AI systems can lead to\nself-reflective hybrid systems (human + AI), thus increasing meaningful human\ncontrol and empowering human moral reasoning by providing comprehensible\ninformation and insights on possible human moral blind spots.",
            "pdfLink": "https://arxiv.org/pdf/2307.06159.pdf",
            "semantic_relevancy_score": 0.30665725469589233
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.30119508504867554
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.3003385066986084
        }
    ],
    [
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.3869946599006653
        },
        {
            "id": "2307.09364",
            "title": "Local Minima Drive Communications in Cooperative Interaction",
            "abstract": "An important open question in human-robot interaction (HRI) is precisely when\nan agent should decide to communicate, particularly in a cooperative task.\nPerceptual Control Theory (PCT) tells us that agents are able to cooperate on a\njoint task simply by sharing the same 'intention', thereby distributing the\neffort required to complete the task among the agents. This is even true for\nagents that do not possess the same abilities, so long as the goal is\nobservable, the combined actions are sufficient to complete the task, and there\nis no local minimum in the search space. If these conditions hold, then a\ncooperative task can be accomplished without any communication between the\ncontributing agents. However, for tasks that do contain local minima, the\nglobal solution can only be reached if at least one of the agents adapts its\nintention at the appropriate moments, and this can only be achieved by\nappropriately timed communication. In other words, it is hypothesised that in\ncooperative tasks, the function of communication is to coordinate actions in a\ncomplex search space that contains local minima. These principles have been\nverified in a computer-based simulation environment in which two independent\none-dimensional agents are obliged to cooperate in order to solve a\ntwo-dimensional path-finding task.",
            "pdfLink": "https://arxiv.org/pdf/2307.09364.pdf",
            "semantic_relevancy_score": 0.3692966103553772
        },
        {
            "id": "2307.02276",
            "title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
            "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.",
            "pdfLink": "https://arxiv.org/pdf/2307.02276.pdf",
            "semantic_relevancy_score": 0.36825236678123474
        }
    ],
    [
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.5803218483924866
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.5351028442382812
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.5132238268852234
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.49034982919692993
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.48255655169487
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.45956096053123474
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.4580645263195038
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.44821470975875854
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.43595001101493835
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.42396822571754456
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.4035652279853821
        },
        {
            "id": "2307.05082",
            "title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning",
            "abstract": "This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.",
            "pdfLink": "https://arxiv.org/pdf/2307.05082.pdf",
            "semantic_relevancy_score": 0.38947737216949463
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.364803671836853
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.3598809242248535
        },
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.3558790981769562
        },
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.3419320583343506
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.33036065101623535
        },
        {
            "id": "2307.02276",
            "title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
            "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.",
            "pdfLink": "https://arxiv.org/pdf/2307.02276.pdf",
            "semantic_relevancy_score": 0.31787753105163574
        },
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.3153601288795471
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.3129802942276001
        }
    ],
    [
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.6209368109703064
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.5364601016044617
        },
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.4891469478607178
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.4799308776855469
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.4795573949813843
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.4256036579608917
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.42513740062713623
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.36625218391418457
        },
        {
            "id": "2307.05082",
            "title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning",
            "abstract": "This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.",
            "pdfLink": "https://arxiv.org/pdf/2307.05082.pdf",
            "semantic_relevancy_score": 0.3661687970161438
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.36010265350341797
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.34618079662323
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.332154244184494
        },
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.32322975993156433
        },
        {
            "id": "2308.05481",
            "title": "LLM As DBA",
            "abstract": "Database administrators (DBAs) play a crucial role in managing, maintaining and optimizing a database system to ensure data availability, performance, and reliability. However, it is hard and tedious for DBAs to manage a large number of database instances (e.g., millions of instances on the cloud databases). Recently large language models (LLMs) have shown great potential to understand valuable documents and accordingly generate reasonable answers. Thus, we propose D-Bot, a LLM-based database administrator that can continuously acquire database maintenance experience from textual sources, and provide reasonable, well-founded, in-time diagnosis and optimization advice for target databases. This paper presents a revolutionary LLM-centric framework for database maintenance, including (i) database maintenance knowledge detection from documents and tools, (ii) tree of thought reasoning for root cause analysis, and (iii) collaborative diagnosis among multiple LLMs. Our preliminary experimental results that D-Bot can efficiently and effectively diagnose the root causes and our code is available at this http URL.",
            "pdfLink": "https://arxiv.org/pdf/2308.05481.pdf",
            "semantic_relevancy_score": 0.32227563858032227
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.30932551622390747
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.30818629264831543
        }
    ],
    [
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.3944443464279175
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.37677085399627686
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.3738420903682709
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.34903961420059204
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.3355066776275635
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.31014394760131836
        }
    ],
    [
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.45802220702171326
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.36337149143218994
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.30561673641204834
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.30093714594841003
        }
    ],
    [
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.32879841327667236
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.31926876306533813
        }
    ],
    [
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.36114901304244995
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.32182198762893677
        }
    ],
    [
        {
            "id": "2307.02276",
            "title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
            "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.",
            "pdfLink": "https://arxiv.org/pdf/2307.02276.pdf",
            "semantic_relevancy_score": 0.5041003227233887
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.45148134231567383
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.3969523310661316
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.39254146814346313
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.3385772109031677
        },
        {
            "id": "2307.08859",
            "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach",
            "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
            "pdfLink": "https://arxiv.org/pdf/2307.08859.pdf",
            "semantic_relevancy_score": 0.3245525360107422
        }
    ],
    [],
    [
        {
            "id": "2307.08859",
            "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach",
            "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
            "pdfLink": "https://arxiv.org/pdf/2307.08859.pdf",
            "semantic_relevancy_score": 0.4572985768318176
        },
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.4247083365917206
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.39663589000701904
        },
        {
            "id": "2307.02390",
            "title": "Causal Discovery with Language Models as Imperfect Experts",
            "abstract": "Understanding the causal relationships that underlie a system is a\nfundamental prerequisite to accurate decision-making. In this work, we explore\nhow expert knowledge can be used to improve the data-driven identification of\ncausal graphs, beyond Markov equivalence classes. In doing so, we consider a\nsetting where we can query an expert about the orientation of causal\nrelationships between variables, but where the expert may provide erroneous\ninformation. We propose strategies for amending such expert knowledge based on\nconsistency properties, e.g., acyclicity and conditional independencies in the\nequivalence class. We then report a case study, on real data, where a large\nlanguage model is used as an imperfect expert.",
            "pdfLink": "https://arxiv.org/pdf/2307.02390.pdf",
            "semantic_relevancy_score": 0.37167245149612427
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.3610650300979614
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.35182952880859375
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.3241407573223114
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.32182759046554565
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.3162125051021576
        },
        {
            "id": "2308.05481",
            "title": "LLM As DBA",
            "abstract": "Database administrators (DBAs) play a crucial role in managing, maintaining and optimizing a database system to ensure data availability, performance, and reliability. However, it is hard and tedious for DBAs to manage a large number of database instances (e.g., millions of instances on the cloud databases). Recently large language models (LLMs) have shown great potential to understand valuable documents and accordingly generate reasonable answers. Thus, we propose D-Bot, a LLM-based database administrator that can continuously acquire database maintenance experience from textual sources, and provide reasonable, well-founded, in-time diagnosis and optimization advice for target databases. This paper presents a revolutionary LLM-centric framework for database maintenance, including (i) database maintenance knowledge detection from documents and tools, (ii) tree of thought reasoning for root cause analysis, and (iii) collaborative diagnosis among multiple LLMs. Our preliminary experimental results that D-Bot can efficiently and effectively diagnose the root causes and our code is available at this http URL.",
            "pdfLink": "https://arxiv.org/pdf/2308.05481.pdf",
            "semantic_relevancy_score": 0.3133399784564972
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.3103495240211487
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.3053378462791443
        }
    ],
    [
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.5800113677978516
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.5588480234146118
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.5251575708389282
        },
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.4996561110019684
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.4856385290622711
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.4601234197616577
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.4508140981197357
        },
        {
            "id": "2307.08859",
            "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach",
            "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
            "pdfLink": "https://arxiv.org/pdf/2307.08859.pdf",
            "semantic_relevancy_score": 0.4434072971343994
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.4344366788864136
        },
        {
            "id": "2307.02390",
            "title": "Causal Discovery with Language Models as Imperfect Experts",
            "abstract": "Understanding the causal relationships that underlie a system is a\nfundamental prerequisite to accurate decision-making. In this work, we explore\nhow expert knowledge can be used to improve the data-driven identification of\ncausal graphs, beyond Markov equivalence classes. In doing so, we consider a\nsetting where we can query an expert about the orientation of causal\nrelationships between variables, but where the expert may provide erroneous\ninformation. We propose strategies for amending such expert knowledge based on\nconsistency properties, e.g., acyclicity and conditional independencies in the\nequivalence class. We then report a case study, on real data, where a large\nlanguage model is used as an imperfect expert.",
            "pdfLink": "https://arxiv.org/pdf/2307.02390.pdf",
            "semantic_relevancy_score": 0.42667680978775024
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.41873639822006226
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.4177880883216858
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.4175409972667694
        },
        {
            "id": "2307.10680",
            "title": "A Personalized Recommender System Based-on Knowledge Graph Embeddings",
            "abstract": "Knowledge graphs have proven to be effective for modeling entities and their\nrelationships through the use of ontologies. The recent emergence in interest\nfor using knowledge graphs as a form of information modeling has led to their\nincreased adoption in recommender systems. By incorporating users and items\ninto the knowledge graph, these systems can better capture the implicit\nconnections between them and provide more accurate recommendations. In this\npaper, we investigate and propose the construction of a personalized\nrecommender system via knowledge graphs embedding applied to the vehicle\npurchase/sale domain. The results of our experimentation demonstrate the\nefficacy of the proposed method in providing relevant recommendations that are\nconsistent with individual users.",
            "pdfLink": "https://arxiv.org/pdf/2307.10680.pdf",
            "semantic_relevancy_score": 0.4058685898780823
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.3884904384613037
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.38375067710876465
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.3808134198188782
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.3801720440387726
        },
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.3743857741355896
        },
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.3451073467731476
        },
        {
            "id": "2308.05481",
            "title": "LLM As DBA",
            "abstract": "Database administrators (DBAs) play a crucial role in managing, maintaining and optimizing a database system to ensure data availability, performance, and reliability. However, it is hard and tedious for DBAs to manage a large number of database instances (e.g., millions of instances on the cloud databases). Recently large language models (LLMs) have shown great potential to understand valuable documents and accordingly generate reasonable answers. Thus, we propose D-Bot, a LLM-based database administrator that can continuously acquire database maintenance experience from textual sources, and provide reasonable, well-founded, in-time diagnosis and optimization advice for target databases. This paper presents a revolutionary LLM-centric framework for database maintenance, including (i) database maintenance knowledge detection from documents and tools, (ii) tree of thought reasoning for root cause analysis, and (iii) collaborative diagnosis among multiple LLMs. Our preliminary experimental results that D-Bot can efficiently and effectively diagnose the root causes and our code is available at this http URL.",
            "pdfLink": "https://arxiv.org/pdf/2308.05481.pdf",
            "semantic_relevancy_score": 0.34446457028388977
        },
        {
            "id": "2307.05082",
            "title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning",
            "abstract": "This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.",
            "pdfLink": "https://arxiv.org/pdf/2307.05082.pdf",
            "semantic_relevancy_score": 0.34196144342422485
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.34071195125579834
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.3069201707839966
        }
    ],
    [
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.5071945190429688
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.48144829273223877
        },
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.46971970796585083
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.462285578250885
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.45864492654800415
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.4503757953643799
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.44034862518310547
        },
        {
            "id": "2307.02276",
            "title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
            "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.",
            "pdfLink": "https://arxiv.org/pdf/2307.02276.pdf",
            "semantic_relevancy_score": 0.4378461241722107
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.4307038187980652
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.4270448684692383
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.425290584564209
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.4225342273712158
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.42029517889022827
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.4185810089111328
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.4161561131477356
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.39403361082077026
        },
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.38520297408103943
        },
        {
            "id": "2307.08859",
            "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach",
            "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
            "pdfLink": "https://arxiv.org/pdf/2307.08859.pdf",
            "semantic_relevancy_score": 0.38115429878234863
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.370328426361084
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.3501875102519989
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.3236573040485382
        }
    ],
    [],
    [
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.5494471788406372
        },
        {
            "id": "2307.05082",
            "title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning",
            "abstract": "This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.",
            "pdfLink": "https://arxiv.org/pdf/2307.05082.pdf",
            "semantic_relevancy_score": 0.5368704199790955
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.5298696756362915
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.5000094771385193
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.48768413066864014
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.48193472623825073
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.46150457859039307
        },
        {
            "id": "2308.05481",
            "title": "LLM As DBA",
            "abstract": "Database administrators (DBAs) play a crucial role in managing, maintaining and optimizing a database system to ensure data availability, performance, and reliability. However, it is hard and tedious for DBAs to manage a large number of database instances (e.g., millions of instances on the cloud databases). Recently large language models (LLMs) have shown great potential to understand valuable documents and accordingly generate reasonable answers. Thus, we propose D-Bot, a LLM-based database administrator that can continuously acquire database maintenance experience from textual sources, and provide reasonable, well-founded, in-time diagnosis and optimization advice for target databases. This paper presents a revolutionary LLM-centric framework for database maintenance, including (i) database maintenance knowledge detection from documents and tools, (ii) tree of thought reasoning for root cause analysis, and (iii) collaborative diagnosis among multiple LLMs. Our preliminary experimental results that D-Bot can efficiently and effectively diagnose the root causes and our code is available at this http URL.",
            "pdfLink": "https://arxiv.org/pdf/2308.05481.pdf",
            "semantic_relevancy_score": 0.44141852855682373
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.4362831711769104
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.42487242817878723
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.41294193267822266
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.4040864109992981
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.401712030172348
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.36203840374946594
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.3614441752433777
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.3576938509941101
        },
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.3522847294807434
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.3499656021595001
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.31831979751586914
        },
        {
            "id": "2307.08859",
            "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach",
            "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
            "pdfLink": "https://arxiv.org/pdf/2307.08859.pdf",
            "semantic_relevancy_score": 0.30072683095932007
        }
    ],
    [],
    [
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.42705100774765015
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.4083290696144104
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.38478806614875793
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.37567338347435
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.37470537424087524
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.3684770166873932
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.3608345687389374
        },
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.35718607902526855
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.35599055886268616
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.3422776162624359
        },
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.3413859009742737
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.3235431909561157
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.32281455397605896
        },
        {
            "id": "2307.08859",
            "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach",
            "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
            "pdfLink": "https://arxiv.org/pdf/2307.08859.pdf",
            "semantic_relevancy_score": 0.3086676597595215
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.30853578448295593
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.30667126178741455
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.30092355608940125
        }
    ],
    [
        {
            "id": "2307.02390",
            "title": "Causal Discovery with Language Models as Imperfect Experts",
            "abstract": "Understanding the causal relationships that underlie a system is a\nfundamental prerequisite to accurate decision-making. In this work, we explore\nhow expert knowledge can be used to improve the data-driven identification of\ncausal graphs, beyond Markov equivalence classes. In doing so, we consider a\nsetting where we can query an expert about the orientation of causal\nrelationships between variables, but where the expert may provide erroneous\ninformation. We propose strategies for amending such expert knowledge based on\nconsistency properties, e.g., acyclicity and conditional independencies in the\nequivalence class. We then report a case study, on real data, where a large\nlanguage model is used as an imperfect expert.",
            "pdfLink": "https://arxiv.org/pdf/2307.02390.pdf",
            "semantic_relevancy_score": 0.3530070185661316
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.31510138511657715
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.301436185836792
        }
    ],
    [
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.44807133078575134
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.41320520639419556
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.3736454248428345
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.368837833404541
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.35791537165641785
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.34438103437423706
        },
        {
            "id": "2307.08859",
            "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach",
            "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
            "pdfLink": "https://arxiv.org/pdf/2307.08859.pdf",
            "semantic_relevancy_score": 0.3307799994945526
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.3236430883407593
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.31695300340652466
        }
    ],
    [
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.39659491181373596
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.3782958388328552
        },
        {
            "id": "2307.09364",
            "title": "Local Minima Drive Communications in Cooperative Interaction",
            "abstract": "An important open question in human-robot interaction (HRI) is precisely when\nan agent should decide to communicate, particularly in a cooperative task.\nPerceptual Control Theory (PCT) tells us that agents are able to cooperate on a\njoint task simply by sharing the same 'intention', thereby distributing the\neffort required to complete the task among the agents. This is even true for\nagents that do not possess the same abilities, so long as the goal is\nobservable, the combined actions are sufficient to complete the task, and there\nis no local minimum in the search space. If these conditions hold, then a\ncooperative task can be accomplished without any communication between the\ncontributing agents. However, for tasks that do contain local minima, the\nglobal solution can only be reached if at least one of the agents adapts its\nintention at the appropriate moments, and this can only be achieved by\nappropriately timed communication. In other words, it is hypothesised that in\ncooperative tasks, the function of communication is to coordinate actions in a\ncomplex search space that contains local minima. These principles have been\nverified in a computer-based simulation environment in which two independent\none-dimensional agents are obliged to cooperate in order to solve a\ntwo-dimensional path-finding task.",
            "pdfLink": "https://arxiv.org/pdf/2307.09364.pdf",
            "semantic_relevancy_score": 0.3520496189594269
        },
        {
            "id": "2307.06159",
            "title": "Reflective Hybrid Intelligence for Meaningful Human Control in Decision-Support Systems",
            "abstract": "With the growing capabilities and pervasiveness of AI systems, societies must\ncollectively choose between reduced human autonomy, endangered democracies and\nlimited human rights, and AI that is aligned to human and social values,\nnurturing collaboration, resilience, knowledge and ethical behaviour. In this\nchapter, we introduce the notion of self-reflective AI systems for meaningful\nhuman control over AI systems. Focusing on decision support systems, we propose\na framework that integrates knowledge from psychology and philosophy with\nformal reasoning methods and machine learning approaches to create AI systems\nresponsive to human values and social norms. We also propose a possible\nresearch approach to design and develop self-reflective capability in AI\nsystems. Finally, we argue that self-reflective AI systems can lead to\nself-reflective hybrid systems (human + AI), thus increasing meaningful human\ncontrol and empowering human moral reasoning by providing comprehensible\ninformation and insights on possible human moral blind spots.",
            "pdfLink": "https://arxiv.org/pdf/2307.06159.pdf",
            "semantic_relevancy_score": 0.330305278301239
        }
    ],
    [
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.30474841594696045
        }
    ],
    [
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.4296267032623291
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.4247908592224121
        },
        {
            "id": "2307.08859",
            "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach",
            "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
            "pdfLink": "https://arxiv.org/pdf/2307.08859.pdf",
            "semantic_relevancy_score": 0.4220304489135742
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.4142451286315918
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.4122951328754425
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.40341663360595703
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.397422194480896
        },
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.3870117664337158
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.32987794280052185
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.30797192454338074
        },
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.3036845028400421
        }
    ],
    [
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.5279988646507263
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.48145610094070435
        },
        {
            "id": "2307.02276",
            "title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
            "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.",
            "pdfLink": "https://arxiv.org/pdf/2307.02276.pdf",
            "semantic_relevancy_score": 0.4647998809814453
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.3994462192058563
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.38145995140075684
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.38090038299560547
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.3714415431022644
        },
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.32399001717567444
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.32153746485710144
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.31876835227012634
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.31821730732917786
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.31489458680152893
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.30947232246398926
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.3064245879650116
        }
    ],
    [
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.3795885443687439
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.36149004101753235
        },
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.3343065679073334
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.32614606618881226
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.32380831241607666
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.32363927364349365
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.3221323788166046
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.3220965266227722
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.3199455142021179
        },
        {
            "id": "2307.02276",
            "title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
            "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.",
            "pdfLink": "https://arxiv.org/pdf/2307.02276.pdf",
            "semantic_relevancy_score": 0.3071264922618866
        }
    ],
    [
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.34408342838287354
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.31236428022384644
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.3076082468032837
        }
    ],
    [
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.5925620198249817
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.5439180135726929
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.5208310484886169
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.5050734281539917
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.4919888377189636
        },
        {
            "id": "2307.02276",
            "title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
            "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.",
            "pdfLink": "https://arxiv.org/pdf/2307.02276.pdf",
            "semantic_relevancy_score": 0.4917600750923157
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.48130181431770325
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.4717146158218384
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.463635116815567
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.4550977945327759
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.43794164061546326
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.42978960275650024
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.42311450839042664
        },
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.40669745206832886
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.3984633684158325
        },
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.3969111442565918
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.39414435625076294
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.378452330827713
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.37839841842651367
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.351528525352478
        },
        {
            "id": "2307.08859",
            "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach",
            "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
            "pdfLink": "https://arxiv.org/pdf/2307.08859.pdf",
            "semantic_relevancy_score": 0.30192187428474426
        }
    ],
    [
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.587917685508728
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.5727074146270752
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.5657756328582764
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.5454058647155762
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.5251239538192749
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.5081971883773804
        },
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.49830663204193115
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.48348698019981384
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.4790773093700409
        },
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.4777050316333771
        },
        {
            "id": "2307.05082",
            "title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning",
            "abstract": "This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.",
            "pdfLink": "https://arxiv.org/pdf/2307.05082.pdf",
            "semantic_relevancy_score": 0.47502565383911133
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.47312650084495544
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.44464918971061707
        },
        {
            "id": "2307.02276",
            "title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
            "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.",
            "pdfLink": "https://arxiv.org/pdf/2307.02276.pdf",
            "semantic_relevancy_score": 0.4285426735877991
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.42149537801742554
        },
        {
            "id": "2308.05481",
            "title": "LLM As DBA",
            "abstract": "Database administrators (DBAs) play a crucial role in managing, maintaining and optimizing a database system to ensure data availability, performance, and reliability. However, it is hard and tedious for DBAs to manage a large number of database instances (e.g., millions of instances on the cloud databases). Recently large language models (LLMs) have shown great potential to understand valuable documents and accordingly generate reasonable answers. Thus, we propose D-Bot, a LLM-based database administrator that can continuously acquire database maintenance experience from textual sources, and provide reasonable, well-founded, in-time diagnosis and optimization advice for target databases. This paper presents a revolutionary LLM-centric framework for database maintenance, including (i) database maintenance knowledge detection from documents and tools, (ii) tree of thought reasoning for root cause analysis, and (iii) collaborative diagnosis among multiple LLMs. Our preliminary experimental results that D-Bot can efficiently and effectively diagnose the root causes and our code is available at this http URL.",
            "pdfLink": "https://arxiv.org/pdf/2308.05481.pdf",
            "semantic_relevancy_score": 0.4211333990097046
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.4167554974555969
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.41324156522750854
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.390944242477417
        },
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.3896280527114868
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.35864341259002686
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.34019625186920166
        },
        {
            "id": "2307.02390",
            "title": "Causal Discovery with Language Models as Imperfect Experts",
            "abstract": "Understanding the causal relationships that underlie a system is a\nfundamental prerequisite to accurate decision-making. In this work, we explore\nhow expert knowledge can be used to improve the data-driven identification of\ncausal graphs, beyond Markov equivalence classes. In doing so, we consider a\nsetting where we can query an expert about the orientation of causal\nrelationships between variables, but where the expert may provide erroneous\ninformation. We propose strategies for amending such expert knowledge based on\nconsistency properties, e.g., acyclicity and conditional independencies in the\nequivalence class. We then report a case study, on real data, where a large\nlanguage model is used as an imperfect expert.",
            "pdfLink": "https://arxiv.org/pdf/2307.02390.pdf",
            "semantic_relevancy_score": 0.3384699523448944
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.31097275018692017
        },
        {
            "id": "2307.08859",
            "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach",
            "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
            "pdfLink": "https://arxiv.org/pdf/2307.08859.pdf",
            "semantic_relevancy_score": 0.30582982301712036
        }
    ],
    [
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.39414578676223755
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.3379911482334137
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.3232031464576721
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.3201256990432739
        }
    ],
    [
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.5207894444465637
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.48405659198760986
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.47975844144821167
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.4496985077857971
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.44643503427505493
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.41906383633613586
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.41873878240585327
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.4103436768054962
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.4060947299003601
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.396989643573761
        },
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.3821510672569275
        },
        {
            "id": "2307.05082",
            "title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning",
            "abstract": "This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.",
            "pdfLink": "https://arxiv.org/pdf/2307.05082.pdf",
            "semantic_relevancy_score": 0.36664241552352905
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.35859811305999756
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.35774028301239014
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.34895771741867065
        },
        {
            "id": "2307.08859",
            "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach",
            "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
            "pdfLink": "https://arxiv.org/pdf/2307.08859.pdf",
            "semantic_relevancy_score": 0.3392343521118164
        },
        {
            "id": "2307.02276",
            "title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
            "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.",
            "pdfLink": "https://arxiv.org/pdf/2307.02276.pdf",
            "semantic_relevancy_score": 0.3232664465904236
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.32113465666770935
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.314716100692749
        }
    ],
    [
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.44303572177886963
        },
        {
            "id": "2307.08859",
            "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach",
            "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
            "pdfLink": "https://arxiv.org/pdf/2307.08859.pdf",
            "semantic_relevancy_score": 0.44074007868766785
        },
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.38638830184936523
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.3606354892253876
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.35496607422828674
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.34817206859588623
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.3148423135280609
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.308428555727005
        }
    ],
    [
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.5138653516769409
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.49478286504745483
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.4723067283630371
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.4220176637172699
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.4212753474712372
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.41982176899909973
        },
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.4167878329753876
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.4160248637199402
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.41450098156929016
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.4107087552547455
        },
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.39762240648269653
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.3907470703125
        },
        {
            "id": "2307.05300",
            "title": "Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration",
            "abstract": "Human intelligence thrives on the concept of cognitive synergy, where\ncollaboration and information integration among different cognitive processes\nyield superior outcomes compared to individual cognitive processes in\nisolation. Although Large Language Models (LLMs) have demonstrated promising\nperformance as general task-solving agents, they still struggle with tasks that\nrequire intensive domain knowledge and complex reasoning. In this work, we\npropose Solo Performance Prompting (SPP), which transforms a single LLM into a\ncognitive synergist by engaging in multi-turn self-collaboration with multiple\npersonas. A cognitive synergist refers to an intelligent agent that\ncollaborates with multiple minds, combining their individual strengths and\nknowledge, to enhance problem-solving and overall performance in complex tasks.\nBy dynamically identifying and simulating different personas based on task\ninputs, SPP unleashes the potential of cognitive synergy in LLMs. We have\ndiscovered that assigning multiple, fine-grained personas in LLMs elicits\nbetter problem-solving abilities compared to using a single or fixed number of\npersonas. We evaluate SPP on three challenging tasks: Trivia Creative Writing,\nCodenames Collaborative, and Logic Grid Puzzle, encompassing both\nknowledge-intensive and reasoning-intensive types. Unlike previous works, such\nas Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP\neffectively elicits internal knowledge acquisition abilities, reduces\nhallucination, and maintains strong reasoning capabilities. Code, data, and\nprompts can be found at:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.05300.pdf",
            "semantic_relevancy_score": 0.36662518978118896
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.36268624663352966
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.3316723108291626
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.3288590610027313
        },
        {
            "id": "2307.02276",
            "title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
            "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.",
            "pdfLink": "https://arxiv.org/pdf/2307.02276.pdf",
            "semantic_relevancy_score": 0.32752957940101624
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.3184053301811218
        }
    ],
    [],
    [],
    [
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.35230553150177
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.3008546829223633
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.3005279302597046
        }
    ],
    [
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.32416412234306335
        }
    ],
    [
        {
            "id": "2307.08859",
            "title": "Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach",
            "abstract": "A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.",
            "pdfLink": "https://arxiv.org/pdf/2307.08859.pdf",
            "semantic_relevancy_score": 0.3509620130062103
        }
    ],
    [
        {
            "id": "2307.08962",
            "title": "REX: Rapid Exploration and eXploitation for AI Agents",
            "abstract": "In this paper, we propose an enhanced approach for Rapid Exploration and\neXploitation for AI Agents called REX. Existing AutoGPT-style techniques have\ninherent limitations, such as a heavy reliance on precise descriptions for\ndecision-making, and the lack of a systematic approach to leverage try-and-fail\nprocedures akin to traditional Reinforcement Learning (RL). REX introduces an\nadditional layer of rewards and integrates concepts similar to Upper Confidence\nBound (UCB) scores, leading to more robust and efficient AI agent performance.\nThis approach has the advantage of enabling the utilization of offline\nbehaviors from logs and allowing seamless integration with existing foundation\nmodels while it does not require any model fine-tuning. Through comparative\nanalysis with existing methods such as Chain-of-Thoughts(CoT) and Reasoning viA\nPlanning(RAP), REX-based methods demonstrate comparable performance and, in\ncertain cases, even surpass the results achieved by these existing techniques.\nNotably, REX-based methods exhibit remarkable reductions in execution time,\nenhancing their practical applicability across a diverse set of scenarios.",
            "pdfLink": "https://arxiv.org/pdf/2307.08962.pdf",
            "semantic_relevancy_score": 0.5241562128067017
        },
        {
            "id": "2307.02276",
            "title": "First-Explore, then Exploit: Meta-Learning Intelligent Exploration",
            "abstract": "Standard reinforcement learning (RL) agents never intelligently explore like\na human (i.e. by taking into account complex domain priors and previous\nexplorations). Even the most basic intelligent exploration strategies such as\nexhaustive search are only inefficiently or poorly approximated by approaches\nsuch as novelty search or intrinsic motivation, let alone more complicated\nstrategies like learning new skills, climbing stairs, opening doors, or\nconducting experiments. This lack of intelligent exploration limits sample\nefficiency and prevents solving hard exploration domains. We argue a core\nbarrier prohibiting many RL approaches from learning intelligent exploration is\nthat the methods attempt to explore and exploit simultaneously, which harms\nboth exploration and exploitation as the goals often conflict. We propose a\nnovel meta-RL framework (First-Explore) with two policies: one policy learns to\nonly explore and one policy learns to only exploit. Once trained, we can then\nexplore with the explore policy, for as long as desired, and then exploit based\non all the information gained during exploration. This approach avoids the\nconflict of trying to do both exploration and exploitation at once. We\ndemonstrate that First-Explore can learn intelligent exploration strategies\nsuch as exhaustive search and more, and that it outperforms dominant standard\nRL and meta-RL approaches on domains where exploration requires sacrificing\nreward. First-Explore is a significant step towards creating meta-RL algorithms\ncapable of learning human-level exploration which is essential to solve\nchallenging unseen hard-exploration domains.",
            "pdfLink": "https://arxiv.org/pdf/2307.02276.pdf",
            "semantic_relevancy_score": 0.5098387598991394
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.4659855365753174
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.3653411269187927
        },
        {
            "id": "2307.01928",
            "title": "Robots That Ask For Help: Uncertainty Alignment for Large Language Model Planners",
            "abstract": "Large language models (LLMs) exhibit a wide range of promising capabilities\n-- from step-by-step planning to commonsense reasoning -- that may provide\nutility for robots, but remain prone to confidently hallucinated predictions.\nIn this work, we present KnowNo, which is a framework for measuring and\naligning the uncertainty of LLM-based planners such that they know when they\ndon't know and ask for help when needed. KnowNo builds on the theory of\nconformal prediction to provide statistical guarantees on task completion while\nminimizing human help in complex multi-step planning settings. Experiments\nacross a variety of simulated and real robot setups that involve tasks with\ndifferent modes of ambiguity (e.g., from spatial to numeric uncertainties, from\nhuman preferences to Winograd schemas) show that KnowNo performs favorably over\nmodern baselines (which may involve ensembles or extensive prompt tuning) in\nterms of improving efficiency and autonomy, while providing formal assurances.\nKnowNo can be used with LLMs out of the box without model-finetuning, and\nsuggests a promising lightweight approach to modeling uncertainty that can\ncomplement and scale with the growing capabilities of foundation models.\nWebsite: this https URL",
            "pdfLink": "https://arxiv.org/pdf/2307.01928.pdf",
            "semantic_relevancy_score": 0.3534930348396301
        },
        {
            "id": "2307.01403",
            "title": "Learning to Communicate using Contrastive Learning",
            "abstract": "Communication is a powerful tool for coordination in multi-agent RL. But\ninducing an effective, common language is a difficult challenge, particularly\nin the decentralized setting. In this work, we introduce an alternative\nperspective where communicative messages sent between agents are considered as\ndifferent incomplete views of the environment state. By examining the\nrelationship between messages sent and received, we propose to learn to\ncommunicate using contrastive learning to maximize the mutual information\nbetween messages of a given trajectory. In communication-essential\nenvironments, our method outperforms previous work in both performance and\nlearning speed. Using qualitative metrics and representation probing, we show\nthat our method induces more symmetric communication and captures global state\ninformation from the environment. Overall, we show the power of contrastive\nlearning and the importance of leveraging messages as encodings for effective\ncommunication.",
            "pdfLink": "https://arxiv.org/pdf/2307.01403.pdf",
            "semantic_relevancy_score": 0.33030906319618225
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.31009572744369507
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.30423760414123535
        }
    ],
    [
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.3659069538116455
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.356292188167572
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.35168689489364624
        },
        {
            "id": "2307.02390",
            "title": "Causal Discovery with Language Models as Imperfect Experts",
            "abstract": "Understanding the causal relationships that underlie a system is a\nfundamental prerequisite to accurate decision-making. In this work, we explore\nhow expert knowledge can be used to improve the data-driven identification of\ncausal graphs, beyond Markov equivalence classes. In doing so, we consider a\nsetting where we can query an expert about the orientation of causal\nrelationships between variables, but where the expert may provide erroneous\ninformation. We propose strategies for amending such expert knowledge based on\nconsistency properties, e.g., acyclicity and conditional independencies in the\nequivalence class. We then report a case study, on real data, where a large\nlanguage model is used as an imperfect expert.",
            "pdfLink": "https://arxiv.org/pdf/2307.02390.pdf",
            "semantic_relevancy_score": 0.33394789695739746
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.32274365425109863
        }
    ],
    [
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.6390739679336548
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.5160951614379883
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.5103024244308472
        },
        {
            "id": "2307.10680",
            "title": "A Personalized Recommender System Based-on Knowledge Graph Embeddings",
            "abstract": "Knowledge graphs have proven to be effective for modeling entities and their\nrelationships through the use of ontologies. The recent emergence in interest\nfor using knowledge graphs as a form of information modeling has led to their\nincreased adoption in recommender systems. By incorporating users and items\ninto the knowledge graph, these systems can better capture the implicit\nconnections between them and provide more accurate recommendations. In this\npaper, we investigate and propose the construction of a personalized\nrecommender system via knowledge graphs embedding applied to the vehicle\npurchase/sale domain. The results of our experimentation demonstrate the\nefficacy of the proposed method in providing relevant recommendations that are\nconsistent with individual users.",
            "pdfLink": "https://arxiv.org/pdf/2307.10680.pdf",
            "semantic_relevancy_score": 0.5023535490036011
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.495079904794693
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.4684872627258301
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.4572749733924866
        },
        {
            "id": "2307.01577",
            "title": "Conceptual Cognitive Maps Formation with Neural Successor Networks and Word Embeddings",
            "abstract": "The human brain possesses the extraordinary capability to contextualize the\ninformation it receives from our environment. The entorhinal-hippocampal plays\na critical role in this function, as it is deeply engaged in memory processing\nand constructing cognitive maps using place and grid cells. Comprehending and\nleveraging this ability could significantly augment the field of artificial\nintelligence. The multi-scale successor representation serves as a good model\nfor the functionality of place and grid cells and has already shown promise in\nthis role. Here, we introduce a model that employs successor representations\nand neural networks, along with word embedding vectors, to construct a\ncognitive map of three separate concepts. The network adeptly learns two\ndifferent scaled maps and situates new information in proximity to related\npre-existing representations. The dispersion of information across the\ncognitive map varies according to its scale - either being heavily\nconcentrated, resulting in the formation of the three concepts, or spread\nevenly throughout the map. We suggest that our model could potentially improve\ncurrent AI models by providing multi-modal context information to any input,\nbased on a similarity metric for the input and pre-existing knowledge\nrepresentations.",
            "pdfLink": "https://arxiv.org/pdf/2307.01577.pdf",
            "semantic_relevancy_score": 0.39532506465911865
        },
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.38962942361831665
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.3682781457901001
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.3551371693611145
        },
        {
            "id": "2210.02441",
            "title": "Ask Me Anything: A simple strategy for prompting language models",
            "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply\ngiven a natural language prompt that demonstrates how to perform the task and\nno additional training. Prompting is a brittle process wherein small\nmodifications to the prompt can cause large variations in the model\npredictions, and therefore significant effort is dedicated towards designing a\npainstakingly \"perfect prompt\" for a task. To mitigate the high degree of\neffort involved in prompt-design, we instead ask whether producing multiple\neffective, yet imperfect, prompts and aggregating them can lead to a high\nquality prompting strategy. Our observations motivate our proposed prompting\nmethod, ASK ME ANYTHING (AMA). We first develop an understanding of the\neffective prompt formats, finding that question-answering (QA) prompts, which\nencourage open-ended generation (\"Who went to the park?\") tend to outperform\nthose that restrict the model outputs (\"John went to the park. Output True or\nFalse.\"). Our approach recursively uses the LLM itself to transform task inputs\nto the effective QA format. We apply the collected prompts to obtain several\nnoisy votes for the input's true label. We find that the prompts can have very\ndifferent accuracies and complex dependencies and thus propose to use weak\nsupervision, a procedure for combining the noisy predictions, to produce the\nfinal predictions for the inputs. We evaluate AMA across open-source model\nfamilies (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B\nparameters), demonstrating an average performance lift of 10.2% over the\nfew-shot baseline. This simple strategy enables the open-source GPT-J-6B model\nto match and exceed the performance of few-shot GPT3-175B on 15 of 20 popular\nbenchmarks. Averaged across these tasks, the GPT-J-6B model outperforms\nfew-shot GPT3-175B. We release our code here:\nthis https URL",
            "pdfLink": "https://arxiv.org/pdf/2210.02441.pdf",
            "semantic_relevancy_score": 0.3454436659812927
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.32425230741500854
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.3000679314136505
        }
    ],
    [
        {
            "id": "2307.02390",
            "title": "Causal Discovery with Language Models as Imperfect Experts",
            "abstract": "Understanding the causal relationships that underlie a system is a\nfundamental prerequisite to accurate decision-making. In this work, we explore\nhow expert knowledge can be used to improve the data-driven identification of\ncausal graphs, beyond Markov equivalence classes. In doing so, we consider a\nsetting where we can query an expert about the orientation of causal\nrelationships between variables, but where the expert may provide erroneous\ninformation. We propose strategies for amending such expert knowledge based on\nconsistency properties, e.g., acyclicity and conditional independencies in the\nequivalence class. We then report a case study, on real data, where a large\nlanguage model is used as an imperfect expert.",
            "pdfLink": "https://arxiv.org/pdf/2307.02390.pdf",
            "semantic_relevancy_score": 0.5316157341003418
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.4160463213920593
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.31473013758659363
        }
    ],
    [
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.481453001499176
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.4296249747276306
        },
        {
            "id": "2307.05082",
            "title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning",
            "abstract": "This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.",
            "pdfLink": "https://arxiv.org/pdf/2307.05082.pdf",
            "semantic_relevancy_score": 0.36540865898132324
        },
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.34062477946281433
        },
        {
            "id": "2307.09909",
            "title": "Chit-Chat or Deep Talk: Prompt Engineering for Process Mining",
            "abstract": "This research investigates the application of Large Language Models (LLMs) to\naugment conversational agents in process mining, aiming to tackle its inherent\ncomplexity and diverse skill requirements. While LLM advancements present novel\nopportunities for conversational process mining, generating efficient outputs\nis still a hurdle. We propose an innovative approach that amend many issues in\nexisting solutions, informed by prior research on Natural Language Processing\n(NLP) for conversational agents. Leveraging LLMs, our framework improves both\naccessibility and agent performance, as demonstrated by experiments on public\nquestion and data sets. Our research sets the stage for future explorations\ninto LLMs' role in process mining and concludes with propositions for enhancing\nLLM memory, implementing real-time user testing, and examining diverse data\nsets.",
            "pdfLink": "https://arxiv.org/pdf/2307.09909.pdf",
            "semantic_relevancy_score": 0.3261412978172302
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.31523603200912476
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.30458348989486694
        },
        {
            "id": "2305.10601",
            "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
            "abstract": "Language models are increasingly being deployed for general problem solving\nacross a wide range of tasks, but are still confined to token-level,\nleft-to-right decision-making processes during inference. This means they can\nfall short in tasks that require exploration, strategic lookahead, or where\ninitial decisions play a pivotal role. To surmount these challenges, we\nintroduce a new framework for language model inference, Tree of Thoughts (ToT),\nwhich generalizes over the popular Chain of Thought approach to prompting\nlanguage models, and enables exploration over coherent units of text (thoughts)\nthat serve as intermediate steps toward problem solving. ToT allows LMs to\nperform deliberate decision making by considering multiple different reasoning\npaths and self-evaluating choices to decide the next course of action, as well\nas looking ahead or backtracking when necessary to make global choices. Our\nexperiments show that ToT significantly enhances language models'\nproblem-solving abilities on three novel tasks requiring non-trivial planning\nor search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in\nGame of 24, while GPT-4 with chain-of-thought prompting only solved 4% of\ntasks, our method achieved a success rate of 74%. Code repo with all prompts:\nthis https URL.",
            "pdfLink": "https://arxiv.org/pdf/2305.10601.pdf",
            "semantic_relevancy_score": 0.3029398024082184
        }
    ],
    [
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.4586424231529236
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.4523518681526184
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.4018358886241913
        },
        {
            "id": "1801.07243",
            "title": "Personalizing Dialogue Agents: I have a dog, do you have pets too?",
            "abstract": "Chit-chat models are known to have several problems: they lack specificity,\ndo not display a consistent personality and are often not very captivating. In\nthis work we present the task of making chit-chat more engaging by conditioning\non profile information. We collect data and train models to (i) condition on\ntheir given profile information; and (ii) information about the person they are\ntalking to, resulting in improved dialogues, as measured by next utterance\nprediction. Since (ii) is initially unknown our model is trained to engage its\npartner with personal topics, and we show the resulting dialogue can be used to\npredict profile information about the interlocutors.",
            "pdfLink": "https://arxiv.org/pdf/1801.07243.pdf",
            "semantic_relevancy_score": 0.3816313147544861
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.3779107332229614
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.3515833914279938
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.34493258595466614
        },
        {
            "id": "2307.02477",
            "title": "Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks",
            "abstract": "The impressive performance of recent language models across a wide range of\ntasks suggests that they possess a degree of abstract reasoning skills. Are\nthese skills general and transferable, or specialized to specific tasks seen\nduring pretraining? To disentangle these effects, we propose an evaluation\nframework based on \"counterfactual\" task variants that deviate from the default\nassumptions underlying standard tasks. Across a suite of 11 tasks, we observe\nnontrivial performance on the counterfactual variants, but nevertheless find\nthat performance substantially and consistently degrades compared to the\ndefault conditions. This suggests that while current LMs may possess abstract\ntask-solving skills to a degree, they often also rely on narrow,\nnon-transferable procedures for task-solving. These results motivate a more\ncareful interpretation of language model performance that teases apart these\naspects of behavior.",
            "pdfLink": "https://arxiv.org/pdf/2307.02477.pdf",
            "semantic_relevancy_score": 0.31962066888809204
        },
        {
            "id": "2307.02295",
            "title": "Meta-Learning Adversarial Bandit Algorithms",
            "abstract": "We study online meta-learning with bandit feedback, with the goal of\nimproving performance across multiple tasks if they are similar according to\nsome natural similarity measure. As the first to target the adversarial\nonline-within-online partial-information setting, we design meta-algorithms\nthat combine outer learners to simultaneously tune the initialization and other\nhyperparameters of an inner learner for two important cases: multi-armed\nbandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners\ninitialize and set hyperparameters of the Tsallis-entropy generalization of\nExp3, with the task-averaged regret improving if the entropy of the\noptima-in-hindsight is small. For BLO, we learn to initialize and tune online\nmirror descent (OMD) with self-concordant barrier regularizers, showing that\ntask-averaged regret varies directly with an action space-dependent measure\nthey induce. Our guarantees rely on proving that unregularized\nfollow-the-leader combined with two levels of low-dimensional hyperparameter\ntuning is enough to learn a sequence of affine functions of non-Lipschitz and\nsometimes non-convex Bregman divergences bounding the regret of OMD.",
            "pdfLink": "https://arxiv.org/pdf/2307.02295.pdf",
            "semantic_relevancy_score": 0.30528968572616577
        }
    ],
    [
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.31296563148498535
        },
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.3041346073150635
        }
    ],
    [
        {
            "id": "2206.08853",
            "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
            "abstract": "Autonomous agents have made great strides in specialist domains like Atari\ngames and Go. However, they typically learn tabula rasa in isolated\nenvironments with limited and manually conceived objectives, thus failing to\ngeneralize across a wide spectrum of tasks and capabilities. Inspired by how\nhumans continually learn and adapt in the open world, we advocate a trinity of\ningredients for building generalist agents: 1) an environment that supports a\nmultitude of tasks and goals, 2) a large-scale database of multimodal\nknowledge, and 3) a flexible and scalable agent architecture. We introduce\nMineDojo, a new framework built on the popular Minecraft game that features a\nsimulation suite with thousands of diverse open-ended tasks and an\ninternet-scale knowledge base with Minecraft videos, tutorials, wiki pages, and\nforum discussions. Using MineDojo's data, we propose a novel agent learning\nalgorithm that leverages large pre-trained video-language models as a learned\nreward function. Our agent is able to solve a variety of open-ended tasks\nspecified in free-form language without any manually designed dense shaping\nreward. We open-source the simulation suite, knowledge bases, algorithm\nimplementation, and pretrained models (this https URL) to promote\nresearch towards the goal of generally capable embodied agents.",
            "pdfLink": "https://arxiv.org/pdf/2206.08853.pdf",
            "semantic_relevancy_score": 0.3712047338485718
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.3304237127304077
        },
        {
            "id": "2307.02485",
            "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
            "abstract": "Large Language Models (LLMs) have demonstrated impressive planning abilities\nin single-agent embodied tasks across various domains. However, their capacity\nfor planning and communication in multi-agent cooperation remains unclear, even\nthough these are crucial skills for intelligent embodied agents. In this paper,\nwe present a novel framework that utilizes LLMs for multi-agent cooperation and\ntests it in various embodied environments. Our framework enables embodied\nagents to plan, communicate, and cooperate with other embodied agents or humans\nto accomplish long-horizon tasks efficiently. We demonstrate that recent LLMs,\nsuch as GPT-4, can surpass strong planning-based methods and exhibit emergent\neffective communication using our framework without requiring fine-tuning or\nfew-shot prompting. We also discover that LLM-based agents that communicate in\nnatural language can earn more trust and cooperate more effectively with\nhumans. Our research underscores the potential of LLMs for embodied AI and lays\nthe foundation for future research in multi-agent cooperation. Videos can be\nfound on the project website this https URL.",
            "pdfLink": "https://arxiv.org/pdf/2307.02485.pdf",
            "semantic_relevancy_score": 0.32607656717300415
        },
        {
            "id": "2307.07255",
            "title": "Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for Designing Effective Conversational Systems",
            "abstract": "Sharing ideas through communication with peers is the primary mode of human\ninteraction. Consequently, extensive research has been conducted in the area of\nconversational AI, leading to an increase in the availability and diversity of\nconversational tasks, datasets, and methods. However, with numerous tasks being\nexplored simultaneously, the current landscape of conversational AI becomes\nfragmented. Therefore, initiating a well-thought-out model for a dialogue agent\ncan pose significant challenges for a practitioner. Towards highlighting the\ncritical ingredients needed for a practitioner to design a dialogue agent from\nscratch, the current study provides a comprehensive overview of the primary\ncharacteristics of a dialogue agent, the supporting tasks, their corresponding\nopen-domain datasets, and the methods used to benchmark these datasets. We\nobserve that different methods have been used to tackle distinct dialogue\ntasks. However, building separate models for each task is costly and does not\nleverage the correlation among the several tasks of a dialogue agent. As a\nresult, recent trends suggest a shift towards building unified foundation\nmodels. To this end, we propose UNIT, a UNified dIalogue dataseT constructed\nfrom conversations of existing datasets for different dialogue tasks capturing\nthe nuances for each of them. We also examine the evaluation strategies used to\nmeasure the performance of dialogue agents and highlight the scope for future\nresearch in the area of conversational AI.",
            "pdfLink": "https://arxiv.org/pdf/2307.07255.pdf",
            "semantic_relevancy_score": 0.31676381826400757
        }
    ],
    [
        {
            "id": "2307.06917",
            "title": "LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT",
            "abstract": "Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.",
            "pdfLink": "https://arxiv.org/pdf/2307.06917.pdf",
            "semantic_relevancy_score": 0.5160602331161499
        },
        {
            "id": "2307.05082",
            "title": "OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning",
            "abstract": "This research presents a comprehensive methodology for utilizing an\nontology-driven structured prompts system in interplay with ChatGPT, a widely\nused large language model (LLM). The study develops formal models, both\ninformation and functional, and establishes the methodological foundations for\nintegrating ontology-driven prompts with ChatGPT's meta-learning capabilities.\nThe resulting productive triad comprises the methodological foundations,\nadvanced information technology, and the OntoChatGPT system, which collectively\nenhance the effectiveness and performance of chatbot systems. The\nimplementation of this technology is demonstrated using the Ukrainian language\nwithin the domain of rehabilitation. By applying the proposed methodology, the\nOntoChatGPT system effectively extracts entities from contexts, classifies\nthem, and generates relevant responses. The study highlights the versatility of\nthe methodology, emphasizing its applicability not only to ChatGPT but also to\nother chatbot systems based on LLMs, such as Google's Bard utilizing the PaLM 2\nLLM. The underlying principles of meta-learning, structured prompts, and\nontology-driven information retrieval form the core of the proposed\nmethodology, enabling their adaptation and utilization in various LLM-based\nsystems. This versatile approach opens up new possibilities for NLP and\ndialogue systems, empowering developers to enhance the performance and\nfunctionality of chatbot systems across different domains and languages.",
            "pdfLink": "https://arxiv.org/pdf/2307.05082.pdf",
            "semantic_relevancy_score": 0.48427730798721313
        },
        {
            "id": "2307.02390",
            "title": "Causal Discovery with Language Models as Imperfect Experts",
            "abstract": "Understanding the causal relationships that underlie a system is a\nfundamental prerequisite to accurate decision-making. In this work, we explore\nhow expert knowledge can be used to improve the data-driven identification of\ncausal graphs, beyond Markov equivalence classes. In doing so, we consider a\nsetting where we can query an expert about the orientation of causal\nrelationships between variables, but where the expert may provide erroneous\ninformation. We propose strategies for amending such expert knowledge based on\nconsistency properties, e.g., acyclicity and conditional independencies in the\nequivalence class. We then report a case study, on real data, where a large\nlanguage model is used as an imperfect expert.",
            "pdfLink": "https://arxiv.org/pdf/2307.02390.pdf",
            "semantic_relevancy_score": 0.3761667013168335
        },
        {
            "id": "2307.01204",
            "title": "Towards Few-shot Inductive Link Prediction on Knowledge Graphs: A Relational Anonymous Walk-guided Neural Process Approach",
            "abstract": "Few-shot inductive link prediction on knowledge graphs (KGs) aims to predict\nmissing links for unseen entities with few-shot links observed. Previous\nmethods are limited to transductive scenarios, where entities exist in the\nknowledge graphs, so they are unable to handle unseen entities. Therefore,\nrecent inductive methods utilize the sub-graphs around unseen entities to\nobtain the semantics and predict links inductively. However, in the few-shot\nsetting, the sub-graphs are often sparse and cannot provide meaningful\ninductive patterns. In this paper, we propose a novel relational anonymous\nwalk-guided neural process for few-shot inductive link prediction on knowledge\ngraphs, denoted as RawNP. Specifically, we develop a neural process-based\nmethod to model a flexible distribution over link prediction functions. This\nenables the model to quickly adapt to new entities and estimate the uncertainty\nwhen making predictions. To capture general inductive patterns, we present a\nrelational anonymous walk to extract a series of relational motifs from\nfew-shot observations. These motifs reveal the distinctive semantic patterns on\nKGs that support inductive predictions. Extensive experiments on typical\nbenchmark datasets demonstrate that our model derives new state-of-the-art\nperformance.",
            "pdfLink": "https://arxiv.org/pdf/2307.01204.pdf",
            "semantic_relevancy_score": 0.3515883684158325
        },
        {
            "id": "2307.01548",
            "title": "Knowledge Graph for NLG in the context of conversational agents",
            "abstract": "The use of knowledge graphs (KGs) enhances the accuracy and comprehensiveness\nof the responses provided by a conversational agent. While generating answers\nduring conversations consists in generating text from these KGs, it is still\nregarded as a challenging task that has gained significant attention in recent\nyears. In this document, we provide a review of different architectures used\nfor knowledge graph-to-text generation including: Graph Neural Networks, the\nGraph Transformer, and linearization with seq2seq models. We discuss the\nadvantages and limitations of each architecture and conclude that the choice of\narchitecture will depend on the specific requirements of the task at hand. We\nalso highlight the importance of considering constraints such as execution time\nand model validity, particularly in the context of conversational agents. Based\non these constraints and the availability of labeled data for the domains of\nDAVI, we choose to use seq2seq Transformer-based models (PLMs) for the\nKnowledge Graph-to-Text Generation task. We aim to refine benchmark datasets of\nkg-to-text generation on PLMs and to explore the emotional and multilingual\ndimensions in our future work. Overall, this review provides insights into the\ndifferent approaches for knowledge graph-to-text generation and outlines future\ndirections for research in this area.",
            "pdfLink": "https://arxiv.org/pdf/2307.01548.pdf",
            "semantic_relevancy_score": 0.35065552592277527
        },
        {
            "id": "2308.05481",
            "title": "LLM As DBA",
            "abstract": "Database administrators (DBAs) play a crucial role in managing, maintaining and optimizing a database system to ensure data availability, performance, and reliability. However, it is hard and tedious for DBAs to manage a large number of database instances (e.g., millions of instances on the cloud databases). Recently large language models (LLMs) have shown great potential to understand valuable documents and accordingly generate reasonable answers. Thus, we propose D-Bot, a LLM-based database administrator that can continuously acquire database maintenance experience from textual sources, and provide reasonable, well-founded, in-time diagnosis and optimization advice for target databases. This paper presents a revolutionary LLM-centric framework for database maintenance, including (i) database maintenance knowledge detection from documents and tools, (ii) tree of thought reasoning for root cause analysis, and (iii) collaborative diagnosis among multiple LLMs. Our preliminary experimental results that D-Bot can efficiently and effectively diagnose the root causes and our code is available at this http URL.",
            "pdfLink": "https://arxiv.org/pdf/2308.05481.pdf",
            "semantic_relevancy_score": 0.34879112243652344
        },
        {
            "id": "2307.10680",
            "title": "A Personalized Recommender System Based-on Knowledge Graph Embeddings",
            "abstract": "Knowledge graphs have proven to be effective for modeling entities and their\nrelationships through the use of ontologies. The recent emergence in interest\nfor using knowledge graphs as a form of information modeling has led to their\nincreased adoption in recommender systems. By incorporating users and items\ninto the knowledge graph, these systems can better capture the implicit\nconnections between them and provide more accurate recommendations. In this\npaper, we investigate and propose the construction of a personalized\nrecommender system via knowledge graphs embedding applied to the vehicle\npurchase/sale domain. The results of our experimentation demonstrate the\nefficacy of the proposed method in providing relevant recommendations that are\nconsistent with individual users.",
            "pdfLink": "https://arxiv.org/pdf/2307.10680.pdf",
            "semantic_relevancy_score": 0.3317619860172272
        },
        {
            "id": "2307.01933",
            "title": "Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs",
            "abstract": "Knowledge graph embeddings (KGE) have been extensively studied to embed\nlarge-scale relational data for many real-world applications. Existing methods\nhave long ignored the fact many KGs contain two fundamentally different views:\nhigh-level ontology-view concepts and fine-grained instance-view entities. They\nusually embed all nodes as vectors in one latent space. However, a single\ngeometric representation fails to capture the structural differences between\ntwo views and lacks probabilistic semantics towards concepts' granularity. We\npropose Concept2Box, a novel approach that jointly embeds the two views of a KG\nusing dual geometric representations. We model concepts with box embeddings,\nwhich learn the hierarchy structure and complex relations such as overlap and\ndisjoint among them. Box volumes can be interpreted as concepts' granularity.\nDifferent from concepts, we model entities as vectors. To bridge the gap\nbetween concept box embeddings and entity vector embeddings, we propose a novel\nvector-to-box distance metric and learn both embeddings jointly. Experiments on\nboth the public DBpedia KG and a newly-created industrial KG showed the\neffectiveness of Concept2Box.",
            "pdfLink": "https://arxiv.org/pdf/2307.01933.pdf",
            "semantic_relevancy_score": 0.3299228250980377
        },
        {
            "id": "2307.02046",
            "title": "Recommender Systems in the Era of Large Language Models (LLMs)",
            "abstract": "With the prosperity of e-commerce and web applications, Recommender Systems\n(RecSys) have become an important component of our daily life, providing\npersonalized suggestions that cater to user preferences. While Deep Neural\nNetworks (DNNs) have made significant advancements in enhancing recommender\nsystems by modeling user-item interactions and incorporating textual side\ninformation, DNN-based methods still face limitations, such as difficulties in\nunderstanding users' interests and capturing textual side information,\ninabilities in generalizing to various recommendation scenarios and reasoning\non their predictions, etc. Meanwhile, the emergence of Large Language Models\n(LLMs), such as ChatGPT and GPT4, has revolutionized the fields of Natural\nLanguage Processing (NLP) and Artificial Intelligence (AI), due to their\nremarkable abilities in fundamental responsibilities of language understanding\nand generation, as well as impressive generalization and reasoning\ncapabilities. As a result, recent studies have attempted to harness the power\nof LLMs to enhance recommender systems. Given the rapid evolution of this\nresearch direction in recommender systems, there is a pressing need for a\nsystematic overview that summarizes existing LLM-empowered recommender systems,\nto provide researchers in relevant fields with an in-depth understanding.\nTherefore, in this paper, we conduct a comprehensive review of LLM-empowered\nrecommender systems from various aspects including Pre-training, Fine-tuning,\nand Prompting. More specifically, we first introduce representative methods to\nharness the power of LLMs (as a feature encoder) for learning representations\nof users and items. Then, we review recent techniques of LLMs for enhancing\nrecommender systems from three paradigms, namely pre-training, fine-tuning, and\nprompting. Finally, we comprehensively discuss future directions in this\nemerging field.",
            "pdfLink": "https://arxiv.org/pdf/2307.02046.pdf",
            "semantic_relevancy_score": 0.3117198944091797
        },
        {
            "id": "2307.09721",
            "title": "Multi-Grained Multimodal Interaction Network for Entity Linking",
            "abstract": "Multimodal entity linking (MEL) task, which aims at resolving ambiguous\nmentions to a multimodal knowledge graph, has attracted wide attention in\nrecent years. Though large efforts have been made to explore the complementary\neffect among multiple modalities, however, they may fail to fully absorb the\ncomprehensive expression of abbreviated textual context and implicit visual\nindication. Even worse, the inevitable noisy data may cause inconsistency of\ndifferent modalities during the learning process, which severely degenerates\nthe performance. To address the above issues, in this paper, we propose a novel\nMulti-GraIned Multimodal InteraCtion Network (MIMIC)\\textbf{(MIMIC)} framework for\nsolving the MEL task. Specifically, the unified inputs of mentions and entities\nare first encoded by textual/visual encoders separately, to extract global\ndescriptive features and local detailed features. Then, to derive the\nsimilarity matching score for each mention-entity pair, we device three\ninteraction units to comprehensively explore the intra-modal interaction and\ninter-modal fusion among features of entities and mentions. In particular,\nthree modules, namely the Text-based Global-Local interaction Unit (TGLU),\nVision-based DuaL interaction Unit (VDLU) and Cross-Modal Fusion-based\ninteraction Unit (CMFU) are designed to capture and integrate the fine-grained\nrepresentation lying in abbreviated text and implicit visual cues. Afterwards,\nwe introduce a unit-consistency objective function via contrastive learning to\navoid inconsistency and model degradation. Experimental results on three public\nbenchmark datasets demonstrate that our solution outperforms various\nstate-of-the-art baselines, and ablation studies verify the effectiveness of\ndesigned modules.",
            "pdfLink": "https://arxiv.org/pdf/2307.09721.pdf",
            "semantic_relevancy_score": 0.30451691150665283
        }
    ]
]