[
  {
    "id": "2402.19195",
    "title": "Negative Sampling in Knowledge Graph Representation Learning: A Review",
    "abstract": "  Knowledge graph representation learning (KGRL) or knowledge graph embedding\n(KGE) plays a crucial role in AI applications for knowledge construction and\ninformation exploration. These models aim to encode entities and relations\npresent in a knowledge graph into a lower-dimensional vector space. During the\ntraining process of KGE models, using positive and negative samples becomes\nessential for discrimination purposes. However, obtaining negative samples\ndirectly from existing knowledge graphs poses a challenge, emphasizing the need\nfor effective generation techniques. The quality of these negative samples\ngreatly impacts the accuracy of the learned embeddings, making their generation\na critical aspect of KGRL. This comprehensive survey paper systematically\nreviews various negative sampling (NS) methods and their contributions to the\nsuccess of KGRL. Their respective advantages and disadvantages are outlined by\ncategorizing existing NS methods into five distinct categories. Moreover, this\nsurvey identifies open research questions that serve as potential directions\nfor future investigations. By offering a generalization and alignment of\nfundamental NS concepts, this survey provides valuable insights for designing\neffective NS methods in the context of KGRL and serves as a motivating force\nfor further advancements in the field.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19195v1",
    "authors": ["Tiroshan Madushanka", "Ryutaro Ichise"]
  },
  {
    "id": "2402.18784",
    "title": "Brain-inspired and Self-based Artificial Intelligence",
    "abstract": "  The question \"Can machines think?\" and the Turing Test to assess whether\nmachines could achieve human-level intelligence is one of the roots of AI. With\nthe philosophical argument \"I think, therefore I am\", this paper challenge the\nidea of a \"thinking machine\" supported by current AIs since there is no sense\nof self in them. Current artificial intelligence is only seemingly intelligent\ninformation processing and does not truly understand or be subjectively aware\nof oneself and perceive the world with the self as human intelligence does. In\nthis paper, we introduce a Brain-inspired and Self-based Artificial\nIntelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to\ncoordinating various cognitive functions and learning strategies in a\nself-organized manner to build human-level AI models and robotic applications.\nSpecifically, BriSe AI emphasizes the crucial role of the Self in shaping the\nfuture AI, rooted with a practical hierarchical Self framework, including\nPerception and Learning, Bodily Self, Autonomous Self, Social Self, and\nConceptual Self. The hierarchical framework of the Self highlights self-based\nenvironment perception, self-bodily modeling, autonomous interaction with the\nenvironment, social interaction and collaboration with others, and even more\nabstract understanding of the Self. Furthermore, the positive mutual promotion\nand support among multiple levels of Self, as well as between Self and\nlearning, enhance the BriSe AI's conscious understanding of information and\nflexible adaptation to complex environments, serving as a driving force\npropelling BriSe AI towards real Artificial General Intelligence.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18784v1",
    "authors": [
      "Yi Zeng",
      "Feifei Zhao",
      "Yuxuan Zhao",
      "Dongcheng Zhao",
      "Enmeng Lu",
      "Qian Zhang",
      "Yuwei Wang",
      "Hui Feng",
      "Zhuoya Zhao",
      "Jihang Wang",
      "Qingqun Kong",
      "Yinqian Sun",
      "Yang Li",
      "Guobin Shen",
      "Bing Han",
      "Yiting Dong",
      "Wenxuan Pan",
      "Xiang He",
      "Aorigele Bao",
      "Jin Wang"
    ]
  },
  {
    "id": "2402.18807",
    "title": "On the Decision-Making Abilities in Role-Playing using Large Language\n  Models",
    "abstract": "  Large language models (LLMs) are now increasingly utilized for role-playing\ntasks, especially in impersonating domain-specific experts, primarily through\nrole-playing prompts. When interacting in real-world scenarios, the\ndecision-making abilities of a role significantly shape its behavioral\npatterns. In this paper, we concentrate on evaluating the decision-making\nabilities of LLMs post role-playing thereby validating the efficacy of\nrole-playing. Our goal is to provide metrics and guidance for enhancing the\ndecision-making abilities of LLMs in role-playing tasks. Specifically, we first\nuse LLMs to generate virtual role descriptions corresponding to the 16\npersonality types of Myers-Briggs Type Indicator (abbreviated as MBTI)\nrepresenting a segmentation of the population. Then we design specific\nquantitative operations to evaluate the decision-making abilities of LLMs post\nrole-playing from four aspects: adaptability, exploration$\\&$exploitation\ntrade-off ability, reasoning ability, and safety. Finally, we analyze the\nassociation between the performance of decision-making and the corresponding\nMBTI types through GPT-4. Extensive experiments demonstrate stable differences\nin the four aspects of decision-making abilities across distinct roles,\nsignifying a robust correlation between decision-making abilities and the roles\nemulated by LLMs. These results underscore that LLMs can effectively\nimpersonate varied roles while embodying their genuine sociological\ncharacteristics.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18807v1",
    "authors": ["Chenglei Shen", "Guofu Xie", "Xiao Zhang", "Jun Xu"]
  },
  {
    "id": "2402.18815",
    "title": "How do Large Language Models Handle Multilingualism?",
    "abstract": "  Large language models (LLMs) demonstrate remarkable performance across a\nspectrum of languages. In this work, we delve into the question: How do LLMs\nhandle multilingualism? We introduce a framework that depicts LLMs' processing\nof multilingual inputs: In the first several layers, LLMs understand the\nquestion, converting multilingual inputs into English to facilitate the\ntask-solving phase. In the intermediate layers, LLMs engage in problem-solving\nby thinking in English and incorporating multilingual knowledge to obtain\nfactual content, leveraging the self-attention and feed-forward structures,\nrespectively. In the last several layers, LLMs generate responses that align\nwith the original language of the query. In addition, we investigate the\nexistence of language-specific neurons when processing a certain language. To\ndetect neurons activated by the input language, even without labels, we\ninnovatively design a Parallel Language specific Neuron Detection\n($\\texttt{PLND}$) method that effectively measures the significance of neurons\nwhen handling multilingual inputs. By comprehensive ablation analysis through\ndeactivating neurons of different layers and structures, we verify the\nframework that we propose. Additionally, we demonstrate that we can utilize\nsuch a framework to effectively enhance the multilingual ability with much less\ntraining effort.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18815v1",
    "authors": ["Yiran Zhao", "Wenxuan Zhang", "Guizhen Chen", "Kenji Kawaguchi", "Lidong Bing"]
  },
  {
    "id": "2402.18909",
    "title": "Updating Language Models with Unstructured Facts: Towards Practical\n  Knowledge Editing",
    "abstract": "  Knowledge editing aims to inject knowledge updates into language models to\nkeep them correct and up-to-date. However, its current evaluation strategies\nare notably impractical: they solely update with well-curated structured facts\n(triplets with subjects, relations, and objects), whereas real-world knowledge\nupdates commonly emerge in unstructured texts like news articles. In this\npaper, we propose a new benchmark, Unstructured Knowledge Editing (UKE). It\nevaluates editing performance directly using unstructured texts as knowledge\nupdates, termed unstructured facts. Hence UKE avoids the laborious construction\nof structured facts and enables efficient and responsive knowledge editing,\nbecoming a more practical benchmark. We conduct extensive experiments on newly\nbuilt datasets and demonstrate that UKE poses a significant challenge to\nstate-of-the-art knowledge editing methods, resulting in their critical\nperformance declines. We further show that this challenge persists even if we\nextract triplets as structured facts. Our analysis discloses key insights to\nmotivate future research in UKE for more practical knowledge editing.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18909v1",
    "authors": ["Xiaobao Wu", "Liangming Pan", "William Yang Wang", "Anh Tuan Luu"]
  },
  {
    "id": "2402.18913",
    "title": "AdaMergeX: Cross-Lingual Transfer with Large Language Models via\n  Adaptive Adapter Merging",
    "abstract": "  As an effective alternative to the direct fine-tuning on target tasks in\nspecific languages, cross-lingual transfer addresses the challenges of limited\ntraining data by decoupling ''task ability'' and ''language ability'' by\nfine-tuning on the target task in the source language and another selected task\nin the target language, respectively. However, they fail to fully separate the\ntask ability from the source language or the language ability from the chosen\ntask. In this paper, we acknowledge the mutual reliance between task ability\nand language ability and direct our attention toward the gap between the target\nlanguage and the source language on tasks. As the gap removes the impact of\ntasks, we assume that it remains consistent across tasks. Based on this\nassumption, we propose a new cross-lingual transfer method called\n$\\texttt{AdaMergeX}$ that utilizes adaptive adapter merging. By introducing a\nreference task, we can determine that the divergence of adapters fine-tuned on\nthe reference task in both languages follows the same distribution as the\ndivergence of adapters fine-tuned on the target task in both languages. Hence,\nwe can obtain target adapters by combining the other three adapters.\nFurthermore, we propose a structure-adaptive adapter merging method. Our\nempirical results demonstrate that our approach yields new and effective\ncross-lingual transfer, outperforming existing methods across all settings.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18913v1",
    "authors": ["Yiran Zhao", "Wenxuan Zhang", "Huiming Wang", "Kenji Kawaguchi", "Lidong Bing"]
  },
  {
    "id": "2402.18929",
    "title": "Navigating Beyond Dropout: An Intriguing Solution Towards Generalizable\n  Image Super Resolution",
    "abstract": "  Deep learning has led to a dramatic leap on Single Image Super-Resolution\n(SISR) performances in recent years. %Despite the substantial advancement%\nWhile most existing work assumes a simple and fixed degradation model (e.g.,\nbicubic downsampling), the research of Blind SR seeks to improve model\ngeneralization ability with unknown degradation. Recently, Kong et al pioneer\nthe investigation of a more suitable training strategy for Blind SR using\nDropout. Although such method indeed brings substantial generalization\nimprovements via mitigating overfitting, we argue that Dropout simultaneously\nintroduces undesirable side-effect that compromises model's capacity to\nfaithfully reconstruct fine details. We show both the theoretical and\nexperimental analyses in our paper, and furthermore, we present another easy\nyet effective training strategy that enhances the generalization ability of the\nmodel by simply modulating its first and second-order features statistics.\nExperimental results have shown that our method could serve as a model-agnostic\nregularization and outperforms Dropout on seven benchmark datasets including\nboth synthetic and real-world scenarios.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18929v2",
    "authors": ["Hongjun Wang", "Jiyuan Chen", "Yinqiang Zheng", "Tieyong Zeng"]
  },
  {
    "id": "2402.18944",
    "title": "SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in\n  Conversation (EDiReF)",
    "abstract": "  We present SemEval-2024 Task 10, a shared task centred on identifying\nemotions and finding the rationale behind their flips within monolingual\nEnglish and Hindi-English code-mixed dialogues. This task comprises three\ndistinct subtasks - emotion recognition in conversation for code-mixed\ndialogues, emotion flip reasoning for code-mixed dialogues, and emotion flip\nreasoning for English dialogues. Participating systems were tasked to\nautomatically execute one or more of these subtasks. The datasets for these\ntasks comprise manually annotated conversations focusing on emotions and\ntriggers for emotion shifts (The task data is available at\nhttps://github.com/LCS2-IIITD/EDiReF-SemEval2024.git). A total of 84\nparticipants engaged in this task, with the most adept systems attaining\nF1-scores of 0.70, 0.79, and 0.76 for the respective subtasks. This paper\nsummarises the results and findings from 24 teams alongside their system\ndescriptions.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18944v1",
    "authors": ["Shivani Kumar", "Md Shad Akhtar", "Erik Cambria", "Tanmoy Chakraborty"]
  },
  {
    "id": "2402.18960",
    "title": "Towards Out-of-Distribution Detection for breast cancer classification\n  in Point-of-Care Ultrasound Imaging",
    "abstract": "  Deep learning has shown to have great potential in medical applications. In\ncritical domains as such, it is of high interest to have trustworthy algorithms\nwhich are able to tell when reliable assessments cannot be guaranteed.\nDetecting out-of-distribution (OOD) samples is a crucial step towards building\na safe classifier. Following a previous study, showing that it is possible to\nclassify breast cancer in point-of-care ultrasound images, this study\ninvestigates OOD detection using three different methods: softmax, energy score\nand deep ensembles. All methods are tested on three different OOD data sets.\nThe results show that the energy score method outperforms the softmax method,\nperforming well on two of the data sets. The ensemble method is the most\nrobust, performing the best at detecting OOD samples for all three OOD data\nsets.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18960v1",
    "authors": [
      "Jennie Karlsson",
      "Marisa Wodrich",
      "Niels Christian Overgaard",
      "Freja Sahlin",
      "Kristina Lång",
      "Anders Heyden",
      "Ida Arvidsson"
    ]
  },
  {
    "id": "2402.18975",
    "title": "Theoretically Achieving Continuous Representation of Oriented Bounding\n  Boxes",
    "abstract": "  Considerable efforts have been devoted to Oriented Object Detection (OOD).\nHowever, one lasting issue regarding the discontinuity in Oriented Bounding Box\n(OBB) representation remains unresolved, which is an inherent bottleneck for\nextant OOD methods. This paper endeavors to completely solve this issue in a\ntheoretically guaranteed manner and puts an end to the ad-hoc efforts in this\ndirection. Prior studies typically can only address one of the two cases of\ndiscontinuity: rotation and aspect ratio, and often inadvertently introduce\ndecoding discontinuity, e.g. Decoding Incompleteness (DI) and Decoding\nAmbiguity (DA) as discussed in literature. Specifically, we propose a novel\nrepresentation method called Continuous OBB (COBB), which can be readily\nintegrated into existing detectors e.g. Faster-RCNN as a plugin. It can\ntheoretically ensure continuity in bounding box regression which to our best\nknowledge, has not been achieved in literature for rectangle-based object\nrepresentation. For fairness and transparency of experiments, we have developed\na modularized benchmark based on the open-source deep learning framework\nJittor's detection toolbox JDet for OOD evaluation. On the popular DOTA\ndataset, by integrating Faster-RCNN as the same baseline model, our new method\noutperforms the peer method Gliding Vertex by 1.13% mAP50 (relative improvement\n1.54%), and 2.46% mAP75 (relative improvement 5.91%), without any tricks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18975v1",
    "authors": ["Zikai Xiao", "Guo-Ye Yang", "Xue Yang", "Tai-Jiang Mu", "Junchi Yan", "Shi-min Hu"]
  },
  {
    "id": "2402.19002",
    "title": "GoalNet: Goal Areas Oriented Pedestrian Trajectory Prediction",
    "abstract": "  Predicting the future trajectories of pedestrians on the road is an important\ntask for autonomous driving. The pedestrian trajectory prediction is affected\nby scene paths, pedestrian's intentions and decision-making, which is a\nmulti-modal problem. Most recent studies use past trajectories to predict a\nvariety of potential future trajectory distributions, which do not account for\nthe scene context and pedestrian targets. Instead of predicting the future\ntrajectory directly, we propose to use scene context and observed trajectory to\npredict the goal points first, and then reuse the goal points to predict the\nfuture trajectories. By leveraging the information from scene context and\nobserved trajectory, the uncertainty can be limited to a few target areas,\nwhich represent the \"goals\" of the pedestrians. In this paper, we propose\nGoalNet, a new trajectory prediction neural network based on the goal areas of\na pedestrian. Our network can predict both pedestrian's trajectories and\nbounding boxes. The overall model is efficient and modular, and its outputs can\nbe changed according to the usage scenario. Experimental results show that\nGoalNet significantly improves the previous state-of-the-art performance by\n48.7% on the JAAD and 40.8% on the PIE dataset.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19002v1",
    "authors": ["Ching-Lin Lee", "Zhi-Xuan Wang", "Kuan-Ting Lai", "Amar Fadillah"]
  },
  {
    "id": "2402.19009",
    "title": "Generating, Reconstructing, and Representing Discrete and Continuous\n  Data: Generalized Diffusion with Learnable Encoding-Decoding",
    "abstract": "  The vast applications of deep generative models are anchored in three core\ncapabilities -- generating new instances, reconstructing inputs, and learning\ncompact representations -- across various data types, such as discrete\ntext/protein sequences and continuous images. Existing model families, like\nVariational Autoencoders (VAEs), Generative Adversarial Networks (GANs),\nautoregressive models, and diffusion models, generally excel in specific\ncapabilities and data types but fall short in others. We introduce generalized\ndiffusion with learnable encoder-decoder (DiLED), that seamlessly integrates\nthe core capabilities for broad applicability and enhanced performance. DiLED\ngeneralizes the Gaussian noising-denoising in standard diffusion by introducing\nparameterized encoding-decoding. Crucially, DiLED is compatible with the\nwell-established diffusion model objective and training recipes, allowing\neffective learning of the encoder-decoder parameters jointly with diffusion. By\nchoosing appropriate encoder/decoder (e.g., large language models), DiLED\nnaturally applies to different data types. Extensive experiments on text,\nproteins, and images demonstrate DiLED's flexibility to handle diverse data and\ntasks and its strong improvement over various existing models.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19009v1",
    "authors": [
      "Guangyi Liu",
      "Yu Wang",
      "Zeyu Feng",
      "Qiyu Wu",
      "Liping Tang",
      "Yuan Gao",
      "Zhen Li",
      "Shuguang Cui",
      "Julian McAuley",
      "Eric P. Xing",
      "Zichao Yang",
      "Zhiting Hu"
    ]
  },
  {
    "id": "2402.19025",
    "title": "Combination of Weak Learners eXplanations to Improve Random Forest\n  eXplicability Robustness",
    "abstract": "  The notion of robustness in XAI refers to the observed variations in the\nexplanation of the prediction of a learned model with respect to changes in the\ninput leading to that prediction. Intuitively, if the input being explained is\nmodified slightly subtly enough so as to not change the prediction of the model\ntoo much, then we would expect that the explanation provided for that new input\ndoes not change much either. We argue that a combination through discriminative\naveraging of ensembles weak learners explanations can improve the robustness of\nexplanations in ensemble methods.This approach has been implemented and tested\nwith post-hoc SHAP method and Random Forest ensemble with successful results.\nThe improvements obtained have been measured quantitatively and some insights\ninto the explicability robustness in ensemble methods are presented.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19025v1",
    "authors": ["Riccardo Pala", "Esteban García-Cuesta"]
  },
  {
    "id": "2402.19027",
    "title": "How to Train your Antivirus: RL-based Hardening through the\n  Problem-Space",
    "abstract": "  ML-based malware detection on dynamic analysis reports is vulnerable to both\nevasion and spurious correlations. In this work, we investigate a specific ML\narchitecture employed in the pipeline of a widely-known commercial antivirus\ncompany, with the goal to harden it against adversarial malware. Adversarial\ntraining, the sole defensive technique that can confer empirical robustness, is\nnot applicable out of the box in this domain, for the principal reason that\ngradient-based perturbations rarely map back to feasible problem-space\nprograms. We introduce a novel Reinforcement Learning approach for constructing\nadversarial examples, a constituent part of adversarially training a model\nagainst evasion. Our approach comes with multiple advantages. It performs\nmodifications that are feasible in the problem-space, and only those; thus it\ncircumvents the inverse mapping problem. It also makes possible to provide\ntheoretical guarantees on the robustness of the model against a particular set\nof adversarial capabilities. Our empirical exploration validates our\ntheoretical insights, where we can consistently reach 0\\% Attack Success Rate\nafter a few adversarial retraining iterations.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19027v1",
    "authors": [
      "Jacopo Cortellazzi",
      "Ilias Tsingenopoulos",
      "Branislav Bošanský",
      "Simone Aonzo",
      "Davy Preuveneers",
      "Wouter Joosen",
      "Fabio Pierazzi",
      "Lorenzo Cavallaro"
    ]
  },
  {
    "id": "2402.19054",
    "title": "RobWE: Robust Watermark Embedding for Personalized Federated Learning\n  Model Ownership Protection",
    "abstract": "  Embedding watermarks into models has been widely used to protect model\nownership in federated learning (FL). However, existing methods are inadequate\nfor protecting the ownership of personalized models acquired by clients in\npersonalized FL (PFL). This is due to the aggregation of the global model in\nPFL, resulting in conflicts over clients' private watermarks. Moreover,\nmalicious clients may tamper with embedded watermarks to facilitate model\nleakage and evade accountability. This paper presents a robust watermark\nembedding scheme, named RobWE, to protect the ownership of personalized models\nin PFL. We first decouple the watermark embedding of personalized models into\ntwo parts: head layer embedding and representation layer embedding. The head\nlayer belongs to clients' private part without participating in model\naggregation, while the representation layer is the shared part for aggregation.\nFor representation layer embedding, we employ a watermark slice embedding\noperation, which avoids watermark embedding conflicts. Furthermore, we design a\nmalicious watermark detection scheme enabling the server to verify the\ncorrectness of watermarks before aggregating local models. We conduct an\nexhaustive experimental evaluation of RobWE. The results demonstrate that RobWE\nsignificantly outperforms the state-of-the-art watermark embedding schemes in\nFL in terms of fidelity, reliability, and robustness.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19054v1",
    "authors": [
      "Yang Xu",
      "Yunlin Tan",
      "Cheng Zhang",
      "Kai Chi",
      "Peng Sun",
      "Wenyuan Yang",
      "Ju Ren",
      "Hongbo Jiang",
      "Yaoxue Zhang"
    ]
  },
  {
    "id": "2402.19072",
    "title": "TimeXer: Empowering Transformers for Time Series Forecasting with\n  Exogenous Variables",
    "abstract": "  Recent studies have demonstrated remarkable performance in time series\nforecasting. However, due to the partially-observed nature of real-world\napplications, solely focusing on the target of interest, so-called endogenous\nvariables, is usually insufficient to guarantee accurate forecasting. Notably,\na system is often recorded into multiple variables, where the exogenous series\ncan provide valuable external information for endogenous variables. Thus,\nunlike prior well-established multivariate or univariate forecasting that\neither treats all the variables equally or overlooks exogenous information,\nthis paper focuses on a practical setting, which is time series forecasting\nwith exogenous variables. We propose a novel framework, TimeXer, to utilize\nexternal information to enhance the forecasting of endogenous variables. With a\ndeftly designed embedding layer, TimeXer empowers the canonical Transformer\narchitecture with the ability to reconcile endogenous and exogenous\ninformation, where patch-wise self-attention and variate-wise cross-attention\nare employed. Moreover, a global endogenous variate token is adopted to\neffectively bridge the exogenous series into endogenous temporal patches.\nExperimentally, TimeXer significantly improves time series forecasting with\nexogenous variables and achieves consistent state-of-the-art performance in\ntwelve real-world forecasting benchmarks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19072v1",
    "authors": [
      "Yuxuan Wang",
      "Haixu Wu",
      "Jiaxiang Dong",
      "Yong Liu",
      "Yunzhong Qiu",
      "Haoran Zhang",
      "Jianmin Wang",
      "Mingsheng Long"
    ]
  },
  {
    "id": "2402.19088",
    "title": "Survey in Characterization of Semantic Change",
    "abstract": "  Live languages continuously evolve to integrate the cultural change of human\nsocieties. This evolution manifests through neologisms (new words) or\n\\textbf{semantic changes} of words (new meaning to existing words).\nUnderstanding the meaning of words is vital for interpreting texts coming from\ndifferent cultures (regionalism or slang), domains (e.g., technical terms), or\nperiods. In computer science, these words are relevant to computational\nlinguistics algorithms such as translation, information retrieval, question\nanswering, etc. Semantic changes can potentially impact the quality of the\noutcomes of these algorithms. Therefore, it is important to understand and\ncharacterize these changes formally. The study of this impact is a recent\nproblem that has attracted the attention of the computational linguistics\ncommunity. Several approaches propose methods to detect semantic changes with\ngood precision, but more effort is needed to characterize how the meaning of\nwords changes and to reason about how to reduce the impact of semantic change.\nThis survey provides an understandable overview of existing approaches to the\n\\textit{characterization of semantic changes} and also formally defines three\nclasses of characterizations: if the meaning of a word becomes more general or\nnarrow (change in dimension) if the word is used in a more pejorative or\npositive/ameliorated sense (change in orientation), and if there is a trend to\nuse the word in a, for instance, metaphoric or metonymic context (change in\nrelation). We summarized the main aspects of the selected publications in a\ntable and discussed the needs and trends in the research activities on semantic\nchange characterization.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19088v1",
    "authors": ["Jader Martins Camboim de Sá", "Marcos Da Silveira", "Cédric Pruski"]
  },
  {
    "id": "2402.19103",
    "title": "Whispers that Shake Foundations: Analyzing and Mitigating False Premise\n  Hallucinations in Large Language Models",
    "abstract": "  Large Language Models (LLMs) have shown impressive capabilities but still\nsuffer from the issue of hallucinations. A significant type of this issue is\nthe false premise hallucination, which we define as the phenomenon when LLMs\ngenerate hallucinated text when confronted with false premise questions. In\nthis paper, we perform a comprehensive analysis of the false premise\nhallucination and elucidate its internal working mechanism: a small subset of\nattention heads (which we designate as false premise heads) disturb the\nknowledge extraction process, leading to the occurrence of false premise\nhallucination. Based on our analysis, we propose \\textbf{FAITH} (\\textbf{F}alse\npremise \\textbf{A}ttention head constra\\textbf{I}ining for mi\\textbf{T}igating\n\\textbf{H}allucinations), a novel and effective method to mitigate false\npremise hallucinations. It constrains the false premise attention heads during\nthe model inference process. Impressively, extensive experiments demonstrate\nthat constraining only approximately $1\\%$ of the attention heads in the model\nyields a notable increase of nearly $20\\%$ of model performance.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19103v1",
    "authors": [
      "Hongbang Yuan",
      "Pengfei Cao",
      "Zhuoran Jin",
      "Yubo Chen",
      "Daojian Zeng",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  {
    "id": "2402.19105",
    "title": "CollaFuse: Navigating Limited Resources and Privacy in Collaborative\n  Generative AI",
    "abstract": "  In the landscape of generative artificial intelligence, diffusion-based\nmodels present challenges for socio-technical systems in data requirements and\nprivacy. Traditional approaches like federated learning distribute the learning\nprocess but strain individual clients, especially with constrained resources\n(e.g., edge devices). In response to these challenges, we introduce CollaFuse,\na novel framework inspired by split learning. Tailored for efficient and\ncollaborative use of denoising diffusion probabilistic models, CollaFuse\nenables shared server training and inference, alleviating client computational\nburdens. This is achieved by retaining data and computationally inexpensive GPU\nprocesses locally at each client while outsourcing the computationally\nexpensive processes to the shared server. Demonstrated in a healthcare context,\nCollaFuse enhances privacy by highly reducing the need for sensitive\ninformation sharing. These capabilities hold the potential to impact various\napplication areas, such as the design of edge computing solutions, healthcare\nresearch, or autonomous driving. In essence, our work advances distributed\nmachine learning, shaping the future of collaborative GenAI networks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19105v1",
    "authors": ["Domenique Zipperling", "Simeon Allmendinger", "Lukas Struppek", "Niklas Kühl"]
  },
  {
    "id": "2402.19116",
    "title": "How to Understand \"Support\"? An Implicit-enhanced Causal Inference\n  Approach for Weakly-supervised Phrase Grounding",
    "abstract": "  Weakly-supervised Phrase Grounding (WPG) is an emerging task of inferring the\nfine-grained phrase-region matching, while merely leveraging the coarse-grained\nsentence-image pairs for training. However, existing studies on WPG largely\nignore the implicit phrase-region matching relations, which are crucial for\nevaluating the capability of models in understanding the deep multimodal\nsemantics. To this end, this paper proposes an Implicit-Enhanced Causal\nInference (IECI) approach to address the challenges of modeling the implicit\nrelations and highlighting them beyond the explicit. Specifically, this\napproach leverages both the intervention and counterfactual techniques to\ntackle the above two challenges respectively. Furthermore, a high-quality\nimplicit-enhanced dataset is annotated to evaluate IECI and detailed\nevaluations show the great advantages of IECI over the state-of-the-art\nbaselines. Particularly, we observe an interesting finding that IECI\noutperforms the advanced multimodal LLMs by a large margin on this\nimplicit-enhanced dataset, which may facilitate more research to evaluate the\nmultimodal LLMs in this direction.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19116v2",
    "authors": ["Jiamin Luo", "Jianing Zhao", "Jingjing Wang", "Guodong Zhou"]
  },
  {
    "id": "2402.19135",
    "title": "Think Fast, Think Slow, Think Critical: Designing an Automated\n  Propaganda Detection Tool",
    "abstract": "  In today's digital age, characterized by rapid news consumption and\nincreasing vulnerability to propaganda, fostering citizens' critical thinking\nis crucial for stable democracies. This paper introduces the design of\nClarifAI, a novel automated propaganda detection tool designed to nudge readers\ntowards more critical news consumption by activating the analytical mode of\nthinking, following Kahneman's dual-system theory of cognition. Using Large\nLanguage Models, ClarifAI detects propaganda in news articles and provides\ncontext-rich explanations, enhancing users' understanding and critical\nthinking. Our contribution is threefold: first, we propose the design of\nClarifAI; second, in an online experiment, we demonstrate that this design\neffectively encourages news readers to engage in more critical reading; and\nthird, we emphasize the value of explanations for fostering critical thinking.\nThe study thus offers both a practical tool and useful design knowledge for\nmitigating propaganda in digital news.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19135v1",
    "authors": [
      "Liudmila Zavolokina",
      "Kilian Sprenkamp",
      "Zoya Katashinskaya",
      "Daniel Gordon Jones",
      "Gerhard Schwabe"
    ]
  },
  {
    "id": "2402.19170",
    "title": "Improving Legal Judgement Prediction in Romanian with Long Text Encoders",
    "abstract": "  In recent years,the entire field of Natural Language Processing (NLP) has\nenjoyed amazing novel results achieving almost human-like performance on a\nvariety of tasks. Legal NLP domain has also been part of this process, as it\nhas seen an impressive growth. However, general-purpose models are not readily\napplicable for legal domain. Due to the nature of the domain (e.g. specialized\nvocabulary, long documents) specific models and methods are often needed for\nLegal NLP. In this work we investigate both specialized and general models for\npredicting the final ruling of a legal case, task known as Legal Judgment\nPrediction (LJP). We particularly focus on methods to extend to sequence length\nof Transformer-based models to better understand the long documents present in\nlegal corpora. Extensive experiments on 4 LJP datasets in Romanian, originating\nfrom 2 sources with significantly different sizes and document lengths, show\nthat specialized models and handling long texts are critical for a good\nperformance.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19170v2",
    "authors": ["Mihai Masala", "Traian Rebedea", "Horia Velicu"]
  },
  {
    "id": "2402.19173",
    "title": "StarCoder 2 and The Stack v2: The Next Generation",
    "abstract": "  The BigCode project, an open-scientific collaboration focused on the\nresponsible development of Large Language Models for Code (Code LLMs),\nintroduces StarCoder2. In partnership with Software Heritage (SWH), we build\nThe Stack v2 on top of the digital commons of their source code archive.\nAlongside the SWH repositories spanning 619 programming languages, we carefully\nselect other high-quality data sources, such as GitHub pull requests, Kaggle\nnotebooks, and code documentation. This results in a training set that is 4x\nlarger than the first StarCoder dataset. We train StarCoder2 models with 3B,\n7B, and 15B parameters on 3.3 to 4.3 trillion tokens and thoroughly evaluate\nthem on a comprehensive set of Code LLM benchmarks. We find that our small\nmodel, StarCoder2-3B, outperforms other Code LLMs of similar size on most\nbenchmarks, and also outperforms StarCoderBase-15B. Our large model,\nStarCoder2- 15B, significantly outperforms other models of comparable size. In\naddition, it matches or outperforms CodeLlama-34B, a model more than twice its\nsize. Although DeepSeekCoder- 33B is the best-performing model at code\ncompletion for high-resource languages, we find that StarCoder2-15B outperforms\nit on math and code reasoning benchmarks, as well as several low-resource\nlanguages. We make the model weights available under an OpenRAIL license and\nensure full transparency regarding the training data by releasing the SoftWare\nHeritage persistent IDentifiers (SWHIDs) of the source code data.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19173v1",
    "authors": [
      "Anton Lozhkov",
      "Raymond Li",
      "Loubna Ben Allal",
      "Federico Cassano",
      "Joel Lamy-Poirier",
      "Nouamane Tazi",
      "Ao Tang",
      "Dmytro Pykhtar",
      "Jiawei Liu",
      "Yuxiang Wei",
      "Tianyang Liu",
      "Max Tian",
      "Denis Kocetkov",
      "Arthur Zucker",
      "Younes Belkada",
      "Zijian Wang",
      "Qian Liu",
      "Dmitry Abulkhanov",
      "Indraneil Paul",
      "Zhuang Li",
      "Wen-Ding Li",
      "Megan Risdal",
      "Jia Li",
      "Jian Zhu",
      "Terry Yue Zhuo",
      "Evgenii Zheltonozhskii",
      "Nii Osae Osae Dade",
      "Wenhao Yu",
      "Lucas Krauß",
      "Naman Jain",
      "Yixuan Su",
      "Xuanli He",
      "Manan Dey",
      "Edoardo Abati",
      "Yekun Chai",
      "Niklas Muennighoff",
      "Xiangru Tang",
      "Muhtasham Oblokulov",
      "Christopher Akiki",
      "Marc Marone",
      "Chenghao Mou",
      "Mayank Mishra",
      "Alex Gu",
      "Binyuan Hui",
      "Tri Dao",
      "Armel Zebaze",
      "Olivier Dehaene",
      "Nicolas Patry",
      "Canwen Xu",
      "Julian McAuley",
      "Han Hu",
      "Torsten Scholak",
      "Sebastien Paquet",
      "Jennifer Robinson",
      "Carolyn Jane Anderson",
      "Nicolas Chapados",
      "Mostofa Patwary",
      "Nima Tajbakhsh",
      "Yacine Jernite",
      "Carlos Muñoz Ferrandis",
      "Lingming Zhang",
      "Sean Hughes",
      "Thomas Wolf",
      "Arjun Guha",
      "Leandro von Werra",
      "Harm de Vries"
    ]
  },
  {
    "id": "2402.19251",
    "title": "A Cognitive-Based Trajectory Prediction Approach for Autonomous Driving",
    "abstract": "  In autonomous vehicle (AV) technology, the ability to accurately predict the\nmovements of surrounding vehicles is paramount for ensuring safety and\noperational efficiency. Incorporating human decision-making insights enables\nAVs to more effectively anticipate the potential actions of other vehicles,\nsignificantly improving prediction accuracy and responsiveness in dynamic\nenvironments. This paper introduces the Human-Like Trajectory Prediction (HLTP)\nmodel, which adopts a teacher-student knowledge distillation framework inspired\nby human cognitive processes. The HLTP model incorporates a sophisticated\nteacher-student knowledge distillation framework. The \"teacher\" model, equipped\nwith an adaptive visual sector, mimics the visual processing of the human\nbrain, particularly the functions of the occipital and temporal lobes. The\n\"student\" model focuses on real-time interaction and decision-making, drawing\nparallels to prefrontal and parietal cortex functions. This approach allows for\ndynamic adaptation to changing driving scenarios, capturing essential\nperceptual cues for accurate prediction. Evaluated using the Macao Connected\nand Autonomous Driving (MoCAD) dataset, along with the NGSIM and HighD\nbenchmarks, HLTP demonstrates superior performance compared to existing models,\nparticularly in challenging environments with incomplete data. The project page\nis available at Github.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19251v1",
    "authors": [
      "Haicheng Liao",
      "Yongkang Li",
      "Zhenning Li",
      "Chengyue Wang",
      "Zhiyong Cui",
      "Shengbo Eben Li",
      "Chengzhong Xu"
    ]
  },
  {
    "id": "2402.19263",
    "title": "Spinal Osteophyte Detection via Robust Patch Extraction on minimally\n  annotated X-rays",
    "abstract": "  The development and progression of arthritis is strongly associated with\nosteophytes, which are small and elusive bone growths. This paper presents one\nof the first efforts towards automated spinal osteophyte detection in spinal\nX-rays. A novel automated patch extraction process, called SegPatch, has been\nproposed based on deep learning-driven vertebrae segmentation and the\nenlargement of mask contours. A final patch classification accuracy of 84.5\\%\nis secured, surpassing a baseline tiling-based patch generation technique by\n9.5%. This demonstrates that even with limited annotations, SegPatch can\ndeliver superior performance for detection of tiny structures such as\nosteophytes. The proposed approach has potential to assist clinicians in\nexpediting the process of manually identifying osteophytes in spinal X-ray.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19263v1",
    "authors": [
      "Soumya Snigdha Kundu",
      "Yuanhan Mo",
      "Nicharee Srikijkasemwat",
      "Bartłomiej W. Papiez"
    ]
  },
  {
    "id": "2402.19267",
    "title": "Robust Guidance for Unsupervised Data Selection: Capturing Perplexing\n  Named Entities for Domain-Specific Machine Translation",
    "abstract": "  Employing extensive datasets enables the training of multilingual machine\ntranslation models; however, these models often fail to accurately translate\nsentences within specialized domains. Although obtaining and translating\ndomain-specific data incurs high costs, it is inevitable for high-quality\ntranslations. Hence, finding the most 'effective' data with an unsupervised\nsetting becomes a practical strategy for reducing labeling costs. Recent\nresearch indicates that this effective data could be found by selecting\n'properly difficult data' based on its volume. This means the data should not\nbe excessively challenging or overly simplistic, especially if the amount of\ndata is limited. However, we found that establishing a criterion for\nunsupervised data selection remains challenging, as the 'proper difficulty'\nmight vary based on the data domain being trained on. We introduce a novel\nunsupervised data selection method, 'Capturing Perplexing Named Entities',\nwhich adopts the maximum inference entropy in translated named entities as a\nselection measure. The motivation was that named entities in domain-specific\ndata are considered the most complex portion of the data and should be\npredicted with high confidence. When verified with the 'Korean-English Parallel\nCorpus of Specialized Domains,' our method served as a robust guidance for\nunsupervised data selection, in contrast to existing methods.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19267v1",
    "authors": ["Seunghyun Ji", "Hagai Raja Sinulingga", "Darongsae Kwon"]
  },
  {
    "id": "2402.19294",
    "title": "Degradation Modeling and Prognostic Analysis Under Unknown Failure Modes",
    "abstract": "  Operating units often experience various failure modes in complex systems,\nleading to distinct degradation paths. Relying on a prognostic model trained on\na single failure mode may lead to poor generalization performance across\nmultiple failure modes. Therefore, accurately identifying the failure mode is\nof critical importance. Current prognostic approaches either ignore failure\nmodes during degradation or assume known failure mode labels, which can be\nchallenging to acquire in practice. Moreover, the high dimensionality and\ncomplex relations of sensor signals make it challenging to identify the failure\nmodes accurately. To address these issues, we propose a novel failure mode\ndiagnosis method that leverages a dimension reduction technique called UMAP\n(Uniform Manifold Approximation and Projection) to project and visualize each\nunit's degradation trajectory into a lower dimension. Then, using these\ndegradation trajectories, we develop a time series-based clustering method to\nidentify the training units' failure modes. Finally, we introduce a\nmonotonically constrained prognostic model to predict the failure mode labels\nand RUL of the test units simultaneously using the obtained failure modes of\nthe training units. The proposed prognostic model provides failure\nmode-specific RUL predictions while preserving the monotonic property of the\nRUL predictions across consecutive time steps. We evaluate the proposed model\nusing a case study with the aircraft gas turbine engine dataset.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19294v1",
    "authors": ["Ying Fu", "Ye Kwon Huh", "Kaibo Liu"]
  },
  {
    "id": "2402.19299",
    "title": "RL-GPT: Integrating Reinforcement Learning and Code-as-policy",
    "abstract": "  Large Language Models (LLMs) have demonstrated proficiency in utilizing\nvarious tools by coding, yet they face limitations in handling intricate logic\nand precise control. In embodied tasks, high-level planning is amenable to\ndirect coding, while low-level actions often necessitate task-specific\nrefinement, such as Reinforcement Learning (RL). To seamlessly integrate both\nmodalities, we introduce a two-level hierarchical framework, RL-GPT, comprising\na slow agent and a fast agent. The slow agent analyzes actions suitable for\ncoding, while the fast agent executes coding tasks. This decomposition\neffectively focuses each agent on specific tasks, proving highly efficient\nwithin our pipeline. Our approach outperforms traditional RL methods and\nexisting GPT agents, demonstrating superior efficiency. In the Minecraft game,\nit rapidly obtains diamonds within a single day on an RTX3090. Additionally, it\nachieves SOTA performance across all designated MineDojo tasks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19299v1",
    "authors": [
      "Shaoteng Liu",
      "Haoqi Yuan",
      "Minda Hu",
      "Yanwei Li",
      "Yukang Chen",
      "Shu Liu",
      "Zongqing Lu",
      "Jiaya Jia"
    ]
  },
  {
    "id": "2402.19339",
    "title": "Stitching Gaps: Fusing Situated Perceptual Knowledge with Vision\n  Transformers for High-Level Image Classification",
    "abstract": "  The increasing demand for automatic high-level image understanding,\nparticularly in detecting abstract concepts (AC) within images, underscores the\nnecessity for innovative and more interpretable approaches. These approaches\nneed to harmonize traditional deep vision methods with the nuanced,\ncontext-dependent knowledge humans employ to interpret images at intricate\nsemantic levels. In this work, we leverage situated perceptual knowledge of\ncultural images to enhance performance and interpretability in AC image\nclassification. We automatically extract perceptual semantic units from images,\nwhich we then model and integrate into the ARTstract Knowledge Graph (AKG).\nThis resource captures situated perceptual semantics gleaned from over 14,000\ncultural images labeled with ACs. Additionally, we enhance the AKG with\nhigh-level linguistic frames. We compute KG embeddings and experiment with\nrelative representations and hybrid approaches that fuse these embeddings with\nvisual transformer embeddings. Finally, for interpretability, we conduct\nposthoc qualitative analyses by examining model similarities with training\ninstances. Our results show that our hybrid KGE-ViT methods outperform existing\ntechniques in AC image classification. The posthoc interpretability analyses\nreveal the visual transformer's proficiency in capturing pixel-level visual\nattributes, contrasting with our method's efficacy in representing more\nabstract and semantic scene elements. We demonstrate the synergy and\ncomplementarity between KGE embeddings' situated perceptual knowledge and deep\nvisual model's sensory-perceptual understanding for AC image classification.\nThis work suggests a strong potential of neuro-symbolic methods for knowledge\nintegration and robust image representation for use in downstream intricate\nvisual comprehension tasks. All the materials and code are available online.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19339v1",
    "authors": ["Delfina Sol Martinez Pandiani", "Nicolas Lazzari", "Valentina Presutti"]
  },
  {
    "id": "2402.19348",
    "title": "Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy,\n  Advances, and Outlook",
    "abstract": "  As cities continue to burgeon, Urban Computing emerges as a pivotal\ndiscipline for sustainable development by harnessing the power of cross-domain\ndata fusion from diverse sources (e.g., geographical, traffic, social media,\nand environmental data) and modalities (e.g., spatio-temporal, visual, and\ntextual modalities). Recently, we are witnessing a rising trend that utilizes\nvarious deep-learning methods to facilitate cross-domain data fusion in smart\ncities. To this end, we propose the first survey that systematically reviews\nthe latest advancements in deep learning-based data fusion methods tailored for\nurban computing. Specifically, we first delve into data perspective to\ncomprehend the role of each modality and data source. Secondly, we classify the\nmethodology into four primary categories: feature-based, alignment-based,\ncontrast-based, and generation-based fusion methods. Thirdly, we further\ncategorize multi-modal urban applications into seven types: urban planning,\ntransportation, economy, public safety, society, environment, and energy.\nCompared with previous surveys, we focus more on the synergy of deep learning\nmethods with urban computing applications. Furthermore, we shed light on the\ninterplay between Large Language Models (LLMs) and urban computing, postulating\nfuture research directions that could revolutionize the field. We firmly\nbelieve that the taxonomy, progress, and prospects delineated in our survey\nstand poised to significantly enrich the research community. The summary of the\ncomprehensive and up-to-date paper list can be found at\nhttps://github.com/yoshall/Awesome-Multimodal-Urban-Computing.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19348v1",
    "authors": [
      "Xingchen Zou",
      "Yibo Yan",
      "Xixuan Hao",
      "Yuehong Hu",
      "Haomin Wen",
      "Erdong Liu",
      "Junbo Zhang",
      "Yong Li",
      "Tianrui Li",
      "Yu Zheng",
      "Yuxuan Liang"
    ]
  },
  {
    "id": "2402.19366",
    "title": "SoK: Exploring the Potential of Large Language Models for Improving\n  Digital Forensic Investigation Efficiency",
    "abstract": "  The growing number of cases requiring digital forensic analysis raises\nconcerns about law enforcement's ability to conduct investigations promptly.\nConsequently, this systemisation of knowledge paper delves into the potential\nand effectiveness of integrating Large Language Models (LLMs) into digital\nforensic investigation to address these challenges. A thorough literature\nreview is undertaken, encompassing existing digital forensic models, tools,\nLLMs, deep learning techniques, and the utilisation of LLMs in investigations.\nThe review identifies current challenges within existing digital forensic\nprocesses and explores both the obstacles and possibilities of incorporating\nLLMs. In conclusion, the study asserts that the adoption of LLMs in digital\nforensics, with appropriate constraints, holds the potential to enhance\ninvestigation efficiency, improve traceability, and alleviate technical and\njudicial barriers faced by law enforcement entities.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19366v1",
    "authors": ["Akila Wickramasekara", "Frank Breitinger", "Mark Scanlon"]
  },
  {
    "id": "2402.19402",
    "title": "A Scalable and Transferable Time Series Prediction Framework for Demand\n  Forecasting",
    "abstract": "  Time series forecasting is one of the most essential and ubiquitous tasks in\nmany business problems, including demand forecasting and logistics\noptimization. Traditional time series forecasting methods, however, have\nresulted in small models with limited expressive power because they have\ndifficulty in scaling their model size up while maintaining high accuracy. In\nthis paper, we propose Forecasting orchestra (Forchestra), a simple but\npowerful framework capable of accurately predicting future demand for a diverse\nrange of items. We empirically demonstrate that the model size is scalable to\nup to 0.8 billion parameters. The proposed method not only outperforms existing\nforecasting models with a significant margin, but it could generalize well to\nunseen data points when evaluated in a zero-shot fashion on downstream\ndatasets. Last but not least, we present extensive qualitative and quantitative\nstudies to analyze how the proposed model outperforms baseline models and\ndiffers from conventional approaches. The original paper was presented as a\nfull paper at ICDM 2022 and is available at:\nhttps://ieeexplore.ieee.org/document/10027662.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19402v1",
    "authors": ["Young-Jin Park", "Donghyun Kim", "Frédéric Odermatt", "Juho Lee", "Kyung-Min Kim"]
  },
  {
    "id": "2402.19406",
    "title": "On the Scaling Laws of Geographical Representation in Language Models",
    "abstract": "  Language models have long been shown to embed geographical information in\ntheir hidden representations. This line of work has recently been revisited by\nextending this result to Large Language Models (LLMs). In this paper, we\npropose to fill the gap between well-established and recent literature by\nobserving how geographical knowledge evolves when scaling language models. We\nshow that geographical knowledge is observable even for tiny models, and that\nit scales consistently as we increase the model size. Notably, we observe that\nlarger language models cannot mitigate the geographical bias that is inherent\nto the training data.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19406v2",
    "authors": ["Nathan Godey", "Éric de la Clergerie", "Benoît Sagot"]
  },
  {
    "id": "2402.19422",
    "title": "PEM: Prototype-based Efficient MaskFormer for Image Segmentation",
    "abstract": "  Recent transformer-based architectures have shown impressive results in the\nfield of image segmentation. Thanks to their flexibility, they obtain\noutstanding performance in multiple segmentation tasks, such as semantic and\npanoptic, under a single unified framework. To achieve such impressive\nperformance, these architectures employ intensive operations and require\nsubstantial computational resources, which are often not available, especially\non edge devices. To fill this gap, we propose Prototype-based Efficient\nMaskFormer (PEM), an efficient transformer-based architecture that can operate\nin multiple segmentation tasks. PEM proposes a novel prototype-based\ncross-attention which leverages the redundancy of visual features to restrict\nthe computation and improve the efficiency without harming the performance. In\naddition, PEM introduces an efficient multi-scale feature pyramid network,\ncapable of extracting features that have high semantic content in an efficient\nway, thanks to the combination of deformable convolutions and context-based\nself-modulation. We benchmark the proposed PEM architecture on two tasks,\nsemantic and panoptic segmentation, evaluated on two different datasets,\nCityscapes and ADE20K. PEM demonstrates outstanding performance on every task\nand dataset, outperforming task-specific architectures while being comparable\nand even better than computationally-expensive baselines.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19422v2",
    "authors": [
      "Niccolò Cavagnero",
      "Gabriele Rosi",
      "Claudia Cuttano",
      "Francesca Pistilli",
      "Marco Ciccone",
      "Giuseppe Averta",
      "Fabio Cermelli"
    ]
  },
  {
    "id": "2402.19423",
    "title": "Leveraging AI Predicted and Expert Revised Annotations in Interactive\n  Segmentation: Continual Tuning or Full Training?",
    "abstract": "  Interactive segmentation, an integration of AI algorithms and human\nexpertise, premises to improve the accuracy and efficiency of curating\nlarge-scale, detailed-annotated datasets in healthcare. Human experts revise\nthe annotations predicted by AI, and in turn, AI improves its predictions by\nlearning from these revised annotations. This interactive process continues to\nenhance the quality of annotations until no major revision is needed from\nexperts. The key challenge is how to leverage AI predicted and expert revised\nannotations to iteratively improve the AI. Two problems arise: (1) The risk of\ncatastrophic forgetting--the AI tends to forget the previously learned classes\nif it is only retrained using the expert revised classes. (2) Computational\ninefficiency when retraining the AI using both AI predicted and expert revised\nannotations; moreover, given the dominant AI predicted annotations in the\ndataset, the contribution of newly revised annotations--often account for a\nvery small fraction--to the AI training remains marginal. This paper proposes\nContinual Tuning to address the problems from two perspectives: network design\nand data reuse. Firstly, we design a shared network for all classes followed by\nclass-specific networks dedicated to individual classes. To mitigate\nforgetting, we freeze the shared network for previously learned classes and\nonly update the class-specific network for revised classes. Secondly, we reuse\na small fraction of data with previous annotations to avoid over-computing. The\nselection of such data relies on the importance estimate of each data. The\nimportance score is computed by combining the uncertainty and consistency of AI\npredictions. Our experiments demonstrate that Continual Tuning achieves a speed\n16x greater than repeatedly training AI from scratch without compromising the\nperformance.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19423v1",
    "authors": ["Tiezheng Zhang", "Xiaoxi Chen", "Chongyu Qu", "Alan Yuille", "Zongwei Zhou"]
  },
  {
    "id": "2402.19450",
    "title": "Functional Benchmarks for Robust Evaluation of Reasoning Performance,\n  and the Reasoning Gap",
    "abstract": "  We propose a framework for robust evaluation of reasoning capabilities of\nlanguage models, using functional variants of benchmarks. Models that solve a\nreasoning test should exhibit no difference in performance over the static\nversion of a problem compared to a snapshot of the functional variant. We have\nrewritten the relevant fragment of the MATH benchmark into its functional\nvariant MATH(), with functionalization of other benchmarks to follow. When\nevaluating current state-of-the-art models over snapshots of MATH(), we find a\nreasoning gap -- the percentage difference between the static and functional\naccuracies. We find reasoning gaps from 58.35% to 80.31% among the\nstate-of-the-art closed and open weights models that perform well on static\nbenchmarks, with the caveat that the gaps are likely to be smaller with more\nsophisticated prompting strategies. Here we show that models which anecdotally\nhave good reasoning performance over real-world tasks, have quantifiable lower\ngaps, motivating the open problem of building \"gap 0\" models. Code for\nevaluation and new evaluation datasets, three MATH() snapshots, are publicly\navailable at https://github.com/consequentai/fneval/.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19450v1",
    "authors": [
      "Saurabh Srivastava",
      "Annarose M B",
      "Anto P V",
      "Shashank Menon",
      "Ajay Sukumar",
      "Adwaith Samod T",
      "Alan Philipose",
      "Stevin Prince",
      "Sooraj Thomas"
    ]
  },
  {
    "id": "2402.19457",
    "title": "$\\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization\n  Evaluation",
    "abstract": "  Assessing the quality of summarizers poses significant challenges. In\nresponse, we propose a novel task-oriented evaluation approach that assesses\nsummarizers based on their capacity to produce summaries that are useful for\ndownstream tasks, while preserving task outcomes. We theoretically establish a\ndirect relationship between the resulting error probability of these tasks and\nthe mutual information between source texts and generated summaries. We\nintroduce $\\texttt{COSMIC}$ as a practical implementation of this metric,\ndemonstrating its strong correlation with human judgment-based metrics and its\neffectiveness in predicting downstream task performance. Comparative analyses\nagainst established metrics like $\\texttt{BERTScore}$ and $\\texttt{ROUGE}$\nhighlight the competitive performance of $\\texttt{COSMIC}$.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19457v2",
    "authors": ["Maxime Darrin", "Philippe Formont", "Jackie Chi Kit Cheung", "Pablo Piantanida"]
  },
  {
    "id": "2402.19465",
    "title": "Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period\n  of Large Language Models",
    "abstract": "  Ensuring the trustworthiness of large language models (LLMs) is crucial. Most\nstudies concentrate on fully pre-trained LLMs to better understand and improve\nLLMs' trustworthiness. In this paper, to reveal the untapped potential of\npre-training, we pioneer the exploration of LLMs' trustworthiness during this\nperiod, focusing on five key dimensions: reliability, privacy, toxicity,\nfairness, and robustness. To begin with, we apply linear probing to LLMs. The\nhigh probing accuracy suggests that \\textit{LLMs in early pre-training can\nalready distinguish concepts in each trustworthiness dimension}. Therefore, to\nfurther uncover the hidden possibilities of pre-training, we extract steering\nvectors from a LLM's pre-training checkpoints to enhance the LLM's\ntrustworthiness. Finally, inspired by~\\citet{choi2023understanding} that mutual\ninformation estimation is bounded by linear probing accuracy, we also probe\nLLMs with mutual information to investigate the dynamics of trustworthiness\nduring pre-training. We are the first to observe a similar two-phase\nphenomenon: fitting and compression~\\citep{shwartz2017opening}. This research\nprovides an initial exploration of trustworthiness modeling during LLM\npre-training, seeking to unveil new insights and spur further developments in\nthe field. We will make our code publicly accessible at\n\\url{https://github.com/ChnQ/TracingLLM}.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19465v1",
    "authors": [
      "Chen Qian",
      "Jie Zhang",
      "Wei Yao",
      "Dongrui Liu",
      "Zhenfei Yin",
      "Yu Qiao",
      "Yong Liu",
      "Jing Shao"
    ]
  },
  {
    "id": "2402.19471",
    "title": "Loose LIPS Sink Ships: Asking Questions in Battleship with\n  Language-Informed Program Sampling",
    "abstract": "  Questions combine our mastery of language with our remarkable facility for\nreasoning about uncertainty. How do people navigate vast hypothesis spaces to\npose informative questions given limited cognitive resources? We study these\ntradeoffs in a classic grounded question-asking task based on the board game\nBattleship. Our language-informed program sampling (LIPS) model uses large\nlanguage models (LLMs) to generate natural language questions, translate them\ninto symbolic programs, and evaluate their expected information gain. We find\nthat with a surprisingly modest resource budget, this simple Monte Carlo\noptimization strategy yields informative questions that mirror human\nperformance across varied Battleship board scenarios. In contrast, LLM-only\nbaselines struggle to ground questions in the board state; notably, GPT-4V\nprovides no improvement over non-visual baselines. Our results illustrate how\nBayesian models of question-asking can leverage the statistics of language to\ncapture human priors, while highlighting some shortcomings of pure LLMs as\ngrounded reasoners.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19471v1",
    "authors": ["Gabriel Grand", "Valerio Pepe", "Jacob Andreas", "Joshua B. Tenenbaum"]
  },
  {
    "id": "2403.00071",
    "title": "Resonance RoPE: Improving Context Length Generalization of Large\n  Language Models",
    "abstract": "  This paper addresses the challenge of train-short-test-long (TSTL) scenarios\nin Large Language Models (LLMs) equipped with Rotary Position Embedding (RoPE),\nwhere models pre-trained on shorter sequences face difficulty with\nout-of-distribution (OOD) token positions in longer sequences. We introduce\nResonance RoPE, a novel approach designed to narrow the generalization gap in\nTSTL scenarios by refining the interpolation of RoPE features for OOD\npositions, significantly improving the model performance without additional\nonline computational costs. Furthermore, we present PosGen, a new synthetic\nbenchmark specifically designed for fine-grained behavior analysis in TSTL\nscenarios, aiming to isolate the constantly increasing difficulty of token\ngeneration on long contexts from the challenges of recognizing new token\npositions. Our experiments on synthetic tasks show that after applying\nResonance RoPE, Transformers recognize OOD position better and more robustly.\nOur extensive LLM experiments also show superior performance after applying\nResonance RoPE to the current state-of-the-art RoPE scaling method, YaRN, on\nboth upstream language modeling tasks and a variety of downstream long-text\napplications.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00071v1",
    "authors": ["Suyuchen Wang", "Ivan Kobyzev", "Peng Lu", "Mehdi Rezagholizadeh", "Bang Liu"]
  },
  {
    "id": "2403.00116",
    "title": "Federated Linear Contextual Bandits with Heterogeneous Clients",
    "abstract": "  The demand for collaborative and private bandit learning across multiple\nagents is surging due to the growing quantity of data generated from\ndistributed systems. Federated bandit learning has emerged as a promising\nframework for private, efficient, and decentralized online learning. However,\nalmost all previous works rely on strong assumptions of client homogeneity,\ni.e., all participating clients shall share the same bandit model; otherwise,\nthey all would suffer linear regret. This greatly restricts the application of\nfederated bandit learning in practice. In this work, we introduce a new\napproach for federated bandits for heterogeneous clients, which clusters\nclients for collaborative bandit learning under the federated learning setting.\nOur proposed algorithm achieves non-trivial sub-linear regret and communication\ncost for all clients, subject to the communication protocol under federated\nlearning that at anytime only one model can be shared by the server.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00116v1",
    "authors": ["Ethan Blaser", "Chuanhao Li", "Hongning Wang"]
  },
  {
    "id": "2403.00131",
    "title": "UniTS: Building a Unified Time Series Model",
    "abstract": "  Foundation models, especially LLMs, are profoundly transforming deep\nlearning. Instead of training many task-specific models, we can adapt a single\npretrained model to many tasks via fewshot prompting or fine-tuning. However,\ncurrent foundation models apply to sequence data but not to time series, which\npresent unique challenges due to the inherent diverse and multidomain time\nseries datasets, diverging task specifications across forecasting,\nclassification and other types of tasks, and the apparent need for\ntask-specialized models. We developed UNITS, a unified time series model that\nsupports a universal task specification, accommodating classification,\nforecasting, imputation, and anomaly detection tasks. This is achieved through\na novel unified network backbone, which incorporates sequence and variable\nattention along with a dynamic linear operator and is trained as a unified\nmodel. Across 38 multi-domain datasets, UNITS demonstrates superior performance\ncompared to task-specific models and repurposed natural language-based LLMs.\nUNITS exhibits remarkable zero-shot, few-shot, and prompt learning capabilities\nwhen evaluated on new data domains and tasks. The source code and datasets are\navailable at https://github.com/mims-harvard/UniTS.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00131v1",
    "authors": [
      "Shanghua Gao",
      "Teddy Koker",
      "Owen Queen",
      "Thomas Hartvigsen",
      "Theodoros Tsiligkaridis",
      "Marinka Zitnik"
    ]
  },
  {
    "id": "2403.00141",
    "title": "EROS: Entity-Driven Controlled Policy Document Summarization",
    "abstract": "  Privacy policy documents have a crucial role in educating individuals about\nthe collection, usage, and protection of users' personal data by organizations.\nHowever, they are notorious for their lengthy, complex, and convoluted language\nespecially involving privacy-related entities. Hence, they pose a significant\nchallenge to users who attempt to comprehend organization's data usage policy.\nIn this paper, we propose to enhance the interpretability and readability of\npolicy documents by using controlled abstractive summarization -- we enforce\nthe generated summaries to include critical privacy-related entities (e.g.,\ndata and medium) and organization's rationale (e.g.,target and reason) in\ncollecting those entities. To achieve this, we develop PD-Sum, a\npolicy-document summarization dataset with marked privacy-related entity\nlabels. Our proposed model, EROS, identifies critical entities through a\nspan-based entity extraction model and employs them to control the information\ncontent of the summaries using proximal policy optimization (PPO). Comparison\nshows encouraging improvement over various baselines. Furthermore, we furnish\nqualitative and human evaluations to establish the efficacy of EROS.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00141v1",
    "authors": ["Joykirat Singh", "Sehban Fazili", "Rohan Jain", "Md Shad Akhtar"]
  },
  {
    "id": "2403.00154",
    "title": "LLMs in Political Science: Heralding a New Era of Visual Analysis",
    "abstract": "  Interest is increasing among political scientists in leveraging the extensive\ninformation available in images. However, the challenge of interpreting these\nimages lies in the need for specialized knowledge in computer vision and access\nto specialized hardware. As a result, image analysis has been limited to a\nrelatively small group within the political science community. This landscape\ncould potentially change thanks to the rise of large language models (LLMs).\nThis paper aims to raise awareness of the feasibility of using Gemini for image\ncontent analysis. A retrospective analysis was conducted on a corpus of 688\nimages. Content reports were elicited from Gemini for each image and then\nmanually evaluated by the authors. We find that Gemini is highly accurate in\nperforming object detection, which is arguably the most common and fundamental\ntask in image analysis for political scientists. Equally important, we show\nthat it is easy to implement as the entire command consists of a single prompt\nin natural language; it is fast to run and should meet the time budget of most\nresearchers; and it is free to use and does not require any specialized\nhardware. In addition, we illustrate how political scientists can leverage\nGemini for other image understanding tasks, including face identification,\nsentiment analysis, and caption generation. Our findings suggest that Gemini\nand other similar LLMs have the potential to drastically stimulate and\naccelerate image research in political science and social sciences more\nbroadly.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00154v1",
    "authors": ["Yu Wang", "Mengying Xing"]
  },
  {
    "id": "2403.00175",
    "title": "FusionVision: A comprehensive approach of 3D object reconstruction and\n  segmentation from RGB-D cameras using YOLO and fast segment anything",
    "abstract": "  In the realm of computer vision, the integration of advanced techniques into\nthe processing of RGB-D camera inputs poses a significant challenge, given the\ninherent complexities arising from diverse environmental conditions and varying\nobject appearances. Therefore, this paper introduces FusionVision, an\nexhaustive pipeline adapted for the robust 3D segmentation of objects in RGB-D\nimagery. Traditional computer vision systems face limitations in simultaneously\ncapturing precise object boundaries and achieving high-precision object\ndetection on depth map as they are mainly proposed for RGB cameras. To address\nthis challenge, FusionVision adopts an integrated approach by merging\nstate-of-the-art object detection techniques, with advanced instance\nsegmentation methods. The integration of these components enables a holistic\n(unified analysis of information obtained from both color \\textit{RGB} and\ndepth \\textit{D} channels) interpretation of RGB-D data, facilitating the\nextraction of comprehensive and accurate object information. The proposed\nFusionVision pipeline employs YOLO for identifying objects within the RGB image\ndomain. Subsequently, FastSAM, an innovative semantic segmentation model, is\napplied to delineate object boundaries, yielding refined segmentation masks.\nThe synergy between these components and their integration into 3D scene\nunderstanding ensures a cohesive fusion of object detection and segmentation,\nenhancing overall precision in 3D object segmentation. The code and pre-trained\nmodels are publicly available at https://github.com/safouaneelg/FusionVision/.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00175v1",
    "authors": [
      "Safouane El Ghazouali",
      "Youssef Mhirit",
      "Ali Oukhrid",
      "Umberto Michelucci",
      "Hichem Nouira"
    ]
  },
  {
    "id": "2403.00178",
    "title": "Causal Graph ODE: Continuous Treatment Effect Modeling in Multi-agent\n  Dynamical Systems",
    "abstract": "  Real-world multi-agent systems are often dynamic and continuous, where the\nagents co-evolve and undergo changes in their trajectories and interactions\nover time. For example, the COVID-19 transmission in the U.S. can be viewed as\na multi-agent system, where states act as agents and daily population movements\nbetween them are interactions. Estimating the counterfactual outcomes in such\nsystems enables accurate future predictions and effective decision-making, such\nas formulating COVID-19 policies. However, existing methods fail to model the\ncontinuous dynamic effects of treatments on the outcome, especially when\nmultiple treatments (e.g., \"stay-at-home\" and \"get-vaccine\" policies) are\napplied simultaneously. To tackle this challenge, we propose Causal Graph\nOrdinary Differential Equations (CAG-ODE), a novel model that captures the\ncontinuous interaction among agents using a Graph Neural Network (GNN) as the\nODE function. The key innovation of our model is to learn time-dependent\nrepresentations of treatments and incorporate them into the ODE function,\nenabling precise predictions of potential outcomes. To mitigate confounding\nbias, we further propose two domain adversarial learning-based objectives,\nwhich enable our model to learn balanced continuous representations that are\nnot affected by treatments or interference. Experiments on two datasets (i.e.,\nCOVID-19 and tumor growth) demonstrate the superior performance of our proposed\nmodel.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00178v1",
    "authors": [
      "Zijie Huang",
      "Jeehyun Hwang",
      "Junkai Zhang",
      "Jinwoo Baik",
      "Weitong Zhang",
      "Dominik Wodarz",
      "Yizhou Sun",
      "Quanquan Gu",
      "Wei Wang"
    ]
  },
  {
    "id": "2403.00190",
    "title": "Identification of important nodes in the information propagation network\n  based on the artificial intelligence method",
    "abstract": "  This study presents an integrated approach for identifying key nodes in\ninformation propagation networks using advanced artificial intelligence\nmethods. We introduce a novel technique that combines the Decision-making Trial\nand Evaluation Laboratory (DEMATEL) method with the Global Structure Model\n(GSM), creating a synergistic model that effectively captures both local and\nglobal influences within a network. This method is applied across various\ncomplex networks, such as social, transportation, and communication systems,\nutilizing the Global Network Influence Dataset (GNID). Our analysis highlights\nthe structural dynamics and resilience of these networks, revealing insights\ninto node connectivity and community formation. The findings demonstrate the\neffectiveness of our AI-based approach in offering a comprehensive\nunderstanding of network behavior, contributing significantly to strategic\nnetwork analysis and optimization.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00190v1",
    "authors": ["Bin Yuan", "Tianbo Song", "Jerry Yao"]
  },
  {
    "id": "2403.00839",
    "title": "ToolNet: Connecting Large Language Models with Massive Tools via Tool\n  Graph",
    "abstract": "  While achieving remarkable progress in a broad range of tasks, large language\nmodels (LLMs) remain significantly limited in properly using massive external\ntools. Existing in-context learning approaches simply format tools into a list\nof plain text descriptions and input them to LLMs, from which, LLMs generate a\nsequence of tool calls to solve problems step by step. Such a paradigm ignores\nthe intrinsic dependency between tools and offloads all reasoning loads to\nLLMs, making them restricted to a limited number of specifically designed\ntools. It thus remains challenging for LLMs to operate on a library of massive\ntools, casting a great limitation when confronted with real-world scenarios.\nThis paper proposes ToolNet, a plug-and-play framework that scales up the\nnumber of tools to thousands with a moderate increase in token consumption.\nToolNet organizes tools into a directed graph. Each node represents a tool, and\nweighted edges denote tool transition. Starting from an initial tool node, an\nLLM navigates in the graph by iteratively choosing the next one from its\nsuccessors until the task is resolved. Extensive experiments show that ToolNet\ncan achieve impressive results in challenging multi-hop tool learning datasets\nand is resilient to tool failures.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00839v1",
    "authors": [
      "Xukun Liu",
      "Zhiyuan Peng",
      "Xiaoyuan Yi",
      "Xing Xie",
      "Lirong Xiang",
      "Yuchen Liu",
      "Dongkuan Xu"
    ]
  },
  {
    "id": "2403.00840",
    "title": "EyeGPT: Ophthalmic Assistant with Large Language Models",
    "abstract": "  Artificial intelligence (AI) has gained significant attention in healthcare\nconsultation due to its potential to improve clinical workflow and enhance\nmedical communication. However, owing to the complex nature of medical\ninformation, large language models (LLM) trained with general world knowledge\nmight not possess the capability to tackle medical-related tasks at an expert\nlevel. Here, we introduce EyeGPT, a specialized LLM designed specifically for\nophthalmology, using three optimization strategies including role-playing,\nfinetuning, and retrieval-augmented generation. In particular, we proposed a\ncomprehensive evaluation framework that encompasses a diverse dataset, covering\nvarious subspecialties of ophthalmology, different users, and diverse inquiry\nintents. Moreover, we considered multiple evaluation metrics, including\naccuracy, understandability, trustworthiness, empathy, and the proportion of\nhallucinations. By assessing the performance of different EyeGPT variants, we\nidentify the most effective one, which exhibits comparable levels of\nunderstandability, trustworthiness, and empathy to human ophthalmologists (all\nPs>0.05). Overall, ur study provides valuable insights for future research,\nfacilitating comprehensive comparisons and evaluations of different strategies\nfor developing specialized LLMs in ophthalmology. The potential benefits\ninclude enhancing the patient experience in eye care and optimizing\nophthalmologists' services.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00840v1",
    "authors": [
      "Xiaolan Chen",
      "Ziwei Zhao",
      "Weiyi Zhang",
      "Pusheng Xu",
      "Le Gao",
      "Mingpu Xu",
      "Yue Wu",
      "Yinwen Li",
      "Danli Shi",
      "Mingguang He"
    ]
  },
  {
    "id": "2403.00861",
    "title": "Pivoting Retail Supply Chain with Deep Generative Techniques: Taxonomy,\n  Survey and Insights",
    "abstract": "  Generative AI applications, such as ChatGPT or DALL-E, have shown the world\ntheir impressive capabilities in generating human-like text or image. Diving\ndeeper, the science stakeholder for those AI applications are Deep Generative\nModels, a.k.a DGMs, which are designed to learn the underlying distribution of\nthe data and generate new data points that are statistically similar to the\noriginal dataset. One critical question is raised: how can we leverage DGMs\ninto morden retail supply chain realm? To address this question, this paper\nexpects to provide a comprehensive review of DGMs and discuss their existing\nand potential usecases in retail supply chain, by (1) providing a taxonomy and\noverview of state-of-the-art DGMs and their variants, (2) reviewing existing\nDGM applications in retail supply chain from a end-to-end view of point, and\n(3) discussing insights and potential directions on how DGMs can be further\nutilized on solving retail supply chain problems.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00861v1",
    "authors": ["Yuan Wang", "Lokesh Kumar Sambasivan", "Mingang Fu", "Prakhar Mehrotra"]
  },
  {
    "id": "2403.00862",
    "title": "NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and\n  Safety Adherence in Chinese Journalistic Editorial Applications",
    "abstract": "  This study presents NewsBench, a novel benchmark framework developed to\nevaluate the capability of Large Language Models (LLMs) in Chinese Journalistic\nWriting Proficiency (JWP) and their Safety Adherence (SA), addressing the gap\nbetween journalistic ethics and the risks associated with AI utilization.\nComprising 1,267 tasks across 5 editorial applications, 7 aspects (including\nsafety and journalistic writing with 4 detailed facets), and spanning 24 news\ntopics domains, NewsBench employs two GPT-4 based automatic evaluation\nprotocols validated by human assessment. Our comprehensive analysis of 11 LLMs\nhighlighted GPT-4 and ERNIE Bot as top performers, yet revealed a relative\ndeficiency in journalistic ethic adherence during creative writing tasks. These\nfindings underscore the need for enhanced ethical guidance in AI-generated\njournalistic content, marking a step forward in aligning AI capabilities with\njournalistic standards and safety considerations.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00862v1",
    "authors": [
      "Miao Li",
      "Ming-Bin Chen",
      "Bo Tang",
      "Shengbin Hou",
      "Pengyu Wang",
      "Haiying Deng",
      "Zhiyu Li",
      "Feiyu Xiong",
      "Keming Mao",
      "Peng Cheng",
      "Yi Luo"
    ]
  },
  {
    "id": "2402.18826",
    "title": "The Machine Can't Replace the Human Heart",
    "abstract": "  What is the true heart of mental healthcare -- innovation or humanity? Can\nvirtual therapy ever replicate the profound human bonds where healing arises?\nAs artificial intelligence and immersive technologies promise expanded access,\nsafeguards must ensure technologies remain supplementary tools guided by\nproviders' wisdom. Implementation requires nuance balancing efficiency and\nempathy. If conscious of ethical risks, perhaps AI could restore humanity by\nautomating tasks, giving providers more time to listen. Yet no algorithm can\nreplicate the seat of dignity within. We must ask ourselves: What future has\npeople at its core? One where AI thoughtfully plays a collaborative role? Or\nwhere pursuit of progress leaves vulnerability behind? This commentary argues\nfor a balanced approach thoughtfully integrating technology while retaining\ncare's irreplaceable human essence, at the heart of this profoundly human\nprofession. Ultimately, by nurturing innovation and humanity together, perhaps\nwe reach new heights of empathy previously unimaginable.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18826v2",
    "authors": ["Baihan Lin"]
  },
  {
    "id": "2402.18849",
    "title": "Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP\n  Models on Accuracy and Semantic Coherence",
    "abstract": "  This study discusses a new method combining image steganography technology\nwith Natural Language Processing (NLP) large models, aimed at improving the\naccuracy and robustness of extracting steganographic text. Traditional Least\nSignificant Bit (LSB) steganography techniques face challenges in accuracy and\nrobustness of information extraction when dealing with complex character\nencoding, such as Chinese characters. To address this issue, this study\nproposes an innovative LSB-NLP hybrid framework. This framework integrates the\nadvanced capabilities of NLP large models, such as error detection, correction,\nand semantic consistency analysis, as well as information reconstruction\ntechniques, thereby significantly enhancing the robustness of steganographic\ntext extraction. Experimental results show that the LSB-NLP hybrid framework\nexcels in improving the extraction accuracy of steganographic text, especially\nin handling Chinese characters. The findings of this study not only confirm the\neffectiveness of combining image steganography technology and NLP large models\nbut also propose new ideas for research and application in the field of\ninformation hiding. The successful implementation of this interdisciplinary\napproach demonstrates the great potential of integrating image steganography\ntechnology with natural language processing technology in solving complex\ninformation processing problems.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18849v1",
    "authors": ["Mingyang Li", "Maoqin Yuan", "Luyao Li", "Han Pengsihua"]
  },
  {
    "id": "2402.18851",
    "title": "Applications of 0-1 Neural Networks in Prescription and Prediction",
    "abstract": "  A key challenge in medical decision making is learning treatment policies for\npatients with limited observational data. This challenge is particularly\nevident in personalized healthcare decision-making, where models need to take\ninto account the intricate relationships between patient characteristics,\ntreatment options, and health outcomes. To address this, we introduce\nprescriptive networks (PNNs), shallow 0-1 neural networks trained with mixed\ninteger programming that can be used with counterfactual estimation to optimize\npolicies in medium data settings. These models offer greater interpretability\nthan deep neural networks and can encode more complex policies than common\nmodels such as decision trees. We show that PNNs can outperform existing\nmethods in both synthetic data experiments and in a case study of assigning\ntreatments for postpartum hypertension. In particular, PNNs are shown to\nproduce policies that could reduce peak blood pressure by 5.47 mm Hg (p=0.02)\nover existing clinical practice, and by 2 mm Hg (p=0.01) over the next best\nprescriptive modeling technique. Moreover PNNs were more likely than all other\nmodels to correctly identify clinically significant features while existing\nmodels relied on potentially dangerous features such as patient insurance\ninformation and race that could lead to bias in treatment.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18851v1",
    "authors": ["Vrishabh Patil", "Kara Hoppe", "Yonatan Mintz"]
  },
  {
    "id": "2402.18853",
    "title": "Rethinking Multi-domain Generalization with A General Learning Objective",
    "abstract": "  Multi-domain generalization (mDG) is universally aimed to minimize the\ndiscrepancy between training and testing distributions to enhance\nmarginal-to-label distribution mapping. However, existing mDG literature lacks\na general learning objective paradigm and often imposes constraints on static\ntarget marginal distributions. In this paper, we propose to leverage a\n$Y$-mapping to relax the constraint. We rethink the learning objective for mDG\nand design a new \\textbf{general learning objective} to interpret and analyze\nmost existing mDG wisdom. This general objective is bifurcated into two\nsynergistic amis: learning domain-independent conditional features and\nmaximizing a posterior. Explorations also extend to two effective\nregularization terms that incorporate prior information and suppress invalid\ncausality, alleviating the issues that come with relaxed constraints. We\ntheoretically contribute an upper bound for the domain alignment of\ndomain-independent conditional features, disclosing that many previous mDG\nendeavors actually \\textbf{optimize partially the objective} and thus lead to\nlimited performance. As such, our study distills a general learning objective\ninto four practical components, providing a general, robust, and flexible\nmechanism to handle complex domain shifts. Extensive empirical results indicate\nthat the proposed objective with $Y$-mapping leads to substantially better mDG\nperformance in various downstream tasks, including regression, segmentation,\nand classification.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18853v1",
    "authors": ["Zhaorui Tan", "Xi Yang", "Kaizhu Huang"]
  },
  {
    "id": "2402.18865",
    "title": "Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient\n  Tuning",
    "abstract": "  Existing research has shown that large language models (LLMs) exhibit\nremarkable performance in language understanding and generation. However, when\nLLMs are continuously fine-tuned on complex and diverse domain-specific\ndownstream tasks, the inference performance on historical tasks decreases\ndramatically, which is known as a catastrophic forgetting problem. A trade-off\nneeds to be kept between learning plasticity and memory stability. Plenty of\nexisting works have explored strategies like memory replay, regularization and\nparameter isolation, but little is known about the geometric connection of\nvarious adjacent minima in the continual LLMs fine-tuning scenarios. In this\nwork, we investigate the geometric connections of different minima through the\nlens of mode connectivity, which means different minima can be connected by a\nlow-loss valley. Through extensive experiments, we uncover the mode\nconnectivity phenomenon in the LLMs continual learning scenario and find that\nit can strike a balance between plasticity and stability. Building upon these\nfindings, we propose a simple yet effective method called Interpolation-based\nLoRA (I-LoRA), which constructs a dual-memory experience replay framework based\non LoRA parameter interpolations. Extensive experiments and analysis on eight\ndomain-specific CL benchmarks demonstrate that I-LoRA consistently show\nsignificant improvement over the previous state-of-the-art approaches with up\nto $11\\%$ performance gains, providing a strong baseline and insights for\nfuture research on the large language model continual learning problem. Our\ncode is available at \\url{https://github.com/which47/LLMCL}.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18865v1",
    "authors": ["Weijieying Ren", "Xinlong Li", "Lei Wang", "Tianxiang Zhao", "Wei Qin"]
  },
  {
    "id": "2402.18905",
    "title": "On the Convergence of Differentially-Private Fine-tuning: To Linearly\n  Probe or to Fully Fine-tune?",
    "abstract": "  Differentially private (DP) machine learning pipelines typically involve a\ntwo-phase process: non-private pre-training on a public dataset, followed by\nfine-tuning on private data using DP optimization techniques. In the DP\nsetting, it has been observed that full fine-tuning may not always yield the\nbest test accuracy, even for in-distribution data. This paper (1) analyzes the\ntraining dynamics of DP linear probing (LP) and full fine-tuning (FT), and (2)\nexplores the phenomenon of sequential fine-tuning, starting with linear probing\nand transitioning to full fine-tuning (LP-FT), and its impact on test loss. We\nprovide theoretical insights into the convergence of DP fine-tuning within an\noverparameterized neural network and establish a utility curve that determines\nthe allocation of privacy budget between linear probing and full fine-tuning.\nThe theoretical results are supported by empirical evaluations on various\nbenchmarks and models. The findings reveal the complex nature of DP fine-tuning\nmethods. These results contribute to a deeper understanding of DP machine\nlearning and highlight the importance of considering the allocation of privacy\nbudget in the fine-tuning process.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18905v1",
    "authors": ["Shuqi Ke", "Charlie Hou", "Giulia Fanti", "Sewoong Oh"]
  },
  {
    "id": "2402.18908",
    "title": "Facility Location Games with Scaling Effects",
    "abstract": "  We take the classic facility location problem and consider a variation, in\nwhich each agent's individual cost function is equal to their distance from the\nfacility multiplied by a scaling factor which is determined by the facility\nplacement. In addition to the general class of continuous scaling functions, we\nalso provide results for piecewise linear scaling functions which can\neffectively approximate or model the scaling of many real world scenarios. We\nfocus on the objectives of total and maximum cost, describing the computation\nof the optimal solution. We then move to the approximate mechanism design\nsetting, observing that the agents' preferences may no longer be single-peaked.\nConsequently, we characterize the conditions on scaling functions which ensure\nthat agents have single-peaked preferences. Under these conditions, we find\nresults on the total and maximum cost approximation ratios achievable by\nstrategyproof and anonymous mechanisms.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18908v1",
    "authors": ["Yu He", "Alexander Lam", "Minming Li"]
  },
  {
    "id": "2402.18910",
    "title": "DIGIC: Domain Generalizable Imitation Learning by Causal Discovery",
    "abstract": "  Causality has been combined with machine learning to produce robust\nrepresentations for domain generalization. Most existing methods of this type\nrequire massive data from multiple domains to identify causal features by\ncross-domain variations, which can be expensive or even infeasible and may lead\nto misidentification in some cases. In this work, we make a different attempt\nby leveraging the demonstration data distribution to discover the causal\nfeatures for a domain generalizable policy. We design a novel framework, called\nDIGIC, to identify the causal features by finding the direct cause of the\nexpert action from the demonstration data distribution via causal discovery.\nOur framework can achieve domain generalizable imitation learning with only\nsingle-domain data and serve as a complement for cross-domain variation-based\nmethods under non-structural assumptions on the underlying causal models. Our\nempirical study in various control tasks shows that the proposed framework\nevidently improves the domain generalization performance and has comparable\nperformance to the expert in the original domain simultaneously.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18910v1",
    "authors": ["Yang Chen", "Yitao Liang", "Zhouchen Lin"]
  },
  {
    "id": "2402.18920",
    "title": "Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation",
    "abstract": "  Although 3D shape matching and interpolation are highly interrelated, they\nare often studied separately and applied sequentially to relate different 3D\nshapes, thus resulting in sub-optimal performance. In this work we present a\nunified framework to predict both point-wise correspondences and shape\ninterpolation between 3D shapes. To this end, we combine the deep functional\nmap framework with classical surface deformation models to map shapes in both\nspectral and spatial domains. On the one hand, by incorporating spatial maps,\nour method obtains more accurate and smooth point-wise correspondences compared\nto previous functional map methods for shape matching. On the other hand, by\nintroducing spectral maps, our method gets rid of commonly used but\ncomputationally expensive geodesic distance constraints that are only valid for\nnear-isometric shape deformations. Furthermore, we propose a novel test-time\nadaptation scheme to capture both pose-dominant and shape-dominant\ndeformations. Using different challenging datasets, we demonstrate that our\nmethod outperforms previous state-of-the-art methods for both shape matching\nand interpolation, even compared to supervised approaches.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18920v2",
    "authors": [
      "Dongliang Cao",
      "Marvin Eisenberger",
      "Nafie El Amrani",
      "Daniel Cremers",
      "Florian Bernard"
    ]
  },
  {
    "id": "2402.18945",
    "title": "Syntactic Ghost: An Imperceptible General-purpose Backdoor Attacks on\n  Pre-trained Language Models",
    "abstract": "  Pre-trained language models (PLMs) have been found susceptible to backdoor\nattacks, which can transfer vulnerabilities to various downstream tasks.\nHowever, existing PLM backdoors are conducted with explicit triggers under the\nmanually aligned, thus failing to satisfy expectation goals simultaneously in\nterms of effectiveness, stealthiness, and universality. In this paper, we\npropose a novel approach to achieve invisible and general backdoor\nimplantation, called \\textbf{Syntactic Ghost} (synGhost for short).\nSpecifically, the method hostilely manipulates poisoned samples with different\npredefined syntactic structures as stealth triggers and then implants the\nbackdoor to pre-trained representation space without disturbing the primitive\nknowledge. The output representations of poisoned samples are distributed as\nuniformly as possible in the feature space via contrastive learning, forming a\nwide range of backdoors. Additionally, in light of the unique properties of\nsyntactic triggers, we introduce an auxiliary module to drive the PLMs to learn\nthis knowledge in priority, which can alleviate the interference between\ndifferent syntactic structures. Experiments show that our method outperforms\nthe previous methods and achieves the predefined objectives. Not only do severe\nthreats to various natural language understanding (NLU) tasks on two tuning\nparadigms but also to multiple PLMs. Meanwhile, the synGhost is imperceptible\nagainst three countermeasures based on perplexity, fine-pruning, and the\nproposed maxEntropy.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18945v1",
    "authors": [
      "Pengzhou Cheng",
      "Wei Du",
      "Zongru Wu",
      "Fengwei Zhang",
      "Libo Chen",
      "Gongshen Liu"
    ]
  },
  {
    "id": "2402.18995",
    "title": "Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous\n  Overdispersed Count Time Series",
    "abstract": "  Modeling count-valued time series has been receiving increasing attention\nsince count time series naturally arise in physical and social domains. Poisson\ngamma dynamical systems (PGDSs) are newly-developed methods, which can well\ncapture the expressive latent transition structure and bursty dynamics behind\ncount sequences. In particular, PGDSs demonstrate superior performance in terms\nof data imputation and prediction, compared with canonical linear dynamical\nsystem (LDS) based methods. Despite these advantages, PGDS cannot capture the\nheterogeneous overdispersed behaviours of the underlying dynamic processes. To\nmitigate this defect, we propose a negative-binomial-randomized gamma Markov\nprocess, which not only significantly improves the predictive performance of\nthe proposed dynamical system, but also facilitates the fast convergence of the\ninference algorithm. Moreover, we develop methods to estimate both\nfactor-structured and graph-structured transition dynamics, which enable us to\ninfer more explainable latent structure, compared with PGDSs. Finally, we\ndemonstrate the explainable latent structure learned by the proposed method,\nand show its superior performance in imputing missing data and forecasting\nfuture observations, compared with the related models.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.18995v1",
    "authors": ["Rui Huang", "Sikun Yang", "Heinz Koeppl"]
  },
  {
    "id": "2402.19041",
    "title": "Atmospheric Turbulence Removal with Video Sequence Deep Visual Priors",
    "abstract": "  Atmospheric turbulence poses a challenge for the interpretation and visual\nperception of visual imagery due to its distortion effects. Model-based\napproaches have been used to address this, but such methods often suffer from\nartefacts associated with moving content. Conversely, deep learning based\nmethods are dependent on large and diverse datasets that may not effectively\nrepresent any specific content. In this paper, we address these problems with a\nself-supervised learning method that does not require ground truth. The\nproposed method is not dependent on any dataset outside of the single data\nsequence being processed but is also able to improve the quality of any input\nraw sequences or pre-processed sequences. Specifically, our method is based on\nan accelerated Deep Image Prior (DIP), but integrates temporal information\nusing pixel shuffling and a temporal sliding window. This efficiently learns\nspatio-temporal priors leading to a system that effectively mitigates\natmospheric turbulence distortions. The experiments show that our method\nimproves visual quality results qualitatively and quantitatively.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19041v1",
    "authors": ["P. Hill", "N. Anantrasirichai", "A. Achim", "D. R. Bull"]
  },
  {
    "id": "2402.19078",
    "title": "Smooth Tchebycheff Scalarization for Multi-Objective Optimization",
    "abstract": "  Multi-objective optimization problems can be found in many real-world\napplications, where the objectives often conflict each other and cannot be\noptimized by a single solution. In the past few decades, numerous methods have\nbeen proposed to find Pareto solutions that represent different optimal\ntrade-offs among the objectives for a given problem. However, these existing\nmethods could have high computational complexity or may not have good\ntheoretical properties for solving a general differentiable multi-objective\noptimization problem. In this work, by leveraging the smooth optimization\ntechnique, we propose a novel and lightweight smooth Tchebycheff scalarization\napproach for gradient-based multi-objective optimization. It has good\ntheoretical properties for finding all Pareto solutions with valid trade-off\npreferences, while enjoying significantly lower computational complexity\ncompared to other methods. Experimental results on various real-world\napplication problems fully demonstrate the effectiveness of our proposed\nmethod.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19078v1",
    "authors": [
      "Xi Lin",
      "Xiaoyuan Zhang",
      "Zhiyuan Yang",
      "Fei Liu",
      "Zhenkun Wang",
      "Qingfu Zhang"
    ]
  },
  {
    "id": "2402.19085",
    "title": "Controllable Preference Optimization: Toward Controllable\n  Multi-Objective Alignment",
    "abstract": "  Alignment in artificial intelligence pursues the consistency between model\nresponses and human preferences as well as values. In practice, the\nmultifaceted nature of human preferences inadvertently introduces what is known\nas the \"alignment tax\" -a compromise where enhancements in alignment within one\nobjective (e.g.,harmlessness) can diminish performance in others\n(e.g.,helpfulness). However, existing alignment techniques are mostly\nunidirectional, leading to suboptimal trade-offs and poor flexibility over\nvarious objectives. To navigate this challenge, we argue the prominence of\ngrounding LLMs with evident preferences. We introduce controllable preference\noptimization (CPO), which explicitly specifies preference scores for different\nobjectives, thereby guiding the model to generate responses that meet the\nrequirements. Our experimental analysis reveals that the aligned models can\nprovide responses that match various preferences among the \"3H\" (helpfulness,\nhonesty, harmlessness) desiderata. Furthermore, by introducing diverse data and\nalignment goals, we surpass baseline methods in aligning with single\nobjectives, hence mitigating the impact of the alignment tax and achieving\nPareto improvements in multi-objective alignment.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19085v1",
    "authors": [
      "Yiju Guo",
      "Ganqu Cui",
      "Lifan Yuan",
      "Ning Ding",
      "Jiexin Wang",
      "Huimin Chen",
      "Bowen Sun",
      "Ruobing Xie",
      "Jie Zhou",
      "Yankai Lin",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  {
    "id": "2402.19102",
    "title": "FlatNAS: optimizing Flatness in Neural Architecture Search for\n  Out-of-Distribution Robustness",
    "abstract": "  Neural Architecture Search (NAS) paves the way for the automatic definition\nof Neural Network (NN) architectures, attracting increasing research attention\nand offering solutions in various scenarios. This study introduces a novel NAS\nsolution, called Flat Neural Architecture Search (FlatNAS), which explores the\ninterplay between a novel figure of merit based on robustness to weight\nperturbations and single NN optimization with Sharpness-Aware Minimization\n(SAM). FlatNAS is the first work in the literature to systematically explore\nflat regions in the loss landscape of NNs in a NAS procedure, while jointly\noptimizing their performance on in-distribution data, their out-of-distribution\n(OOD) robustness, and constraining the number of parameters in their\narchitecture. Differently from current studies primarily concentrating on OOD\nalgorithms, FlatNAS successfully evaluates the impact of NN architectures on\nOOD robustness, a crucial aspect in real-world applications of machine and deep\nlearning. FlatNAS achieves a good trade-off between performance, OOD\ngeneralization, and the number of parameters, by using only in-distribution\ndata in the NAS exploration. The OOD robustness of the NAS-designed models is\nevaluated by focusing on robustness to input data corruptions, using popular\nbenchmark datasets in the literature.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19102v1",
    "authors": ["Matteo Gambella", "Fabrizio Pittorino", "Manuel Roveri"]
  },
  {
    "id": "2402.19161",
    "title": "MemoNav: Working Memory Model for Visual Navigation",
    "abstract": "  Image-goal navigation is a challenging task that requires an agent to\nnavigate to a goal indicated by an image in unfamiliar environments. Existing\nmethods utilizing diverse scene memories suffer from inefficient exploration\nsince they use all historical observations for decision-making without\nconsidering the goal-relevant fraction. To address this limitation, we present\nMemoNav, a novel memory model for image-goal navigation, which utilizes a\nworking memory-inspired pipeline to improve navigation performance.\nSpecifically, we employ three types of navigation memory. The node features on\na map are stored in the short-term memory (STM), as these features are\ndynamically updated. A forgetting module then retains the informative STM\nfraction to increase efficiency. We also introduce long-term memory (LTM) to\nlearn global scene representations by progressively aggregating STM features.\nSubsequently, a graph attention module encodes the retained STM and the LTM to\ngenerate working memory (WM) which contains the scene features essential for\nefficient navigation. The synergy among these three memory types boosts\nnavigation performance by enabling the agent to learn and leverage\ngoal-relevant scene features within a topological map. Our evaluation on\nmulti-goal tasks demonstrates that MemoNav significantly outperforms previous\nmethods across all difficulty levels in both Gibson and Matterport3D scenes.\nQualitative results further illustrate that MemoNav plans more efficient\nroutes.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19161v1",
    "authors": ["Hongxin Li", "Zeyu Wang", "Xu Yang", "Yuran Yang", "Shuqi Mei", "Zhaoxiang Zhang"]
  },
  {
    "id": "2402.19197",
    "title": "Fine Structure-Aware Sampling: A New Sampling Training Scheme for\n  Pixel-Aligned Implicit Models in Single-View Human Reconstruction",
    "abstract": "  Pixel-aligned implicit models, such as PIFu, PIFuHD, and ICON, are used for\nsingle-view clothed human reconstruction. These models need to be trained using\na sampling training scheme. Existing sampling training schemes either fail to\ncapture thin surfaces (e.g. ears, fingers) or cause noisy artefacts in\nreconstructed meshes. To address these problems, we introduce Fine\nStructured-Aware Sampling (FSS), a new sampling training scheme to train\npixel-aligned implicit models for single-view human reconstruction. FSS\nresolves the aforementioned problems by proactively adapting to the thickness\nand complexity of surfaces. In addition, unlike existing sampling training\nschemes, FSS shows how normals of sample points can be capitalized in the\ntraining process to improve results. Lastly, to further improve the training\nprocess, FSS proposes a mesh thickness loss signal for pixel-aligned implicit\nmodels. It becomes computationally feasible to introduce this loss once a\nslight reworking of the pixel-aligned implicit function framework is carried\nout. Our results show that our methods significantly outperform SOTA methods\nqualitatively and quantitatively. Our code is publicly available at\nhttps://github.com/kcyt/FSS.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19197v1",
    "authors": ["Kennard Yanting Chan", "Fayao Liu", "Guosheng Lin", "Chuan Sheng Foo", "Weisi Lin"]
  },
  {
    "id": "2402.19265",
    "title": "Learning Logic Specifications for Policy Guidance in POMDPs: an\n  Inductive Logic Programming Approach",
    "abstract": "  Partially Observable Markov Decision Processes (POMDPs) are a powerful\nframework for planning under uncertainty. They allow to model state uncertainty\nas a belief probability distribution. Approximate solvers based on Monte Carlo\nsampling show great success to relax the computational demand and perform\nonline planning. However, scaling to complex realistic domains with many\nactions and long planning horizons is still a major challenge, and a key point\nto achieve good performance is guiding the action-selection process with\ndomain-dependent policy heuristics which are tailored for the specific\napplication domain. We propose to learn high-quality heuristics from POMDP\ntraces of executions generated by any solver. We convert the belief-action\npairs to a logical semantics, and exploit data- and time-efficient Inductive\nLogic Programming (ILP) to generate interpretable belief-based policy\nspecifications, which are then used as online heuristics. We evaluate\nthoroughly our methodology on two notoriously challenging POMDP problems,\ninvolving large action spaces and long planning horizons, namely, rocksample\nand pocman. Considering different state-of-the-art online POMDP solvers,\nincluding POMCP, DESPOT and AdaOPS, we show that learned heuristics expressed\nin Answer Set Programming (ASP) yield performance superior to neural networks\nand similar to optimal handcrafted task-specific heuristics within lower\ncomputational time. Moreover, they well generalize to more challenging\nscenarios not experienced in the training phase (e.g., increasing rocks and\ngrid size in rocksample, incrementing the size of the map and the aggressivity\nof ghosts in pocman).\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19265v1",
    "authors": ["Daniele Meli", "Alberto Castellini", "Alessandro Farinelli"]
  },
  {
    "id": "2402.19361",
    "title": "Watermark Stealing in Large Language Models",
    "abstract": "  LLM watermarking has attracted attention as a promising way to detect\nAI-generated content, with some works suggesting that current schemes may\nalready be fit for deployment. In this work we dispute this claim, identifying\nwatermark stealing (WS) as a fundamental vulnerability of these schemes. We\nshow that querying the API of the watermarked LLM to approximately\nreverse-engineer a watermark enables practical spoofing attacks, as suggested\nin prior work, but also greatly boosts scrubbing attacks, which was previously\nunnoticed. We are the first to propose an automated WS algorithm and use it in\nthe first comprehensive study of spoofing and scrubbing in realistic settings.\nWe show that for under $50 an attacker can both spoof and scrub\nstate-of-the-art schemes previously considered safe, with average success rate\nof over 80%. Our findings challenge common beliefs about LLM watermarking,\nstressing the need for more robust schemes. We make all our code and additional\nexamples available at https://watermark-stealing.org.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19361v1",
    "authors": ["Nikola Jovanović", "Robin Staab", "Martin Vechev"]
  },
  {
    "id": "2402.19371",
    "title": "OpenMedLM: Prompt engineering can out-perform fine-tuning in medical\n  question-answering with open-source large language models",
    "abstract": "  LLMs have become increasingly capable at accomplishing a range of\nspecialized-tasks and can be utilized to expand equitable access to medical\nknowledge. Most medical LLMs have involved extensive fine-tuning, leveraging\nspecialized medical data and significant, thus costly, amounts of computational\npower. Many of the top performing LLMs are proprietary and their access is\nlimited to very few research groups. However, open-source (OS) models represent\na key area of growth for medical LLMs due to significant improvements in\nperformance and an inherent ability to provide the transparency and compliance\nrequired in healthcare. We present OpenMedLM, a prompting platform which\ndelivers state-of-the-art (SOTA) performance for OS LLMs on medical benchmarks.\nWe evaluated a range of OS foundation LLMs (7B-70B) on four medical benchmarks\n(MedQA, MedMCQA, PubMedQA, MMLU medical-subset). We employed a series of\nprompting strategies, including zero-shot, few-shot, chain-of-thought (random\nselection and kNN selection), and ensemble/self-consistency voting. We found\nthat OpenMedLM delivers OS SOTA results on three common medical LLM benchmarks,\nsurpassing the previous best performing OS models that leveraged\ncomputationally costly extensive fine-tuning. The model delivers a 72.6%\naccuracy on the MedQA benchmark, outperforming the previous SOTA by 2.4%, and\nachieves 81.7% accuracy on the MMLU medical-subset, establishing itself as the\nfirst OS LLM to surpass 80% accuracy on this benchmark. Our results highlight\nmedical-specific emergent properties in OS LLMs which have not yet been\ndocumented to date elsewhere, and showcase the benefits of further leveraging\nprompt engineering to improve the performance of accessible LLMs for medical\napplications.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19371v1",
    "authors": [
      "Jenish Maharjan",
      "Anurag Garikipati",
      "Navan Preet Singh",
      "Leo Cyrus",
      "Mayank Sharma",
      "Madalina Ciobanu",
      "Gina Barnes",
      "Rahul Thapa",
      "Qingqing Mao",
      "Ritankar Das"
    ]
  },
  {
    "id": "2402.19379",
    "title": "Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match\n  Human Crowd Accuracy",
    "abstract": "  Human forecasting accuracy in practice relies on the 'wisdom of the crowd'\neffect, in which predictions about future events are significantly improved by\naggregating across a crowd of individual forecasters. Past work on the\nforecasting ability of large language models (LLMs) suggests that frontier\nLLMs, as individual forecasters, underperform compared to the gold standard of\na human crowd forecasting tournament aggregate. In Study 1, we expand this\nresearch by using an LLM ensemble approach consisting of a crowd of twelve\nLLMs. We compare the aggregated LLM predictions on 31 binary questions to that\nof a crowd of 925 human forecasters from a three-month forecasting tournament.\nOur main analysis shows that the LLM crowd outperforms a simple no-information\nbenchmark and is statistically equivalent to the human crowd. We also observe\nan acquiescence effect, with mean model predictions being significantly above\n50%, despite an almost even split of positive and negative resolutions.\nMoreover, in Study 2, we test whether LLM predictions (of GPT-4 and Claude 2)\ncan be improved by drawing on human cognitive output. We find that both models'\nforecasting accuracy benefits from exposure to the median human prediction as\ninformation, improving accuracy by between 17% and 28%: though this leads to\nless accurate predictions than simply averaging human and machine forecasts.\nOur results suggest that LLMs can achieve forecasting accuracy rivaling that of\nhuman crowd forecasting tournaments: via the simple, practically applicable\nmethod of forecast aggregation. This replicates the 'wisdom of the crowd'\neffect for LLMs, and opens up their use for a variety applications throughout\nsociety.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19379v1",
    "authors": ["Philipp Schoenegger", "Indre Tuminauskaite", "Peter S. Park", "Philip E. Tetlock"]
  },
  {
    "id": "2402.19420",
    "title": "Understanding Iterative Combinatorial Auction Designs via Multi-Agent\n  Reinforcement Learning",
    "abstract": "  Iterative combinatorial auctions are widely used in high stakes settings such\nas spectrum auctions. Such auctions can be hard to understand analytically,\nmaking it difficult for bidders to determine how to behave and for designers to\noptimize auction rules to ensure desirable outcomes such as high revenue or\nwelfare. In this paper, we investigate whether multi-agent reinforcement\nlearning (MARL) algorithms can be used to understand iterative combinatorial\nauctions, given that these algorithms have recently shown empirical success in\nseveral other domains. We find that MARL can indeed benefit auction analysis,\nbut that deploying it effectively is nontrivial. We begin by describing\nmodelling decisions that keep the resulting game tractable without sacrificing\nimportant features such as imperfect information or asymmetry between bidders.\nWe also discuss how to navigate pitfalls of various MARL algorithms, how to\novercome challenges in verifying convergence, and how to generate and interpret\nmultiple equilibria. We illustrate the promise of our resulting approach by\nusing it to evaluate a specific rule change to a clock auction, finding\nsubstantially different auction outcomes due to complex changes in bidders'\nbehavior.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19420v1",
    "authors": ["Greg d'Eon", "Neil Newman", "Kevin Leyton-Brown"]
  },
  {
    "id": "2402.19421",
    "title": "Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based\n  Search Engines",
    "abstract": "  In the domain of digital information dissemination, search engines act as\npivotal conduits linking information seekers with providers. The advent of\nchat-based search engines utilizing Large Language Models (LLMs) and Retrieval\nAugmented Generation (RAG), exemplified by Bing Chat, marks an evolutionary\nleap in the search ecosystem. They demonstrate metacognitive abilities in\ninterpreting web information and crafting responses with human-like\nunderstanding and creativity. Nonetheless, the intricate nature of LLMs renders\ntheir \"cognitive\" processes opaque, challenging even their designers'\nunderstanding. This research aims to dissect the mechanisms through which an\nLLM-powered chat-based search engine, specifically Bing Chat, selects\ninformation sources for its responses. To this end, an extensive dataset has\nbeen compiled through engagements with New Bing, documenting the websites it\ncites alongside those listed by the conventional search engine. Employing\nnatural language processing (NLP) techniques, the research reveals that Bing\nChat exhibits a preference for content that is not only readable and formally\nstructured, but also demonstrates lower perplexity levels, indicating a unique\ninclination towards text that is predictable by the underlying LLM. Further\nenriching our analysis, we procure an additional dataset through interactions\nwith the GPT-4 based knowledge retrieval API, unveiling a congruent text\npreference between the RAG API and Bing Chat. This consensus suggests that\nthese text preferences intrinsically emerge from the underlying language\nmodels, rather than being explicitly crafted by Bing Chat's developers.\nMoreover, our investigation documents a greater similarity among websites cited\nby RAG technologies compared to those ranked highest by conventional search\nengines.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19421v1",
    "authors": ["Lijia Ma", "Xingchen Xu", "Yong Tan"]
  },
  {
    "id": "2402.19431",
    "title": "Compositional API Recommendation for Library-Oriented Code Generation",
    "abstract": "  Large language models (LLMs) have achieved exceptional performance in code\ngeneration. However, the performance remains unsatisfactory in generating\nlibrary-oriented code, especially for the libraries not present in the training\ndata of LLMs. Previous work utilizes API recommendation technology to help LLMs\nuse libraries: it retrieves APIs related to the user requirements, then\nleverages them as context to prompt LLMs. However, developmental requirements\ncan be coarse-grained, requiring a combination of multiple fine-grained APIs.\nThis granularity inconsistency makes API recommendation a challenging task. To\naddress this, we propose CAPIR (Compositional API Recommendation), which adopts\na \"divide-and-conquer\" strategy to recommend APIs for coarse-grained\nrequirements. Specifically, CAPIR employs an LLM-based Decomposer to break down\na coarse-grained task description into several detailed subtasks. Then, CAPIR\napplies an embedding-based Retriever to identify relevant APIs corresponding to\neach subtask. Moreover, CAPIR leverages an LLM-based Reranker to filter out\nredundant APIs and provides the final recommendation. To facilitate the\nevaluation of API recommendation methods on coarse-grained requirements, we\npresent two challenging benchmarks, RAPID (Recommend APIs based on\nDocumentation) and LOCG (Library-Oriented Code Generation). Experimental\nresults on these benchmarks, demonstrate the effectiveness of CAPIR in\ncomparison to existing baselines. Specifically, on RAPID's Torchdata-AR\ndataset, compared to the state-of-the-art API recommendation approach, CAPIR\nimproves recall@5 from 18.7% to 43.2% and precision@5 from 15.5% to 37.1%. On\nLOCG's Torchdata-Code dataset, compared to code generation without API\nrecommendation, CAPIR improves pass@100 from 16.0% to 28.0%.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19431v1",
    "authors": ["Zexiong Ma", "Shengnan An", "Bing Xie", "Zeqi Lin"]
  },
  {
    "id": "2402.19437",
    "title": "Differentially Private Worst-group Risk Minimization",
    "abstract": "  We initiate a systematic study of worst-group risk minimization under\n$(\\epsilon, \\delta)$-differential privacy (DP). The goal is to privately find a\nmodel that approximately minimizes the maximal risk across $p$ sub-populations\n(groups) with different distributions, where each group distribution is\naccessed via a sample oracle. We first present a new algorithm that achieves\nexcess worst-group population risk of $\\tilde{O}(\\frac{p\\sqrt{d}}{K\\epsilon} +\n\\sqrt{\\frac{p}{K}})$, where $K$ is the total number of samples drawn from all\ngroups and $d$ is the problem dimension. Our rate is nearly optimal when each\ndistribution is observed via a fixed-size dataset of size $K/p$. Our result is\nbased on a new stability-based analysis for the generalization error. In\nparticular, we show that $\\Delta$-uniform argument stability implies\n$\\tilde{O}(\\Delta + \\frac{1}{\\sqrt{n}})$ generalization error w.r.t. the\nworst-group risk, where $n$ is the number of samples drawn from each sample\noracle. Next, we propose an algorithmic framework for worst-group population\nrisk minimization using any DP online convex optimization algorithm as a\nsubroutine. Hence, we give another excess risk bound of $\\tilde{O}\\left(\n\\sqrt{\\frac{d^{1/2}}{\\epsilon K}} +\\sqrt{\\frac{p}{K\\epsilon^2}} \\right)$.\nAssuming the typical setting of $\\epsilon=\\Theta(1)$, this bound is more\nfavorable than our first bound in a certain range of $p$ as a function of $K$\nand $d$. Finally, we study differentially private worst-group empirical risk\nminimization in the offline setting, where each group distribution is observed\nby a fixed-size dataset. We present a new algorithm with nearly optimal excess\nrisk of $\\tilde{O}(\\frac{p\\sqrt{d}}{K\\epsilon})$.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19437v1",
    "authors": ["Xinyu Zhou", "Raef Bassily"]
  },
  {
    "id": "2402.19443",
    "title": "Probing the Information Encoded in Neural-based Acoustic Models of\n  Automatic Speech Recognition Systems",
    "abstract": "  Deep learning architectures have made significant progress in terms of\nperformance in many research areas. The automatic speech recognition (ASR)\nfield has thus benefited from these scientific and technological advances,\nparticularly for acoustic modeling, now integrating deep neural network\narchitectures. However, these performance gains have translated into increased\ncomplexity regarding the information learned and conveyed through these\nblack-box architectures. Following many researches in neural networks\ninterpretability, we propose in this article a protocol that aims to determine\nwhich and where information is located in an ASR acoustic model (AM). To do so,\nwe propose to evaluate AM performance on a determined set of tasks using\nintermediate representations (here, at different layer levels). Regarding the\nperformance variation and targeted tasks, we can emit hypothesis about which\ninformation is enhanced or perturbed at different architecture steps.\nExperiments are performed on both speaker verification, acoustic environment\nclassification, gender classification, tempo-distortion detection systems and\nspeech sentiment/emotion identification. Analysis showed that neural-based AMs\nhold heterogeneous information that seems surprisingly uncorrelated with\nphoneme recognition, such as emotion, sentiment or speaker identity. The\nlow-level hidden layers globally appears useful for the structuring of\ninformation while the upper ones would tend to delete useless information for\nphoneme recognition.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19443v1",
    "authors": ["Quentin Raymondaud", "Mickael Rouvier", "Richard Dufour"]
  },
  {
    "id": "2402.19446",
    "title": "ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL",
    "abstract": "  A broad use case of large language models (LLMs) is in goal-directed\ndecision-making tasks (or \"agent\" tasks), where an LLM needs to not just\ngenerate completions for a given prompt, but rather make intelligent decisions\nover a multi-turn interaction to accomplish a task (e.g., when interacting with\nthe web, using tools, or providing customer support). Reinforcement learning\n(RL) provides a general paradigm to address such agent tasks, but current RL\nmethods for LLMs largely focus on optimizing single-turn rewards. By\nconstruction, most single-turn RL methods cannot endow LLMs with the ability to\nintelligently seek information over multiple turns, perform credit assignment,\nor reason about their past actions -- all of which are critical in agent tasks.\nThis raises the question: how can we design effective and efficient multi-turn\nRL algorithms for LLMs? In this paper, we develop a framework for building\nmulti-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility\nof existing single-turn RL methods for LLMs (e.g., proximal policy\noptimization), while accommodating multiple turns, long horizons, and delayed\nrewards effectively. To do this, our framework adopts a hierarchical RL\napproach and runs two RL algorithms in parallel: a high-level off-policy\nvalue-based RL algorithm to aggregate reward over utterances, and a low-level\nRL algorithm that utilizes this high-level value function to train a token\npolicy within each utterance or turn. Our hierarchical framework, Actor-Critic\nFramework with a Hierarchical Structure (ArCHer), can also give rise to other\nRL methods. Empirically, we find that ArCHer significantly improves efficiency\nand performance on agent tasks, attaining a sample efficiency of about 100x\nover existing methods, while also improving with larger model capacity (upto\nthe 7 billion scale that we tested on).\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19446v1",
    "authors": ["Yifei Zhou", "Andrea Zanette", "Jiayi Pan", "Sergey Levine", "Aviral Kumar"]
  },
  {
    "id": "2402.19464",
    "title": "Curiosity-driven Red-teaming for Large Language Models",
    "abstract": "  Large language models (LLMs) hold great potential for many natural language\napplications but risk generating incorrect or toxic content. To probe when an\nLLM generates unwanted content, the current paradigm is to recruit a\n\\textit{red team} of human testers to design input prompts (i.e., test cases)\nthat elicit undesirable responses from LLMs. However, relying solely on human\ntesters is expensive and time-consuming. Recent works automate red teaming by\ntraining a separate red team LLM with reinforcement learning (RL) to generate\ntest cases that maximize the chance of eliciting undesirable responses from the\ntarget LLM. However, current RL methods are only able to generate a small\nnumber of effective test cases resulting in a low coverage of the span of\nprompts that elicit undesirable responses from the target LLM. To overcome this\nlimitation, we draw a connection between the problem of increasing the coverage\nof generated test cases and the well-studied approach of curiosity-driven\nexploration that optimizes for novelty. Our method of curiosity-driven red\nteaming (CRT) achieves greater coverage of test cases while mantaining or\nincreasing their effectiveness compared to existing methods. Our method, CRT\nsuccessfully provokes toxic responses from LLaMA2 model that has been heavily\nfine-tuned using human preferences to avoid toxic outputs. Code is available at\n\\url{https://github.com/Improbable-AI/curiosity_redteam}\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19464v1",
    "authors": [
      "Zhang-Wei Hong",
      "Idan Shenfeld",
      "Tsun-Hsuan Wang",
      "Yung-Sung Chuang",
      "Aldo Pareja",
      "James Glass",
      "Akash Srivastava",
      "Pulkit Agrawal"
    ]
  },
  {
    "id": "2402.19467",
    "title": "TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning",
    "abstract": "  It is challenging to perform question-answering over complex, multimodal\ncontent such as television clips. This is in part because current\nvideo-language models rely on single-modality reasoning, have lowered\nperformance on long inputs, and lack interpetability. We propose TV-TREES, the\nfirst multimodal entailment tree generator. TV-TREES serves as an approach to\nvideo understanding that promotes interpretable joint-modality reasoning by\nproducing trees of entailment relationships between simple premises directly\nentailed by the videos and higher-level conclusions. We then introduce the task\nof multimodal entailment tree generation to evaluate the reasoning quality of\nsuch methods. Our method's experimental results on the challenging TVQA dataset\ndemonstrate intepretable, state-of-the-art zero-shot performance on full video\nclips, illustrating a best of both worlds contrast to black-box methods.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19467v2",
    "authors": ["Kate Sanders", "Nathaniel Weir", "Benjamin Van Durme"]
  },
  {
    "id": "2402.19475",
    "title": "The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of\n  Their Incorrect Generations?",
    "abstract": "  While language models are increasingly more proficient at code generation,\nthey still frequently generate incorrect programs. Many of these programs are\nobviously wrong, but others are more subtle and pass weaker correctness checks\nsuch as being able to compile. In this work, we focus on these counterfeit\nsamples: programs sampled from a language model that 1) have a high enough\nlog-probability to be generated at a moderate temperature and 2) pass weak\ncorrectness checks. Overall, we discover that most models have a very shallow\nunderstanding of counterfeits through three clear failure modes. First, models\nmistakenly classify them as correct. Second, models are worse at reasoning\nabout the execution behaviour of counterfeits and often predict their execution\nresults as if they were correct. Third, when asking models to fix counterfeits,\nthe likelihood of a model successfully repairing a counterfeit is often even\nlower than that of sampling a correct program from scratch. Counterfeits also\nhave very unexpected properties: first, counterfeit programs for problems that\nare easier for a model to solve are not necessarily easier to detect and only\nslightly easier to execute and repair. Second, counterfeits from a given model\nare just as confusing to the model itself as they are to other models. Finally,\nboth strong and weak models are able to generate counterfeit samples that\nequally challenge all models. In light of our findings, we recommend that care\nand caution be taken when relying on models to understand their own samples,\nespecially when no external feedback is incorporated.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19475v1",
    "authors": [
      "Alex Gu",
      "Wen-Ding Li",
      "Naman Jain",
      "Theo X. Olausson",
      "Celine Lee",
      "Koushik Sen",
      "Armando Solar-Lezama"
    ]
  },
  {
    "id": "2403.00037",
    "title": "Evolving to the Future: Unseen Event Adaptive Fake News Detection on\n  Social Media",
    "abstract": "  With the rapid development of social media, the wide dissemination of fake\nnews on social media is increasingly threatening both individuals and society.\nIn the dynamic landscape of social media, fake news detection aims to develop a\nmodel trained on news reporting past events. The objective is to predict and\nidentify fake news about future events, which often relate to subjects entirely\ndifferent from those in the past. However, existing fake detection methods\nexhibit a lack of robustness and cannot generalize to unseen events. To address\nthis, we introduce Future ADaptive Event-based Fake news Detection (FADE)\nframework. Specifically, we train a target predictor through an adaptive\naugmentation strategy and graph contrastive learning to make more robust\noverall predictions. Simultaneously, we independently train an event-only\npredictor to obtain biased predictions. Then we further mitigate event bias by\nobtaining the final prediction by subtracting the output of the event-only\npredictor from the output of the target predictor. Encouraging results from\nexperiments designed to emulate real-world social media conditions validate the\neffectiveness of our method in comparison to existing state-of-the-art\napproaches.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00037v1",
    "authors": ["Jiajun Zhang", "Zhixun Li", "Qiang Liu", "Shu Wu", "Liang Wang"]
  },
  {
    "id": "2403.00039",
    "title": "FhGenie: A Custom, Confidentiality-preserving Chat AI for Corporate and\n  Scientific Use",
    "abstract": "  Since OpenAI's release of ChatGPT, generative AI has received significant\nattention across various domains. These AI-based chat systems have the\npotential to enhance the productivity of knowledge workers in diverse tasks.\nHowever, the use of free public services poses a risk of data leakage, as\nservice providers may exploit user input for additional training and\noptimization without clear boundaries. Even subscription-based alternatives\nsometimes lack transparency in handling user data. To address these concerns\nand enable Fraunhofer staff to leverage this technology while ensuring\nconfidentiality, we have designed and developed a customized chat AI called\nFhGenie (genie being a reference to a helpful spirit). Within few days of its\nrelease, thousands of Fraunhofer employees started using this service. As\npioneers in implementing such a system, many other organizations have followed\nsuit. Our solution builds upon commercial large language models (LLMs), which\nwe have carefully integrated into our system to meet our specific requirements\nand compliance constraints, including confidentiality and GDPR. In this paper,\nwe share detailed insights into the architectural considerations, design,\nimplementation, and subsequent updates of FhGenie. Additionally, we discuss\nchallenges, observations, and the core lessons learned from its productive\nusage.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00039v1",
    "authors": [
      "Ingo Weber",
      "Hendrik Linka",
      "Daniel Mertens",
      "Tamara Muryshkin",
      "Heinrich Opgenoorth",
      "Stefan Langer"
    ]
  },
  {
    "id": "2403.00041",
    "title": "Global and Local Prompts Cooperation via Optimal Transport for Federated\n  Learning",
    "abstract": "  Prompt learning in pretrained visual-language models has shown remarkable\nflexibility across various downstream tasks. Leveraging its inherent\nlightweight nature, recent research attempted to integrate the powerful\npretrained models into federated learning frameworks to simultaneously reduce\ncommunication costs and promote local training on insufficient data. Despite\nthese efforts, current federated prompt learning methods lack specialized\ndesigns to systematically address severe data heterogeneities, e.g., data\ndistribution with both label and feature shifts involved. To address this\nchallenge, we present Federated Prompts Cooperation via Optimal Transport\n(FedOTP), which introduces efficient collaborative prompt learning strategies\nto capture diverse category traits on a per-client basis. Specifically, for\neach client, we learn a global prompt to extract consensus knowledge among\nclients, and a local prompt to capture client-specific category\ncharacteristics. Unbalanced Optimal Transport is then employed to align local\nvisual features with these prompts, striking a balance between global consensus\nand local personalization. Extensive experiments on datasets with various types\nof heterogeneities have demonstrated that our FedOTP outperforms the\nstate-of-the-art methods.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00041v1",
    "authors": ["Hongxia Li", "Wei Huang", "Jingya Wang", "Ye Shi"]
  },
  {
    "id": "2403.00044",
    "title": "Scaling up Dynamic Edge Partition Models via Stochastic Gradient MCMC",
    "abstract": "  The edge partition model (EPM) is a generative model for extracting an\noverlapping community structure from static graph-structured data. In the EPM,\nthe gamma process (GaP) prior is adopted to infer the appropriate number of\nlatent communities, and each vertex is endowed with a gamma distributed\npositive memberships vector. Despite having many attractive properties,\ninference in the EPM is typically performed using Markov chain Monte Carlo\n(MCMC) methods that prevent it from being applied to massive network data. In\nthis paper, we generalize the EPM to account for dynamic enviroment by\nrepresenting each vertex with a positive memberships vector constructed using\nDirichlet prior specification, and capturing the time-evolving behaviour of\nvertices via a Dirichlet Markov chain construction. A simple-to-implement Gibbs\nsampler is proposed to perform posterior computation using Negative- Binomial\naugmentation technique. For large network data, we propose a stochastic\ngradient Markov chain Monte Carlo (SG-MCMC) algorithm for scalable inference in\nthe proposed model. The experimental results show that the novel methods\nachieve competitive performance in terms of link prediction, while being much\nfaster.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00044v1",
    "authors": ["Sikun Yang", "Heinz Koeppl"]
  },
  {
    "id": "2403.00046",
    "title": "SEED: Customize Large Language Models with Sample-Efficient Adaptation\n  for Code Generation",
    "abstract": "  Although Large Language Models (LLMs) have made significant progress in code\ngeneration, they still struggle with code generation tasks in specific\nscenarios. These scenarios usually necessitate the adaptation of LLMs to\nfulfill specific needs, but the limited training data available in practice\nleads to poor code generation performance. How to effectively adapt LLMs to new\nscenarios with fewer training samples is a major challenge for current code\ngeneration. In this paper, we propose a novel adaptation approach named SEED,\nwhich stands for Sample-Efficient adaptation with Error-Driven learning for\ncode generation. SEED leverages the errors made by LLMs as learning\nopportunities, using error revision to overcome its own shortcomings, thus\nachieving efficient learning. Specifically, SEED involves identifying error\ncode generated by LLMs, employing Self-revise for code revision, optimizing the\nmodel with revised code, and iteratively adapting the process for continuous\nimprovement. Experimental results show that, compared to traditional\nfine-tuning approaches, SEED achieves superior performance with fewer training\nsamples, showing a relative improvement of 27.2%-325.0% in Pass@1. We also\nvalidate the effectiveness of Self-revise, which generates revised code that\noptimizes the model more efficiently compared to the code samples from\ndatasets. Moreover, SEED consistently demonstrates strong performance across\nvarious LLMs, underscoring its generalizability.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00046v1",
    "authors": ["Xue Jiang", "Yihong Dong", "Zhi Jin", "Ge Li"]
  },
  {
    "id": "2403.00108",
    "title": "LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario",
    "abstract": "  Fine-tuning LLMs is crucial to enhancing their task-specific performance and\nensuring model behaviors are aligned with human preferences. Among various\nfine-tuning methods, LoRA is popular for its efficiency and ease to use,\nallowing end-users to easily post and adopt lightweight LoRA modules on\nopen-source platforms to tailor their model for different customization.\nHowever, such a handy share-and-play setting opens up new attack surfaces, that\nthe attacker can render LoRA as an attacker, such as backdoor injection, and\nwidely distribute the adversarial LoRA to the community easily. This can result\nin detrimental outcomes. Despite the huge potential risks of sharing LoRA\nmodules, this aspect however has not been fully explored. To fill the gap, in\nthis study we thoroughly investigate the attack opportunities enabled in the\ngrowing share-and-play scenario. Specifically, we study how to inject backdoor\ninto the LoRA module and dive deeper into LoRA's infection mechanisms. We found\nthat training-free mechanism is possible in LoRA backdoor injection. We also\ndiscover the impact of backdoor attacks with the presence of multiple LoRA\nadaptions concurrently as well as LoRA based backdoor transferability. Our aim\nis to raise awareness of the potential risks under the emerging share-and-play\nscenario, so as to proactively prevent potential consequences caused by\nLoRA-as-an-Attack. Warning: the paper contains potential offensive content\ngenerated by models.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00108v1",
    "authors": [
      "Hongyi Liu",
      "Zirui Liu",
      "Ruixiang Tang",
      "Jiayi Yuan",
      "Shaochen Zhong",
      "Yu-Neng Chuang",
      "Li Li",
      "Rui Chen",
      "Xia Hu"
    ]
  },
  {
    "id": "2403.00143",
    "title": "Ensemble-Based Unsupervised Discontinuous Constituency Parsing by Tree\n  Averaging",
    "abstract": "  We address unsupervised discontinuous constituency parsing, where we observe\na high variance in the performance of the only previous model. We propose to\nbuild an ensemble of different runs of the existing discontinuous parser by\naveraging the predicted trees, to stabilize and boost performance. To begin\nwith, we provide comprehensive computational complexity analysis (in terms of P\nand NP-complete) for tree averaging under different setups of binarity and\ncontinuity. We then develop an efficient exact algorithm to tackle the task,\nwhich runs in a reasonable time for all samples in our experiments. Results on\nthree datasets show our method outperforms all baselines in all metrics; we\nalso provide in-depth analyses of our approach.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00143v1",
    "authors": ["Behzad Shayegh", "Yuqiao Wen", "Lili Mou"]
  },
  {
    "id": "2403.00144",
    "title": "EBBS: An Ensemble with Bi-Level Beam Search for Zero-Shot Machine\n  Translation",
    "abstract": "  The ability of zero-shot translation emerges when we train a multilingual\nmodel with certain translation directions; the model can then directly\ntranslate in unseen directions. Alternatively, zero-shot translation can be\naccomplished by pivoting through a third language (e.g., English). In our work,\nwe observe that both direct and pivot translations are noisy and achieve less\nsatisfactory performance. We propose EBBS, an ensemble method with a novel\nbi-level beam search algorithm, where each ensemble component explores its own\nprediction step by step at the lower level but they are synchronized by a \"soft\nvoting\" mechanism at the upper level. Results on two popular multilingual\ntranslation datasets show that EBBS consistently outperforms direct and pivot\ntranslations as well as existing ensemble techniques. Further, we can distill\nthe ensemble's knowledge back to the multilingual model to improve inference\nefficiency; profoundly, our EBBS-based distillation does not sacrifice, or even\nimproves, the translation quality.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00144v1",
    "authors": ["Yuqiao Wen", "Behzad Shayegh", "Chenyang Huang", "Yanshuai Cao", "Lili Mou"]
  },
  {
    "id": "2403.00172",
    "title": "Go Beyond Black-box Policies: Rethinking the Design of Learning Agent\n  for Interpretable and Verifiable HVAC Control",
    "abstract": "  Recent research has shown the potential of Model-based Reinforcement Learning\n(MBRL) to enhance energy efficiency of Heating, Ventilation, and Air\nConditioning (HVAC) systems. However, existing methods rely on black-box\nthermal dynamics models and stochastic optimizers, lacking reliability\nguarantees and posing risks to occupant health. In this work, we overcome the\nreliability bottleneck by redesigning HVAC controllers using decision trees\nextracted from existing thermal dynamics models and historical data. Our\ndecision tree-based policies are deterministic, verifiable, interpretable, and\nmore energy-efficient than current MBRL methods. First, we introduce a novel\nverification criterion for RL agents in HVAC control based on domain knowledge.\nSecond, we develop a policy extraction procedure that produces a verifiable\ndecision tree policy. We found that the high dimensionality of the thermal\ndynamics model input hinders the efficiency of policy extraction. To tackle the\ndimensionality challenge, we leverage importance sampling conditioned on\nhistorical data distributions, significantly improving policy extraction\nefficiency. Lastly, we present an offline verification algorithm that\nguarantees the reliability of a control policy. Extensive experiments show that\nour method saves 68.4% more energy and increases human comfort gain by 14.8%\ncompared to the state-of-the-art method, in addition to an 1127x reduction in\ncomputation overhead. Our code and data are available at\nhttps://github.com/ryeii/Veri_HVAC\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00172v1",
    "authors": ["Zhiyu An", "Xianzhong Ding", "Wan Du"]
  },
  {
    "id": "2403.00176",
    "title": "SoD$^2$: Statically Optimizing Dynamic Deep Neural Network",
    "abstract": "  Though many compilation and runtime systems have been developed for DNNs in\nrecent years, the focus has largely been on static DNNs. Dynamic DNNs, where\ntensor shapes and sizes and even the set of operators used are dependent upon\nthe input and/or execution, are becoming common. This paper presents SoD$^2$, a\ncomprehensive framework for optimizing Dynamic DNNs. The basis of our approach\nis a classification of common operators that form DNNs, and the use of this\nclassification towards a Rank and Dimension Propagation (RDP) method. This\nframework statically determines the shapes of operators as known constants,\nsymbolic constants, or operations on these. Next, using RDP we enable a series\nof optimizations, like fused code generation, execution (order) planning, and\neven runtime memory allocation plan generation. By evaluating the framework on\n10 emerging Dynamic DNNs and comparing it against several existing systems, we\ndemonstrate both reductions in execution latency and memory requirements, with\nRDP-enabled key optimizations responsible for much of the gains. Our evaluation\nresults show that SoD$^2$ runs up to $3.9\\times$ faster than these systems\nwhile saving up to $88\\%$ peak memory consumption.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00176v1",
    "authors": ["Wei Niu", "Gagan Agrawal", "Bin Ren"]
  },
  {
    "id": "2403.00196",
    "title": "Learning to Find Missing Video Frames with Synthetic Data Augmentation:\n  A General Framework and Application in Generating Thermal Images Using RGB\n  Cameras",
    "abstract": "  Advanced Driver Assistance Systems (ADAS) in intelligent vehicles rely on\naccurate driver perception within the vehicle cabin, often leveraging a\ncombination of sensing modalities. However, these modalities operate at varying\nrates, posing challenges for real-time, comprehensive driver state monitoring.\nThis paper addresses the issue of missing data due to sensor frame rate\nmismatches, introducing a generative model approach to create synthetic yet\nrealistic thermal imagery. We propose using conditional generative adversarial\nnetworks (cGANs), specifically comparing the pix2pix and CycleGAN\narchitectures. Experimental results demonstrate that pix2pix outperforms\nCycleGAN, and utilizing multi-view input styles, especially stacked views,\nenhances the accuracy of thermal image generation. Moreover, the study\nevaluates the model's generalizability across different subjects, revealing the\nimportance of individualized training for optimal performance. The findings\nsuggest the potential of generative models in addressing missing frames,\nadvancing driver state monitoring for intelligent vehicles, and underscoring\nthe need for continued research in model generalization and customization.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00196v1",
    "authors": ["Mathias Viborg Andersen", "Ross Greer", "Andreas Møgelmose", "Mohan Trivedi"]
  },
  {
    "id": "2403.00841",
    "title": "Offline Fictitious Self-Play for Competitive Games",
    "abstract": "  Offline Reinforcement Learning (RL) has received significant interest due to\nits ability to improve policies in previously collected datasets without online\ninteractions. Despite its success in the single-agent setting, offline\nmulti-agent RL remains a challenge, especially in competitive games. Firstly,\nunaware of the game structure, it is impossible to interact with the opponents\nand conduct a major learning paradigm, self-play, for competitive games.\nSecondly, real-world datasets cannot cover all the state and action space in\nthe game, resulting in barriers to identifying Nash equilibrium (NE). To\naddress these issues, this paper introduces Off-FSP, the first practical\nmodel-free offline RL algorithm for competitive games. We start by simulating\ninteractions with various opponents by adjusting the weights of the fixed\ndataset with importance sampling. This technique allows us to learn best\nresponses to different opponents and employ the Offline Self-Play learning\nframework. In this framework, we further implement Fictitious Self-Play (FSP)\nto approximate NE. In partially covered real-world datasets, our methods show\nthe potential to approach NE by incorporating any single-agent offline RL\nmethod. Experimental results in Leduc Hold'em Poker show that our method\nsignificantly improves performances compared with state-of-the-art baselines.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00841v1",
    "authors": ["Jingxiao Chen", "Weiji Xie", "Weinan Zhang", "Yong yu", "Ying Wen"]
  },
  {
    "id": "2403.00843",
    "title": "Enhancing Long-Term Recommendation with Bi-level Learnable Large\n  Language Model Planning",
    "abstract": "  Traditional recommendation setting tends to excessively cater to users'\nimmediate interests and neglect their long-term engagement. To address it, it\nis crucial to incorporate planning capabilities into the recommendation\ndecision-making process to develop policies that take into account both\nimmediate interests and long-term engagement. Despite Reinforcement Learning\n(RL) can learn planning capacity by maximizing cumulative reward, the scarcity\nof recommendation data presents challenges such as instability and\nsusceptibility to overfitting when training RL models from scratch.\n  In this context, we propose to leverage the remarkable planning capabilities\nover sparse data of Large Language Models (LLMs) for long-term recommendation.\nThe key lies in enabling a language model to understand and apply task-solving\nprinciples effectively in personalized recommendation scenarios, as the model's\npre-training may not naturally encompass these principles, necessitating the\nneed to inspire or teach the model. To achieve this, we propose a Bi-level\nLearnable LLM Planner framework, which combines macro-learning and\nmicro-learning through a hierarchical mechanism. The framework includes a\nPlanner and Reflector for acquiring high-level guiding principles and an\nActor-Critic component for planning personalization. Extensive experiments\nvalidate the superiority of the framework in learning to plan for long-term\nrecommendations.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00843v1",
    "authors": [
      "Wentao Shi",
      "Xiangnan He",
      "Yang Zhang",
      "Chongming Gao",
      "Xinyue Li",
      "Jizhi Zhang",
      "Qifan Wang",
      "Fuli Feng"
    ]
  },
  {
    "id": "2403.00858",
    "title": "Direct Alignment of Draft Model for Speculative Decoding with\n  Chat-Fine-Tuned LLMs",
    "abstract": "  Text generation with Large Language Models (LLMs) is known to be memory bound\ndue to the combination of their auto-regressive nature, huge parameter counts,\nand limited memory bandwidths, often resulting in low token rates. Speculative\ndecoding has been proposed as a solution for LLM inference acceleration.\nHowever, since draft models are often unavailable in the modern open-source LLM\nfamilies, e.g., for Llama 2 7B, training a high-quality draft model is required\nto enable inference acceleration via speculative decoding. In this paper, we\npropose a simple draft model training framework for direct alignment to\nchat-capable target models. With the proposed framework, we train Llama 2 Chat\nDrafter 115M, a draft model for Llama 2 Chat 7B or larger, with only 1.64\\% of\nthe original size. Our training framework only consists of pretraining,\ndistillation dataset generation, and finetuning with knowledge distillation,\nwith no additional alignment procedure. For the finetuning step, we use\ninstruction-response pairs generated by target model for distillation in\nplausible data distribution, and propose a new Total Variation Distance++\n(TVD++) loss that incorporates variance reduction techniques inspired from the\npolicy gradient method in reinforcement learning. Our empirical results show\nthat Llama 2 Chat Drafter 115M with speculative decoding achieves up to 2.3\nblock efficiency and 2.4$\\times$ speed-up relative to autoregressive decoding\non various tasks with no further task-specific fine-tuning.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00858v1",
    "authors": [
      "Raghavv Goel",
      "Mukul Gagrani",
      "Wonseok Jeon",
      "Junyoung Park",
      "Mingu Lee",
      "Christopher Lott"
    ]
  },
  {
    "id": "2403.00859",
    "title": "Team Formation amidst Conflicts",
    "abstract": "  In this work, we formulate the problem of team formation amidst conflicts.\nThe goal is to assign individuals to tasks, with given capacities, taking into\naccount individuals' task preferences and the conflicts between them. Using\ndependent rounding schemes as our main toolbox, we provide efficient\napproximation algorithms. Our framework is extremely versatile and can model\nmany different real-world scenarios as they arise in educational settings and\nhuman-resource management. We test and deploy our algorithms on real-world\ndatasets and we show that our algorithms find assignments that are better than\nthose found by natural baselines. In the educational setting we also show how\nour assignments are far better than those done manually by human experts. In\nthe human resource management application we show how our assignments increase\nthe diversity of teams. Finally, using a synthetic dataset we demonstrate that\nour algorithms scale very well in practice.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00859v1",
    "authors": ["Iasonas Nikolaou", "Evimaria Terzi"]
  },
  {
    "id": "2403.00860",
    "title": "Parallel Algorithms for Exact Enumeration of Deep Neural Network\n  Activation Regions",
    "abstract": "  A feedforward neural network using rectified linear units constructs a\nmapping from inputs to outputs by partitioning its input space into a set of\nconvex regions where points within a region share a single affine\ntransformation. In order to understand how neural networks work, when and why\nthey fail, and how they compare to biological intelligence, we need to\nunderstand the organization and formation of these regions. Step one is to\ndesign and implement algorithms for exact region enumeration in networks beyond\ntoy examples.\n  In this work, we present parallel algorithms for exact enumeration in deep\n(and shallow) neural networks. Our work has three main contributions: (1) we\npresent a novel algorithm framework and parallel algorithms for region\nenumeration; (2) we implement one of our algorithms on a variety of network\narchitectures and experimentally show how the number of regions dictates\nruntime; and (3) we show, using our algorithm's output, how the dimension of a\nregion's affine transformation impacts further partitioning of the region by\ndeeper layers.\n  To our knowledge, we run our implemented algorithm on networks larger than\nall of the networks used in the existing region enumeration literature.\nFurther, we experimentally demonstrate the importance of parallelism for region\nenumeration of any reasonably sized network.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00860v1",
    "authors": [
      "Sabrina Drammis",
      "Bowen Zheng",
      "Karthik Srinivasan",
      "Robert C. Berwick",
      "Nancy A. Lynch",
      "Robert Ajemian"
    ]
  },
  {
    "id": "2403.00863",
    "title": "LLM-Ensemble: Optimal Large Language Model Ensemble Method for\n  E-commerce Product Attribute Value Extraction",
    "abstract": "  Product attribute value extraction is a pivotal component in Natural Language\nProcessing (NLP) and the contemporary e-commerce industry. The provision of\nprecise product attribute values is fundamental in ensuring high-quality\nrecommendations and enhancing customer satisfaction. The recently emerging\nLarge Language Models (LLMs) have demonstrated state-of-the-art performance in\nnumerous attribute extraction tasks, without the need for domain-specific\ntraining data. Nevertheless, varying strengths and weaknesses are exhibited by\ndifferent LLMs due to the diversity in data, architectures, and\nhyperparameters. This variation makes them complementary to each other, with no\nsingle LLM dominating all others. Considering the diverse strengths and\nweaknesses of LLMs, it becomes necessary to develop an ensemble method that\nleverages their complementary potentials. In this paper, we propose a novel\nalgorithm called LLM-ensemble to ensemble different LLMs' outputs for attribute\nvalue extraction. We iteratively learn the weights for different LLMs to\naggregate the labels with weights to predict the final attribute value. Not\nonly can our proposed method be proven theoretically optimal, but it also\nensures efficient computation, fast convergence, and safe deployment. We have\nalso conducted extensive experiments with various state-of-the-art LLMs,\nincluding Llama2-13B, Llama2-70B, PaLM-2, GPT-3.5, and GPT-4, on Walmart's\ninternal data. Our offline metrics demonstrate that the LLM-ensemble method\noutperforms all the state-of-the-art single LLMs on Walmart's internal dataset.\nThis method has been launched in several production models, leading to improved\nGross Merchandise Volume (GMV), Click-Through Rate (CTR), Conversion Rate\n(CVR), and Add-to-Cart Rate (ATC).\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00863v1",
    "authors": [
      "Chenhao Fang",
      "Xiaohan Li",
      "Zezhong Fan",
      "Jianpeng Xu",
      "Kaushiki Nag",
      "Evren Korpeoglu",
      "Sushant Kumar",
      "Kannan Achan"
    ]
  },
  {
    "id": "2403.00036",
    "title": "Influencing Bandits: Arm Selection for Preference Shaping",
    "abstract": "  We consider a non stationary multi-armed bandit in which the population\npreferences are positively and negatively reinforced by the observed rewards.\nThe objective of the algorithm is to shape the population preferences to\nmaximize the fraction of the population favouring a predetermined arm. For the\ncase of binary opinions, two types of opinion dynamics are considered --\ndecreasing elasticity (modeled as a Polya urn with increasing number of balls)\nand constant elasticity (using the voter model). For the first case, we\ndescribe an Explore-then-commit policy and a Thompson sampling policy and\nanalyse the regret for each of these policies. We then show that these\nalgorithms and their analyses carry over to the constant elasticity case. We\nalso describe a Thompson sampling based algorithm for the case when more than\ntwo types of opinions are present. Finally, we discuss the case where presence\nof multiple recommendation systems gives rise to a trade-off between their\npopularity and opinion shaping objectives.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00036v1",
    "authors": ["Viraj Nadkarni", "D. Manjunath", "Sharayu Moharir"]
  },
  {
    "id": "2402.19442",
    "title": "Training Dynamics of Multi-Head Softmax Attention for In-Context\n  Learning: Emergence, Convergence, and Optimality",
    "abstract": "  We study the dynamics of gradient flow for training a multi-head softmax\nattention model for in-context learning of multi-task linear regression. We\nestablish the global convergence of gradient flow under suitable choices of\ninitialization. In addition, we prove that an interesting \"task allocation\"\nphenomenon emerges during the gradient flow dynamics, where each attention head\nfocuses on solving a single task of the multi-task model. Specifically, we\nprove that the gradient flow dynamics can be split into three phases -- a\nwarm-up phase where the loss decreases rather slowly and the attention heads\ngradually build up their inclination towards individual tasks, an emergence\nphase where each head selects a single task and the loss rapidly decreases, and\na convergence phase where the attention parameters converge to a limit.\nFurthermore, we prove the optimality of gradient flow in the sense that the\nlimiting model learned by gradient flow is on par with the best possible\nmulti-head softmax attention model up to a constant factor. Our analysis also\ndelineates a strict separation in terms of the prediction accuracy of ICL\nbetween single-head and multi-head attention models. The key technique for our\nconvergence analysis is to map the gradient flow dynamics in the parameter\nspace to a set of ordinary differential equations in the spectral domain, where\nthe relative magnitudes of the semi-singular values of the attention weights\ndetermines task allocation. To our best knowledge, our work provides the first\nconvergence result for the multi-head softmax attention model.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.19442v1",
    "authors": ["Siyu Chen", "Heejune Sheen", "Tianhao Wang", "Zhuoran Yang"]
  },
  {
    "id": "2403.00854",
    "title": "Speaker-Independent Dysarthria Severity Classification using\n  Self-Supervised Transformers and Multi-Task Learning",
    "abstract": "  Dysarthria, a condition resulting from impaired control of the speech muscles\ndue to neurological disorders, significantly impacts the communication and\nquality of life of patients. The condition's complexity, human scoring and\nvaried presentations make its assessment and management challenging. This study\npresents a transformer-based framework for automatically assessing dysarthria\nseverity from raw speech data. It can offer an objective, repeatable,\naccessible, standardised and cost-effective and compared to traditional methods\nrequiring human expert assessors. We develop a transformer framework, called\nSpeaker-Agnostic Latent Regularisation (SALR), incorporating a multi-task\nlearning objective and contrastive learning for speaker-independent multi-class\ndysarthria severity classification. The multi-task framework is designed to\nreduce reliance on speaker-specific characteristics and address the intrinsic\nintra-class variability of dysarthric speech. We evaluated on the Universal\nAccess Speech dataset using leave-one-speaker-out cross-validation, our model\ndemonstrated superior performance over traditional machine learning approaches,\nwith an accuracy of $70.48\\%$ and an F1 score of $59.23\\%$. Our SALR model also\nexceeded the previous benchmark for AI-based classification, which used support\nvector machines, by $16.58\\%$. We open the black box of our model by\nvisualising the latent space where we can observe how the model substantially\nreduces speaker-specific cues and amplifies task-specific ones, thereby showing\nits robustness. In conclusion, SALR establishes a new benchmark in\nspeaker-independent multi-class dysarthria severity classification using\ngenerative AI. The potential implications of our findings for broader clinical\napplications in automated dysarthria severity assessments.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00854v1",
    "authors": ["Lauren Stumpf", "Balasundaram Kadirvelu", "Sigourney Waibel", "A. Aldo Faisal"]
  }
]
