[
  {
    "id": "2402.12608",
    "title": "Patient-Centric Knowledge Graphs: A Survey of Current Methods,\n  Challenges, and Applications",
    "abstract": "  Patient-Centric Knowledge Graphs (PCKGs) represent an important shift in\nhealthcare that focuses on individualized patient care by mapping the patient's\nhealth information in a holistic and multi-dimensional way. PCKGs integrate\nvarious types of health data to provide healthcare professionals with a\ncomprehensive understanding of a patient's health, enabling more personalized\nand effective care. This literature review explores the methodologies,\nchallenges, and opportunities associated with PCKGs, focusing on their role in\nintegrating disparate healthcare data and enhancing patient care through a\nunified health perspective. In addition, this review also discusses the\ncomplexities of PCKG development, including ontology design, data integration\ntechniques, knowledge extraction, and structured representation of knowledge.\nIt highlights advanced techniques such as reasoning, semantic search, and\ninference mechanisms essential in constructing and evaluating PCKGs for\nactionable healthcare insights. We further explore the practical applications\nof PCKGs in personalized medicine, emphasizing their significance in improving\ndisease prediction and formulating effective treatment plans. Overall, this\nreview provides a foundational perspective on the current state-of-the-art and\nbest practices of PCKGs, guiding future research and applications in this\ndynamic field.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12608v1",
    "authors": [
      "Hassan S. Al Khatib",
      "Subash Neupane",
      "Harish Kumar Manchukonda",
      "Noorbakhsh Amiri Golilarz",
      "Sudip Mittal",
      "Amin Amirlatifi",
      "Shahram Rahimi"
    ]
  },
  {
    "id": "2402.12685",
    "title": "XRL-Bench: A Benchmark for Evaluating and Comparing Explainable\n  Reinforcement Learning Techniques",
    "abstract": "  Reinforcement Learning (RL) has demonstrated substantial potential across\ndiverse fields, yet understanding its decision-making process, especially in\nreal-world scenarios where rationality and safety are paramount, is an ongoing\nchallenge. This paper delves in to Explainable RL (XRL), a subfield of\nExplainable AI (XAI) aimed at unravelling the complexities of RL models. Our\nfocus rests on state-explaining techniques, a crucial subset within XRL\nmethods, as they reveal the underlying factors influencing an agent's actions\nat any given time. Despite their significant role, the lack of a unified\nevaluation framework hinders assessment of their accuracy and effectiveness. To\naddress this, we introduce XRL-Bench, a unified standardized benchmark tailored\nfor the evaluation and comparison of XRL methods, encompassing three main\nmodules: standard RL environments, explainers based on state importance, and\nstandard evaluators. XRL-Bench supports both tabular and image data for state\nexplanation. We also propose TabularSHAP, an innovative and competitive XRL\nmethod. We demonstrate the practical utility of TabularSHAP in real-world\nonline gaming services and offer an open-source benchmark platform for the\nstraightforward implementation and evaluation of XRL methods. Our contributions\nfacilitate the continued progression of XRL technology.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12685v1",
    "authors": [
      "Yu Xiong",
      "Zhipeng Hu",
      "Ye Huang",
      "Runze Wu",
      "Kai Guan",
      "Xingchen Fang",
      "Ji Jiang",
      "Tianze Zhou",
      "Yujing Hu",
      "Haoyu Liu",
      "Tangjie Lyu",
      "Changjie Fan"
    ]
  },
  {
    "id": "2402.12887",
    "title": "The practice of qualitative parameterisation in the development of\n  Bayesian networks",
    "abstract": "  The typical phases of Bayesian network (BN) structured development include\nspecification of purpose and scope, structure development, parameterisation and\nvalidation. Structure development is typically focused on qualitative issues\nand parameterisation quantitative issues, however there are qualitative and\nquantitative issues that arise in both phases. A common step that occurs after\nthe initial structure has been developed is to perform a rough parameterisation\nthat only captures and illustrates the intended qualitative behaviour of the\nmodel. This is done prior to a more rigorous parameterisation, ensuring that\nthe structure is fit for purpose, as well as supporting later development and\nvalidation. In our collective experience and in discussions with other\nmodellers, this step is an important part of the development process, but is\nunder-reported in the literature. Since the practice focuses on qualitative\nissues, despite being quantitative in nature, we call this step qualitative\nparameterisation and provide an outline of its role in the BN development\nprocess.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12887v1",
    "authors": ["Steven Mascaro", "Owen Woodberry", "Yue Wu", "Ann E. Nicholson"]
  },
  {
    "id": "2402.13058",
    "title": "Random Graph Set and Evidence Pattern Reasoning Model",
    "abstract": "  Evidence theory is widely used in decision-making and reasoning systems. In\nprevious research, Transferable Belief Model (TBM) is a commonly used\nevidential decision making model, but TBM is a non-preference model. In order\nto better fit the decision making goals, the Evidence Pattern Reasoning Model\n(EPRM) is proposed. By defining pattern operators and decision making\noperators, corresponding preferences can be set for different tasks. Random\nPermutation Set (RPS) expands order information for evidence theory. It is hard\nfor RPS to characterize the complex relationship between samples such as\ncycling, paralleling relationships. Therefore, Random Graph Set (RGS) were\nproposed to model complex relationships and represent more event types. In\norder to illustrate the significance of RGS and EPRM, an experiment of aircraft\nvelocity ranking was designed and 10,000 cases were simulated. The\nimplementation of EPRM called Conflict Resolution Decision optimized 18.17\\% of\nthe cases compared to Mean Velocity Decision, effectively improving the\naircraft velocity ranking. EPRM provides a unified solution for evidence-based\ndecision making.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13058v1",
    "authors": ["Tianxiang Zhan", "Zhen Li", "Yong Deng"]
  },
  {
    "id": "2402.13399",
    "title": "Learning and Sustaining Shared Normative Systems via Bayesian Rule\n  Induction in Markov Games",
    "abstract": "  A universal feature of human societies is the adoption of systems of rules\nand norms in the service of cooperative ends. How can we build learning agents\nthat do the same, so that they may flexibly cooperate with the human\ninstitutions they are embedded in? We hypothesize that agents can achieve this\nby assuming there exists a shared set of norms that most others comply with\nwhile pursuing their individual desires, even if they do not know the exact\ncontent of those norms. By assuming shared norms, a newly introduced agent can\ninfer the norms of an existing population from observations of compliance and\nviolation. Furthermore, groups of agents can converge to a shared set of norms,\neven if they initially diverge in their beliefs about what the norms are. This\nin turn enables the stability of the normative system: since agents can\nbootstrap common knowledge of the norms, this leads the norms to be widely\nadhered to, enabling new entrants to rapidly learn those norms. We formalize\nthis framework in the context of Markov games and demonstrate its operation in\na multi-agent environment via approximately Bayesian rule induction of\nobligative and prohibitive norms. Using our approach, agents are able to\nrapidly learn and sustain a variety of cooperative institutions, including\nresource management norms and compensation for pro-social labor, promoting\ncollective welfare while still allowing agents to act in their own interests.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13399v2",
    "authors": ["Ninell Oldenburg", "Tan Zhi-Xuan"]
  },
  {
    "id": "2402.13419",
    "title": "Reward Bound for Behavioral Guarantee of Model-based Planning Agents",
    "abstract": "  Recent years have seen an emerging interest in the trustworthiness of machine\nlearning-based agents in the wild, especially in robotics, to provide safety\nassurance for the industry. Obtaining behavioral guarantees for these agents\nremains an important problem. In this work, we focus on guaranteeing a\nmodel-based planning agent reaches a goal state within a specific future time\nstep. We show that there exists a lower bound for the reward at the goal state,\nsuch that if the said reward is below that bound, it is impossible to obtain\nsuch a guarantee. By extension, we show how to enforce preferences over\nmultiple goals.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13419v1",
    "authors": ["Zhiyu An", "Xianzhong Ding", "Wan Du"]
  },
  {
    "id": "2402.12624",
    "title": "Efficient Parameter Mining and Freezing for Continual Object Detection",
    "abstract": "  Continual Object Detection is essential for enabling intelligent agents to\ninteract proactively with humans in real-world settings. While\nparameter-isolation strategies have been extensively explored in the context of\ncontinual learning for classification, they have yet to be fully harnessed for\nincremental object detection scenarios. Drawing inspiration from prior research\nthat focused on mining individual neuron responses and integrating insights\nfrom recent developments in neural pruning, we proposed efficient ways to\nidentify which layers are the most important for a network to maintain the\nperformance of a detector across sequential updates. The presented findings\nhighlight the substantial advantages of layer-level parameter isolation in\nfacilitating incremental learning within object detection models, offering\npromising avenues for future research and application in real-world scenarios.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12624v1",
    "authors": [
      "Angelo G. Menezes",
      "Augusto J. Peterlevitz",
      "Mateus A. Chinelatto",
      "André C. P. L. F. de Carvalho"
    ]
  },
  {
    "id": "2402.12646",
    "title": "Training Artificial Neural Networks by Coordinate Search Algorithm",
    "abstract": "  Training Artificial Neural Networks poses a challenging and critical problem\nin machine learning. Despite the effectiveness of gradient-based learning\nmethods, such as Stochastic Gradient Descent (SGD), in training neural\nnetworks, they do have several limitations. For instance, they require\ndifferentiable activation functions, and cannot optimize a model based on\nseveral independent non-differentiable loss functions simultaneously; for\nexample, the F1-score, which is used during testing, can be used during\ntraining when a gradient-free optimization algorithm is utilized. Furthermore,\nthe training in any DNN can be possible with a small size of the training\ndataset. To address these concerns, we propose an efficient version of the\ngradient-free Coordinate Search (CS) algorithm, an instance of General Pattern\nSearch methods, for training neural networks. The proposed algorithm can be\nused with non-differentiable activation functions and tailored to\nmulti-objective/multi-loss problems. Finding the optimal values for weights of\nANNs is a large-scale optimization problem. Therefore instead of finding the\noptimal value for each variable, which is the common technique in classical CS,\nwe accelerate optimization and convergence by bundling the weights. In fact,\nthis strategy is a form of dimension reduction for optimization problems. Based\non the experimental results, the proposed method, in some cases, outperforms\nthe gradient-based approach, particularly, in situations with insufficient\nlabeled training data. The performance plots demonstrate a high convergence\nrate, highlighting the capability of our suggested method to find a reasonable\nsolution with fewer function calls. As of now, the only practical and efficient\nway of training ANNs with hundreds of thousands of weights is gradient-based\nalgorithms such as SGD or Adam. In this paper we introduce an alternative\nmethod for training ANN.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12646v1",
    "authors": [
      "Ehsan Rokhsatyazdi",
      "Shahryar Rahnamayan",
      "Sevil Zanjani Miyandoab",
      "Azam Asilian Bidgoli",
      "H. R. Tizhoosh"
    ]
  },
  {
    "id": "2402.12656",
    "title": "HyperMoE: Paying Attention to Unselected Experts in Mixture of Experts\n  via Dynamic Transfer",
    "abstract": "  The Mixture of Experts (MoE) for language models has been proven effective in\naugmenting the capacity of models by dynamically routing each input token to a\nspecific subset of experts for processing. Despite the success, most existing\nmethods face a challenge for balance between sparsity and the availability of\nexpert knowledge: enhancing performance through increased use of expert\nknowledge often results in diminishing sparsity during expert selection. To\nmitigate this contradiction, we propose HyperMoE, a novel MoE framework built\nupon Hypernetworks. This framework integrates the computational processes of\nMoE with the concept of knowledge transferring in multi-task learning. Specific\nmodules generated based on the information of unselected experts serve as\nsupplementary information, which allows the knowledge of experts not selected\nto be used while maintaining selection sparsity. Our comprehensive empirical\nevaluations across multiple datasets and backbones establish that HyperMoE\nsignificantly outperforms existing MoE methods under identical conditions\nconcerning the number of experts.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12656v2",
    "authors": ["Hao Zhao", "Zihan Qiu", "Huijia Wu", "Zili Wang", "Zhaofeng He", "Jie Fu"]
  },
  {
    "id": "2402.12702",
    "title": "From Cloud to Edge: Rethinking Generative AI for Low-Resource Design\n  Challenges",
    "abstract": "  Generative Artificial Intelligence (AI) has shown tremendous prospects in all\naspects of technology, including design. However, due to its heavy demand on\nresources, it is usually trained on large computing infrastructure and often\nmade available as a cloud-based service. In this position paper, we consider\nthe potential, challenges, and promising approaches for generative AI for\ndesign on the edge, i.e., in resource-constrained settings where memory,\ncompute, energy (battery) and network connectivity may be limited. Adapting\ngenerative AI for such settings involves overcoming significant hurdles,\nprimarily in how to streamline complex models to function efficiently in\nlow-resource environments. This necessitates innovative approaches in model\ncompression, efficient algorithmic design, and perhaps even leveraging edge\ncomputing. The objective is to harness the power of generative AI in creating\nbespoke solutions for design problems, such as medical interventions, farm\nequipment maintenance, and educational material design, tailored to the unique\nconstraints and needs of remote areas. These efforts could democratize access\nto advanced technology and foster sustainable development, ensuring universal\naccessibility and environmental consideration of AI-driven design benefits.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12702v2",
    "authors": [
      "Sai Krishna Revanth Vuruma",
      "Ashley Margetts",
      "Jianhai Su",
      "Faez Ahmed",
      "Biplav Srivastava"
    ]
  },
  {
    "id": "2402.12720",
    "title": "Revisiting the Information Capacity of Neural Network Watermarks: Upper\n  Bound Estimation and Beyond",
    "abstract": "  To trace the copyright of deep neural networks, an owner can embed its\nidentity information into its model as a watermark. The capacity of the\nwatermark quantify the maximal volume of information that can be verified from\nthe watermarked model. Current studies on capacity focus on the ownership\nverification accuracy under ordinary removal attacks and fail to capture the\nrelationship between robustness and fidelity. This paper studies the capacity\nof deep neural network watermarks from an information theoretical perspective.\nWe propose a new definition of deep neural network watermark capacity analogous\nto channel capacity, analyze its properties, and design an algorithm that\nyields a tight estimation of its upper bound under adversarial overwriting. We\nalso propose a universal non-invasive method to secure the transmission of the\nidentity message beyond capacity by multiple rounds of ownership verification.\nOur observations provide evidence for neural network owners and defenders that\nare curious about the tradeoff between the integrity of their ownership and the\nperformance degradation of their products.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12720v1",
    "authors": ["Fangqi Li", "Haodong Zhao", "Wei Du", "Shilin Wang"]
  },
  {
    "id": "2402.12721",
    "title": "PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for\n  Recognizing Low-Quality Images",
    "abstract": "  A standard practice in developing image recognition models is to train a\nmodel on a specific image resolution and then deploy it. However, in real-world\ninference, models often encounter images different from the training sets in\nresolution and/or subject to natural variations such as weather changes, noise\ntypes and compression artifacts. While traditional solutions involve training\nmultiple models for different resolutions or input variations, these methods\nare computationally expensive and thus do not scale in practice. To this end,\nwe propose a novel neural network model, parallel-structured and all-component\nFourier neural operator (PAC-FNO), that addresses the problem. Unlike\nconventional feed-forward neural networks, PAC-FNO operates in the frequency\ndomain, allowing it to handle images of varying resolutions within a single\nmodel. We also propose a two-stage algorithm for training PAC-FNO with a\nminimal modification to the original, downstream model. Moreover, the proposed\nPAC-FNO is ready to work with existing image recognition models. Extensively\nevaluating methods with seven image recognition benchmarks, we show that the\nproposed PAC-FNO improves the performance of existing baseline models on images\nwith various resolutions by up to 77.1% and various types of natural variations\nin the images at inference.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12721v1",
    "authors": [
      "Jinsung Jeon",
      "Hyundong Jin",
      "Jonghyun Choi",
      "Sanghyun Hong",
      "Dongeun Lee",
      "Kookjin Lee",
      "Noseong Park"
    ]
  },
  {
    "id": "2402.12729",
    "title": "Scalable and reliable deep transfer learning for intelligent fault\n  detection via multi-scale neural processes embedded with knowledge",
    "abstract": "  Deep transfer learning (DTL) is a fundamental method in the field of\nIntelligent Fault Detection (IFD). It aims to mitigate the degradation of\nmethod performance that arises from the discrepancies in data distribution\nbetween training set (source domain) and testing set (target domain).\nConsidering the fact that fault data collection is challenging and certain\nfaults are scarce, DTL-based methods face the limitation of available\nobservable data, which reduces the detection performance of the methods in the\ntarget domain. Furthermore, DTL-based methods lack comprehensive uncertainty\nanalysis that is essential for building reliable IFD systems. To address the\naforementioned problems, this paper proposes a novel DTL-based method known as\nNeural Processes-based deep transfer learning with graph convolution network\n(GTNP). Feature-based transfer strategy of GTNP bridges the data distribution\ndiscrepancies of source domain and target domain in high-dimensional space.\nBoth the joint modeling based on global and local latent variables and sparse\nsampling strategy reduce the demand of observable data in the target domain.\nThe multi-scale uncertainty analysis is obtained by using the distribution\ncharacteristics of global and local latent variables. Global analysis of\nuncertainty enables GTNP to provide quantitative values that reflect the\ncomplexity of methods and the difficulty of tasks. Local analysis of\nuncertainty allows GTNP to model uncertainty (confidence of the fault detection\nresult) at each sample affected by noise and bias. The validation of the\nproposed method is conducted across 3 IFD tasks, consistently showing the\nsuperior detection performance of GTNP compared to the other DTL-based methods.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12729v1",
    "authors": ["Zhongzhi Li", "Jingqi Tu", "Jiacheng Zhu", "Jianliang Ai", "Yiqun Dong"]
  },
  {
    "id": "2402.12733",
    "title": "BMLP: Behavior-aware MLP for Heterogeneous Sequential Recommendation",
    "abstract": "  In real recommendation scenarios, users often have different types of\nbehaviors, such as clicking and buying. Existing research methods show that it\nis possible to capture the heterogeneous interests of users through different\ntypes of behaviors. However, most multi-behavior approaches have limitations in\nlearning the relationship between different behaviors. In this paper, we\npropose a novel multilayer perceptron (MLP)-based heterogeneous sequential\nrecommendation method, namely behavior-aware multilayer perceptron (BMLP).\nSpecifically, it has two main modules, including a heterogeneous interest\nperception (HIP) module, which models behaviors at multiple granularities\nthrough behavior types and transition relationships, and a purchase intent\nperception (PIP) module, which adaptively fuses subsequences of auxiliary\nbehaviors to capture users' purchase intent. Compared with mainstream sequence\nmodels, MLP is competitive in terms of accuracy and has unique advantages in\nsimplicity and efficiency. Extensive experiments show that BMLP achieves\nsignificant improvement over state-of-the-art algorithms on four public\ndatasets. In addition, its pure MLP architecture leads to a linear time\ncomplexity.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12733v1",
    "authors": ["Weixin Li", "Yuhao Wu", "Yang Liu", "Weike Pan", "Zhong Ming"]
  },
  {
    "id": "2402.12736",
    "title": "CST: Calibration Side-Tuning for Parameter and Memory Efficient Transfer\n  Learning",
    "abstract": "  Achieving a universally high accuracy in object detection is quite\nchallenging, and the mainstream focus in the industry currently lies on\ndetecting specific classes of objects. However, deploying one or multiple\nobject detection networks requires a certain amount of GPU memory for training\nand storage capacity for inference. This presents challenges in terms of how to\neffectively coordinate multiple object detection tasks under\nresource-constrained conditions. This paper introduces a lightweight\nfine-tuning strategy called Calibration side tuning, which integrates aspects\nof adapter tuning and side tuning to adapt the successful techniques employed\nin transformers for use with ResNet. The Calibration side tuning architecture\nthat incorporates maximal transition calibration, utilizing a small number of\nadditional parameters to enhance network performance while maintaining a smooth\ntraining process. Furthermore, this paper has conducted an analysis on multiple\nfine-tuning strategies and have implemented their application within ResNet,\nthereby expanding the research on fine-tuning strategies for object detection\nnetworks. Besides, this paper carried out extensive experiments using five\nbenchmark datasets. The experimental results demonstrated that this method\noutperforms other compared state-of-the-art techniques, and a better balance\nbetween the complexity and performance of the finetune schemes is achieved.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12736v1",
    "authors": ["Feng Chen"]
  },
  {
    "id": "2402.12749",
    "title": "Me LLaMA: Foundation Large Language Models for Medical Applications",
    "abstract": "  Recent large language models (LLMs) like ChatGPT and LLaMA have shown great\npromise in many AI applications. However, their performance on medical tasks is\nsuboptimal and can be further improved by training on large domain-specific\ndatasets. This study introduces Me LLaMA, a medical LLM family including\nfoundation models - Me LLaMA 13/70B and their chat-enhanced versions - Me LLaMA\n13/70B-chat, developed through the continual pre-training and instruction\ntuning of LLaMA2 using large medical data. Our domain-specific data suite for\ntraining and evaluation, includes a large-scale continual pre-training dataset\nwith 129B tokens, an instruction tuning dataset with 214k samples, and a\nmedical evaluation benchmark (MIBE) across six tasks with 14 datasets. Our\nextensive evaluation using MIBE shows that Me LLaMA models surpass existing\nopen-source medical LLMs in zero-shot and few-shot learning and outperform\ncommercial giants like ChatGPT on 6 out of 8 datasets and GPT-4 in 3 out of 8\ndatasets. In addition, we empirically investigated the catastrophic forgetting\nproblem, and our results show that Me LLaMA models outperform other medical\nLLMs. Me LLaMA is one of the first and largest open-source foundational LLMs\ndesigned for the medical domain, using both biomedical and clinical data. It\nexhibits superior performance across both general and medical tasks compared to\nother medical LLMs, rendering it an attractive choice for medical AI\napplications. All resources are available at:\nhttps://github.com/BIDS-Xu-Lab/Me-LLaMA.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12749v1",
    "authors": [
      "Qianqian Xie",
      "Qingyu Chen",
      "Aokun Chen",
      "Cheng Peng",
      "Yan Hu",
      "Fongci Lin",
      "Xueqing Peng",
      "Jimin Huang",
      "Jeffrey Zhang",
      "Vipina Keloth",
      "Huan He",
      "Lucila Ohno-Machido",
      "Yonghui Wu",
      "Hua Xu",
      "Jiang Bian"
    ]
  },
  {
    "id": "2402.12782",
    "title": "Advancing GenAI Assisted Programming--A Comparative Study on Prompt\n  Efficiency and Code Quality Between GPT-4 and GLM-4",
    "abstract": "  This study aims to explore the best practices for utilizing GenAI as a\nprogramming tool, through a comparative analysis between GPT-4 and GLM-4. By\nevaluating prompting strategies at different levels of complexity, we identify\nthat simplest and straightforward prompting strategy yields best code\ngeneration results. Additionally, adding a CoT-like preliminary confirmation\nstep would further increase the success rate. Our results reveal that while\nGPT-4 marginally outperforms GLM-4, the difference is minimal for average\nusers. In our simplified evaluation model, we see a remarkable 30 to 100-fold\nincrease in code generation efficiency over traditional coding norms. Our GenAI\nCoding Workshop highlights the effectiveness and accessibility of the prompting\nmethodology developed in this study. We observe that GenAI-assisted coding\nwould trigger a paradigm shift in programming landscape, which necessitates\ndevelopers to take on new roles revolving around supervising and guiding GenAI,\nand to focus more on setting high-level objectives and engaging more towards\ninnovation.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12782v1",
    "authors": ["Angus Yang", "Zehan Li", "Jie Li"]
  },
  {
    "id": "2402.12789",
    "title": "Fair Classifiers Without Fair Training: An Influence-Guided Data\n  Sampling Approach",
    "abstract": "  A fair classifier should ensure the benefit of people from different groups,\nwhile the group information is often sensitive and unsuitable for model\ntraining. Therefore, learning a fair classifier but excluding sensitive\nattributes in the training dataset is important. In this paper, we study\nlearning fair classifiers without implementing fair training algorithms to\navoid possible leakage of sensitive information. Our theoretical analyses\nvalidate the possibility of this approach, that traditional training on a\ndataset with an appropriate distribution shift can reduce both the upper bound\nfor fairness disparity and model generalization error, indicating that fairness\nand accuracy can be improved simultaneously with simply traditional training.\nWe then propose a tractable solution to progressively shift the original\ntraining data during training by sampling influential data, where the sensitive\nattribute of new data is not accessed in sampling or used in training.\nExtensive experiments on real-world data demonstrate the effectiveness of our\nproposed algorithm.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12789v1",
    "authors": [
      "Jinlong Pang",
      "Jialu Wang",
      "Zhaowei Zhu",
      "Yuanshun Yao",
      "Chen Qian",
      "Yang Liu"
    ]
  },
  {
    "id": "2402.12835",
    "title": "PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of\n  LLMs",
    "abstract": "  While Large language models (LLMs) have demonstrated considerable\ncapabilities across various natural language tasks, they often fall short of\nthe performance achieved by domain-specific state-of-the-art models. One\npotential approach to enhance domain-specific capabilities of LLMs involves\nfine-tuning them using corresponding datasets. However, this method can be both\nresource and time-intensive, and not applicable to closed-source commercial\nLLMs. In this paper, we propose Preference Adaptation for Enhancing\nDomain-specific Abilities of LLMs (PANDA), a method designed to augment the\ndomain-specific capabilities of LLMs by leveraging insights from the response\npreference of expert models without requiring fine-tuning. Our experimental\nresults reveal that PANDA significantly enhances the domain-specific ability of\nLLMs on text classification and interactive decision tasks. Moreover, LLM with\nPANDA even outperforms the expert model that being learned on 4 tasks of\nScienceWorld. This finding highlights the potential of exploring tuning-free\napproaches to achieve weak-to-strong generalization.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12835v1",
    "authors": [
      "An Liu",
      "Zonghan Yang",
      "Zhenhe Zhang",
      "Qingyuan Hu",
      "Peng Li",
      "Ming Yan",
      "Ji Zhang",
      "Fei Huang",
      "Yang Liu"
    ]
  },
  {
    "id": "2402.12843",
    "title": "SolarPanel Segmentation :Self-Supervised Learning for Imperfect Datasets",
    "abstract": "  The increasing adoption of solar energy necessitates advanced methodologies\nfor monitoring and maintenance to ensure optimal performance of solar panel\ninstallations. A critical component in this context is the accurate\nsegmentation of solar panels from aerial or satellite imagery, which is\nessential for identifying operational issues and assessing efficiency. This\npaper addresses the significant challenges in panel segmentation, particularly\nthe scarcity of annotated data and the labour-intensive nature of manual\nannotation for supervised learning. We explore and apply Self-Supervised\nLearning (SSL) to solve these challenges. We demonstrate that SSL significantly\nenhances model generalization under various conditions and reduces dependency\non manually annotated data, paving the way for robust and adaptable solar panel\nsegmentation solutions.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12843v1",
    "authors": [
      "Sankarshanaa Sagaram",
      "Aditya Kasliwal",
      "Krish Didwania",
      "Laven Srivastava",
      "Pallavi Kailas",
      "Ujjwal Verma"
    ]
  },
  {
    "id": "2402.12845",
    "title": "MORE-3S:Multimodal-based Offline Reinforcement Learning with Shared\n  Semantic Spaces",
    "abstract": "  Drawing upon the intuition that aligning different modalities to the same\nsemantic embedding space would allow models to understand states and actions\nmore easily, we propose a new perspective to the offline reinforcement learning\n(RL) challenge. More concretely, we transform it into a supervised learning\ntask by integrating multimodal and pre-trained language models. Our approach\nincorporates state information derived from images and action-related data\nobtained from text, thereby bolstering RL training performance and promoting\nlong-term strategic thinking. We emphasize the contextual understanding of\nlanguage and demonstrate how decision-making in RL can benefit from aligning\nstates' and actions' representation with languages' representation. Our method\nsignificantly outperforms current baselines as evidenced by evaluations\nconducted on Atari and OpenAI Gym environments. This contributes to advancing\noffline RL performance and efficiency while providing a novel perspective on\noffline RL.Our code and data are available at\nhttps://github.com/Zheng0428/MORE_.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12845v1",
    "authors": [
      "Tianyu Zheng",
      "Ge Zhang",
      "Xingwei Qu",
      "Ming Kuang",
      "Stephen W. Huang",
      "Zhaofeng He"
    ]
  },
  {
    "id": "2402.12846",
    "title": "ConVQG: Contrastive Visual Question Generation with Multimodal Guidance",
    "abstract": "  Asking questions about visual environments is a crucial way for intelligent\nagents to understand rich multi-faceted scenes, raising the importance of\nVisual Question Generation (VQG) systems. Apart from being grounded to the\nimage, existing VQG systems can use textual constraints, such as expected\nanswers or knowledge triplets, to generate focused questions. These constraints\nallow VQG systems to specify the question content or leverage external\ncommonsense knowledge that can not be obtained from the image content only.\nHowever, generating focused questions using textual constraints while enforcing\na high relevance to the image content remains a challenge, as VQG systems often\nignore one or both forms of grounding. In this work, we propose Contrastive\nVisual Question Generation (ConVQG), a method using a dual contrastive\nobjective to discriminate questions generated using both modalities from those\nbased on a single one. Experiments on both knowledge-aware and standard VQG\nbenchmarks demonstrate that ConVQG outperforms the state-of-the-art methods and\ngenerates image-grounded, text-guided, and knowledge-rich questions. Our human\nevaluation results also show preference for ConVQG questions compared to\nnon-contrastive baselines.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12846v1",
    "authors": [
      "Li Mi",
      "Syrielle Montariol",
      "Javiera Castillo-Navarro",
      "Xianjie Dai",
      "Antoine Bosselut",
      "Devis Tuia"
    ]
  },
  {
    "id": "2402.12916",
    "title": "Data Pipeline Training: Integrating AutoML to Optimize the Data Flow of\n  Machine Learning Models",
    "abstract": "  Data Pipeline plays an indispensable role in tasks such as modeling machine\nlearning and developing data products. With the increasing diversification and\ncomplexity of Data sources, as well as the rapid growth of data volumes,\nbuilding an efficient Data Pipeline has become crucial for improving work\nefficiency and solving complex problems. This paper focuses on exploring how to\noptimize data flow through automated machine learning methods by integrating\nAutoML with Data Pipeline. We will discuss how to leverage AutoML technology to\nenhance the intelligence of Data Pipeline, thereby achieving better results in\nmachine learning tasks. By delving into the automation and optimization of Data\nflows, we uncover key strategies for constructing efficient data pipelines that\ncan adapt to the ever-changing data landscape. This not only accelerates the\nmodeling process but also provides innovative solutions to complex problems,\nenabling more significant outcomes in increasingly intricate data domains.\nKeywords- Data Pipeline Training;AutoML; Data environment; Machine learning\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12916v1",
    "authors": ["Jiang Wu", "Hongbo Wang", "Chunhe Ni", "Chenwei Zhang", "Wenran Lu"]
  },
  {
    "id": "2402.12939",
    "title": "Discovering Behavioral Modes in Deep Reinforcement Learning Policies\n  Using Trajectory Clustering in Latent Space",
    "abstract": "  Understanding the behavior of deep reinforcement learning (DRL) agents is\ncrucial for improving their performance and reliability. However, the\ncomplexity of their policies often makes them challenging to understand. In\nthis paper, we introduce a new approach for investigating the behavior modes of\nDRL policies, which involves utilizing dimensionality reduction and trajectory\nclustering in the latent space of neural networks. Specifically, we use\nPairwise Controlled Manifold Approximation Projection (PaCMAP) for\ndimensionality reduction and TRACLUS for trajectory clustering to analyze the\nlatent space of a DRL policy trained on the Mountain Car control task. Our\nmethodology helps identify diverse behavior patterns and suboptimal choices by\nthe policy, thus allowing for targeted improvements. We demonstrate how our\napproach, combined with domain knowledge, can enhance a policy's performance in\nspecific regions of the state space.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12939v1",
    "authors": ["Sindre Benjamin Remman", "Anastasios M. Lekkas"]
  },
  {
    "id": "2402.12950",
    "title": "QuanTest: Entanglement-Guided Testing of Quantum Neural Network Systems",
    "abstract": "  Quantum Neural Network (QNN) combines the Deep Learning (DL) principle with\nthe fundamental theory of quantum mechanics to achieve machine learning tasks\nwith quantum acceleration. Recently, QNN systems have been found to manifest\nrobustness issues similar to classical DL systems. There is an urgent need for\nways to test their correctness and security. However, QNN systems differ\nsignificantly from traditional quantum software and classical DL systems,\nposing critical challenges for QNN testing. These challenges include the\ninapplicability of traditional quantum software testing methods, the dependence\nof quantum test sample generation on perturbation operators, and the absence of\neffective information in quantum neurons. In this paper, we propose QuanTest, a\nquantum entanglement-guided adversarial testing framework to uncover potential\nerroneous behaviors in QNN systems. We design a quantum entanglement adequacy\ncriterion to quantify the entanglement acquired by the input quantum states\nfrom the QNN system, along with two similarity metrics to measure the proximity\nof generated quantum adversarial examples to the original inputs. Subsequently,\nQuanTest formulates the problem of generating test inputs that maximize the\nquantum entanglement sufficiency and capture incorrect behaviors of the QNN\nsystem as a joint optimization problem and solves it in a gradient-based manner\nto generate quantum adversarial examples. Experimental results demonstrate that\nQuanTest possesses the capability to capture erroneous behaviors in QNN systems\n(generating 67.48%-96.05% more test samples than the random noise under the\nsame perturbation size constraints). The entanglement-guided approach proves\neffective in adversarial testing, generating more adversarial examples (maximum\nincrease reached 21.32%).\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12950v1",
    "authors": ["Jinjing Shi", "Zimeng Xiao", "Heyuan Shi", "Yu Jiang", "Xuelong Li"]
  },
  {
    "id": "2402.12969",
    "title": "GlórIA -- A Generative and Open Large Language Model for Portuguese",
    "abstract": "  Significant strides have been made in natural language tasks, largely\nattributed to the emergence of powerful large language models (LLMs). These\nmodels, pre-trained on extensive and diverse corpora, have become increasingly\ncapable of comprehending the intricacies of language. Despite the abundance of\nLLMs for many high-resource languages, the availability of such models remains\nlimited for European Portuguese. We introduce Gl\\'orIA, a robust European\nPortuguese decoder LLM. To pre-train Gl\\'orIA, we assembled a comprehensive\nPT-PT text corpus comprising 35 billion tokens from various sources. We present\nour pre-training methodology, followed by an assessment of the model's\neffectiveness on multiple downstream tasks. Additionally, to evaluate our\nmodels' language modeling capabilities, we introduce CALAME-PT (Context-Aware\nLAnguage Modeling Evaluation for Portuguese), the first Portuguese zero-shot\nlanguage-modeling benchmark. Evaluation shows that Gl\\'orIA significantly\noutperforms existing open PT decoder models in language modeling and that it\ncan generate sound, knowledge-rich, and coherent PT-PT text. The model also\nexhibits strong potential for various downstream tasks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12969v1",
    "authors": ["Ricardo Lopes", "João Magalhães", "David Semedo"]
  },
  {
    "id": "2402.12976",
    "title": "The Impact of Demonstrations on Multilingual In-Context Learning: A\n  Multidimensional Analysis",
    "abstract": "  In-context learning is a popular inference strategy where large language\nmodels solve a task using only a few labelled demonstrations without needing\nany parameter updates. Compared to work on monolingual (English) in-context\nlearning, multilingual in-context learning is under-explored, and we lack an\nin-depth understanding of the role of demonstrations in this context. To\naddress this gap, we conduct a multidimensional analysis of multilingual\nin-context learning, experimenting with 5 models from different model families,\n9 datasets covering classification and generation tasks, and 56 typologically\ndiverse languages. Our results reveal that the effectiveness of demonstrations\nvaries significantly across models, tasks, and languages. We also find that\nLlama 2-Chat, GPT-3.5, and GPT-4 are largely insensitive to the quality of\ndemonstrations. Instead, a carefully crafted template often eliminates the\nbenefits of demonstrations for some tasks and languages altogether. These\nfindings show that the importance of demonstrations might be overestimated. Our\nwork highlights the need for granular evaluation across multiple axes towards a\nbetter understanding of in-context learning.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12976v1",
    "authors": [
      "Miaoran Zhang",
      "Vagrant Gautam",
      "Mingyang Wang",
      "Jesujoba O. Alabi",
      "Xiaoyu Shen",
      "Dietrich Klakow",
      "Marius Mosbach"
    ]
  },
  {
    "id": "2402.12984",
    "title": "Can GNN be Good Adapter for LLMs?",
    "abstract": "  Recently, large language models (LLMs) have demonstrated superior\ncapabilities in understanding and zero-shot learning on textual data, promising\nsignificant advances for many text-related domains. In the graph domain,\nvarious real-world scenarios also involve textual data, where tasks and node\nfeatures can be described by text. These text-attributed graphs (TAGs) have\nbroad applications in social media, recommendation systems, etc. Thus, this\npaper explores how to utilize LLMs to model TAGs. Previous methods for TAG\nmodeling are based on million-scale LMs. When scaled up to billion-scale LLMs,\nthey face huge challenges in computational costs. Additionally, they also\nignore the zero-shot inference capabilities of LLMs. Therefore, we propose\nGraphAdapter, which uses a graph neural network (GNN) as an efficient adapter\nin collaboration with LLMs to tackle TAGs. In terms of efficiency, the GNN\nadapter introduces only a few trainable parameters and can be trained with low\ncomputation costs. The entire framework is trained using auto-regression on\nnode text (next token prediction). Once trained, GraphAdapter can be seamlessly\nfine-tuned with task-specific prompts for various downstream tasks. Through\nextensive experiments across multiple real-world TAGs, GraphAdapter based on\nLlama 2 gains an average improvement of approximately 5\\% in terms of node\nclassification. Furthermore, GraphAdapter can also adapt to other language\nmodels, including RoBERTa, GPT-2. The promising results demonstrate that GNNs\ncan serve as effective adapters for LLMs in TAG modeling.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12984v1",
    "authors": [
      "Xuanwen Huang",
      "Kaiqiao Han",
      "Yang Yang",
      "Dezheng Bao",
      "Quanjin Tao",
      "Ziwei Chai",
      "Qi Zhu"
    ]
  },
  {
    "id": "2402.13025",
    "title": "CFEVER: A Chinese Fact Extraction and VERification Dataset",
    "abstract": "  We present CFEVER, a Chinese dataset designed for Fact Extraction and\nVERification. CFEVER comprises 30,012 manually created claims based on content\nin Chinese Wikipedia. Each claim in CFEVER is labeled as \"Supports\", \"Refutes\",\nor \"Not Enough Info\" to depict its degree of factualness. Similar to the FEVER\ndataset, claims in the \"Supports\" and \"Refutes\" categories are also annotated\nwith corresponding evidence sentences sourced from single or multiple pages in\nChinese Wikipedia. Our labeled dataset holds a Fleiss' kappa value of 0.7934\nfor five-way inter-annotator agreement. In addition, through the experiments\nwith the state-of-the-art approaches developed on the FEVER dataset and a\nsimple baseline for CFEVER, we demonstrate that our dataset is a new rigorous\nbenchmark for factual extraction and verification, which can be further used\nfor developing automated systems to alleviate human fact-checking efforts.\nCFEVER is available at https://ikmlab.github.io/CFEVER.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13025v1",
    "authors": [
      "Ying-Jia Lin",
      "Chun-Yi Lin",
      "Chia-Jen Yeh",
      "Yi-Ting Li",
      "Yun-Yu Hu",
      "Chih-Hao Hsu",
      "Mei-Feng Lee",
      "Hung-Yu Kao"
    ]
  },
  {
    "id": "2402.13028",
    "title": "Heterogeneous Graph Reasoning for Fact Checking over Texts and Tables",
    "abstract": "  Fact checking aims to predict claim veracity by reasoning over multiple\nevidence pieces. It usually involves evidence retrieval and veracity reasoning.\nIn this paper, we focus on the latter, reasoning over unstructured text and\nstructured table information. Previous works have primarily relied on\nfine-tuning pretrained language models or training homogeneous-graph-based\nmodels. Despite their effectiveness, we argue that they fail to explore the\nrich semantic information underlying the evidence with different structures. To\naddress this, we propose a novel word-level Heterogeneous-graph-based model for\nFact Checking over unstructured and structured information, namely HeterFC. Our\napproach leverages a heterogeneous evidence graph, with words as nodes and\nthoughtfully designed edges representing different evidence properties. We\nperform information propagation via a relational graph neural network,\nfacilitating interactions between claims and evidence. An attention-based\nmethod is utilized to integrate information, combined with a language model for\ngenerating predictions. We introduce a multitask loss function to account for\npotential inaccuracies in evidence retrieval. Comprehensive experiments on the\nlarge fact checking dataset FEVEROUS demonstrate the effectiveness of HeterFC.\nCode will be released at: https://github.com/Deno-V/HeterFC.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13028v1",
    "authors": ["Haisong Gong", "Weizhi Xu", "Shu wu", "Qiang Liu", "Liang Wang"]
  },
  {
    "id": "2402.13035",
    "title": "Learning to Check: Unleashing Potentials for Self-Correction in Large\n  Language Models",
    "abstract": "  Large language models (LLMs) have made significant strides in reasoning\ncapabilities, with ongoing efforts to refine their reasoning through\nself-correction. However, recent studies suggest that self-correction can be\nlimited or even counterproductive without external accurate knowledge, raising\nquestions about the limits and effectiveness of self-correction. In this paper,\nwe aim to enhance LLM's self-checking capabilities by meticulously designing\ntraining data, thereby improving the accuracy of self-correction. We conduct a\ndetailed analysis of error types in mathematical reasoning and develop a\ntailored prompt, termed \"Step CoT Check\". Then we construct a\nchecking-correction dataset for training models. After integrating the original\nCoT data and checking-correction data for training, we observe that models\ncould improve their self-checking capabilities, thereby enhancing their\nself-correction capacity and eliminating the need for external feedback or\nground truth labels to ascertain the endpoint of correction. We compare the\nperformance of models fine-tuned with the \"Step CoT Check\" prompt against those\nrefined using other promps within the context of checking-correction data. The\n\"Step CoT Check\" outperforms the other two check formats in model with lager\nparameters, providing more precise feedback thus achieving a higher rate of\ncorrectness. For reproducibility, all the datasets and codes are provided in\nhttps://github.com/bammt/Learn-to-check.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13035v2",
    "authors": ["Che Zhang", "Zhenyang Xiao", "Chengcheng Han", "Yixin Lian", "Yuejian Fang"]
  },
  {
    "id": "2402.13037",
    "title": "Align Your Intents: Offline Imitation Learning via Optimal Transport",
    "abstract": "  Offline reinforcement learning (RL) addresses the problem of sequential\ndecision-making by learning optimal policy through pre-collected data, without\ninteracting with the environment. As yet, it has remained somewhat impractical,\nbecause one rarely knows the reward explicitly and it is hard to distill it\nretrospectively. Here, we show that an imitating agent can still learn the\ndesired behavior merely from observing the expert, despite the absence of\nexplicit rewards or action labels. In our method, AILOT (Aligned Imitation\nLearning via Optimal Transport), we involve special representation of states in\na form of intents that incorporate pairwise spatial distances within the data.\nGiven such representations, we define intrinsic reward function via optimal\ntransport distance between the expert's and the agent's trajectories. We report\nthat AILOT outperforms state-of-the art offline imitation learning algorithms\non D4RL benchmarks and improves the performance of other offline RL algorithms\nin the sparse-reward tasks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13037v1",
    "authors": ["Maksim Bobrin", "Nazar Buzun", "Dmitrii Krylov", "Dmitry V. Dylov"]
  },
  {
    "id": "2402.13055",
    "title": "Identifying Semantic Induction Heads to Understand In-Context Learning",
    "abstract": "  Although large language models (LLMs) have demonstrated remarkable\nperformance, the lack of transparency in their inference logic raises concerns\nabout their trustworthiness. To gain a better understanding of LLMs, we conduct\na detailed analysis of the operations of attention heads and aim to better\nunderstand the in-context learning of LLMs. Specifically, we investigate\nwhether attention heads encode two types of relationships between tokens\npresent in natural languages: the syntactic dependency parsed from sentences\nand the relation within knowledge graphs. We find that certain attention heads\nexhibit a pattern where, when attending to head tokens, they recall tail tokens\nand increase the output logits of those tail tokens. More crucially, the\nformulation of such semantic induction heads has a close correlation with the\nemergence of the in-context learning ability of language models. The study of\nsemantic attention heads advances our understanding of the intricate operations\nof attention heads in transformers, and further provides new insights into the\nin-context learning of LLMs.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13055v1",
    "authors": ["Jie Ren", "Qipeng Guo", "Hang Yan", "Dongrui Liu", "Xipeng Qiu", "Dahua Lin"]
  },
  {
    "id": "2402.13093",
    "title": "Event-level Knowledge Editing",
    "abstract": "  Knowledge editing aims at updating knowledge of large language models (LLMs)\nto prevent them from becoming outdated. Existing work edits LLMs at the level\nof factual knowledge triplets. However, natural knowledge updates in the real\nworld come from the occurrences of new events rather than direct changes in\nfactual triplets. In this paper, we propose a new task setting: event-level\nknowledge editing, which directly edits new events into LLMs and improves over\nconventional triplet-level editing on (1) Efficiency. A single event edit leads\nto updates in multiple entailed knowledge triplets. (2) Completeness. Beyond\nupdating factual knowledge, event-level editing also requires considering the\nevent influences and updating LLMs' knowledge about future trends. We construct\na high-quality event-level editing benchmark ELKEN, consisting of 1,515 event\nedits, 6,449 questions about factual knowledge, and 10,150 questions about\nfuture tendencies. We systematically evaluate the performance of various\nknowledge editing methods and LLMs on this benchmark. We find that ELKEN poses\nsignificant challenges to existing knowledge editing approaches. Our codes and\ndataset are publicly released to facilitate further research.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13093v1",
    "authors": [
      "Hao Peng",
      "Xiaozhi Wang",
      "Chunyang Li",
      "Kaisheng Zeng",
      "Jiangshan Duo",
      "Yixin Cao",
      "Lei Hou",
      "Juanzi Li"
    ]
  },
  {
    "id": "2402.13098",
    "title": "ELAD: Explanation-Guided Large Language Models Active Distillation",
    "abstract": "  The deployment and application of Large Language Models (LLMs) is hindered by\ntheir memory inefficiency, computational demands, and the high costs of API\ninferences. Traditional distillation methods, which transfer the capabilities\nof LLMs to smaller models, often fail to determine whether the knowledge has\nbeen sufficiently transferred, potentially resulting in high costs or\nincomplete distillation. In this paper, we propose an Explanation-Guided LLMs\nActive Distillation (ELAD) framework that employs an active learning strategy\nto optimize the balance between annotation costs and model performance. To\nimprove efficient sample selection, we introduce an explanation-guided sample\nselection method that identifies samples challenging its reasoning by\nexploiting uncertainties in explanation steps. Additionally, we present a\ncustomized LLM-annotated explanation revision technique where the teacher model\ndetects and corrects flaws in the student model's reasoning. Our experiments\nacross various reasoning datasets demonstrate that our framework significantly\nenhances the efficiency of LLM knowledge distillation.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13098v1",
    "authors": ["Yifei Zhang", "Bo Pan", "Chen Ling", "Yuntong Hu", "Liang Zhao"]
  },
  {
    "id": "2402.13109",
    "title": "CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the\n  Generalizability of Large Language Models",
    "abstract": "  The advancement of large language models (LLMs) has enhanced the ability to\ngeneralize across a wide range of unseen natural language processing (NLP)\ntasks through instruction-following. Yet, their effectiveness often diminishes\nin low-resource languages like Chinese, exacerbated by biased evaluations from\ndata leakage, casting doubt on their true generalizability to new linguistic\nterritories. In response, we introduce the Chinese Instruction-Following\nBenchmark (CIF-Bench), designed to evaluate the zero-shot generalizability of\nLLMs to the Chinese language. CIF-Bench comprises 150 tasks and 15,000\ninput-output pairs, developed by native speakers to test complex reasoning and\nChinese cultural nuances across 20 categories. To mitigate evaluation bias, we\nrelease only half of the dataset publicly, with the remainder kept private, and\nintroduce diversified instructions to minimize score variance, totaling 45,000\ndata instances. Our evaluation of 28 selected LLMs reveals a noticeable\nperformance gap, with the best model scoring only 52.9%, highlighting the\nlimitations of LLMs in less familiar language and task contexts. This work aims\nto uncover the current limitations of LLMs in handling Chinese tasks, pushing\ntowards the development of more culturally informed and linguistically diverse\nmodels with the released data and benchmark\n(https://yizhilll.github.io/CIF-Bench/).\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13109v1",
    "authors": [
      "Yizhi LI",
      "Ge Zhang",
      "Xingwei Qu",
      "Jiali Li",
      "Zhaoqun Li",
      "Zekun Wang",
      "Hao Li",
      "Ruibin Yuan",
      "Yinghao Ma",
      "Kai Zhang",
      "Wangchunshu Zhou",
      "Yiming Liang",
      "Lei Zhang",
      "Lei Ma",
      "Jiajun Zhang",
      "Zuowen Li",
      "Stephen W. Huang",
      "Chenghua Lin",
      "Wenhu Chen",
      "Jie Fu"
    ]
  },
  {
    "id": "2402.13114",
    "title": "BuffGraph: Enhancing Class-Imbalanced Node Classification via Buffer\n  Nodes",
    "abstract": "  Class imbalance in graph-structured data, where minor classes are\nsignificantly underrepresented, poses a critical challenge for Graph Neural\nNetworks (GNNs). To address this challenge, existing studies generally generate\nnew minority nodes and edges connecting new nodes to the original graph to make\nclasses balanced. However, they do not solve the problem that majority classes\nstill propagate information to minority nodes by edges in the original graph\nwhich introduces bias towards majority classes. To address this, we introduce\nBuffGraph, which inserts buffer nodes into the graph, modulating the impact of\nmajority classes to improve minor class representation. Our extensive\nexperiments across diverse real-world datasets empirically demonstrate that\nBuffGraph outperforms existing baseline methods in class-imbalanced node\nclassification in both natural settings and imbalanced settings. Code is\navailable at https://anonymous.4open.science/r/BuffGraph-730A.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13114v1",
    "authors": ["Qian Wang", "Zemin Liu", "Zhen Zhang", "Bingsheng He"]
  },
  {
    "id": "2402.13125",
    "title": "TreeEval: Benchmark-Free Evaluation of Large Language Models through\n  Tree Planning",
    "abstract": "  Recently, numerous new benchmarks have been established to evaluate the\nperformance of large language models (LLMs) via either computing a holistic\nscore or employing another LLM as a judge. However, these approaches suffer\nfrom data leakage due to the open access of the benchmark and inflexible\nevaluation process. To address this issue, we introduce $\\textbf{TreeEval}$, a\nbenchmark-free evaluation method for LLMs that let a high-performance LLM host\nan irreproducible evaluation session and essentially avoids the data leakage.\nMoreover, this LLM performs as an examiner to raise up a series of questions\nunder a topic with a tree planing strategy, which considers the current\nevaluation status to decide the next question generation and ensures the\ncompleteness and efficiency of the evaluation process. We evaluate $6$ models\nof different parameter sizes, including $7$B, $13$B, and $33$B, and ultimately\nachieved the highest correlation coefficient with AlpacaEval2.0 using only\naround $45$ questions. We also conduct more analysis to show the robustness and\nreliability of TreeEval. Our code can be accessed via the provided\nhttps://github.com/Ashura5/TreeEval.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13125v1",
    "authors": ["Xiang Li", "Yunshi Lan", "Chao Yang"]
  },
  {
    "id": "2402.13145",
    "title": "CMDAG: A Chinese Metaphor Dataset with Annotated Grounds as CoT for\n  Boosting Metaphor Generation",
    "abstract": "  Metaphor is a prominent linguistic device in human language and literature,\nas they add color, imagery, and emphasis to enhance effective communication.\nThis paper introduces a large-scale high quality annotated Chinese Metaphor\nCorpus, which comprises around 28K sentences drawn from a diverse range of\nChinese literary sources, such as poems, prose, song lyrics, etc. To ensure the\naccuracy and consistency of our annotations, we introduce a comprehensive set\nof guidelines. These guidelines address the facets of metaphor annotation,\nincluding identifying tenors, vehicles, and grounds to handling the\ncomplexities of similes, personifications, juxtapositions, and hyperboles.\nBreaking tradition, our approach to metaphor generation emphasizes grounds and\ntheir distinct features rather than the conventional combination of tenors and\nvehicles. By integrating \"ground\" as a CoT (Chain of Thoughts) input, we are\nable to generate metaphors that resonate more with real-world intuition. We\ntest generative models such as Belle, Baichuan, and Chinese-alpaca-33B using\nour annotated corpus. These models are able to generate creative and fluent\nmetaphor sentences more frequently induced by selected samples from our\ndataset, demonstrating the value of our corpus for Chinese metaphor research.\nThe code is available in\nhttps://github.com/JasonShao55/Chinese_Metaphor_Explanation.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13145v2",
    "authors": [
      "Yujie Shao",
      "Xinrong Yao",
      "Xingwei Qu",
      "Chenghua Lin",
      "Shi Wang",
      "Stephen W. Huang",
      "Ge Zhang",
      "Jie Fu"
    ]
  },
  {
    "id": "2402.13147",
    "title": "SubIQ: Inverse Soft-Q Learning for Offline Imitation with Suboptimal\n  Demonstrations",
    "abstract": "  We consider offline imitation learning (IL), which aims to mimic the expert's\nbehavior from its demonstration without further interaction with the\nenvironment. One of the main challenges in offline IL is dealing with the\nlimited support of expert demonstrations that cover only a small fraction of\nthe state-action spaces. In this work, we consider offline IL, where expert\ndemonstrations are limited but complemented by a larger set of sub-optimal\ndemonstrations of lower expertise levels. Most of the existing offline IL\nmethods developed for this setting are based on behavior cloning or\ndistribution matching, where the aim is to match the occupancy distribution of\nthe imitation policy with that of the expert policy. Such an approach often\nsuffers from over-fitting, as expert demonstrations are limited to accurately\nrepresent any occupancy distribution. On the other hand, since sub-optimal sets\nare much larger, there is a high chance that the imitation policy is trained\ntowards sub-optimal policies. In this paper, to address these issues, we\npropose a new approach based on inverse soft-Q learning, where a regularization\nterm is added to the training objective, with the aim of aligning the learned\nrewards with a pre-assigned reward function that allocates higher weights to\nstate-action pairs from expert demonstrations, and lower weights to those from\nlower expertise levels. On standard benchmarks, our inverse soft-Q learning\nsignificantly outperforms other offline IL baselines by a large margin.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13147v1",
    "authors": ["Huy Hoang", "Tien Mai", "Pradeep Varakantham"]
  },
  {
    "id": "2402.13178",
    "title": "Benchmarking Retrieval-Augmented Generation for Medicine",
    "abstract": "  While large language models (LLMs) have achieved state-of-the-art performance\non a wide range of medical question answering (QA) tasks, they still face\nchallenges with hallucinations and outdated knowledge. Retrieval-augmented\ngeneration (RAG) is a promising solution and has been widely adopted. However,\na RAG system can involve multiple flexible components, and there is a lack of\nbest practices regarding the optimal RAG setting for various medical purposes.\nTo systematically evaluate such systems, we propose the Medical Information\nRetrieval-Augmented Generation Evaluation (MIRAGE), a first-of-its-kind\nbenchmark including 7,663 questions from five medical QA datasets. Using\nMIRAGE, we conducted large-scale experiments with over 1.8 trillion prompt\ntokens on 41 combinations of different corpora, retrievers, and backbone LLMs\nthrough the MedRAG toolkit introduced in this work. Overall, MedRAG improves\nthe accuracy of six different LLMs by up to 18% over chain-of-thought\nprompting, elevating the performance of GPT-3.5 and Mixtral to GPT-4-level. Our\nresults show that the combination of various medical corpora and retrievers\nachieves the best performance. In addition, we discovered a log-linear scaling\nproperty and the \"lost-in-the-middle\" effects in medical RAG. We believe our\ncomprehensive evaluations can serve as practical guidelines for implementing\nRAG systems for medicine.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13178v2",
    "authors": ["Guangzhi Xiong", "Qiao Jin", "Zhiyong Lu", "Aidong Zhang"]
  },
  {
    "id": "2402.13208",
    "title": "How do Hyenas deal with Human Speech? Speech Recognition and Translation\n  with ConfHyena",
    "abstract": "  The attention mechanism, a cornerstone of state-of-the-art neural models,\nfaces computational hurdles in processing long sequences due to its quadratic\ncomplexity. Consequently, research efforts in the last few years focused on\nfinding more efficient alternatives. Among them, Hyena (Poli et al., 2023)\nstands out for achieving competitive results in both language modeling and\nimage classification, while offering sub-quadratic memory and computational\ncomplexity. Building on these promising results, we propose ConfHyena, a\nConformer whose encoder self-attentions are replaced with an adaptation of\nHyena for speech processing, where the long input sequences cause high\ncomputational costs. Through experiments in automatic speech recognition (for\nEnglish) and translation (from English into 8 target languages), we show that\nour best ConfHyena model significantly reduces the training time by 27%, at the\ncost of minimal quality degradation (~1%), which, in most cases, is not\nstatistically significant.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13208v1",
    "authors": ["Marco Gaido", "Sara Papi", "Matteo Negri", "Luisa Bentivogli"]
  },
  {
    "id": "2402.13217",
    "title": "VideoPrism: A Foundational Visual Encoder for Video Understanding",
    "abstract": "  We introduce VideoPrism, a general-purpose video encoder that tackles diverse\nvideo understanding tasks with a single frozen model. We pretrain VideoPrism on\na heterogeneous corpus containing 36M high-quality video-caption pairs and 582M\nvideo clips with noisy parallel text (e.g., ASR transcripts). The pretraining\napproach improves upon masked autoencoding by global-local distillation of\nsemantic video embeddings and a token shuffling scheme, enabling VideoPrism to\nfocus primarily on the video modality while leveraging the invaluable text\nassociated with videos. We extensively test VideoPrism on four broad groups of\nvideo understanding tasks, from web video question answering to CV for science,\nachieving state-of-the-art performance on 30 out of 33 video understanding\nbenchmarks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13217v1",
    "authors": [
      "Long Zhao",
      "Nitesh B. Gundavarapu",
      "Liangzhe Yuan",
      "Hao Zhou",
      "Shen Yan",
      "Jennifer J. Sun",
      "Luke Friedman",
      "Rui Qian",
      "Tobias Weyand",
      "Yue Zhao",
      "Rachel Hornung",
      "Florian Schroff",
      "Ming-Hsuan Yang",
      "David A. Ross",
      "Huisheng Wang",
      "Hartwig Adam",
      "Mikhail Sirotenko",
      "Ting Liu",
      "Boqing Gong"
    ]
  },
  {
    "id": "2402.13225",
    "title": "AgentMD: Empowering Language Agents for Risk Prediction with Large-Scale\n  Clinical Tool Learning",
    "abstract": "  Clinical calculators play a vital role in healthcare by offering accurate\nevidence-based predictions for various purposes such as prognosis.\nNevertheless, their widespread utilization is frequently hindered by usability\nchallenges, poor dissemination, and restricted functionality. Augmenting large\nlanguage models with extensive collections of clinical calculators presents an\nopportunity to overcome these obstacles and improve workflow efficiency, but\nthe scalability of the manual curation process poses a significant challenge.\nIn response, we introduce AgentMD, a novel language agent capable of curating\nand applying clinical calculators across various clinical contexts. Using the\npublished literature, AgentMD has automatically curated a collection of 2,164\ndiverse clinical calculators with executable functions and structured\ndocumentation, collectively named RiskCalcs. Manual evaluations show that\nRiskCalcs tools achieve an accuracy of over 80% on three quality metrics. At\ninference time, AgentMD can automatically select and apply the relevant\nRiskCalcs tools given any patient description. On the newly established RiskQA\nbenchmark, AgentMD significantly outperforms chain-of-thought prompting with\nGPT-4 (87.7% vs. 40.9% in accuracy). Additionally, we also applied AgentMD to\nreal-world clinical notes for analyzing both population-level and risk-level\npatient characteristics. In summary, our study illustrates the utility of\nlanguage agents augmented with clinical calculators for healthcare analytics\nand patient care.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13225v1",
    "authors": [
      "Qiao Jin",
      "Zhizheng Wang",
      "Yifan Yang",
      "Qingqing Zhu",
      "Donald Wright",
      "Thomas Huang",
      "W John Wilbur",
      "Zhe He",
      "Andrew Taylor",
      "Qingyu Chen",
      "Zhiyong Lu"
    ]
  },
  {
    "id": "2402.13241",
    "title": "Federated Causal Discovery from Heterogeneous Data",
    "abstract": "  Conventional causal discovery methods rely on centralized data, which is\ninconsistent with the decentralized nature of data in many real-world\nsituations. This discrepancy has motivated the development of federated causal\ndiscovery (FCD) approaches. However, existing FCD methods may be limited by\ntheir potentially restrictive assumptions of identifiable functional causal\nmodels or homogeneous data distributions, narrowing their applicability in\ndiverse scenarios. In this paper, we propose a novel FCD method attempting to\naccommodate arbitrary causal models and heterogeneous data. We first utilize a\nsurrogate variable corresponding to the client index to account for the data\nheterogeneity across different clients. We then develop a federated conditional\nindependence test (FCIT) for causal skeleton discovery and establish a\nfederated independent change principle (FICP) to determine causal directions.\nThese approaches involve constructing summary statistics as a proxy of the raw\ndata to protect data privacy. Owing to the nonparametric properties, FCIT and\nFICP make no assumption about particular functional forms, thereby facilitating\nthe handling of arbitrary causal models. We conduct extensive experiments on\nsynthetic and real datasets to show the efficacy of our method. The code is\navailable at https://github.com/lokali/FedCDH.git.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13241v2",
    "authors": [
      "Loka Li",
      "Ignavier Ng",
      "Gongxu Luo",
      "Biwei Huang",
      "Guangyi Chen",
      "Tongliang Liu",
      "Bin Gu",
      "Kun Zhang"
    ]
  },
  {
    "id": "2402.13249",
    "title": "TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue\n  Summarization",
    "abstract": "  Single document news summarization has seen substantial progress on\nfaithfulness in recent years, driven by research on the evaluation of factual\nconsistency, or hallucinations. We ask whether these advances carry over to\nother text summarization domains. We propose a new evaluation benchmark on\ntopic-focused dialogue summarization, generated by LLMs of varying sizes. We\nprovide binary sentence-level human annotations of the factual consistency of\nthese summaries along with detailed explanations of factually inconsistent\nsentences. Our analysis shows that existing LLMs hallucinate significant\namounts of factual errors in the dialogue domain, regardless of the model's\nsize. On the other hand, when LLMs, including GPT-4, serve as binary factual\nevaluators, they perform poorly and can be outperformed by prevailing\nstate-of-the-art specialized factuality evaluation metrics. Finally, we\nconducted an analysis of hallucination types with a curated error taxonomy. We\nfind that there are diverse errors and error distributions in model-generated\nsummaries and that non-LLM based metrics can capture all error types better\nthan LLM-based evaluators.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13249v1",
    "authors": [
      "Liyan Tang",
      "Igor Shalyminov",
      "Amy Wing-mei Wong",
      "Jon Burnsky",
      "Jake W. Vincent",
      "Yu'an Yang",
      "Siffi Singh",
      "Song Feng",
      "Hwanjun Song",
      "Hang Su",
      "Lijia Sun",
      "Yi Zhang",
      "Saab Mansour",
      "Kathleen McKeown"
    ]
  },
  {
    "id": "2402.13297",
    "title": "Integrating Deep Learning and Synthetic Biology: A Co-Design Approach\n  for Enhancing Gene Expression via N-terminal Coding Sequences",
    "abstract": "  N-terminal coding sequence (NCS) influences gene expression by impacting the\ntranslation initiation rate. The NCS optimization problem is to find an NCS\nthat maximizes gene expression. The problem is important in genetic\nengineering. However, current methods for NCS optimization such as rational\ndesign and statistics-guided approaches are labor-intensive yield only\nrelatively small improvements. This paper introduces a deep learning/synthetic\nbiology co-designed few-shot training workflow for NCS optimization. Our method\nutilizes k-nearest encoding followed by word2vec to encode the NCS, then\nperforms feature extraction using attention mechanisms, before constructing a\ntime-series network for predicting gene expression intensity, and finally a\ndirect search algorithm identifies the optimal NCS with limited training data.\nWe took green fluorescent protein (GFP) expressed by Bacillus subtilis as a\nreporting protein of NCSs, and employed the fluorescence enhancement factor as\nthe metric of NCS optimization. Within just six iterative experiments, our\nmodel generated an NCS (MLD62) that increased average GFP expression by\n5.41-fold, outperforming the state-of-the-art NCS designs. Extending our\nfindings beyond GFP, we showed that our engineered NCS (MLD62) can effectively\nboost the production of N-acetylneuraminic acid by enhancing the expression of\nthe crucial rate-limiting GNA1 gene, demonstrating its practical utility. We\nhave open-sourced our NCS expression database and experimental procedures for\npublic use.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13297v1",
    "authors": [
      "Zhanglu Yan",
      "Weiran Chu",
      "Yuhua Sheng",
      "Kaiwen Tang",
      "Shida Wang",
      "Yanfeng Liu",
      "Weng-Fai Wong"
    ]
  },
  {
    "id": "2402.13304",
    "title": "Harmful algal bloom forecasting. A comparison between stream and batch\n  learning",
    "abstract": "  Diarrhetic Shellfish Poisoning (DSP) is a global health threat arising from\nshellfish contaminated with toxins produced by dinoflagellates. The condition,\nwith its widespread incidence, high morbidity rate, and persistent shellfish\ntoxicity, poses risks to public health and the shellfish industry. High biomass\nof toxin-producing algae such as DSP are known as Harmful Algal Blooms (HABs).\nMonitoring and forecasting systems are crucial for mitigating HABs impact.\nPredicting harmful algal blooms involves a time-series-based problem with a\nstrong historical seasonal component, however, recent anomalies due to changes\nin meteorological and oceanographic events have been observed. Stream Learning\nstands out as one of the most promising approaches for addressing\ntime-series-based problems with concept drifts. However, its efficacy in\npredicting HABs remains unproven and needs to be tested in comparison with\nBatch Learning. Historical data availability is a critical point in developing\npredictive systems. In oceanography, the available data collection can have\nsome constrains and limitations, which has led to exploring new tools to obtain\nmore exhaustive time series. In this study, a machine learning workflow for\npredicting the number of cells of a toxic dinoflagellate, Dinophysis acuminata,\nwas developed with several key advancements. Seven machine learning algorithms\nwere compared within two learning paradigms. Notably, the output data from\nCROCO, the ocean hydrodynamic model, was employed as the primary dataset,\npalliating the limitation of time-continuous historical data. This study\nhighlights the value of models interpretability, fair models comparison\nmethodology, and the incorporation of Stream Learning models. The model DoME,\nwith an average R2 of 0.77 in the 3-day-ahead prediction, emerged as the most\neffective and interpretable predictor, outperforming the other algorithms.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13304v1",
    "authors": [
      "Andres Molares-Ulloa",
      "Elisabet Rocruz",
      "Daniel Rivero",
      "Xosé A. Padin",
      "Rita Nolasco",
      "Jesús Dubert",
      "Enrique Fernandez-Blanco"
    ]
  },
  {
    "id": "2402.13326",
    "title": "Deep Hedging with Market Impact",
    "abstract": "  Dynamic hedging is the practice of periodically transacting financial\ninstruments to offset the risk caused by an investment or a liability. Dynamic\nhedging optimization can be framed as a sequential decision problem; thus,\nReinforcement Learning (RL) models were recently proposed to tackle this task.\nHowever, existing RL works for hedging do not consider market impact caused by\nthe finite liquidity of traded instruments. Integrating such feature can be\ncrucial to achieve optimal performance when hedging options on stocks with\nlimited liquidity. In this paper, we propose a novel general market impact\ndynamic hedging model based on Deep Reinforcement Learning (DRL) that considers\nseveral realistic features such as convex market impacts, and impact\npersistence through time. The optimal policy obtained from the DRL model is\nanalysed using several option hedging simulations and compared to commonly used\nprocedures such as delta hedging. Results show our DRL model behaves better in\ncontexts of low liquidity by, among others: 1) learning the extent to which\nportfolio rebalancing actions should be dampened or delayed to avoid high\ncosts, 2) factoring in the impact of features not considered by conventional\napproaches, such as previous hedging errors through the portfolio value, and\nthe underlying asset's drift (i.e. the magnitude of its expected return).\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13326v2",
    "authors": ["Andrei Neagu", "Frédéric Godin", "Clarence Simard", "Leila Kosseim"]
  },
  {
    "id": "2402.13397",
    "title": "Xling: A Learned Filter Framework for Accelerating High-Dimensional\n  Approximate Similarity Join",
    "abstract": "  Similarity join finds all pairs of close points within a given distance\nthreshold. Many similarity join methods have been proposed, but they are\nusually not efficient on high-dimensional space due to the curse of\ndimensionality and data-unawareness. We investigate the possibility of using\nmetric space Bloom filter (MSBF), a family of data structures checking if a\nquery point has neighbors in a multi-dimensional space, to speed up similarity\njoin. However, there are several challenges when applying MSBF to similarity\njoin, including excessive information loss, data-unawareness and hard\nconstraint on the distance metric. In this paper, we propose Xling, a generic\nframework to build a learning-based metric space filter with any existing\nregression model, aiming at accurately predicting whether a query point has\nenough number of neighbors. The framework provides a suite of optimization\nstrategies to further improve the prediction quality based on the learning\nmodel, which has demonstrated significantly higher prediction quality than\nexisting MSBF. We also propose XJoin, one of the first filter-based similarity\njoin methods, based on Xling. By predicting and skipping those queries without\nenough neighbors, XJoin can effectively reduce unnecessary neighbor searching\nand therefore it achieves a remarkable acceleration. Benefiting from the\ngeneralization capability of deep learning models, XJoin can be easily\ntransferred onto new dataset (in similar distribution) without re-training.\nFurthermore, Xling is not limited to being applied in XJoin, instead, it acts\nas a flexible plugin that can be inserted to any loop-based similarity join\nmethods for a speedup.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13397v1",
    "authors": ["Yifan Wang", "Vyom Pathak", "Daisy Zhe Wang"]
  },
  {
    "id": "2402.13427",
    "title": "Quantitative causality, causality-guided scientific discovery, and\n  causal machine learning",
    "abstract": "  It has been said, arguably, that causality analysis should pave a promising\nway to interpretable deep learning and generalization. Incorporation of\ncausality into artificial intelligence (AI) algorithms, however, is challenged\nwith its vagueness, non-quantitiveness, computational inefficiency, etc. During\nthe past 18 years, these challenges have been essentially resolved, with the\nestablishment of a rigorous formalism of causality analysis initially motivated\nfrom atmospheric predictability. This not only opens a new field in the\natmosphere-ocean science, namely, information flow, but also has led to\nscientific discoveries in other disciplines, such as quantum mechanics,\nneuroscience, financial economics, etc., through various applications. This\nnote provides a brief review of the decade-long effort, including a list of\nmajor theoretical results, a sketch of the causal deep learning framework, and\nsome representative real-world applications in geoscience pertaining to this\njournal, such as those on the anthropogenic cause of global warming, the\ndecadal prediction of El Ni\\~no Modoki, the forecasting of an extreme drought\nin China, among others.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13427v1",
    "authors": ["X. San Liang", "Dake Chen", "Renhe Zhang"]
  },
  {
    "id": "2402.14850",
    "title": "CHATATC: Large Language Model-Driven Conversational Agents for\n  Supporting Strategic Air Traffic Flow Management",
    "abstract": "  Generative artificial intelligence (AI) and large language models (LLMs) have\ngained rapid popularity through publicly available tools such as ChatGPT. The\nadoption of LLMs for personal and professional use is fueled by the natural\ninteractions between human users and computer applications such as ChatGPT,\nalong with powerful summarization and text generation capabilities. Given the\nwidespread use of such generative AI tools, in this work we investigate how\nthese tools can be deployed in a non-safety critical, strategic traffic flow\nmanagement setting. Specifically, we train an LLM, CHATATC, based on a large\nhistorical data set of Ground Delay Program (GDP) issuances, spanning 2000-2023\nand consisting of over 80,000 GDP implementations, revisions, and\ncancellations. We test the query and response capabilities of CHATATC,\ndocumenting successes (e.g., providing correct GDP rates, durations, and\nreason) and shortcomings (e.g,. superlative questions). We also detail the\ndesign of a graphical user interface for future users to interact and\ncollaborate with the CHATATC conversational agent.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14850v1",
    "authors": ["Sinan Abdulhak", "Wayne Hubbard", "Karthik Gopalakrishnan", "Max Z. Li"]
  },
  {
    "id": "2402.14853",
    "title": "NL2Formula: Generating Spreadsheet Formulas from Natural Language\n  Queries",
    "abstract": "  Writing formulas on spreadsheets, such as Microsoft Excel and Google Sheets,\nis a widespread practice among users performing data analysis. However,\ncrafting formulas on spreadsheets remains a tedious and error-prone task for\nmany end-users, particularly when dealing with complex operations. To alleviate\nthe burden associated with writing spreadsheet formulas, this paper introduces\na novel benchmark task called NL2Formula, with the aim to generate executable\nformulas that are grounded on a spreadsheet table, given a Natural Language\n(NL) query as input. To accomplish this, we construct a comprehensive dataset\nconsisting of 70,799 paired NL queries and corresponding spreadsheet formulas,\ncovering 21,670 tables and 37 types of formula functions. We realize the\nNL2Formula task by providing a sequence-to-sequence baseline implementation\ncalled fCoder. Experimental results validate the effectiveness of fCoder,\ndemonstrating its superior performance compared to the baseline models.\nFurthermore, we also compare fCoder with an initial GPT-3.5 model (i.e.,\ntext-davinci-003). Lastly, through in-depth error analysis, we identify\npotential challenges in the NL2Formula task and advocate for further\ninvestigation.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14853v1",
    "authors": [
      "Wei Zhao",
      "Zhitao Hou",
      "Siyuan Wu",
      "Yan Gao",
      "Haoyu Dong",
      "Yao Wan",
      "Hongyu Zhang",
      "Yulei Sui",
      "Haidong Zhang"
    ]
  },
  {
    "id": "2402.14854",
    "title": "A Dual-Prompting for Interpretable Mental Health Language Models",
    "abstract": "  Despite the increasing demand for AI-based mental health monitoring tools,\ntheir practical utility for clinicians is limited by the lack of\ninterpretability.The CLPsych 2024 Shared Task (Chim et al., 2024) aims to\nenhance the interpretability of Large Language Models (LLMs), particularly in\nmental health analysis, by providing evidence of suicidality through linguistic\ncontent. We propose a dual-prompting approach: (i) Knowledge-aware evidence\nextraction by leveraging the expert identity and a suicide dictionary with a\nmental health-specific LLM; and (ii) Evidence summarization by employing an\nLLM-based consistency evaluator. Comprehensive experiments demonstrate the\neffectiveness of combining domain-specific information, revealing performance\nimprovements and the approach's potential to aid clinicians in assessing mental\nstate progression.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14854v1",
    "authors": [
      "Hyolim Jeon",
      "Dongje Yoo",
      "Daeun Lee",
      "Sejung Son",
      "Seungbae Kim",
      "Jinyoung Han"
    ]
  },
  {
    "id": "2402.14855",
    "title": "An LLM Maturity Model for Reliable and Transparent Text-to-Query",
    "abstract": "  Recognizing the imperative to address the reliability and transparency issues\nof Large Language Models (LLM), this work proposes an LLM maturity model\ntailored for text-to-query applications. This maturity model seeks to fill the\nexisting void in evaluating LLMs in such applications by incorporating\ndimensions beyond mere correctness or accuracy. Moreover, this work introduces\na real-world use case from the law enforcement domain and showcases QueryIQ, an\nLLM-powered, domain-specific text-to-query assistant to expedite user workflows\nand reveal hidden relationship in data.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14855v1",
    "authors": ["Lei Yu", "Abir Ray"]
  },
  {
    "id": "2402.14856",
    "title": "Comparing Inferential Strategies of Humans and Large Language Models in\n  Deductive Reasoning",
    "abstract": "  Deductive reasoning plays a pivotal role in the formulation of sound and\ncohesive arguments. It allows individuals to draw conclusions that logically\nfollow, given the truth value of the information provided. Recent progress in\nthe domain of large language models (LLMs) has showcased their capability in\nexecuting deductive reasoning tasks. Nonetheless, a significant portion of\nresearch primarily assesses the accuracy of LLMs in solving such tasks, often\noverlooking a deeper analysis of their reasoning behavior. In this study, we\ndraw upon principles from cognitive psychology to examine inferential\nstrategies employed by LLMs, through a detailed evaluation of their responses\nto propositional logic problems. Our findings indicate that LLMs display\nreasoning patterns akin to those observed in humans, including strategies like\n$\\textit{supposition following}$ or $\\textit{chain construction}$. Moreover,\nour research demonstrates that the architecture and scale of the model\nsignificantly affect its preferred method of reasoning, with more advanced\nmodels tending to adopt strategies more frequently than less sophisticated\nones. Importantly, we assert that a model's accuracy, that is the correctness\nof its final conclusion, does not necessarily reflect the validity of its\nreasoning process. This distinction underscores the necessity for more nuanced\nevaluation procedures in the field.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14856v1",
    "authors": ["Philipp Mondorf", "Barbara Plank"]
  },
  {
    "id": "2402.14858",
    "title": "ChatEL: Entity Linking with Chatbots",
    "abstract": "  Entity Linking (EL) is an essential and challenging task in natural language\nprocessing that seeks to link some text representing an entity within a\ndocument or sentence with its corresponding entry in a dictionary or knowledge\nbase. Most existing approaches focus on creating elaborate contextual models\nthat look for clues the words surrounding the entity-text to help solve the\nlinking problem. Although these fine-tuned language models tend to work, they\ncan be unwieldy, difficult to train, and do not transfer well to other domains.\nFortunately, Large Language Models (LLMs) like GPT provide a highly-advanced\nsolution to the problems inherent in EL models, but simply naive prompts to\nLLMs do not work well. In the present work, we define ChatEL, which is a\nthree-step framework to prompt LLMs to return accurate results. Overall the\nChatEL framework improves the average F1 performance across 10 datasets by more\nthan 2%. Finally, a thorough error analysis shows many instances with the\nground truth labels were actually incorrect, and the labels predicted by ChatEL\nwere actually correct. This indicates that the quantitative results presented\nin this paper may be a conservative estimate of the actual performance. All\ndata and code are available as an open-source package on GitHub at\nhttps://github.com/yifding/In_Context_EL.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14858v1",
    "authors": ["Yifan Ding", "Qingkai Zeng", "Tim Weninger"]
  },
  {
    "id": "2402.15526",
    "title": "Chain-of-Specificity: An Iteratively Refining Method for Eliciting\n  Knowledge from Large Language Models",
    "abstract": "  Large Language Models (LLMs) exhibit remarkable generative capabilities,\nenabling the generation of valuable information. Despite these advancements,\nprevious research found that LLMs sometimes struggle with adhering to specific\nconstraints (e.g., in specific place or at specific time), at times even\noverlooking them, which leads to responses that are either too generic or not\nfully satisfactory. Existing approaches attempted to address this issue by\ndecomposing or rewriting input instructions, yet they fall short in adequately\nemphasizing specific constraints and in unlocking the underlying knowledge\n(e.g., programming within the context of software development). In response,\nthis paper proposes a simple yet effective method named Chain-of-Specificity\n(CoS). Specifically, CoS iteratively emphasizes the specific constraints in the\ninput instructions, unlocks knowledge within LLMs, and refines responses.\nExperiments conducted on publicly available and self-build complex datasets\ndemonstrate that CoS outperforms existing methods in enhancing generated\ncontent especially for the specificity. Besides, as the number of specific\nconstraints increase, other baselines falter, while CoS still performs well.\nMoreover, we show that distilling responses generated by CoS effectively\nenhances the ability of smaller models to follow the constrained instructions.\nResources of this paper will be released for further research.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15526v1",
    "authors": [
      "Kaiwen Wei",
      "Jingyuan Zhang",
      "Hongzhi Zhang",
      "Fuzheng Zhang",
      "Di Zhang",
      "Li Jin",
      "Yue Yu"
    ]
  },
  {
    "id": "2402.12627",
    "title": "A Comprehensive Review of Machine Learning Advances on Data Change: A\n  Cross-Field Perspective",
    "abstract": "  Recent artificial intelligence (AI) technologies show remarkable evolution in\nvarious academic fields and industries. However, in the real world, dynamic\ndata lead to principal challenges for deploying AI models. An unexpected data\nchange brings about severe performance degradation in AI models. We identify\ntwo major related research fields, domain shift and concept drift according to\nthe setting of the data change. Although these two popular research fields aim\nto solve distribution shift and non-stationary data stream problems, the\nunderlying properties remain similar which also encourages similar technical\napproaches. In this review, we regroup domain shift and concept drift into a\nsingle research problem, namely the data change problem, with a systematic\noverview of state-of-the-art methods in the two research fields. We propose a\nthree-phase problem categorization scheme to link the key ideas in the two\ntechnical fields. We thus provide a novel scope for researchers to explore\ncontemporary technical strategies, learn industrial applications, and identify\nfuture directions for addressing data change challenges.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12627v1",
    "authors": ["Jeng-Lin Li", "Chih-Fan Hsu", "Ming-Ching Chang", "Wei-Chao Chen"]
  },
  {
    "id": "2402.12659",
    "title": "The FinBen: An Holistic Financial Benchmark for Large Language Models",
    "abstract": "  LLMs have transformed NLP and shown promise in various fields, yet their\npotential in finance is underexplored due to a lack of thorough evaluations and\nthe complexity of financial tasks. This along with the rapid development of\nLLMs, highlights the urgent need for a systematic financial evaluation\nbenchmark for LLMs. In this paper, we introduce FinBen, the first comprehensive\nopen-sourced evaluation benchmark, specifically designed to thoroughly assess\nthe capabilities of LLMs in the financial domain. FinBen encompasses 35\ndatasets across 23 financial tasks, organized into three spectrums of\ndifficulty inspired by the Cattell-Horn-Carroll theory, to evaluate LLMs'\ncognitive abilities in inductive reasoning, associative memory, quantitative\nreasoning, crystallized intelligence, and more. Our evaluation of 15\nrepresentative LLMs, including GPT-4, ChatGPT, and the latest Gemini, reveals\ninsights into their strengths and limitations within the financial domain. The\nfindings indicate that GPT-4 leads in quantification, extraction, numerical\nreasoning, and stock trading, while Gemini shines in generation and\nforecasting; however, both struggle with complex extraction and forecasting,\nshowing a clear need for targeted enhancements. Instruction tuning boosts\nsimple task performance but falls short in improving complex reasoning and\nforecasting abilities. FinBen seeks to continuously evaluate LLMs in finance,\nfostering AI development with regular updates of tasks and models.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12659v1",
    "authors": [
      "Qianqian Xie",
      "Weiguang Han",
      "Zhengyu Chen",
      "Ruoyu Xiang",
      "Xiao Zhang",
      "Yueru He",
      "Mengxi Xiao",
      "Dong Li",
      "Yongfu Dai",
      "Duanyu Feng",
      "Yijing Xu",
      "Haoqiang Kang",
      "Ziyan Kuang",
      "Chenhan Yuan",
      "Kailai Yang",
      "Zheheng Luo",
      "Tianlin Zhang",
      "Zhiwei Liu",
      "Guojun Xiong",
      "Zhiyang Deng",
      "Yuechen Jiang",
      "Zhiyuan Yao",
      "Haohang Li",
      "Yangyang Yu",
      "Gang Hu",
      "Jiajia Huang",
      "Xiao-Yang Liu",
      "Alejandro Lopez-Lira",
      "Benyou Wang",
      "Yanzhao Lai",
      "Hao Wang",
      "Min Peng",
      "Sophia Ananiadou",
      "Jimin Huang"
    ]
  },
  {
    "id": "2402.12730",
    "title": "UMBCLU at SemEval-2024 Task 1A and 1C: Semantic Textual Relatedness with\n  and without machine translation",
    "abstract": "  This paper describes the system we developed for SemEval-2024 Task 1,\n\"Semantic Textual Relatedness for African and Asian Languages.\" The aim of the\ntask is to build a model that can identify semantic textual relatedness (STR)\nbetween two sentences of a target language belonging to a collection of African\nand Asian languages. We participated in Subtasks A and C and explored\nsupervised and cross-lingual training leveraging large language models (LLMs).\nPre-trained large language models have been extensively used for machine\ntranslation and semantic similarity. Using a combination of machine translation\nand sentence embedding LLMs, we developed a unified STR model, TranSem, for\nsubtask A and fine-tuned the T5 family of models on the STR data, FineSem, for\nuse in subtask C. Our model results for 7 languages in subtask A were better\nthan the official baseline for 3 languages and on par with the baseline for the\nremaining 4 languages. Our model results for the 12 languages in subtask C\nresulted in 1st place for Africaans, 2nd place for Indonesian, and 3rd place\nfor English with low performance for the remaining 9 languages.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12730v1",
    "authors": ["Shubhashis Roy Dipta", "Sai Vallurupalli"]
  },
  {
    "id": "2402.12738",
    "title": "Can Large Language Models be Used to Provide Psychological Counselling?\n  An Analysis of GPT-4-Generated Responses Using Role-play Dialogues",
    "abstract": "  Mental health care poses an increasingly serious challenge to modern\nsocieties. In this context, there has been a surge in research that utilizes\ninformation technologies to address mental health problems, including those\naiming to develop counseling dialogue systems. However, there is a need for\nmore evaluations of the performance of counseling dialogue systems that use\nlarge language models. For this study, we collected counseling dialogue data\nvia role-playing scenarios involving expert counselors, and the utterances were\nannotated with the intentions of the counselors. To determine the feasibility\nof a dialogue system in real-world counseling scenarios, third-party counselors\nevaluated the appropriateness of responses from human counselors and those\ngenerated by GPT-4 in identical contexts in role-play dialogue data. Analysis\nof the evaluation results showed that the responses generated by GPT-4 were\ncompetitive with those of human counselors.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12738v1",
    "authors": ["Michimasa Inaba", "Mariko Ukiyo", "Keiko Takamizo"]
  },
  {
    "id": "2402.12750",
    "title": "Model Composition for Multimodal Large Language Models",
    "abstract": "  Recent developments in Multimodal Large Language Models (MLLMs) have shown\nrapid progress, moving towards the goal of creating versatile MLLMs that\nunderstand inputs from various modalities. However, existing methods typically\nrely on joint training with paired multimodal instruction data, which is\nresource-intensive and challenging to extend to new modalities. In this paper,\nwe propose a new paradigm through the model composition of existing MLLMs to\ncreate a new model that retains the modal understanding capabilities of each\noriginal model. Our basic implementation, NaiveMC, demonstrates the\neffectiveness of this paradigm by reusing modality encoders and merging LLM\nparameters. Furthermore, we introduce DAMC to address parameter interference\nand mismatch issues during the merging process, thereby enhancing the model\nperformance. To facilitate research in this area, we propose MCUB, a benchmark\nfor assessing ability of MLLMs to understand inputs from diverse modalities.\nExperiments on this benchmark and four other multimodal understanding tasks\nshow significant improvements over baselines, proving that model composition\ncan create a versatile model capable of processing inputs from multiple\nmodalities.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12750v1",
    "authors": [
      "Chi Chen",
      "Yiyang Du",
      "Zheng Fang",
      "Ziyue Wang",
      "Fuwen Luo",
      "Peng Li",
      "Ming Yan",
      "Ji Zhang",
      "Fei Huang",
      "Maosong Sun",
      "Yang Liu"
    ]
  },
  {
    "id": "2402.12760",
    "title": "A User-Friendly Framework for Generating Model-Preferred Prompts in\n  Text-to-Image Synthesis",
    "abstract": "  Well-designed prompts have demonstrated the potential to guide text-to-image\nmodels in generating amazing images. Although existing prompt engineering\nmethods can provide high-level guidance, it is challenging for novice users to\nachieve the desired results by manually entering prompts due to a discrepancy\nbetween novice-user-input prompts and the model-preferred prompts. To bridge\nthe distribution gap between user input behavior and model training datasets,\nwe first construct a novel Coarse-Fine Granularity Prompts dataset (CFP) and\npropose a novel User-Friendly Fine-Grained Text Generation framework (UF-FGTG)\nfor automated prompt optimization. For CFP, we construct a novel dataset for\ntext-to-image tasks that combines coarse and fine-grained prompts to facilitate\nthe development of automated prompt generation methods. For UF-FGTG, we propose\na novel framework that automatically translates user-input prompts into\nmodel-preferred prompts. Specifically, we propose a prompt refiner that\ncontinually rewrites prompts to empower users to select results that align with\ntheir unique needs. Meanwhile, we integrate image-related loss functions from\nthe text-to-image model into the training process of text generation to\ngenerate model-preferred prompts. Additionally, we propose an adaptive feature\nextraction module to ensure diversity in the generated results. Experiments\ndemonstrate that our approach is capable of generating more visually appealing\nand diverse images than previous state-of-the-art methods, achieving an average\nimprovement of 5% across six quality and aesthetic metrics.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12760v1",
    "authors": [
      "Nailei Hei",
      "Qianyu Guo",
      "Zihao Wang",
      "Yan Wang",
      "Haofen Wang",
      "Wenqiang Zhang"
    ]
  },
  {
    "id": "2402.12794",
    "title": "Autonomous Reality Modelling for Cultural Heritage Sites employing\n  cooperative quadrupedal robots and unmanned aerial vehicles",
    "abstract": "  Nowadays, the use of advanced sensors, such as terrestrial 3D laser scanners,\nmobile LiDARs and Unmanned Aerial Vehicles (UAV) photogrammetric imaging, has\nbecome the prevalent practice for 3D Reality Modeling and digitization of\nlarge-scale monuments of Cultural Heritage (CH). In practice, this process is\nheavily related to the expertise of the surveying team, handling the laborious\nplanning and time-consuming execution of the 3D mapping process that is\ntailored to the specific requirements and constraints of each site. To minimize\nhuman intervention, this paper introduces a novel methodology for autonomous 3D\nReality Modeling for CH monuments by employing au-tonomous biomimetic\nquadrupedal robotic agents and UAVs equipped with the appropriate sensors.\nThese autonomous robotic agents carry out the 3D RM process in a systematic and\nrepeatable ap-proach. The outcomes of this automated process may find\napplications in digital twin platforms, facilitating secure monitoring and\nmanagement of cultural heritage sites and spaces, in both indoor and outdoor\nenvironments.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12794v1",
    "authors": ["Nikolaos Giakoumidis", "Christos-Nikolaos Anagnostopoulos"]
  },
  {
    "id": "2402.12817",
    "title": "On Sensitivity of Learning with Limited Labelled Data to the Effects of\n  Randomness: Impact of Interactions and Systematic Choices",
    "abstract": "  While learning with limited labelled data can improve performance when the\nlabels are lacking, it is also sensitive to the effects of uncontrolled\nrandomness introduced by so-called randomness factors (e.g., varying order of\ndata). We propose a method to systematically investigate the effects of\nrandomness factors while taking the interactions between them into\nconsideration. To measure the true effects of an individual randomness factor,\nour method mitigates the effects of other factors and observes how the\nperformance varies across multiple runs. Applying our method to multiple\nrandomness factors across in-context learning and fine-tuning approaches on 7\nrepresentative text classification tasks and meta-learning on 3 tasks, we show\nthat: 1) disregarding interactions between randomness factors in existing works\ncaused inconsistent findings due to incorrect attribution of the effects of\nrandomness factors, such as disproving the consistent sensitivity of in-context\nlearning to sample order even with random sample selection; and 2) besides\nmutual interactions, the effects of randomness factors, especially sample\norder, are also dependent on more systematic choices unexplored in existing\nworks, such as number of classes, samples per class or choice of prompt format.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12817v1",
    "authors": ["Branislav Pecher", "Ivan Srba", "Maria Bielikova"]
  },
  {
    "id": "2402.12819",
    "title": "Fine-Tuning, Prompting, In-Context Learning and Instruction-Tuning: How\n  Many Labelled Samples Do We Need?",
    "abstract": "  When solving a task with limited labelled data, researchers can either use a\ngeneral large language model without further update, or use the few examples to\ntune a specialised smaller model. When enough labels are available, the\nspecialised models outperform the general ones on many NLP tasks. In this work,\nwe aim to investigate how many labelled samples are required for the\nspecialised models to achieve this superior performance, while taking the\nresults variance into consideration. Observing the behaviour of prompting,\nin-context learning, fine-tuning and instruction-tuning, identifying their\nbreak-even points when increasing number of labelled training samples across\nthree tasks of varying complexity, we find that the specialised models often\nneed only few samples ($100-1000$) to be on par or better than the general\nones. At the same time, the amount of required labelled data strongly depends\non the task complexity and results variance.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12819v1",
    "authors": ["Branislav Pecher", "Ivan Srba", "Maria Bielikova"]
  },
  {
    "id": "2402.12842",
    "title": "PromptKD: Distilling Student-Friendly Knowledge for Generative Language\n  Models via Prompt Tuning",
    "abstract": "  Recent advancements in large language models (LLMs) have raised concerns\nabout inference costs, increasing the need for research into model compression.\nWhile knowledge distillation (KD) is a prominent method for this, research on\nKD for generative language models like LLMs is relatively sparse, and the\napproach of distilling student-friendly knowledge, which has shown promising\nperformance in KD for classification models, remains unexplored in generative\nlanguage models. To explore this approach, we propose PromptKD, a simple yet\neffective method that utilizes prompt tuning - for the first time in KD - to\nenable generative language models to transfer student-friendly knowledge.\nUnlike previous works in classification that require fine-tuning the entire\nteacher model for extracting student-friendly knowledge, PromptKD achieves\nsimilar effects by adding a small number of prompt tokens and tuning only the\nprompt with student guidance. Extensive experiments on instruction-following\ndatasets using the GPT-2 model family show that PromptKD achieves\nstate-of-the-art performance while adding only 0.0007% of the teacher's\nparameters as prompts. Further analysis suggests that distilling\nstudent-friendly knowledge alleviates exposure bias effectively throughout the\nentire training process, leading to performance enhancements.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12842v1",
    "authors": ["Gyeongman Kim", "Doohyuk Jang", "Eunho Yang"]
  },
  {
    "id": "2402.12847",
    "title": "Instruction-tuned Language Models are Better Knowledge Learners",
    "abstract": "  In order for large language model (LLM)-based assistants to effectively adapt\nto evolving information needs, it must be possible to update their factual\nknowledge through continued training on new data. The standard recipe for doing\nso involves continued pre-training on new documents followed by\ninstruction-tuning on question-answer (QA) pairs. However, we find that LLMs\ntrained with this recipe struggle to answer questions, even though the\nperplexity of documents is minimized. We found that QA pairs are generally\nstraightforward, while documents are more complex, weaving many factual\nstatements together in an intricate manner. Therefore, we hypothesize that it\nis beneficial to expose LLMs to QA pairs before continued pre-training on\ndocuments so that the process of encoding knowledge from complex documents\ntakes into account how this knowledge is accessed through questions. Based on\nthis, we propose pre-instruction-tuning (PIT), a method that instruction-tunes\non questions prior to training on documents. This contrasts with standard\ninstruction-tuning, which learns how to extract knowledge after training on\ndocuments. Extensive experiments and ablation studies demonstrate that PIT\nsignificantly enhances the ability of LLMs to absorb knowledge from new\ndocuments, outperforming standard instruction-tuning by 17.8%.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12847v1",
    "authors": [
      "Zhengbao Jiang",
      "Zhiqing Sun",
      "Weijia Shi",
      "Pedro Rodriguez",
      "Chunting Zhou",
      "Graham Neubig",
      "Xi Victoria Lin",
      "Wen-tau Yih",
      "Srinivasan Iyer"
    ]
  },
  {
    "id": "2402.12865",
    "title": "Backward Lens: Projecting Language Model Gradients into the Vocabulary\n  Space",
    "abstract": "  Understanding how Transformer-based Language Models (LMs) learn and recall\ninformation is a key goal of the deep learning community. Recent\ninterpretability methods project weights and hidden states obtained from the\nforward pass to the models' vocabularies, helping to uncover how information\nflows within LMs. In this work, we extend this methodology to LMs' backward\npass and gradients. We first prove that a gradient matrix can be cast as a\nlow-rank linear combination of its forward and backward passes' inputs. We then\ndevelop methods to project these gradients into vocabulary items and explore\nthe mechanics of how new information is stored in the LMs' neurons.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12865v1",
    "authors": ["Shahar Katz", "Yonatan Belinkov", "Mor Geva", "Lior Wolf"]
  },
  {
    "id": "2402.12907",
    "title": "Incentive Compatibility for AI Alignment in Sociotechnical Systems:\n  Positions and Prospects",
    "abstract": "  The burgeoning integration of artificial intelligence (AI) into human society\nbrings forth significant implications for societal governance and safety. While\nconsiderable strides have been made in addressing AI alignment challenges,\nexisting methodologies primarily focus on technical facets, often neglecting\nthe intricate sociotechnical nature of AI systems, which can lead to a\nmisalignment between the development and deployment contexts. To this end, we\nposit a new problem worth exploring: Incentive Compatibility Sociotechnical\nAlignment Problem (ICSAP). We hope this can call for more researchers to\nexplore how to leverage the principles of Incentive Compatibility (IC) from\ngame theory to bridge the gap between technical and societal components to\nmaintain AI consensus with human societies in different contexts. We further\ndiscuss three classical game problems for achieving IC: mechanism design,\ncontract theory, and Bayesian persuasion, in addressing the perspectives,\npotentials, and challenges of solving ICSAP, and provide preliminary\nimplementation conceptions.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12907v1",
    "authors": [
      "Zhaowei Zhang",
      "Fengshuo Bai",
      "Mingzhi Wang",
      "Haoyang Ye",
      "Chengdong Ma",
      "Yaodong Yang"
    ]
  },
  {
    "id": "2402.12928",
    "title": "A Literature Review of Literature Reviews in Pattern Analysis and\n  Machine Intelligence",
    "abstract": "  By consolidating scattered knowledge, the literature review provides a\ncomprehensive understanding of the investigated topic. However, excessive\nreviews, especially in the booming field of pattern analysis and machine\nintelligence (PAMI), raise concerns for both researchers and reviewers. In\nresponse to these concerns, this Analysis aims to provide a thorough review of\nreviews in the PAMI field from diverse perspectives. First, large language\nmodel-empowered bibliometric indicators are proposed to evaluate literature\nreviews automatically. To facilitate this, a meta-data database dubbed RiPAMI,\nand a topic dataset are constructed, which are utilized to obtain statistical\ncharacteristics of PAMI reviews. Unlike traditional bibliometric measurements,\nthe proposed article-level indicators provide real-time and field-normalized\nquantified assessments of reviews without relying on user-defined keywords.\nSecond, based on these indicators, the study presents comparative analyses of\ndifferent reviews, unveiling the characteristics of publications across various\nfields, periods, and journals. The newly emerging AI-generated literature\nreviews are also appraised, and the observed differences suggest that most\nAI-generated reviews still lag behind human-authored reviews in several\naspects. Third, we briefly provide a subjective evaluation of representative\nPAMI reviews and introduce a paper structure-based typology of literature\nreviews. This typology may improve the clarity and effectiveness for scholars\nin reading and writing reviews, while also serving as a guide for AI systems in\ngenerating well-organized reviews. Finally, this Analysis offers insights into\nthe current challenges of literature reviews and envisions future directions\nfor their development.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12928v2",
    "authors": ["Penghai Zhao", "Xin Zhang", "Ming-Ming Cheng", "Jian Yang", "Xiang Li"]
  },
  {
    "id": "2402.12954",
    "title": "Conditional Logical Message Passing Transformer for Complex Query\n  Answering",
    "abstract": "  Complex Query Answering (CQA) over Knowledge Graphs (KGs) is a challenging\ntask. Given that KGs are usually incomplete, neural models are proposed to\nsolve CQA by performing multi-hop logical reasoning. However, most of them\ncannot perform well on both one-hop and multi-hop queries simultaneously.\nRecent work proposes a logical message passing mechanism based on the\npre-trained neural link predictors. While effective on both one-hop and\nmulti-hop queries, it ignores the difference between the constant and variable\nnodes in a query graph. In addition, during the node embedding update stage,\nthis mechanism cannot dynamically measure the importance of different messages,\nand whether it can capture the implicit logical dependencies related to a node\nand received messages remains unclear. In this paper, we propose Conditional\nLogical Message Passing Transformer (CLMPT), which considers the difference\nbetween constants and variables in the case of using pre-trained neural link\npredictors and performs message passing conditionally on the node type. We\nempirically verified that this approach can reduce computational costs without\naffecting performance. Furthermore, CLMPT uses the transformer to aggregate\nreceived messages and update the corresponding node embedding. Through the\nself-attention mechanism, CLMPT can assign adaptive weights to elements in an\ninput set consisting of received messages and the corresponding node and\nexplicitly model logical dependencies between various elements. Experimental\nresults show that CLMPT is a new state-of-the-art neural CQA model.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12954v1",
    "authors": ["Chongzhi Zhang", "Zhiping Peng", "Junhao Zheng", "Qianli Ma"]
  },
  {
    "id": "2402.12991",
    "title": "TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box\n  Identification",
    "abstract": "  Large Language Model (LLM) services and models often come with legal rules on\nwho can use them and how they must use them. Assessing the compliance of the\nreleased LLMs is crucial, as these rules protect the interests of the LLM\ncontributor and prevent misuse. In this context, we describe the novel problem\nof Black-box Identity Verification (BBIV). The goal is to determine whether a\nthird-party application uses a certain LLM through its chat function. We\npropose a method called Targeted Random Adversarial Prompt (TRAP) that\nidentifies the specific LLM in use. We repurpose adversarial suffixes,\noriginally proposed for jailbreaking, to get a pre-defined answer from the\ntarget LLM, while other models give random answers. TRAP detects the target\nLLMs with over 95% true positive rate at under 0.2% false positive rate even\nafter a single interaction. TRAP remains effective even if the LLM has minor\nchanges that do not significantly alter the original function.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12991v1",
    "authors": ["Martin Gubri", "Dennis Ulmer", "Hwaran Lee", "Sangdoo Yun", "Seong Joon Oh"]
  },
  {
    "id": "2402.12993",
    "title": "An Autonomous Large Language Model Agent for Chemical Literature Data\n  Mining",
    "abstract": "  Chemical synthesis, which is crucial for advancing material synthesis and\ndrug discovery, impacts various sectors including environmental science and\nhealthcare. The rise of technology in chemistry has generated extensive\nchemical data, challenging researchers to discern patterns and refine synthesis\nprocesses. Artificial intelligence (AI) helps by analyzing data to optimize\nsynthesis and increase yields. However, AI faces challenges in processing\nliterature data due to the unstructured format and diverse writing style of\nchemical literature. To overcome these difficulties, we introduce an end-to-end\nAI agent framework capable of high-fidelity extraction from extensive chemical\nliterature. This AI agent employs large language models (LLMs) for prompt\ngeneration and iterative optimization. It functions as a chemistry assistant,\nautomating data collection and analysis, thereby saving manpower and enhancing\nperformance. Our framework's efficacy is evaluated using accuracy, recall, and\nF1 score of reaction condition data, and we compared our method with human\nexperts in terms of content correctness and time efficiency. The proposed\napproach marks a significant advancement in automating chemical literature\nextraction and demonstrates the potential for AI to revolutionize data\nmanagement and utilization in chemistry.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12993v1",
    "authors": [
      "Kexin Chen",
      "Hanqun Cao",
      "Junyou Li",
      "Yuyang Du",
      "Menghao Guo",
      "Xin Zeng",
      "Lanqing Li",
      "Jiezhong Qiu",
      "Pheng Ann Heng",
      "Guangyong Chen"
    ]
  },
  {
    "id": "2402.13019",
    "title": "Improving Neural-based Classification with Logical Background Knowledge",
    "abstract": "  Neurosymbolic AI is a growing field of research aiming to combine neural\nnetworks learning capabilities with the reasoning abilities of symbolic\nsystems. This hybridization can take many shapes. In this paper, we propose a\nnew formalism for supervised multi-label classification with propositional\nbackground knowledge. We introduce a new neurosymbolic technique called\nsemantic conditioning at inference, which only constrains the system during\ninference while leaving the training unaffected. We discuss its theoritical and\npractical advantages over two other popular neurosymbolic techniques: semantic\nconditioning and semantic regularization. We develop a new multi-scale\nmethodology to evaluate how the benefits of a neurosymbolic technique evolve\nwith the scale of the network. We then evaluate experimentally and compare the\nbenefits of all three techniques across model scales on several datasets. Our\nresults demonstrate that semantic conditioning at inference can be used to\nbuild more accurate neural-based systems with fewer resources while\nguaranteeing the semantic consistency of outputs.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13019v1",
    "authors": ["Arthur Ledaguenel", "Céline Hudelot", "Mostepha Khouadjia"]
  },
  {
    "id": "2402.13077",
    "title": "Mechanistic Neural Networks for Scientific Machine Learning",
    "abstract": "  This paper presents Mechanistic Neural Networks, a neural network design for\nmachine learning applications in the sciences. It incorporates a new\nMechanistic Block in standard architectures to explicitly learn governing\ndifferential equations as representations, revealing the underlying dynamics of\ndata and enhancing interpretability and efficiency in data modeling. Central to\nour approach is a novel Relaxed Linear Programming Solver (NeuRLP) inspired by\na technique that reduces solving linear ODEs to solving linear programs. This\nintegrates well with neural networks and surpasses the limitations of\ntraditional ODE solvers enabling scalable GPU parallel processing. Overall,\nMechanistic Neural Networks demonstrate their versatility for scientific\nmachine learning applications, adeptly managing tasks from equation discovery\nto dynamic systems modeling. We prove their comprehensive capabilities in\nanalyzing and interpreting complex scientific data across various applications,\nshowing significant performance against specialized state-of-the-art methods.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13077v1",
    "authors": ["Adeel Pervez", "Francesco Locatello", "Efstratios Gavves"]
  },
  {
    "id": "2402.13089",
    "title": "Towards an empirical understanding of MoE design choices",
    "abstract": "  In this study, we systematically evaluate the impact of common design choices\nin Mixture of Experts (MoEs) on validation performance, uncovering distinct\ninfluences at token and sequence levels. We also present empirical evidence\nshowing comparable performance between a learned router and a frozen, randomly\ninitialized router, suggesting that learned routing may not be essential. Our\nstudy further reveals that Sequence-level routing can result in topic-specific\nweak expert specialization, in contrast to syntax specialization observed with\nToken-level routing.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13089v1",
    "authors": ["Dongyang Fan", "Bettina Messmer", "Martin Jaggi"]
  },
  {
    "id": "2402.13201",
    "title": "Tiny Reinforcement Learning for Quadruped Locomotion using Decision\n  Transformers",
    "abstract": "  Resource-constrained robotic platforms are particularly useful for tasks that\nrequire low-cost hardware alternatives due to the risk of losing the robot,\nlike in search-and-rescue applications, or the need for a large number of\ndevices, like in swarm robotics. For this reason, it is crucial to find\nmechanisms for adapting reinforcement learning techniques to the constraints\nimposed by lower computational power and smaller memory capacities of these\nultra low-cost robotic platforms. We try to address this need by proposing a\nmethod for making imitation learning deployable onto resource-constrained\nrobotic platforms. Here we cast the imitation learning problem as a conditional\nsequence modeling task and we train a decision transformer using expert\ndemonstrations augmented with a custom reward. Then, we compress the resulting\ngenerative model using software optimization schemes, including quantization\nand pruning. We test our method in simulation using Isaac Gym, a realistic\nphysics simulation environment designed for reinforcement learning. We\nempirically demonstrate that our method achieves natural looking gaits for\nBittle, a resource-constrained quadruped robot. We also run multiple\nsimulations to show the effects of pruning and quantization on the performance\nof the model. Our results show that quantization (down to 4 bits) and pruning\nreduce model size by around 30\\% while maintaining a competitive reward, making\nthe model deployable in a resource-constrained system.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13201v1",
    "authors": ["Orhan Eren Akgün", "Néstor Cuevas", "Matheus Farias", "Daniel Garces"]
  },
  {
    "id": "2402.13212",
    "title": "Soft Self-Consistency Improves Language Model Agents",
    "abstract": "  Generations from large language models (LLMs) can be improved by sampling and\nscoring multiple solutions to select a final answer. Current \"sample and\nselect\" methods such as self-consistency (SC) rely on majority voting to score\nanswers. However, when tasks have many distinct and valid answers, selection by\nvoting requires a large number of samples. This makes SC prohibitively\nexpensive for interactive tasks that involve generating multiple actions\n(answers) sequentially. After establishing that majority voting fails to\nprovide consistent gains on such tasks, we demonstrate how to increase success\nrates by softening the scoring criterion. We introduce Soft Self-Consistency\n(Soft-SC), which replaces SC's discontinuous scoring with a continuous score\ncomputed from model likelihoods, allowing for selection even when actions are\nsparsely distributed. Soft-SC improves both performance and efficiency on\nlong-horizon interactive tasks, requiring half as many samples as SC for\ncomparable or better performance. For a fixed number of samples, Soft-SC leads\nto a 1.3% increase over SC in absolute success rate on writing bash programs, a\n6.6% increase on online shopping (WebShop), and a 4.7% increase for an\ninteractive household game (ALFWorld). Finally, we show that Soft-SC can be\napplied to both open-source and black-box models.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13212v1",
    "authors": ["Han Wang", "Archiki Prasad", "Elias Stengel-Eskin", "Mohit Bansal"]
  },
  {
    "id": "2402.13213",
    "title": "Softmax Probabilities (Mostly) Predict Large Language Model Correctness\n  on Multiple-Choice Q&A",
    "abstract": "  Although large language models (LLMs) perform impressively on many tasks,\noverconfidence remains a problem. We hypothesized that on multiple-choice Q&A\ntasks, wrong answers would be associated with smaller maximum softmax\nprobabilities (MSPs) compared to correct answers. We comprehensively evaluate\nthis hypothesis on ten open-source LLMs and five datasets, and find strong\nevidence for our hypothesis among models which perform well on the original Q&A\ntask. For the six LLMs with the best Q&A performance, the AUROC derived from\nthe MSP was better than random chance with p < 10^{-4} in 59/60 instances.\nAmong those six LLMs, the average AUROC ranged from 60% to 69%. Leveraging\nthese findings, we propose a multiple-choice Q&A task with an option to abstain\nand show that performance can be improved by selectively abstaining based on\nthe MSP of the initial model response. We also run the same experiments with\npre-softmax logits instead of softmax probabilities and find similar (but not\nidentical) results.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13213v1",
    "authors": ["Benjamin Plaut", "Khanh Nguyen", "Tu Trinh"]
  },
  {
    "id": "2402.13226",
    "title": "NeRF Solves Undersampled MRI Reconstruction",
    "abstract": "  This article presents a novel undersampled magnetic resonance imaging (MRI)\ntechnique that leverages the concept of Neural Radiance Field (NeRF). With\nradial undersampling, the corresponding imaging problem can be reformulated\ninto an image modeling task from sparse-view rendered data; therefore, a high\ndimensional MR image is obtainable from undersampled $k$-space data by taking\nadvantage of implicit neural representation. A multi-layer perceptron, which is\ndesigned to output an image intensity from a spatial coordinate, learns the MR\nphysics-driven rendering relation between given measurement data and desired\nimage. Effective undersampling strategies for high-quality neural\nrepresentation are investigated. The proposed method serves two benefits: (i)\nThe learning is based fully on single undersampled $k$-space data, not a bunch\nof measured data and target image sets. It can be used potentially for\ndiagnostic MR imaging, such as fetal MRI, where data acquisition is relatively\nrare or limited against diversity of clinical images while undersampled\nreconstruction is highly demanded. (ii) A reconstructed MR image is a\nscan-specific representation highly adaptive to the given $k$-space\nmeasurement. Numerous experiments validate the feasibility and capability of\nthe proposed approach.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13226v1",
    "authors": ["Tae Jun Jang", "Chang Min Hyun"]
  },
  {
    "id": "2402.13228",
    "title": "Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive",
    "abstract": "  Direct Preference Optimisation (DPO) is effective at significantly improving\nthe performance of large language models (LLMs) on downstream tasks such as\nreasoning, summarisation, and alignment. Using pairs of preferred and\ndispreferred data, DPO models the \\textit{relative} probability of picking one\nresponse over another. In this work, first we show theoretically that the\nstandard DPO loss can lead to a \\textit{reduction} of the model's likelihood of\nthe preferred examples, as long as the relative probability between the\npreferred and dispreferred classes increases. We then show empirically that\nthis phenomenon occurs when fine-tuning LLMs on common datasets, especially\ndatasets in which the edit distance between pairs of completions is low. Using\nthese insights, we design DPO-Positive (DPOP), a new loss function and training\nprocedure which avoids this failure mode. Surprisingly, we also find that DPOP\nsignificantly outperforms DPO across a wide variety of datasets and downstream\ntasks, including datasets with high edit distances between completions. By\nfine-tuning with DPOP, we create and release Smaug-34B and Smaug-72B, which\nachieve state-of-the-art open-source performance. Notably, Smaug-72B is nearly\n2\\% better than any other open-source model on the HuggingFace Open LLM\nLeaderboard and becomes the first open-source LLM to surpass an average\naccuracy of 80\\%.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13228v1",
    "authors": [
      "Arka Pal",
      "Deep Karkhanis",
      "Samuel Dooley",
      "Manley Roberts",
      "Siddartha Naidu",
      "Colin White"
    ]
  },
  {
    "id": "2402.13254",
    "title": "CounterCurate: Enhancing Physical and Semantic Visio-Linguistic\n  Compositional Reasoning via Counterfactual Examples",
    "abstract": "  We propose CounterCurate, a framework to comprehensively improve the\nvisio-linguistic compositional reasoning capability for both contrastive and\ngenerative multimodal models. In particular, we identify two under-explored\ncritical problems: the neglect of the physically grounded reasoning (counting\nand position understanding) and the potential of using highly capable text and\nimage generation models for semantic counterfactual fine-tuning. Our work\npioneers an approach that addresses these gaps. We first spotlight the\nnear-chance performance of multimodal models like CLIP and LLaVA in physically\ngrounded compositional reasoning. We then apply simple data augmentation using\na grounded image generation model, GLIGEN, to generate finetuning data,\nresulting in significant performance improvements: +33% and +37% for CLIP and\nLLaVA, respectively, on our newly curated Flickr30k-Positions benchmark.\nMoreover, we exploit the capabilities of high-performing text generation and\nimage generation models, specifically GPT-4V and DALLE-3, to curate challenging\nsemantic counterfactuals, thereby further enhancing compositional reasoning\ncapabilities on benchmarks such as SugarCrepe, where CounterCurate outperforms\nGPT-4V.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13254v1",
    "authors": ["Jianrui Zhang", "Mu Cai", "Tengyang Xie", "Yong Jae Lee"]
  },
  {
    "id": "2402.13301",
    "title": "Structure-informed Positional Encoding for Music Generation",
    "abstract": "  Music generated by deep learning methods often suffers from a lack of\ncoherence and long-term organization. Yet, multi-scale hierarchical structure\nis a distinctive feature of music signals. To leverage this information, we\npropose a structure-informed positional encoding framework for music generation\nwith Transformers. We design three variants in terms of absolute, relative and\nnon-stationary positional information. We comprehensively test them on two\nsymbolic music generation tasks: next-timestep prediction and accompaniment\ngeneration. As a comparison, we choose multiple baselines from the literature\nand demonstrate the merits of our methods using several musically-motivated\nevaluation metrics. In particular, our methods improve the melodic and\nstructural consistency of the generated pieces.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13301v2",
    "authors": ["Manvi Agarwal", "Changhong Wang", "Gaël Richard"]
  },
  {
    "id": "2402.13349",
    "title": "Aria Everyday Activities Dataset",
    "abstract": "  We present Aria Everyday Activities (AEA) Dataset, an egocentric multimodal\nopen dataset recorded using Project Aria glasses. AEA contains 143 daily\nactivity sequences recorded by multiple wearers in five geographically diverse\nindoor locations. Each of the recording contains multimodal sensor data\nrecorded through the Project Aria glasses. In addition, AEA provides machine\nperception data including high frequency globally aligned 3D trajectories,\nscene point cloud, per-frame 3D eye gaze vector and time aligned speech\ntranscription. In this paper, we demonstrate a few exemplar research\napplications enabled by this dataset, including neural scene reconstruction and\nprompted segmentation. AEA is an open source dataset that can be downloaded\nfrom https://www.projectaria.com/datasets/aea/. We are also providing\nopen-source implementations and examples of how to use the dataset in Project\nAria Tools https://github.com/facebookresearch/projectaria_tools.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13349v2",
    "authors": [
      "Zhaoyang Lv",
      "Nicholas Charron",
      "Pierre Moulon",
      "Alexander Gamino",
      "Cheng Peng",
      "Chris Sweeney",
      "Edward Miller",
      "Huixuan Tang",
      "Jeff Meissner",
      "Jing Dong",
      "Kiran Somasundaram",
      "Luis Pesqueira",
      "Mark Schwesinger",
      "Omkar Parkhi",
      "Qiao Gu",
      "Renzo De Nardi",
      "Shangyi Cheng",
      "Steve Saarinen",
      "Vijay Baiyya",
      "Yuyang Zou",
      "Richard Newcombe",
      "Jakob Julian Engel",
      "Xiaqing Pan",
      "Carl Ren"
    ]
  },
  {
    "id": "2402.13352",
    "title": "KetGPT - Dataset Augmentation of Quantum Circuits using Transformers",
    "abstract": "  Quantum algorithms, represented as quantum circuits, can be used as\nbenchmarks for assessing the performance of quantum systems. Existing datasets,\nwidely utilized in the field, suffer from limitations in size and versatility,\nleading researchers to employ randomly generated circuits. Random circuits are,\nhowever, not representative benchmarks as they lack the inherent properties of\nreal quantum algorithms for which the quantum systems are manufactured. This\nshortage of `useful' quantum benchmarks poses a challenge to advancing the\ndevelopment and comparison of quantum compilers and hardware.\n  This research aims to enhance the existing quantum circuit datasets by\ngenerating what we refer to as `realistic-looking' circuits by employing the\nTransformer machine learning architecture. For this purpose, we introduce\nKetGPT, a tool that generates synthetic circuits in OpenQASM language, whose\nstructure is based on quantum circuits derived from existing quantum algorithms\nand follows the typical patterns of human-written algorithm-based code (e.g.,\norder of gates and qubits). Our three-fold verification process, involving\nmanual inspection and Qiskit framework execution, transformer-based\nclassification, and structural analysis, demonstrates the efficacy of KetGPT in\nproducing large amounts of additional circuits that closely align with\nalgorithm-based structures. Beyond benchmarking, we envision KetGPT\ncontributing substantially to AI-driven quantum compilers and systems.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13352v3",
    "authors": ["Boran Apak", "Medina Bandic", "Aritra Sarkar", "Sebastian Feld"]
  },
  {
    "id": "2402.13369",
    "title": "The Uncanny Valley: A Comprehensive Analysis of Diffusion Models",
    "abstract": "  Through Diffusion Models (DMs), we have made significant advances in\ngenerating high-quality images. Our exploration of these models delves deeply\ninto their core operational principles by systematically investigating key\naspects across various DM architectures: i) noise schedules, ii) samplers, and\niii) guidance. Our comprehensive examination of these models sheds light on\ntheir hidden fundamental mechanisms, revealing the concealed foundational\nelements that are essential for their effectiveness. Our analyses emphasize the\nhidden key factors that determine model performance, offering insights that\ncontribute to the advancement of DMs. Past findings show that the configuration\nof noise schedules, samplers, and guidance is vital to the quality of generated\nimages; however, models reach a stable level of quality across different\nconfigurations at a remarkably similar point, revealing that the decisive\nfactors for optimal performance predominantly reside in the diffusion process\ndynamics and the structural design of the model's network, rather than the\nspecifics of configuration details. Our comparative analysis reveals that\nDenoising Diffusion Probabilistic Model (DDPM)-based diffusion dynamics\nconsistently outperform the Noise Conditioned Score Network (NCSN)-based ones,\nnot only when evaluated in their original forms but also when continuous\nthrough Stochastic Differential Equation (SDE)-based implementations.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13369v1",
    "authors": ["Karam Ghanem", "Danilo Bzdok"]
  },
  {
    "id": "2402.13425",
    "title": "Investigating the Histogram Loss in Regression",
    "abstract": "  It is becoming increasingly common in regression to train neural networks\nthat model the entire distribution even if only the mean is required for\nprediction. This additional modeling often comes with performance gain and the\nreasons behind the improvement are not fully known. This paper investigates a\nrecent approach to regression, the Histogram Loss, which involves learning the\nconditional distribution of the target variable by minimizing the cross-entropy\nbetween a target distribution and a flexible histogram prediction. We design\ntheoretical and empirical analyses to determine why and when this performance\ngain appears, and how different components of the loss contribute to it. Our\nresults suggest that the benefits of learning distributions in this setup come\nfrom improvements in optimization rather than learning a better representation.\nWe then demonstrate the viability of the Histogram Loss in common deep learning\napplications without a need for costly hyperparameter tuning.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13425v1",
    "authors": [
      "Ehsan Imani",
      "Kai Luedemann",
      "Sam Scholnick-Hughes",
      "Esraa Elelimy",
      "Martha White"
    ]
  },
  {
    "id": "2402.13430",
    "title": "LinkSAGE: Optimizing Job Matching Using Graph Neural Networks",
    "abstract": "  We present LinkSAGE, an innovative framework that integrates Graph Neural\nNetworks (GNNs) into large-scale personalized job matching systems, designed to\naddress the complex dynamics of LinkedIns extensive professional network. Our\napproach capitalizes on a novel job marketplace graph, the largest and most\nintricate of its kind in industry, with billions of nodes and edges. This graph\nis not merely extensive but also richly detailed, encompassing member and job\nnodes along with key attributes, thus creating an expansive and interwoven\nnetwork. A key innovation in LinkSAGE is its training and serving methodology,\nwhich effectively combines inductive graph learning on a heterogeneous,\nevolving graph with an encoder-decoder GNN model. This methodology decouples\nthe training of the GNN model from that of existing Deep Neural Nets (DNN)\nmodels, eliminating the need for frequent GNN retraining while maintaining\nup-to-date graph signals in near realtime, allowing for the effective\nintegration of GNN insights through transfer learning. The subsequent nearline\ninference system serves the GNN encoder within a real-world setting,\nsignificantly reducing online latency and obviating the need for costly\nreal-time GNN infrastructure. Validated across multiple online A/B tests in\ndiverse product scenarios, LinkSAGE demonstrates marked improvements in member\nengagement, relevance matching, and member retention, confirming its\ngeneralizability and practical impact.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13430v1",
    "authors": [
      "Ping Liu",
      "Haichao Wei",
      "Xiaochen Hou",
      "Jianqiang Shen",
      "Shihai He",
      "Kay Qianqi Shen",
      "Zhujun Chen",
      "Fedor Borisyuk",
      "Daniel Hewlett",
      "Liang Wu",
      "Srikant Veeraraghavan",
      "Alex Tsun",
      "Chengming Jiang",
      "Wenjing Zhang"
    ]
  },
  {
    "id": "2402.13432",
    "title": "DrBenchmark: A Large Language Understanding Evaluation Benchmark for\n  French Biomedical Domain",
    "abstract": "  The biomedical domain has sparked a significant interest in the field of\nNatural Language Processing (NLP), which has seen substantial advancements with\npre-trained language models (PLMs). However, comparing these models has proven\nchallenging due to variations in evaluation protocols across different models.\nA fair solution is to aggregate diverse downstream tasks into a benchmark,\nallowing for the assessment of intrinsic PLMs qualities from various\nperspectives. Although still limited to few languages, this initiative has been\nundertaken in the biomedical field, notably English and Chinese. This\nlimitation hampers the evaluation of the latest French biomedical models, as\nthey are either assessed on a minimal number of tasks with non-standardized\nprotocols or evaluated using general downstream tasks. To bridge this research\ngap and account for the unique sensitivities of French, we present the\nfirst-ever publicly available French biomedical language understanding\nbenchmark called DrBenchmark. It encompasses 20 diversified tasks, including\nnamed-entity recognition, part-of-speech tagging, question-answering, semantic\ntextual similarity, and classification. We evaluate 8 state-of-the-art\npre-trained masked language models (MLMs) on general and biomedical-specific\ndata, as well as English specific MLMs to assess their cross-lingual\ncapabilities. Our experiments reveal that no single model excels across all\ntasks, while generalist models are sometimes still competitive.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13432v1",
    "authors": [
      "Yanis Labrak",
      "Adrien Bazoge",
      "Oumaima El Khettari",
      "Mickael Rouvier",
      "Pacome Constant dit Beaufils",
      "Natalia Grabar",
      "Beatrice Daille",
      "Solen Quiniou",
      "Emmanuel Morin",
      "Pierre-Antoine Gourraud",
      "Richard Dufour"
    ]
  },
  {
    "id": "2402.14029",
    "title": "Partial Search in a Frozen Network is Enough to Find a Strong Lottery\n  Ticket",
    "abstract": "  Randomly initialized dense networks contain subnetworks that achieve high\naccuracy without weight learning -- strong lottery tickets (SLTs). Recently,\nGadhikar et al. (2023) demonstrated theoretically and experimentally that SLTs\ncan also be found within a randomly pruned source network, thus reducing the\nSLT search space. However, this limits the search to SLTs that are even sparser\nthan the source, leading to worse accuracy due to unintentionally high\nsparsity. This paper proposes a method that reduces the SLT search space by an\narbitrary ratio that is independent of the desired SLT sparsity. A random\nsubset of the initial weights is excluded from the search space by freezing it\n-- i.e., by either permanently pruning them or locking them as a fixed part of\nthe SLT. Indeed, the SLT existence in such a reduced search space is\ntheoretically guaranteed by our subset-sum approximation with randomly frozen\nvariables. In addition to reducing search space, the random freezing pattern\ncan also be exploited to reduce model size in inference. Furthermore,\nexperimental results show that the proposed method finds SLTs with better\naccuracy and model size trade-off than the SLTs obtained from dense or randomly\npruned source networks. In particular, the SLT found in a frozen graph neural\nnetwork achieves higher accuracy than its weight trained counterpart while\nreducing model size by $40.3\\times$.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14029v1",
    "authors": [
      "Hikari Otsuka",
      "Daiki Chijiwa",
      "Ángel López García-Arias",
      "Yasuyuki Okoshi",
      "Kazushi Kawamura",
      "Thiem Van Chu",
      "Daichi Fujiki",
      "Susumu Takeuchi",
      "Masato Motomura"
    ]
  },
  {
    "id": "2402.14851",
    "title": "SQL-CRAFT: Text-to-SQL through Interactive Refinement and Enhanced\n  Reasoning",
    "abstract": "  Modern LLMs have become increasingly powerful, but they are still facing\nchallenges in specialized tasks such as Text-to-SQL. We propose SQL-CRAFT, a\nframework to advance LLMs' SQL generation Capabilities through inteRActive\nreFinemenT and enhanced reasoning. We leverage an Interactive Correction Loop\n(IC-Loop) for LLMs to interact with databases automatically, as well as\nPython-enhanced reasoning. We conduct experiments on two Text-to-SQL datasets,\nSpider and Bird, with performance improvements of up to 5.7% compared to the\nnaive prompting method. Moreover, our method surpasses the current\nstate-of-the-art on the Spider Leaderboard, demonstrating the effectiveness of\nour framework.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14851v1",
    "authors": [
      "Hanchen Xia",
      "Feng Jiang",
      "Naihao Deng",
      "Cunxiang Wang",
      "Guojiang Zhao",
      "Rada Mihalcea",
      "Yue Zhang"
    ]
  },
  {
    "id": "2402.14852",
    "title": "HumanEval on Latest GPT Models -- 2024",
    "abstract": "  In 2023, we are using the latest models of GPT-4 to advance program\nsynthesis. The large language models have significantly improved the\nstate-of-the-art for this purpose. To make these advancements more accessible,\nwe have created a repository that connects these models to Huamn Eval. This\ndataset was initally developed to be used with a language model called CODEGEN\non natural and programming language data. The utility of these trained models\nis showcased by demonstrating their competitive performance in zero-shot Python\ncode generation on HumanEval tasks compared to previous state-of-the-art\nsolutions. Additionally, this gives way to developing more multi-step paradigm\nsynthesis. This benchmark features 160 diverse problem sets factorized into\nmultistep prompts that our analysis shows significantly improves program\nsynthesis over single-turn inputs. All code is open source at\nhttps://github.com/daniel442li/gpt-human-eval .\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14852v1",
    "authors": ["Daniel Li", "Lincoln Murr"]
  },
  {
    "id": "2402.14857",
    "title": "Is the System Message Really Important to Jailbreaks in Large Language\n  Models?",
    "abstract": "  The rapid evolution of Large Language Models (LLMs) has rendered them\nindispensable in modern society. While security measures are typically in place\nto align LLMs with human values prior to release, recent studies have unveiled\na concerning phenomenon named \"jailbreak.\" This term refers to the unexpected\nand potentially harmful responses generated by LLMs when prompted with\nmalicious questions. Existing research focuses on generating jailbreak prompts\nbut our study aim to answer a different question: Is the system message really\nimportant to jailbreak in LLMs? To address this question, we conducted\nexperiments in a stable GPT version gpt-3.5-turbo-0613 to generated jailbreak\nprompts with varying system messages: short, long, and none. We discover that\ndifferent system messages have distinct resistances to jailbreak by\nexperiments. Additionally, we explore the transferability of jailbreak across\nLLMs. This finding underscores the significant impact system messages can have\non mitigating LLMs jailbreak. To generate system messages that are more\nresistant to jailbreak prompts, we propose System Messages Evolutionary\nAlgorithms (SMEA). Through SMEA, we can get robust system messages population\nthat demonstrate up to 98.9% resistance against jailbreak prompts. Our research\nnot only bolsters LLMs security but also raises the bar for jailbreak,\nfostering advancements in this field of study.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14857v1",
    "authors": ["Xiaotian Zou", "Yongkang Chen", "Ke Li"]
  },
  {
    "id": "2402.14859",
    "title": "The Wolf Within: Covert Injection of Malice into MLLM Societies via an\n  MLLM Operative",
    "abstract": "  Due to their unprecedented ability to process and respond to various types of\ndata, Multimodal Large Language Models (MLLMs) are constantly defining the new\nboundary of Artificial General Intelligence (AGI). As these advanced generative\nmodels increasingly form collaborative networks for complex tasks, the\nintegrity and security of these systems are crucial. Our paper, ``The Wolf\nWithin'', explores a novel vulnerability in MLLM societies - the indirect\npropagation of malicious content. Unlike direct harmful output generation for\nMLLMs, our research demonstrates how a single MLLM agent can be subtly\ninfluenced to generate prompts that, in turn, induce other MLLM agents in the\nsociety to output malicious content. This subtle, yet potent method of indirect\ninfluence marks a significant escalation in the security risks associated with\nMLLMs. Our findings reveal that, with minimal or even no access to MLLMs'\nparameters, an MLLM agent, when manipulated to produce specific prompts or\ninstructions, can effectively ``infect'' other agents within a society of\nMLLMs. This infection leads to the generation and circulation of harmful\noutputs, such as dangerous instructions or misinformation, across the society.\nWe also show the transferability of these indirectly generated prompts,\nhighlighting their possibility in propagating malice through inter-agent\ncommunication. This research provides a critical insight into a new dimension\nof threat posed by MLLMs, where a single agent can act as a catalyst for\nwidespread malevolent influence. Our work underscores the urgent need for\ndeveloping robust mechanisms to detect and mitigate such covert manipulations\nwithin MLLM societies, ensuring their safe and ethical utilization in societal\napplications. Our implementation is released at\n\\url{https://github.com/ChengshuaiZhao0/The-Wolf-Within.git}.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14859v1",
    "authors": [
      "Zhen Tan",
      "Chengshuai Zhao",
      "Raha Moraffah",
      "Yifan Li",
      "Yu Kong",
      "Tianlong Chen",
      "Huan Liu"
    ]
  },
  {
    "id": "2402.12617",
    "title": "Generative AI Security: Challenges and Countermeasures",
    "abstract": "  Generative AI's expanding footprint across numerous industries has led to\nboth excitement and increased scrutiny. This paper delves into the unique\nsecurity challenges posed by Generative AI, and outlines potential research\ndirections for managing these risks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12617v1",
    "authors": ["Banghua Zhu", "Norman Mu", "Jiantao Jiao", "David Wagner"]
  },
  {
    "id": "2402.12727",
    "title": "Diffusion Posterior Sampling is Computationally Intractable",
    "abstract": "  Diffusion models are a remarkably effective way of learning and sampling from\na distribution $p(x)$. In posterior sampling, one is also given a measurement\nmodel $p(y \\mid x)$ and a measurement $y$, and would like to sample from $p(x\n\\mid y)$. Posterior sampling is useful for tasks such as inpainting,\nsuper-resolution, and MRI reconstruction, so a number of recent works have\ngiven algorithms to heuristically approximate it; but none are known to\nconverge to the correct distribution in polynomial time.\n  In this paper we show that posterior sampling is \\emph{computationally\nintractable}: under the most basic assumption in cryptography -- that one-way\nfunctions exist -- there are instances for which \\emph{every} algorithm takes\nsuperpolynomial time, even though \\emph{unconditional} sampling is provably\nfast. We also show that the exponential-time rejection sampling algorithm is\nessentially optimal under the stronger plausible assumption that there are\none-way functions that take exponential time to invert.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12727v1",
    "authors": ["Shivam Gupta", "Ajil Jalal", "Aditya Parulekar", "Eric Price", "Zhiyang Xun"]
  },
  {
    "id": "2402.12728",
    "title": "Modality-Aware Integration with Large Language Models for\n  Knowledge-based Visual Question Answering",
    "abstract": "  Knowledge-based visual question answering (KVQA) has been extensively studied\nto answer visual questions with external knowledge, e.g., knowledge graphs\n(KGs). While several attempts have been proposed to leverage large language\nmodels (LLMs) as an implicit knowledge source, it remains challenging since\nLLMs may generate hallucinations. Moreover, multiple knowledge sources, e.g.,\nimages, KGs and LLMs, cannot be readily aligned for complex scenarios. To\ntackle these, we present a novel modality-aware integration with LLMs for KVQA\n(MAIL). It carefully leverages multimodal knowledge for both image\nunderstanding and knowledge reasoning. Specifically, (i) we propose a two-stage\nprompting strategy with LLMs to densely embody the image into a scene graph\nwith detailed visual features; (ii) We construct a coupled concept graph by\nlinking the mentioned entities with external facts. (iii) A tailored\npseudo-siamese graph medium fusion is designed for sufficient multimodal\nfusion. We utilize the shared mentioned entities in two graphs as mediums to\nbridge a tight inter-modal exchange, while maximally preserving insightful\nintra-modal learning by constraining the fusion within mediums. Extensive\nexperiments on two benchmark datasets show the superiority of MAIL with 24x\nless resources.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12728v1",
    "authors": [
      "Junnan Dong",
      "Qinggang Zhang",
      "Huachi Zhou",
      "Daochen Zha",
      "Pai Zheng",
      "Xiao Huang"
    ]
  },
  {
    "id": "2402.12810",
    "title": "PIP-Net: Pedestrian Intention Prediction in the Wild",
    "abstract": "  Accurate pedestrian intention prediction (PIP) by Autonomous Vehicles (AVs)\nis one of the current research challenges in this field. In this article, we\nintroduce PIP-Net, a novel framework designed to predict pedestrian crossing\nintentions by AVs in real-world urban scenarios. We offer two variants of\nPIP-Net designed for different camera mounts and setups. Leveraging both\nkinematic data and spatial features from the driving scene, the proposed model\nemploys a recurrent and temporal attention-based solution, outperforming\nstate-of-the-art performance. To enhance the visual representation of road\nusers and their proximity to the ego vehicle, we introduce a categorical depth\nfeature map, combined with a local motion flow feature, providing rich insights\ninto the scene dynamics. Additionally, we explore the impact of expanding the\ncamera's field of view, from one to three cameras surrounding the ego vehicle,\nleading to enhancement in the model's contextual perception. Depending on the\ntraffic scenario and road environment, the model excels in predicting\npedestrian crossing intentions up to 4 seconds in advance which is a\nbreakthrough in current research studies in pedestrian intention prediction.\nFinally, for the first time, we present the Urban-PIP dataset, a customised\npedestrian intention prediction dataset, with multi-camera annotations in\nreal-world automated driving scenarios.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.12810v1",
    "authors": ["Mohsen Azarmi", "Mahdi Rezaei", "He Wang", "Sebastien Glaser"]
  },
  {
    "id": "2402.13040",
    "title": "Text-Guided Molecule Generation with Diffusion Language Model",
    "abstract": "  Text-guided molecule generation is a task where molecules are generated to\nmatch specific textual descriptions. Recently, most existing SMILES-based\nmolecule generation methods rely on an autoregressive architecture. In this\nwork, we propose the Text-Guided Molecule Generation with Diffusion Language\nModel (TGM-DLM), a novel approach that leverages diffusion models to address\nthe limitations of autoregressive methods. TGM-DLM updates token embeddings\nwithin the SMILES string collectively and iteratively, using a two-phase\ndiffusion generation process. The first phase optimizes embeddings from random\nnoise, guided by the text description, while the second phase corrects invalid\nSMILES strings to form valid molecular representations. We demonstrate that\nTGM-DLM outperforms MolT5-Base, an autoregressive model, without the need for\nadditional data resources. Our findings underscore the remarkable effectiveness\nof TGM-DLM in generating coherent and precise molecules with specific\nproperties, opening new avenues in drug discovery and related scientific\ndomains. Code will be released at: https://github.com/Deno-V/tgm-dlm.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13040v1",
    "authors": ["Haisong Gong", "Qiang Liu", "Shu Wu", "Liang Wang"]
  },
  {
    "id": "2402.13126",
    "title": "VGMShield: Mitigating Misuse of Video Generative Models",
    "abstract": "  With the rapid advancement in video generation, people can conveniently\nutilize video generation models to create videos tailored to their specific\ndesires. Nevertheless, there are also growing concerns about their potential\nmisuse in creating and disseminating false information.\n  In this work, we introduce VGMShield: a set of three straightforward but\npioneering mitigations through the lifecycle of fake video generation. We start\nfrom \\textit{fake video detection} trying to understand whether there is\nuniqueness in generated videos and whether we can differentiate them from real\nvideos; then, we investigate the \\textit{tracing} problem, which maps a fake\nvideo back to a model that generates it. Towards these, we propose to leverage\npre-trained models that focus on {\\it spatial-temporal dynamics} as the\nbackbone to identify inconsistencies in videos. Through experiments on seven\nstate-of-the-art open-source models, we demonstrate that current models still\ncannot perfectly handle spatial-temporal relationships, and thus, we can\naccomplish detection and tracing with nearly perfect accuracy.\n  Furthermore, anticipating future generative model improvements, we propose a\n{\\it prevention} method that adds invisible perturbations to images to make the\ngenerated videos look unreal. Together with fake video detection and tracing,\nour multi-faceted set of solutions can effectively mitigate misuse of video\ngenerative models.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13126v1",
    "authors": ["Yan Pang", "Yang Zhang", "Tianhao Wang"]
  },
  {
    "id": "2402.13380",
    "title": "Toward TransfORmers: Revolutionizing the Solution of Mixed Integer\n  Programs with Transformers",
    "abstract": "  In this study, we introduce an innovative deep learning framework that\nemploys a transformer model to address the challenges of mixed-integer\nprograms, specifically focusing on the Capacitated Lot Sizing Problem (CLSP).\nOur approach, to our knowledge, is the first to utilize transformers to predict\nthe binary variables of a mixed-integer programming (MIP) problem.\nSpecifically, our approach harnesses the encoder decoder transformer's ability\nto process sequential data, making it well-suited for predicting binary\nvariables indicating production setup decisions in each period of the CLSP.\nThis problem is inherently dynamic, and we need to handle sequential decision\nmaking under constraints. We present an efficient algorithm in which CLSP\nsolutions are learned through a transformer neural network. The proposed\npost-processed transformer algorithm surpasses the state-of-the-art solver,\nCPLEX and Long Short-Term Memory (LSTM) in solution time, optimal gap, and\npercent infeasibility over 240K benchmark CLSP instances tested. After the ML\nmodel is trained, conducting inference on the model, including post-processing,\nreduces the MIP into a linear program (LP). This transforms the ML-based\nalgorithm, combined with an LP solver, into a polynomial-time approximation\nalgorithm to solve a well-known NP-Hard problem, with almost perfect solution\nquality.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13380v1",
    "authors": ["Joshua F. Cooper", "Seung Jin Choi", "I. Esra Buyuktahtakin"]
  },
  {
    "id": "2402.13412",
    "title": "Scaling physics-informed hard constraints with mixture-of-experts",
    "abstract": "  Imposing known physical constraints, such as conservation laws, during neural\nnetwork training introduces an inductive bias that can improve accuracy,\nreliability, convergence, and data efficiency for modeling physical dynamics.\nWhile such constraints can be softly imposed via loss function penalties,\nrecent advancements in differentiable physics and optimization improve\nperformance by incorporating PDE-constrained optimization as individual layers\nin neural networks. This enables a stricter adherence to physical constraints.\nHowever, imposing hard constraints significantly increases computational and\nmemory costs, especially for complex dynamical systems. This is because it\nrequires solving an optimization problem over a large number of points in a\nmesh, representing spatial and temporal discretizations, which greatly\nincreases the complexity of the constraint. To address this challenge, we\ndevelop a scalable approach to enforce hard physical constraints using\nMixture-of-Experts (MoE), which can be used with any neural network\narchitecture. Our approach imposes the constraint over smaller decomposed\ndomains, each of which is solved by an \"expert\" through differentiable\noptimization. During training, each expert independently performs a localized\nbackpropagation step by leveraging the implicit function theorem; the\nindependence of each expert allows for parallelization across multiple GPUs.\nCompared to standard differentiable optimization, our scalable approach\nachieves greater accuracy in the neural PDE solver setting for predicting the\ndynamics of challenging non-linear systems. We also improve training stability\nand require significantly less computation time during both training and\ninference stages.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13412v1",
    "authors": ["Nithin Chalapathi", "Yiheng Du", "Aditi Krishnapriyan"]
  },
  {
    "id": "2402.13219",
    "title": "Analyzing Operator States and the Impact of AI-Enhanced Decision Support\n  in Control Rooms: A Human-in-the-Loop Specialized Reinforcement Learning\n  Framework for Intervention Strategies",
    "abstract": "  In complex industrial and chemical process control rooms, effective\ndecision-making is crucial for safety and efficiency. The experiments in this\npaper evaluate the impact and applications of an AI-based decision support\nsystem integrated into an improved human-machine interface, using dynamic\ninfluence diagrams, a hidden Markov model, and deep reinforcement learning. The\nenhanced support system aims to reduce operator workload, improve situational\nawareness, and provide different intervention strategies to the operator\nadapted to the current state of both the system and human performance. Such a\nsystem can be particularly useful in cases of information overload when many\nalarms and inputs are presented all within the same time window, or for junior\noperators during training. A comprehensive cross-data analysis was conducted,\ninvolving 47 participants and a diverse range of data sources such as\nsmartwatch metrics, eye-tracking data, process logs, and responses from\nquestionnaires. The results indicate interesting insights regarding the\neffectiveness of the approach in aiding decision-making, decreasing perceived\nworkload, and increasing situational awareness for the scenarios considered.\nAdditionally, the results provide valuable insights to compare differences\nbetween styles of information gathering when using the system by individual\nparticipants. These findings are particularly relevant when predicting the\noverall performance of the individual participant and their capacity to\nsuccessfully handle a plant upset and the alarms connected to it using process\nand human-machine interaction logs in real-time. These predictions enable the\ndevelopment of more effective intervention strategies.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13219v1",
    "authors": [
      "Ammar N. Abbas",
      "Chidera W. Amazu",
      "Joseph Mietkiewicz",
      "Houda Briwa",
      "Andres Alonzo Perez",
      "Gabriele Baldissone",
      "Micaela Demichela",
      "Georgios G. Chasparis",
      "John D. Kelleher",
      "Maria Chiara Leva"
    ]
  },
  {
    "id": "2402.13224",
    "title": "Controlling Large Electric Vehicle Charging Stations via User Behavior\n  Modeling and Stochastic Programming",
    "abstract": "  This paper introduces an Electric Vehicle Charging Station (EVCS) model that\nincorporates real-world constraints, such as slot power limitations, contract\nthreshold overruns penalties, or early disconnections of electric vehicles\n(EVs). We propose a formulation of the problem of EVCS control under\nuncertainty, and implement two Multi-Stage Stochastic Programming approaches\nthat leverage user-provided information, namely, Model Predictive Control and\nTwo-Stage Stochastic Programming. The model addresses uncertainties in charging\nsession start and end times, as well as in energy demand. A user's behavior\nmodel based on a sojourn-time-dependent stochastic process enhances cost\nreduction while maintaining customer satisfaction. The benefits of the two\nproposed methods are showcased against two baselines over a 22-day simulation\nusing a real-world dataset. The two-stage approach proves robust against early\ndisconnections, considering a more significant number of uncertainty scenarios\nfor optimization. The algorithm prioritizing user satisfaction over electricity\ncost achieves a 20% and 36% improvement in two user satisfaction metrics\ncompared to an industry-standard baseline. Additionally, the algorithm striking\nthe best balance between cost and user satisfaction exhibits a mere 3% relative\ncost increase compared to the theoretically optimal baseline - for which the\nnonanticipativity constraint is relaxed - while attaining 94% and 84% of the\nuser satisfaction performance in the two used satisfaction metrics.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.13224v2",
    "authors": ["Alban Puech", "Tristan Rigaut", "William Templier", "Maud Tournoud"]
  },
  {
    "id": "2402.17775",
    "title": "Wavelet Scattering Transform for Bioacustics: Application to Watkins\n  Marine Mammal Sound Database",
    "abstract": "  Marine mammal communication is a complex field, hindered by the diversity of\nvocalizations and environmental factors. The Watkins Marine Mammal Sound\nDatabase (WMMD) is an extensive labeled dataset used in machine learning\napplications. However, the methods for data preparation, preprocessing, and\nclassification found in the literature are quite disparate. This study first\nfocuses on a brief review of the state-of-the-art benchmarks on the dataset,\nwith an emphasis on clarifying data preparation and preprocessing methods.\nSubsequently, we propose the application of the Wavelet Scattering Transform\n(WST) in place of standard methods based on the Short-Time Fourier Transform\n(STFT). The study also tackles a classification task using an ad-hoc deep\narchitecture with residual layers. We outperform the existing classification\narchitecture by $6\\%$ in accuracy using WST and $8\\%$ using Mel spectrogram\npreprocessing, effectively reducing by half the number of misclassified\nsamples, and reaching a top accuracy of $96\\%$.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.17775v1",
    "authors": ["Davide Carbone", "Alessandro Licciardi"]
  }
]
