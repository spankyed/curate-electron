[
  {
    "id": "2402.14460",
    "title": "Reframing the Expected Free Energy: Four Formulations and a Unification",
    "abstract": "  Active inference is a leading theory of perception, learning and decision\nmaking, which can be applied to neuroscience, robotics, psychology, and machine\nlearning. Active inference is based on the expected free energy, which is\nmostly justified by the intuitive plausibility of its formulations, e.g., the\nrisk plus ambiguity and information gain / pragmatic value formulations. This\npaper seek to formalize the problem of deriving these formulations from a\nsingle root expected free energy definition, i.e., the unification problem.\nThen, we study two settings, each one having its own root expected free energy\ndefinition. In the first setting, no justification for the expected free energy\nhas been proposed to date, but all the formulations can be recovered from it.\nHowever, in this setting, the agent cannot have arbitrary prior preferences\nover observations. Indeed, only a limited class of prior preferences over\nobservations is compatible with the likelihood mapping of the generative model.\nIn the second setting, a justification of the root expected free energy\ndefinition is known, but this setting only accounts for two formulations, i.e.,\nthe risk over states plus ambiguity and entropy plus expected energy\nformulations.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14460v1",
    "authors": ["Théophile Champion", "Howard Bowman", "Dimitrije Marković", "Marek Grześ"]
  },
  {
    "id": "2402.14757",
    "title": "SHM-Traffic: DRL and Transfer learning based UAV Control for Structural\n  Health Monitoring of Bridges with Traffic",
    "abstract": "  This work focuses on using advanced techniques for structural health\nmonitoring (SHM) for bridges with Traffic. We propose an approach using deep\nreinforcement learning (DRL)-based control for Unmanned Aerial Vehicle (UAV).\nOur approach conducts a concrete bridge deck survey while traffic is ongoing\nand detects cracks. The UAV performs the crack detection, and the location of\ncracks is initially unknown. We use two edge detection techniques. First, we\nuse canny edge detection for crack detection. We also use a Convolutional\nNeural Network (CNN) for crack detection and compare it with canny edge\ndetection. Transfer learning is applied using CNN with pre-trained weights\nobtained from a crack image dataset. This enables the model to adapt and\nimprove its performance in identifying and localizing cracks. Proximal Policy\nOptimization (PPO) is applied for UAV control and bridge surveys. The\nexperimentation across various scenarios is performed to evaluate the\nperformance of the proposed methodology. Key metrics such as task completion\ntime and reward convergence are observed to gauge the effectiveness of the\napproach. We observe that the Canny edge detector offers up to 40\\% lower task\ncompletion time, while the CNN excels in up to 12\\% better damage detection and\n1.8 times better rewards.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14757v1",
    "authors": ["Divija Swetha Gadiraju", "Saeed Eftekhar Azam", "Deepak Khazanchi"]
  },
  {
    "id": "2402.14182",
    "title": "Do Machines and Humans Focus on Similar Code? Exploring Explainability\n  of Large Language Models in Code Summarization",
    "abstract": "  Recent language models have demonstrated proficiency in summarizing source\ncode. However, as in many other domains of machine learning, language models of\ncode lack sufficient explainability. Informally, we lack a formulaic or\nintuitive understanding of what and how models learn from code. Explainability\nof language models can be partially provided if, as the models learn to produce\nhigher-quality code summaries, they also align in deeming the same code parts\nimportant as those identified by human programmers. In this paper, we report\nnegative results from our investigation of explainability of language models in\ncode summarization through the lens of human comprehension. We measure human\nfocus on code using eye-tracking metrics such as fixation counts and duration\nin code summarization tasks. To approximate language model focus, we employ a\nstate-of-the-art model-agnostic, black-box, perturbation-based approach, SHAP\n(SHapley Additive exPlanations), to identify which code tokens influence that\ngeneration of summaries. Using these settings, we find no statistically\nsignificant relationship between language models' focus and human programmers'\nattention. Furthermore, alignment between model and human foci in this setting\ndoes not seem to dictate the quality of the LLM-generated summaries. Our study\nhighlights an inability to align human focus with SHAP-based model focus\nmeasures. This result calls for future investigation of multiple open questions\nfor explainable language models for code summarization and software engineering\ntasks in general, including the training mechanisms of language models for\ncode, whether there is an alignment between human and model attention on code,\nwhether human attention can improve the development of language models, and\nwhat other model focus measures are appropriate for improving explainability.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14182v1",
    "authors": [
      "Jiliang Li",
      "Yifan Zhang",
      "Zachary Karas",
      "Collin McMillan",
      "Kevin Leach",
      "Yu Huang"
    ]
  },
  {
    "id": "2402.14207",
    "title": "Assisting in Writing Wikipedia-like Articles From Scratch with Large\n  Language Models",
    "abstract": "  We study how to apply large language models to write grounded and organized\nlong-form articles from scratch, with comparable breadth and depth to Wikipedia\npages. This underexplored problem poses new challenges at the pre-writing\nstage, including how to research the topic and prepare an outline prior to\nwriting. We propose STORM, a writing system for the Synthesis of Topic Outlines\nthrough Retrieval and Multi-perspective Question Asking. STORM models the\npre-writing stage by (1) discovering diverse perspectives in researching the\ngiven topic, (2) simulating conversations where writers carrying different\nperspectives pose questions to a topic expert grounded on trusted Internet\nsources, (3) curating the collected information to create an outline.\n  For evaluation, we curate FreshWiki, a dataset of recent high-quality\nWikipedia articles, and formulate outline assessments to evaluate the\npre-writing stage. We further gather feedback from experienced Wikipedia\neditors. Compared to articles generated by an outline-driven\nretrieval-augmented baseline, more of STORM's articles are deemed to be\norganized (by a 25% absolute increase) and broad in coverage (by 10%). The\nexpert feedback also helps identify new challenges for generating grounded long\narticles, such as source bias transfer and over-association of unrelated facts.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14207v1",
    "authors": [
      "Yijia Shao",
      "Yucheng Jiang",
      "Theodore A. Kanell",
      "Peter Xu",
      "Omar Khattab",
      "Monica S. Lam"
    ]
  },
  {
    "id": "2402.14212",
    "title": "Moonwalk: Inverse-Forward Differentiation",
    "abstract": "  Backpropagation, while effective for gradient computation, falls short in\naddressing memory consumption, limiting scalability. This work explores\nforward-mode gradient computation as an alternative in invertible networks,\nshowing its potential to reduce the memory footprint without substantial\ndrawbacks. We introduce a novel technique based on a vector-inverse-Jacobian\nproduct that accelerates the computation of forward gradients while retaining\nthe advantages of memory reduction and preserving the fidelity of true\ngradients. Our method, Moonwalk, has a time complexity linear in the depth of\nthe network, unlike the quadratic time complexity of na\\\"ive forward, and\nempirically reduces computation time by several orders of magnitude without\nallocating more memory. We further accelerate Moonwalk by combining it with\nreverse-mode differentiation to achieve time complexity comparable with\nbackpropagation while maintaining a much smaller memory footprint. Finally, we\nshowcase the robustness of our method across several architecture choices.\nMoonwalk is the first forward-based method to compute true gradients in\ninvertible networks in computation time comparable to backpropagation and using\nsignificantly less memory.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14212v1",
    "authors": ["Dmitrii Krylov", "Armin Karamzade", "Roy Fox"]
  },
  {
    "id": "2402.14228",
    "title": "COPR: Continual Human Preference Learning via Optimal Policy\n  Regularization",
    "abstract": "  Reinforcement Learning from Human Feedback (RLHF) is commonly utilized to\nimprove the alignment of Large Language Models (LLMs) with human preferences.\nGiven the evolving nature of human preferences, continual alignment becomes\nmore crucial and practical in comparison to traditional static alignment.\nNevertheless, making RLHF compatible with Continual Learning (CL) is\nchallenging due to its complex process. Meanwhile, directly learning new human\npreferences may lead to Catastrophic Forgetting (CF) of historical preferences,\nresulting in helpless or harmful outputs. To overcome these challenges, we\npropose the Continual Optimal Policy Regularization (COPR) method, which draws\ninspiration from the optimal policy theory. COPR utilizes a sampling\ndistribution as a demonstration and regularization constraints for CL. It\nadopts the Lagrangian Duality (LD) method to dynamically regularize the current\npolicy based on the historically optimal policy, which prevents CF and avoids\nover-emphasizing unbalanced objectives. We also provide formal proof for the\nlearnability of COPR. The experimental results show that COPR outperforms\nstrong CL baselines on our proposed benchmark, in terms of reward-based, GPT-4\nevaluations and human assessment. Furthermore, we validate the robustness of\nCOPR under various CL settings, including different backbones, replay memory\nsizes, and learning orders.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14228v2",
    "authors": [
      "Han Zhang",
      "Lin Gui",
      "Yu Lei",
      "Yuanzhao Zhai",
      "Yehong Zhang",
      "Yulan He",
      "Hui Wang",
      "Yue Yu",
      "Kam-Fai Wong",
      "Bin Liang",
      "Ruifeng Xu"
    ]
  },
  {
    "id": "2402.14230",
    "title": "MerRec: A Large-scale Multipurpose Mercari Dataset for\n  Consumer-to-Consumer Recommendation Systems",
    "abstract": "  In the evolving e-commerce field, recommendation systems crucially shape user\nexperience and engagement. The rise of Consumer-to-Consumer (C2C)\nrecommendation systems, noted for their flexibility and ease of access for\ncustomer vendors, marks a significant trend. However, the academic focus\nremains largely on Business-to-Consumer (B2C) models, leaving a gap filled by\nthe limited C2C recommendation datasets that lack in item attributes, user\ndiversity, and scale. The intricacy of C2C recommendation systems is further\naccentuated by the dual roles users assume as both sellers and buyers,\nintroducing a spectrum of less uniform and varied inputs. Addressing this, we\nintroduce MerRec, the first large-scale dataset specifically for C2C\nrecommendations, sourced from the Mercari e-commerce platform, covering\nmillions of users and products over 6 months in 2023. MerRec not only includes\nstandard features such as user_id, item_id, and session_id, but also unique\nelements like timestamped action types, product taxonomy, and textual product\nattributes, offering a comprehensive dataset for research. This dataset,\nextensively evaluated across six recommendation tasks, establishes a new\nbenchmark for the development of advanced recommendation algorithms in\nreal-world scenarios, bridging the gap between academia and industry and\npropelling the study of C2C recommendations.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14230v1",
    "authors": [
      "Lichi Li",
      "Zainul Abi Din",
      "Zhen Tan",
      "Sam London",
      "Tianlong Chen",
      "Ajay Daptardar"
    ]
  },
  {
    "id": "2402.14241",
    "title": "A Self-supervised Pressure Map human keypoint Detection Approch:\n  Optimizing Generalization and Computational Efficiency Across Datasets",
    "abstract": "  In environments where RGB images are inadequate, pressure maps is a viable\nalternative, garnering scholarly attention. This study introduces a novel\nself-supervised pressure map keypoint detection (SPMKD) method, addressing the\ncurrent gap in specialized designs for human keypoint extraction from pressure\nmaps. Central to our contribution is the Encoder-Fuser-Decoder (EFD) model,\nwhich is a robust framework that integrates a lightweight encoder for precise\nhuman keypoint detection, a fuser for efficient gradient propagation, and a\ndecoder that transforms human keypoints into reconstructed pressure maps. This\nstructure is further enhanced by the Classification-to-Regression Weight\nTransfer (CRWT) method, which fine-tunes accuracy through initial\nclassification task training. This innovation not only enhances human keypoint\ngeneralization without manual annotations but also showcases remarkable\nefficiency and generalization, evidenced by a reduction to only $5.96\\%$ in\nFLOPs and $1.11\\%$ in parameter count compared to the baseline methods.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14241v1",
    "authors": ["Chengzhang Yu", "Xianjun Yang", "Wenxia Bao", "Shaonan Wang", "Zhiming Yao"]
  },
  {
    "id": "2402.14261",
    "title": "Copilot Evaluation Harness: Evaluating LLM-Guided Software Programming",
    "abstract": "  The integration of Large Language Models (LLMs) into Development Environments\n(IDEs) has become a focal point in modern software development. LLMs such as\nOpenAI GPT-3.5/4 and Code Llama offer the potential to significantly augment\ndeveloper productivity by serving as intelligent, chat-driven programming\nassistants. However, utilizing LLMs out of the box is unlikely to be optimal\nfor any given scenario. Rather, each system requires the LLM to be honed to its\nset of heuristics to ensure the best performance. In this paper, we introduce\nthe Copilot evaluation harness: a set of data and tools for evaluating\nLLM-guided IDE interactions, covering various programming scenarios and\nlanguages. We propose our metrics as a more robust and information-dense\nevaluation than previous state of the art evaluation systems. We design and\ncompute both static and execution based success metrics for scenarios\nencompassing a wide range of developer tasks, including code generation from\nnatural language (generate), documentation generation from code (doc), test\ncase generation (test), bug-fixing (fix), and workspace understanding and query\nresolution (workspace). These success metrics are designed to evaluate the\nperformance of LLMs within a given IDE and its respective parameter space. Our\nlearnings from evaluating three common LLMs using these metrics can inform the\ndevelopment and validation of future scenarios in LLM guided IDEs.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14261v1",
    "authors": [
      "Anisha Agarwal",
      "Aaron Chan",
      "Shubham Chandel",
      "Jinu Jang",
      "Shaun Miller",
      "Roshanak Zilouchian Moghaddam",
      "Yevhen Mohylevskyy",
      "Neel Sundaresan",
      "Michele Tufano"
    ]
  },
  {
    "id": "2402.14277",
    "title": "GATE X-E : A Challenge Set for Gender-Fair Translations from\n  Weakly-Gendered Languages",
    "abstract": "  Neural Machine Translation (NMT) continues to improve in quality and\nadoption, yet the inadvertent perpetuation of gender bias remains a significant\nconcern. Despite numerous studies on gender bias in translations into English\nfrom weakly gendered-languages, there are no benchmarks for evaluating this\nphenomenon or for assessing mitigation strategies. To address this gap, we\nintroduce GATE X-E, an extension to the GATE (Rarrick et al., 2023) corpus,\nthat consists of human translations from Turkish, Hungarian, Finnish, and\nPersian into English. Each translation is accompanied by feminine, masculine,\nand neutral variants. The dataset, which contains between 1250 and 1850\ninstances for each of the four language pairs, features natural sentences with\na wide range of sentence lengths and domains, challenging translation rewriters\non various linguistic phenomena. Additionally, we present a translation gender\nrewriting solution built with GPT-4 and use GATE X-E to evaluate it. We open\nsource our contributions to encourage further research on gender debiasing.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14277v1",
    "authors": ["Spencer Rarrick", "Ranjita Naik", "Sundar Poudel", "Vishal Chowdhary"]
  },
  {
    "id": "2402.14279",
    "title": "Mitigating the Linguistic Gap with Phonemic Representations for Robust\n  Multilingual Language Understanding",
    "abstract": "  Approaches to improving multilingual language understanding often require\nmultiple languages during the training phase, rely on complicated training\ntechniques, and -- importantly -- struggle with significant performance gaps\nbetween high-resource and low-resource languages. We hypothesize that the\nperformance gaps between languages are affected by linguistic gaps between\nthose languages and provide a novel solution for robust multilingual language\nmodeling by employing phonemic representations (specifically, using phonemes as\ninput tokens to LMs rather than subwords). We present quantitative evidence\nfrom three cross-lingual tasks that demonstrate the effectiveness of phonemic\nrepresentation, which is further justified by a theoretical analysis of the\ncross-lingual performance gap.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14279v1",
    "authors": [
      "Haeji Jung",
      "Changdae Oh",
      "Jooeon Kang",
      "Jimin Sohn",
      "Kyungwoo Song",
      "Jinkyu Kim",
      "David R. Mortensen"
    ]
  },
  {
    "id": "2402.14299",
    "title": "We Choose to Go to Space: Agent-driven Human and Multi-Robot\n  Collaboration in Microgravity",
    "abstract": "  We present SpaceAgents-1, a system for learning human and multi-robot\ncollaboration (HMRC) strategies under microgravity conditions. Future space\nexploration requires humans to work together with robots. However, acquiring\nproficient robot skills and adept collaboration under microgravity conditions\nposes significant challenges within ground laboratories. To address this issue,\nwe develop a microgravity simulation environment and present three typical\nconfigurations of intra-cabin robots. We propose a hierarchical heterogeneous\nmulti-agent collaboration architecture: guided by foundation models, a\nDecision-Making Agent serves as a task planner for human-robot collaboration,\nwhile individual Skill-Expert Agents manage the embodied control of robots.\nThis mechanism empowers the SpaceAgents-1 system to execute a range of\nintricate long-horizon HMRC tasks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14299v1",
    "authors": [
      "Miao Xin",
      "Zhongrui You",
      "Zihan Zhang",
      "Taoran Jiang",
      "Tingjia Xu",
      "Haotian Liang",
      "Guojing Ge",
      "Yuchen Ji",
      "Shentong Mo",
      "Jian Cheng"
    ]
  },
  {
    "id": "2402.14320",
    "title": "Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve\n  Knowledge Base Question Answering",
    "abstract": "  Recent progress with LLM-based agents has shown promising results across\nvarious tasks. However, their use in answering questions from knowledge bases\nremains largely unexplored. Implementing a KBQA system using traditional\nmethods is challenging due to the shortage of task-specific training data and\nthe complexity of creating task-focused model structures. In this paper, we\npresent Triad, a unified framework that utilizes an LLM-based agent with three\nroles for KBQA tasks. The agent is assigned three roles to tackle different\nKBQA subtasks: agent as a generalist for mastering various subtasks, as a\ndecision maker for the selection of candidates, and as an advisor for answering\nquestions with knowledge. Our KBQA framework is executed in four phases,\ninvolving the collaboration of the agent's multiple roles. We evaluated the\nperformance of our framework using three benchmark datasets, and the results\nshow that our framework outperforms state-of-the-art systems on the LC-QuAD and\nYAGO-QA benchmarks, yielding F1 scores of 11.8% and 20.7%, respectively.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14320v1",
    "authors": [
      "Chang Zong",
      "Yuchen Yan",
      "Weiming Lu",
      "Eliot Huang",
      "Jian Shao",
      "Yueting Zhuang"
    ]
  },
  {
    "id": "2402.14323",
    "title": "REPOFUSE: Repository-Level Code Completion with Fused Dual Context",
    "abstract": "  The success of language models in code assistance has spurred the proposal of\nrepository-level code completion as a means to enhance prediction accuracy,\nutilizing the context from the entire codebase. However, this amplified context\ncan inadvertently increase inference latency, potentially undermining the\ndeveloper experience and deterring tool adoption - a challenge we termed the\nContext-Latency Conundrum. This paper introduces REPOFUSE, a pioneering\nsolution designed to enhance repository-level code completion without the\nlatency trade-off. REPOFUSE uniquely fuses two types of context: the analogy\ncontext, rooted in code analogies, and the rationale context, which encompasses\nin-depth semantic relationships. We propose a novel rank truncated generation\n(RTG) technique that efficiently condenses these contexts into prompts with\nrestricted size. This enables REPOFUSE to deliver precise code completions\nwhile maintaining inference efficiency. Through testing with the CrossCodeEval\nsuite, REPOFUSE has demonstrated a significant leap over existing models,\nachieving a 40.90% to 59.75% increase in exact match (EM) accuracy for code\ncompletions and a 26.8% enhancement in inference speed. Beyond experimental\nvalidation, REPOFUSE has been integrated into the workflow of a large\nenterprise, where it actively supports various coding tasks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14323v2",
    "authors": [
      "Ming Liang",
      "Xiaoheng Xie",
      "Gehao Zhang",
      "Xunjin Zheng",
      "Peng Di",
      "wei jiang",
      "Hongwei Chen",
      "Chengpeng Wang",
      "Gang Fan"
    ]
  },
  {
    "id": "2402.14346",
    "title": "Dependable Distributed Training of Compressed Machine Learning Models",
    "abstract": "  The existing work on the distributed training of machine learning (ML) models\nhas consistently overlooked the distribution of the achieved learning quality,\nfocusing instead on its average value. This leads to a poor dependability}of\nthe resulting ML models, whose performance may be much worse than expected. We\nfill this gap by proposing DepL, a framework for dependable learning\norchestration, able to make high-quality, efficient decisions on (i) the data\nto leverage for learning, (ii) the models to use and when to switch among them,\nand (iii) the clusters of nodes, and the resources thereof, to exploit. For\nconcreteness, we consider as possible available models a full DNN and its\ncompressed versions. Unlike previous studies, DepL guarantees that a target\nlearning quality is reached with a target probability, while keeping the\ntraining cost at a minimum. We prove that DepL has constant competitive ratio\nand polynomial complexity, and show that it outperforms the state-of-the-art by\nover 27% and closely matches the optimum.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14346v1",
    "authors": [
      "Francesco Malandrino",
      "Giuseppe Di Giacomo",
      "Marco Levorato",
      "Carla Fabiana Chiasserini"
    ]
  },
  {
    "id": "2402.14398",
    "title": "Gradual Residuals Alignment: A Dual-Stream Framework for GAN Inversion\n  and Image Attribute Editing",
    "abstract": "  GAN-based image attribute editing firstly leverages GAN Inversion to project\nreal images into the latent space of GAN and then manipulates corresponding\nlatent codes. Recent inversion methods mainly utilize additional high-bit\nfeatures to improve image details preservation, as low-bit codes cannot\nfaithfully reconstruct source images, leading to the loss of details. However,\nduring editing, existing works fail to accurately complement the lost details\nand suffer from poor editability. The main reason is they inject all the lost\ndetails indiscriminately at one time, which inherently induces the position and\nquantity of details to overfit source images, resulting in inconsistent content\nand artifacts in edited images. This work argues that details should be\ngradually injected into both the reconstruction and editing process in a\nmulti-stage coarse-to-fine manner for better detail preservation and high\neditability. Therefore, a novel dual-stream framework is proposed to accurately\ncomplement details at each stage. The Reconstruction Stream is employed to\nembed coarse-to-fine lost details into residual features and then adaptively\nadd them to the GAN generator. In the Editing Stream, residual features are\naccurately aligned by our Selective Attention mechanism and then injected into\nthe editing process in a multi-stage manner. Extensive experiments have shown\nthe superiority of our framework in both reconstruction accuracy and editing\nquality compared with existing methods.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14398v1",
    "authors": ["Hao Li", "Mengqi Huang", "Lei Zhang", "Bo Hu", "Yi Liu", "Zhendong Mao"]
  },
  {
    "id": "2402.14399",
    "title": "Ensure Timeliness and Accuracy: A Novel Sliding Window Data Stream\n  Paradigm for Live Streaming Recommendation",
    "abstract": "  Live streaming recommender system is specifically designed to recommend\nreal-time live streaming of interest to users. Due to the dynamic changes of\nlive content, improving the timeliness of the live streaming recommender system\nis a critical problem. Intuitively, the timeliness of the data determines the\nupper bound of the timeliness that models can learn. However, none of the\nprevious works addresses the timeliness problem of the live streaming\nrecommender system from the perspective of data stream design. Employing the\nconventional fixed window data stream paradigm introduces a trade-off dilemma\nbetween labeling accuracy and timeliness. In this paper, we propose a new data\nstream design paradigm, dubbed Sliver, that addresses the timeliness and\naccuracy problem of labels by reducing the window size and implementing a\nsliding window correspondingly. Meanwhile, we propose a time-sensitive re-reco\nstrategy reducing the latency between request and impression to improve the\ntimeliness of the recommendation service and features by periodically\nrequesting the recommendation service. To demonstrate the effectiveness of our\napproach, we conduct offline experiments on a multi-task live streaming dataset\nwith labeling timestamps collected from the Kuaishou live streaming platform.\nExperimental results demonstrate that Sliver outperforms two fixed-window data\nstreams with varying window sizes across all targets in four typical multi-task\nrecommendation models. Furthermore, we deployed Sliver on the Kuaishou live\nstreaming platform. Results of the online A/B test show a significant\nimprovement in click-through rate (CTR), and new follow number (NFN), further\nvalidating the effectiveness of Sliver.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14399v1",
    "authors": [
      "Fengqi Liang",
      "Baigong Zheng",
      "Liqin Zhao",
      "Guorui Zhou",
      "Qian Wang",
      "Yanan Niu"
    ]
  },
  {
    "id": "2402.14404",
    "title": "On the Tip of the Tongue: Analyzing Conceptual Representation in Large\n  Language Models with Reverse-Dictionary Probe",
    "abstract": "  Probing and enhancing large language models' reasoning capacity remains a\ncrucial open question. Here we re-purpose the reverse dictionary task as a case\nstudy to probe LLMs' capacity for conceptual inference. We use in-context\nlearning to guide the models to generate the term for an object concept implied\nin a linguistic description. Models robustly achieve high accuracy in this\ntask, and their representation space encodes information about object\ncategories and fine-grained features. Further experiments suggest that the\nconceptual inference ability as probed by the reverse-dictionary task predicts\nmodel's general reasoning performance across multiple benchmarks, despite\nsimilar syntactic generalization behaviors across models. Explorative analyses\nsuggest that prompting LLMs with description$\\Rightarrow$word examples may\ninduce generalization beyond surface-level differences in task construals and\nfacilitate models on broader commonsense reasoning problems.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14404v2",
    "authors": ["Ningyu Xu", "Qi Zhang", "Menghan Zhang", "Peng Qian", "Xuanjing Huang"]
  },
  {
    "id": "2402.14418",
    "title": "Uncertainty-Aware Evaluation for Vision-Language Models",
    "abstract": "  Vision-Language Models like GPT-4, LLaVA, and CogVLM have surged in\npopularity recently due to their impressive performance in several\nvision-language tasks. Current evaluation methods, however, overlook an\nessential component: uncertainty, which is crucial for a comprehensive\nassessment of VLMs. Addressing this oversight, we present a benchmark\nincorporating uncertainty quantification into evaluating VLMs.\n  Our analysis spans 20+ VLMs, focusing on the multiple-choice Visual Question\nAnswering (VQA) task. We examine models on 5 datasets that evaluate various\nvision-language capabilities.\n  Using conformal prediction as an uncertainty estimation approach, we\ndemonstrate that the models' uncertainty is not aligned with their accuracy.\nSpecifically, we show that models with the highest accuracy may also have the\nhighest uncertainty, which confirms the importance of measuring it for VLMs.\nOur empirical findings also reveal a correlation between model uncertainty and\nits language model part.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14418v2",
    "authors": ["Vasily Kostumov", "Bulat Nutfullin", "Oleg Pilipenko", "Eugene Ilyushin"]
  },
  {
    "id": "2402.14424",
    "title": "Automating Psychological Hypothesis Generation with AI: Large Language\n  Models Meet Causal Graph",
    "abstract": "  Leveraging the synergy between causal knowledge graphs and a large language\nmodel (LLM), our study introduces a groundbreaking approach for computational\nhypothesis generation in psychology. We analyzed 43,312 psychology articles\nusing a LLM to extract causal relation pairs. This analysis produced a\nspecialized causal graph for psychology. Applying link prediction algorithms,\nwe generated 130 potential psychological hypotheses focusing on `well-being',\nthen compared them against research ideas conceived by doctoral scholars and\nthose produced solely by the LLM. Interestingly, our combined approach of a LLM\nand causal graphs mirrored the expert-level insights in terms of novelty,\nclearly surpassing the LLM-only hypotheses (t(59) = 3.34, p=0.007 and t(59) =\n4.32, p<0.001, respectively). This alignment was further corroborated using\ndeep semantic analysis. Our results show that combining LLM with machine\nlearning techniques such as causal knowledge graphs can revolutionize automated\ndiscovery in psychology, extracting novel insights from the extensive\nliterature. This work stands at the crossroads of psychology and artificial\nintelligence, championing a new enriched paradigm for data-driven hypothesis\ngeneration in psychological research.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14424v1",
    "authors": ["Song Tong", "Kai Mao", "Zhen Huang", "Yukun Zhao", "Kaiping Peng"]
  },
  {
    "id": "2402.14428",
    "title": "KoCoSa: Korean Context-aware Sarcasm Detection Dataset",
    "abstract": "  Sarcasm is a way of verbal irony where someone says the opposite of what they\nmean, often to ridicule a person, situation, or idea. It is often difficult to\ndetect sarcasm in the dialogue since detecting sarcasm should reflect the\ncontext (i.e., dialogue history). In this paper, we introduce a new dataset for\nthe Korean dialogue sarcasm detection task, KoCoSa (Korean Context-aware\nSarcasm Detection Dataset), which consists of 12.8K daily Korean dialogues and\nthe labels for this task on the last response. To build the dataset, we propose\nan efficient sarcasm detection dataset generation pipeline: 1) generating new\nsarcastic dialogues from source dialogues with large language models, 2)\nautomatic and manual filtering of abnormal and toxic dialogues, and 3) human\nannotation for the sarcasm detection task. We also provide a simple but\neffective baseline for the Korean sarcasm detection task trained on our\ndataset. Experimental results on the dataset show that our baseline system\noutperforms strong baselines like large language models, such as GPT-3.5, in\nthe Korean sarcasm detection task. We show that the sarcasm detection task\nrelies deeply on the existence of sufficient context. We will release the\ndataset at https://anonymous.4open.science/r/KoCoSa-2372.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14428v1",
    "authors": ["Yumin Kim", "Heejae Suh", "Mingi Kim", "Dongyeon Won", "Hwanhee Lee"]
  },
  {
    "id": "2402.14433",
    "title": "A Language Model's Guide Through Latent Space",
    "abstract": "  Concept guidance has emerged as a cheap and simple way to control the\nbehavior of language models by probing their hidden representations for concept\nvectors and using them to perturb activations at inference time. While the\nfocus of previous work has largely been on truthfulness, in this paper we\nextend this framework to a richer set of concepts such as appropriateness,\nhumor, creativity and quality, and explore to what degree current detection and\nguidance strategies work in these challenging settings. To facilitate\nevaluation, we develop a novel metric for concept guidance that takes into\naccount both the success of concept elicitation as well as the potential\ndegradation in fluency of the guided model. Our extensive experiments reveal\nthat while some concepts such as truthfulness more easily allow for guidance\nwith current techniques, novel concepts such as appropriateness or humor either\nremain difficult to elicit, need extensive tuning to work, or even experience\nconfusion. Moreover, we find that probes with optimal detection accuracies do\nnot necessarily make for the optimal guides, contradicting previous\nobservations for truthfulness. Our work warrants a deeper investigation into\nthe interplay between detectability, guidability, and the nature of the\nconcept, and we hope that our rich experimental test-bed for guidance research\ninspires stronger follow-up approaches.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14433v1",
    "authors": ["Dimitri von Rütte", "Sotiris Anagnostidis", "Gregor Bachmann", "Thomas Hofmann"]
  },
  {
    "id": "2402.14458",
    "title": "NLAS-multi: A Multilingual Corpus of Automatically Generated Natural\n  Language Argumentation Schemes",
    "abstract": "  Some of the major limitations identified in the areas of argument mining,\nargument generation, and natural language argument analysis are related to the\ncomplexity of annotating argumentatively rich data, the limited size of these\ncorpora, and the constraints that represent the different languages and domains\nin which these data is annotated. To address these limitations, in this paper\nwe present the following contributions: (i) an effective methodology for the\nautomatic generation of natural language arguments in different topics and\nlanguages, (ii) the largest publicly available corpus of natural language\nargumentation schemes, and (iii) a set of solid baselines and fine-tuned models\nfor the automatic identification of argumentation schemes.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14458v1",
    "authors": ["Ramon Ruiz-Dolz", "Joaquin Taverner", "John Lawrence", "Chris Reed"]
  },
  {
    "id": "2402.14473",
    "title": "Personalized Behavior-Aware Transformer for Multi-Behavior Sequential\n  Recommendation",
    "abstract": "  Sequential Recommendation (SR) captures users' dynamic preferences by\nmodeling how users transit among items. However, SR models that utilize only\nsingle type of behavior interaction data encounter performance degradation when\nthe sequences are short. To tackle this problem, we focus on Multi-Behavior\nSequential Recommendation (MBSR) in this paper, which aims to leverage\ntime-evolving heterogeneous behavioral dependencies for better exploring users'\npotential intents on the target behavior. Solving MBSR is challenging. On the\none hand, users exhibit diverse multi-behavior patterns due to personal\ncharacteristics. On the other hand, there exists comprehensive co-influence\nbetween behavior correlations and item collaborations, the intensity of which\nis deeply affected by temporal factors. To tackle these challenges, we propose\na Personalized Behavior-Aware Transformer framework (PBAT) for MBSR problem,\nwhich models personalized patterns and multifaceted sequential collaborations\nin a novel way to boost recommendation performance. First, PBAT develops a\npersonalized behavior pattern generator in the representation layer, which\nextracts dynamic and discriminative behavior patterns for sequential learning.\nSecond, PBAT reforms the self-attention layer with a behavior-aware\ncollaboration extractor, which introduces a fused behavior-aware attention\nmechanism for incorporating both behavioral and temporal impacts into\ncollaborative transitions. We conduct experiments on three benchmark datasets\nand the results demonstrate the effectiveness and interpretability of our\nframework. Our implementation code is released at\nhttps://github.com/TiliaceaeSU/PBAT.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14473v1",
    "authors": ["Jiajie Su", "Chaochao Chen", "Zibin Lin", "Xi Li", "Weiming Liu", "Xiaolin Zheng"]
  },
  {
    "id": "2402.14492",
    "title": "INSTRAUG: Automatic Instruction Augmentation for Multimodal Instruction\n  Fine-tuning",
    "abstract": "  Fine-tuning large language models (LLMs) on multi-task instruction-following\ndata has been proven to be a powerful learning paradigm for improving their\nzero-shot capabilities on new tasks. Recent works about high-quality\ninstruction-following data generation and selection require amounts of human\nlabor to conceive model-understandable instructions for the given tasks and\ncarefully filter the LLM-generated data. In this work, we introduce an\nautomatic instruction augmentation method named INSTRAUG in multimodal tasks.\nIt starts from a handful of basic and straightforward meta instructions but can\nexpand an instruction-following dataset by 30 times. Results on two popular\nmultimodal instructionfollowing benchmarks MULTIINSTRUCT and InstructBLIP show\nthat INSTRAUG can significantly improve the alignment of multimodal large\nlanguage models (MLLMs) across 12 multimodal tasks, which is even equivalent to\nthe benefits of scaling up training data multiple times.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14492v1",
    "authors": ["Wei Han", "Hui Chen", "Soujanya Poria"]
  },
  {
    "id": "2402.14498",
    "title": "A Collision-Aware Cable Grasping Method in Cluttered Environment",
    "abstract": "  We introduce a Cable Grasping-Convolutional Neural Network designed to\nfacilitate robust cable grasping in cluttered environments. Utilizing physics\nsimulations, we generate an extensive dataset that mimics the intricacies of\ncable grasping, factoring in potential collisions between cables and robotic\ngrippers. We employ the Approximate Convex Decomposition technique to dissect\nthe non-convex cable model, with grasp quality autonomously labeled based on\nsimulated grasping attempts. The CG-CNN is refined using this simulated dataset\nand enhanced through domain randomization techniques. Subsequently, the trained\nmodel predicts grasp quality, guiding the optimal grasp pose to the robot\ncontroller for execution. Grasping efficacy is assessed across both synthetic\nand real-world settings. Given our model implicit collision sensitivity, we\nachieved commendable success rates of 92.3% for known cables and 88.4% for\nunknown cables, surpassing contemporary state-of-the-art approaches.\nSupplementary materials can be found at\nhttps://leizhang-public.github.io/cg-cnn/ .\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14498v1",
    "authors": ["Lei Zhang", "Kaixin Bai", "Qiang Li", "Zhaopeng Chen", "Jianwei Zhang"]
  },
  {
    "id": "2402.14505",
    "title": "Towards Seamless Adaptation of Pre-trained Models for Visual Place\n  Recognition",
    "abstract": "  Recent studies show that vision models pre-trained in generic visual learning\ntasks with large-scale data can provide useful feature representations for a\nwide range of visual perception problems. However, few attempts have been made\nto exploit pre-trained foundation models in visual place recognition (VPR). Due\nto the inherent difference in training objectives and data between the tasks of\nmodel pre-training and VPR, how to bridge the gap and fully unleash the\ncapability of pre-trained models for VPR is still a key issue to address. To\nthis end, we propose a novel method to realize seamless adaptation of\npre-trained models for VPR. Specifically, to obtain both global and local\nfeatures that focus on salient landmarks for discriminating places, we design a\nhybrid adaptation method to achieve both global and local adaptation\nefficiently, in which only lightweight adapters are tuned without adjusting the\npre-trained model. Besides, to guide effective adaptation, we propose a mutual\nnearest neighbor local feature loss, which ensures proper dense local features\nare produced for local matching and avoids time-consuming spatial verification\nin re-ranking. Experimental results show that our method outperforms the\nstate-of-the-art methods with less training data and training time, and uses\nabout only 3% retrieval runtime of the two-stage VPR methods with RANSAC-based\nspatial verification. It ranks 1st on the MSLS challenge leaderboard (at the\ntime of submission). The code is released at\nhttps://github.com/Lu-Feng/SelaVPR.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14505v1",
    "authors": [
      "Feng Lu",
      "Lijun Zhang",
      "Xiangyuan Lan",
      "Shuting Dong",
      "Yaowei Wang",
      "Chun Yuan"
    ]
  },
  {
    "id": "2402.14526",
    "title": "Balanced Data Sampling for Language Model Training with Clustering",
    "abstract": "  Data plays a fundamental role in the training of Large Language Models\n(LLMs). While attention has been paid to the collection and composition of\ndatasets, determining the data sampling strategy in training remains an open\nquestion. Most LLMs are trained with a simple strategy, random sampling.\nHowever, this sampling strategy ignores the unbalanced nature of training data\ndistribution, which can be sub-optimal. In this paper, we propose ClusterClip\nSampling to balance the text distribution of training data for better model\ntraining. Specifically, ClusterClip Sampling utilizes data clustering to\nreflect the data distribution of the training set and balances the common\nsamples and rare samples during training based on the cluster results. A\nrepetition clip operation is introduced to mitigate the overfitting issue led\nby samples from certain clusters. Extensive experiments validate the\neffectiveness of ClusterClip Sampling, which outperforms random sampling and\nother cluster-based sampling variants under various training datasets and large\nlanguage models.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14526v1",
    "authors": ["Yunfan Shao", "Linyang Li", "Zhaoye Fei", "Hang Yan", "Dahua Lin", "Xipeng Qiu"]
  },
  {
    "id": "2402.14528",
    "title": "ACE : Off-Policy Actor-Critic with Causality-Aware Entropy\n  Regularization",
    "abstract": "  The varying significance of distinct primitive behaviors during the policy\nlearning process has been overlooked by prior model-free RL algorithms.\nLeveraging this insight, we explore the causal relationship between different\naction dimensions and rewards to evaluate the significance of various primitive\nbehaviors during training. We introduce a causality-aware entropy term that\neffectively identifies and prioritizes actions with high potential impacts for\nefficient exploration. Furthermore, to prevent excessive focus on specific\nprimitive behaviors, we analyze the gradient dormancy phenomenon and introduce\na dormancy-guided reset mechanism to further enhance the efficacy of our\nmethod. Our proposed algorithm, ACE: Off-policy Actor-critic with\nCausality-aware Entropy regularization, demonstrates a substantial performance\nadvantage across 29 diverse continuous control tasks spanning 7 domains\ncompared to model-free RL baselines, which underscores the effectiveness,\nversatility, and efficient sample efficiency of our approach. Benchmark results\nand videos are available at https://ace-rl.github.io/.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14528v1",
    "authors": [
      "Tianying Ji",
      "Yongyuan Liang",
      "Yan Zeng",
      "Yu Luo",
      "Guowei Xu",
      "Jiawei Guo",
      "Ruijie Zheng",
      "Furong Huang",
      "Fuchun Sun",
      "Huazhe Xu"
    ]
  },
  {
    "id": "2402.14569",
    "title": "Transformable Gaussian Reward Function for Socially-Aware Navigation\n  with Deep Reinforcement Learning",
    "abstract": "  Robot navigation has transitioned from prioritizing obstacle avoidance to\nadopting socially aware navigation strategies that accommodate human presence.\nAs a result, the recognition of socially aware navigation within dynamic\nhuman-centric environments has gained prominence in the field of robotics.\nAlthough reinforcement learning technique has fostered the advancement of\nsocially aware navigation, defining appropriate reward functions, especially in\ncongested environments, has posed a significant challenge. These rewards,\ncrucial in guiding robot actions, demand intricate human-crafted design due to\ntheir complex nature and inability to be automatically set. The multitude of\nmanually designed rewards poses issues with hyperparameter redundancy,\nimbalance, and inadequate representation of unique object characteristics. To\naddress these challenges, we introduce a transformable gaussian reward function\n(TGRF). The TGRF significantly reduces the burden of hyperparameter tuning,\ndisplays adaptability across various reward functions, and demonstrates\naccelerated learning rates, particularly excelling in crowded environments\nutilizing deep reinforcement learning (DRL). We introduce and validate TGRF\nthrough sections highlighting its conceptual background, characteristics,\nexperiments, and real-world application, paving the way for a more effective\nand adaptable approach in robotics.The complete source code is available on\nhttps://github.com/JinnnK/TGRF\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14569v1",
    "authors": [
      "Jinyeob Kim",
      "Sumin Kang",
      "Sungwoo Yang",
      "Beomjoon Kim",
      "Jargalbaatar Yura",
      "Donghan Kim"
    ]
  },
  {
    "id": "2402.14648",
    "title": "Rethinking Invariance Regularization in Adversarial Training to Improve\n  Robustness-Accuracy Trade-off",
    "abstract": "  Although adversarial training has been the state-of-the-art approach to\ndefend against adversarial examples (AEs), they suffer from a\nrobustness-accuracy trade-off. In this work, we revisit representation-based\ninvariance regularization to learn discriminative yet adversarially invariant\nrepresentations, aiming to mitigate this trade-off. We empirically identify two\nkey issues hindering invariance regularization: (1) a \"gradient conflict\"\nbetween invariance loss and classification objectives, indicating the existence\nof \"collapsing solutions,\" and (2) the mixture distribution problem arising\nfrom diverged distributions of clean and adversarial inputs. To address these\nissues, we propose Asymmetrically Representation-regularized Adversarial\nTraining (AR-AT), which incorporates a stop-gradient operation and a pre-dictor\nin the invariance loss to avoid \"collapsing solutions,\" inspired by a recent\nnon-contrastive self-supervised learning approach, and a split-BatchNorm (BN)\nstructure to resolve the mixture distribution problem. Our method significantly\nimproves the robustness-accuracy trade-off by learning adversarially invariant\nrepresentations without sacrificing discriminative power. Furthermore, we\ndiscuss the relevance of our findings to knowledge-distillation-based defense\nmethods, contributing to a deeper understanding of their relative successes.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14648v1",
    "authors": ["Futa Waseda", "Isao Echizen"]
  },
  {
    "id": "2402.14660",
    "title": "ConceptMath: A Bilingual Concept-wise Benchmark for Measuring\n  Mathematical Reasoning of Large Language Models",
    "abstract": "  This paper introduces ConceptMath, a bilingual (English and Chinese),\nfine-grained benchmark that evaluates concept-wise mathematical reasoning of\nLarge Language Models (LLMs). Unlike traditional benchmarks that evaluate\ngeneral mathematical reasoning with an average accuracy, ConceptMath\nsystematically organizes math problems under a hierarchy of math concepts, so\nthat mathematical reasoning can be evaluated at different granularity with\nconcept-wise accuracies. Based on our ConcepthMath, we evaluate a broad range\nof LLMs, and we observe existing LLMs, though achieving high average accuracies\non traditional benchmarks, exhibit significant performance variations across\ndifferent math concepts and may even fail catastrophically on the most basic\nones. Besides, we also introduce an efficient fine-tuning strategy to enhance\nthe weaknesses of existing LLMs. Finally, we hope ConceptMath could guide the\ndevelopers to understand the fine-grained mathematical abilities of their\nmodels and facilitate the growth of foundation models.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14660v2",
    "authors": [
      "Yanan Wu",
      "Jie Liu",
      "Xingyuan Bu",
      "Jiaheng Liu",
      "Zhanhui Zhou",
      "Yuanxing Zhang",
      "Chenchen Zhang",
      "Zhiqi Bai",
      "Haibin Chen",
      "Tiezheng Ge",
      "Wanli Ouyang",
      "Wenbo Su",
      "Bo Zheng"
    ]
  },
  {
    "id": "2402.14672",
    "title": "Middleware for LLMs: Tools Are Instrumental for Language Agents in\n  Complex Environments",
    "abstract": "  The applications of large language models (LLMs) have expanded well beyond\nthe confines of text processing, signaling a new era where LLMs are envisioned\nas generalist language agents capable of operating within complex real-world\nenvironments. These environments are often highly expansive, making it\nimpossible for the LLM to process them within its short-term memory. Motivated\nby recent research on extending the capabilities of LLMs with tools, this paper\ninvestigates the intriguing potential of tools to augment LLMs in handling such\ncomplexity. To this end, we design customized tools to aid in the proactive\nexploration within these massive environments. Such tools can serve as a\nmiddleware layer shielding the LLM from environmental complexity. In two\nrepresentative complex environments -- knowledge bases (KBs) and databases --\nwe demonstrate the significant potential of augmenting language agents with\ntools in complex environments. Notably, equipped with these tools, GPT-4\nachieves 2.8X the performance of the best baseline in tasks requiring access to\ndatabase content and 2.2X in KB tasks. Our findings illuminate the path for\nadvancing language agents in complex real-world applications.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14672v1",
    "authors": [
      "Yu Gu",
      "Yiheng Shu",
      "Hao Yu",
      "Xiao Liu",
      "Yuxiao Dong",
      "Jie Tang",
      "Jayanth Srinivasa",
      "Hugo Latapie",
      "Yu Su"
    ]
  },
  {
    "id": "2402.14698",
    "title": "Big data analytics to classify earthwork-related locations: A Chengdu\n  study",
    "abstract": "  Air pollution has significantly intensified, leading to severe health\nconsequences worldwide. Earthwork-related locations (ERLs) constitute\nsignificant sources of urban dust pollution. The effective management of ERLs\nhas long posed challenges for governmental and environmental agencies,\nprimarily due to their classification under different regulatory authorities,\ninformation barriers, delays in data updating, and a lack of dust suppression\nmeasures for various sources of dust pollution. To address these challenges, we\nclassified urban dust pollution sources using dump truck trajectory, urban\npoint of interest (POI), and land cover data. We compared several prediction\nmodels and investigated the relationship between features and dust pollution\nsources using real data. The results demonstrate that high-accuracy\nclassification can be achieved with a limited number of features. This method\nwas successfully implemented in the system called Alpha MAPS in Chengdu to\nprovide decision support for urban pollution control.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14698v1",
    "authors": ["Lei Yu", "Ke Han"]
  },
  {
    "id": "2402.14714",
    "title": "Efficient and Effective Vocabulary Expansion Towards Multilingual Large\n  Language Models",
    "abstract": "  This report introduces \\texttt{EEVE-Korean-v1.0}, a Korean adaptation of\nlarge language models that exhibit remarkable capabilities across English and\nKorean text understanding. Building on recent highly capable but\nEnglish-centric LLMs, such as SOLAR-10.7B and Phi-2, where non-English texts\nare inefficiently processed with English-centric tokenizers, we present an\nefficient and effective vocabulary expansion (EEVE) method, which encompasses\nparameter freezing and subword initialization. In contrast to previous efforts\nthat believe new embeddings require trillions of training tokens, we show that\nour method can significantly boost non-English proficiency within just 2\nbillion tokens. Surpassing most instruction-tuned LLMs on the Open Ko-LLM\nLeaderboard, as of January 2024, our model \\texttt{EEVE-Korean-10.8B-v1.0}\nranks as the leading Korean pre-trained model in the open-source community,\naccording to Hugging Face's leaderboard. We open-source our models on\nHuggingface to empower the open research community in various languages.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14714v1",
    "authors": ["Seungduk Kim", "Seungtaek Choi", "Myeongho Jeong"]
  },
  {
    "id": "2402.14728",
    "title": "The European Commitment to Human-Centered Technology: The Integral Role\n  of HCI in the EU AI Act's Success",
    "abstract": "  The evolution of AI is set to profoundly reshape the future. The European\nUnion, recognizing this impending prominence, has enacted the AI Act,\nregulating market access for AI-based systems. A salient feature of the Act is\nto guard democratic and humanistic values by focusing regulation on\ntransparency, explainability, and the human ability to understand and control\nAI systems. Hereby, the EU AI Act does not merely specify technological\nrequirements for AI systems. The EU issues a democratic call for human-centered\nAI systems and, in turn, an interdisciplinary research agenda for\nhuman-centered innovation in AI development. Without robust methods to assess\nAI systems and their effect on individuals and society, the EU AI Act may lead\nto repeating the mistakes of the General Data Protection Regulation of the EU\nand to rushed, chaotic, ad-hoc, and ambiguous implementation, causing more\nconfusion than lending guidance. Moreover, determined research activities in\nHuman-AI interaction will be pivotal for both regulatory compliance and the\nadvancement of AI in a manner that is both ethical and effective. Such an\napproach will ensure that AI development aligns with human values and needs,\nfostering a technology landscape that is innovative, responsible, and an\nintegral part of our society.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14728v1",
    "authors": [
      "André Calero Valdez",
      "Moreen Heine",
      "Thomas Franke",
      "Nicole Jochems",
      "Hans-Christian Jetter",
      "Tim Schrills"
    ]
  },
  {
    "id": "2402.14730",
    "title": "Clifford-Steerable Convolutional Neural Networks",
    "abstract": "  We present Clifford-Steerable Convolutional Neural Networks (CS-CNNs), a\nnovel class of $\\mathrm{E}(p, q)$-equivariant CNNs. CS-CNNs process multivector\nfields on pseudo-Euclidean spaces $\\mathbb{R}^{p,q}$. They cover, for instance,\n$\\mathrm{E}(3)$-equivariance on $\\mathbb{R}^3$ and Poincar\\'e-equivariance on\nMinkowski spacetime $\\mathbb{R}^{1,3}$. Our approach is based on an implicit\nparametrization of $\\mathrm{O}(p,q)$-steerable kernels via Clifford group\nequivariant neural networks. We significantly and consistently outperform\nbaseline methods on fluid dynamics as well as relativistic electrodynamics\nforecasting tasks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14730v1",
    "authors": [
      "Maksim Zhdanov",
      "David Ruhe",
      "Maurice Weiler",
      "Ana Lucic",
      "Johannes Brandstetter",
      "Patrick Forré"
    ]
  },
  {
    "id": "2402.14762",
    "title": "MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language\n  Models in Multi-Turn Dialogues",
    "abstract": "  The advent of Large Language Models (LLMs) has drastically enhanced dialogue\nsystems. However, comprehensively evaluating the dialogue abilities of LLMs\nremains a challenge. Previous benchmarks have primarily focused on single-turn\ndialogues or provided coarse-grained and incomplete assessments of multi-turn\ndialogues, overlooking the complexity and fine-grained nuances of real-life\ndialogues. To address this issue, we introduce MT-Bench-101, specifically\ndesigned to evaluate the fine-grained abilities of LLMs in multi-turn\ndialogues. By conducting a detailed analysis of real multi-turn dialogue data,\nwe construct a three-tier hierarchical ability taxonomy comprising 4208 turns\nacross 1388 multi-turn dialogues in 13 distinct tasks. We then evaluate 21\npopular LLMs based on MT-Bench-101, conducting comprehensive analyses from both\nability and task perspectives and observing differing trends in LLMs\nperformance across dialogue turns within various tasks. Further analysis\nindicates that neither utilizing common alignment techniques nor chat-specific\ndesigns has led to obvious enhancements in the multi-turn abilities of LLMs.\nExtensive case studies suggest that our designed tasks accurately assess the\ncorresponding multi-turn abilities.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14762v1",
    "authors": [
      "Ge Bai",
      "Jie Liu",
      "Xingyuan Bu",
      "Yancheng He",
      "Jiaheng Liu",
      "Zhanhui Zhou",
      "Zhuoran Lin",
      "Wenbo Su",
      "Tiezheng Ge",
      "Bo Zheng",
      "Wanli Ouyang"
    ]
  },
  {
    "id": "2402.14778",
    "title": "Zero-shot cross-lingual transfer in instruction tuning of large language\n  model",
    "abstract": "  Instruction tuning (IT) is widely used to teach pretrained large language\nmodels (LLMs) to follow arbitrary instructions, but is under-studied in\nmultilingual settings. In this work, we conduct a systematic study of zero-shot\ncross-lingual transfer in IT, when an LLM is instruction-tuned on English-only\ndata and then tested on user prompts in other languages. We investigate the\ninfluence of model configuration choices and devise a multi-facet evaluation\nstrategy for multilingual instruction following. We find that cross-lingual\ntransfer does happen successfully in IT even if all stages of model training\nare English-centric, but only if multiliguality is taken into account in\nhyperparameter tuning and with large enough IT data. English-trained LLMs are\ncapable of generating correct-language, comprehensive and helpful responses in\nthe other languages, but suffer from low factuality and may occasionally have\nfluency errors.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14778v1",
    "authors": ["Nadezhda Chirkova", "Vassilina Nikoulina"]
  },
  {
    "id": "2402.14789",
    "title": "Self-Guided Masked Autoencoders for Domain-Agnostic Self-Supervised\n  Learning",
    "abstract": "  Self-supervised learning excels in learning representations from large\namounts of unlabeled data, demonstrating success across multiple data\nmodalities. Yet, extending self-supervised learning to new modalities is\nnon-trivial because the specifics of existing methods are tailored to each\ndomain, such as domain-specific augmentations which reflect the invariances in\nthe target task. While masked modeling is promising as a domain-agnostic\nframework for self-supervised learning because it does not rely on input\naugmentations, its mask sampling procedure remains domain-specific. We present\nSelf-guided Masked Autoencoders (SMA), a fully domain-agnostic masked modeling\nmethod. SMA trains an attention based model using a masked modeling objective,\nby learning masks to sample without any domain-specific assumptions. We\nevaluate SMA on three self-supervised learning benchmarks in protein biology,\nchemical property prediction, and particle physics. We find SMA is capable of\nlearning representations without domain-specific knowledge and achieves\nstate-of-the-art performance on these three benchmarks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14789v1",
    "authors": ["Johnathan Xie", "Yoonho Lee", "Annie S. Chen", "Chelsea Finn"]
  },
  {
    "id": "2402.14797",
    "title": "Snap Video: Scaled Spatiotemporal Transformers for Text-to-Video\n  Synthesis",
    "abstract": "  Contemporary models for generating images show remarkable quality and\nversatility. Swayed by these advantages, the research community repurposes them\nto generate videos. Since video content is highly redundant, we argue that\nnaively bringing advances of image models to the video generation domain\nreduces motion fidelity, visual quality and impairs scalability. In this work,\nwe build Snap Video, a video-first model that systematically addresses these\nchallenges. To do that, we first extend the EDM framework to take into account\nspatially and temporally redundant pixels and naturally support video\ngeneration. Second, we show that a U-Net - a workhorse behind image generation\n- scales poorly when generating videos, requiring significant computational\noverhead. Hence, we propose a new transformer-based architecture that trains\n3.31 times faster than U-Nets (and is ~4.5 faster at inference). This allows us\nto efficiently train a text-to-video model with billions of parameters for the\nfirst time, reach state-of-the-art results on a number of benchmarks, and\ngenerate videos with substantially higher quality, temporal consistency, and\nmotion complexity. The user studies showed that our model was favored by a\nlarge margin over the most recent methods. See our website at\nhttps://snap-research.github.io/snapvideo/.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14797v1",
    "authors": [
      "Willi Menapace",
      "Aliaksandr Siarohin",
      "Ivan Skorokhodov",
      "Ekaterina Deyneka",
      "Tsai-Shien Chen",
      "Anil Kag",
      "Yuwei Fang",
      "Aleksei Stoliar",
      "Elisa Ricci",
      "Jian Ren",
      "Sergey Tulyakov"
    ]
  },
  {
    "id": "2402.14798",
    "title": "Enhancing Systematic Decompositional Natural Language Inference Using\n  Informal Logic",
    "abstract": "  Contemporary language models enable new opportunities for structured\nreasoning with text, such as the construction and evaluation of intuitive,\nproof-like textual entailment trees without relying on brittle formal logic.\nHowever, progress in this direction has been hampered by a long-standing lack\nof a clear protocol for determining what valid compositional entailment is.\nThis absence causes noisy datasets and limited performance gains by modern\nneuro-symbolic engines. To address these problems, we formulate a consistent\nand theoretically grounded approach to annotating decompositional entailment\ndatasets, and evaluate its impact on LLM-based textual inference. We find that\nour resulting dataset, RDTE (Recognizing Decompositional Textual Entailment),\nhas a substantially higher internal consistency (+9%) than prior\ndecompositional entailment datasets, suggesting that RDTE is a significant step\nforward in the long-standing problem of forming a clear protocol for discerning\nentailment. We also find that training an RDTE-oriented entailment classifier\nvia knowledge distillation and employing it in a modern neuro-symbolic\nreasoning engine significantly improves results (both accuracy and proof\nquality) over other entailment classifier baselines, illustrating the practical\nbenefit of this advance for textual inference.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14798v2",
    "authors": [
      "Nathaniel Weir",
      "Kate Sanders",
      "Orion Weller",
      "Shreya Sharma",
      "Dongwei Jiang",
      "Zhengping Jiang",
      "Bhavana Dalvi Mishra",
      "Oyvind Tafjord",
      "Peter Jansen",
      "Peter Clark",
      "Benjamin Van Durme"
    ]
  },
  {
    "id": "2402.14805",
    "title": "Identifying Multiple Personalities in Large Language Models with\n  External Evaluation",
    "abstract": "  As Large Language Models (LLMs) are integrated with human daily applications\nrapidly, many societal and ethical concerns are raised regarding the behavior\nof LLMs. One of the ways to comprehend LLMs' behavior is to analyze their\npersonalities. Many recent studies quantify LLMs' personalities using\nself-assessment tests that are created for humans. Yet many critiques question\nthe applicability and reliability of these self-assessment tests when applied\nto LLMs. In this paper, we investigate LLM personalities using an alternate\npersonality measurement method, which we refer to as the external evaluation\nmethod, where instead of prompting LLMs with multiple-choice questions in the\nLikert scale, we evaluate LLMs' personalities by analyzing their responses\ntoward open-ended situational questions using an external machine learning\nmodel. We first fine-tuned a Llama2-7B model as the MBTI personality predictor\nthat outperforms the state-of-the-art models as the tool to analyze LLMs'\nresponses. Then, we prompt the LLMs with situational questions and ask them to\ngenerate Twitter posts and comments, respectively, in order to assess their\npersonalities when playing two different roles. Using the external personality\nevaluation method, we identify that the obtained personality types for LLMs are\nsignificantly different when generating posts versus comments, whereas humans\nshow a consistent personality profile in these two different situations. This\nshows that LLMs can exhibit different personalities based on different\nscenarios, thus highlighting a fundamental difference between personality in\nLLMs and humans. With our work, we call for a re-evaluation of personality\ndefinition and measurement in LLMs.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14805v1",
    "authors": [
      "Xiaoyang Song",
      "Yuta Adachi",
      "Jessie Feng",
      "Mouwei Lin",
      "Linhao Yu",
      "Frank Li",
      "Akshat Gupta",
      "Gopala Anumanchipalli",
      "Simerjot Kaur"
    ]
  },
  {
    "id": "2402.14812",
    "title": "WeakSAM: Segment Anything Meets Weakly-supervised Instance-level\n  Recognition",
    "abstract": "  Weakly supervised visual recognition using inexact supervision is a critical\nyet challenging learning problem. It significantly reduces human labeling costs\nand traditionally relies on multi-instance learning and pseudo-labeling. This\npaper introduces WeakSAM and solves the weakly-supervised object detection\n(WSOD) and segmentation by utilizing the pre-learned world knowledge contained\nin a vision foundation model, i.e., the Segment Anything Model (SAM). WeakSAM\naddresses two critical limitations in traditional WSOD retraining, i.e., pseudo\nground truth (PGT) incompleteness and noisy PGT instances, through adaptive PGT\ngeneration and Region of Interest (RoI) drop regularization. It also addresses\nthe SAM's problems of requiring prompts and category unawareness for automatic\nobject detection and segmentation. Our results indicate that WeakSAM\nsignificantly surpasses previous state-of-the-art methods in WSOD and WSIS\nbenchmarks with large margins, i.e. average improvements of 7.4% and 8.5%,\nrespectively. The code is available at \\url{https://github.com/hustvl/WeakSAM}.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14812v1",
    "authors": ["Lianghui Zhu", "Junwei Zhou", "Yan Liu", "Xin Hao", "Wenyu Liu", "Xinggang Wang"]
  },
  {
    "id": "2402.14886",
    "title": "Applying Reinforcement Learning to Optimize Traffic Light Cycles",
    "abstract": "  Manual optimization of traffic light cycles is a complex and time-consuming\ntask, necessitating the development of automated solutions. In this paper, we\npropose the application of reinforcement learning to optimize traffic light\ncycles in real-time. We present a case study using the Simulation Urban\nMobility simulator to train a Deep Q-Network algorithm. The experimental\nresults showed 44.16% decrease in the average number of Emergency stops,\nshowing the potential of our approach to reduce traffic congestion and improve\ntraffic flow. Furthermore, we discuss avenues for future research and\nenhancements to the reinforcement learning model.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14886v1",
    "authors": ["Seungah Son", "Juhee Jin"]
  },
  {
    "id": "2402.14889",
    "title": "COBIAS: Contextual Reliability in Bias Assessment",
    "abstract": "  Large Language Models (LLMs) are trained on inherently biased data. Previous\nworks on debiasing models rely on benchmark datasets to measure model\nperformance. However, these datasets suffer from several pitfalls due to the\nextremely subjective understanding of bias, highlighting a critical need for\ncontextual exploration. We propose understanding the context of user inputs\nwith consideration of the diverse situations in which input statements are\npossible. This approach would allow for frameworks that foster bias awareness\nrather than guardrails that hurt user engagement. Our contribution is twofold:\n(i) we create a dataset of 2287 stereotyped statements augmented with points\nfor adding context; (ii) we develop the Context-Oriented Bias Indicator and\nAssessment Score (COBIAS) to assess statements' contextual reliability in\nmeasuring bias. Our metric is a significant predictor of the contextual\nreliability of bias-benchmark datasets ($\\chi^2=71.02, p<2.2 \\cdot 10^{-16})$.\nCOBIAS can be used to create reliable datasets, resulting in an improvement in\nbias mitigation works.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14889v1",
    "authors": [
      "Priyanshul Govil",
      "Vamshi Krishna Bonagiri",
      "Manas Gaur",
      "Ponnurangam Kumaraguru",
      "Sanorita Dey"
    ]
  },
  {
    "id": "2402.14891",
    "title": "LLMBind: A Unified Modality-Task Integration Framework",
    "abstract": "  While recent progress in multimodal large language models tackles various\nmodality tasks, they posses limited integration capabilities for complex\nmulti-modality tasks, consequently constraining the development of the field.\nIn this work, we take the initiative to explore and propose the LLMBind, a\nunified framework for modality task integration, which binds Large Language\nModels and corresponding pre-trained task models with task-specific tokens.\nConsequently, LLMBind can interpret inputs and produce outputs in versatile\ncombinations of image, text, video, and audio. Specifically, we introduce a\nMixture-of-Experts technique to enable effective learning for different\nmultimodal tasks through collaboration among diverse experts. Furthermore, we\ncreate a multi-task dataset comprising 400k instruction data, which unlocks the\nability for interactive visual generation and editing tasks. Extensive\nexperiments show the effectiveness of our framework across various tasks,\nincluding image, video, audio generation, image segmentation, and image\nediting. More encouragingly, our framework can be easily extended to other\nmodality tasks, showcasing the promising potential of creating a unified AI\nagent for modeling universal modalities.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14891v2",
    "authors": [
      "Bin Zhu",
      "Peng Jin",
      "Munan Ning",
      "Bin Lin",
      "Jinfa Huang",
      "Qi Song",
      "Junwu Zhang",
      "Zhenyu Tang",
      "Mingjun Pan",
      "Xing Zhou",
      "Li Yuan"
    ]
  },
  {
    "id": "2402.14901",
    "title": "A Usage-centric Take on Intent Understanding in E-Commerce",
    "abstract": "  Identifying and understanding user intents is a pivotal task for E-Commerce.\nDespite its popularity, intent understanding has not been consistently defined\nor accurately benchmarked. In this paper, we focus on predicative user intents\nas \"how a customer uses a product\", and pose intent understanding as a natural\nlanguage reasoning task, independent of product ontologies. We identify two\nweaknesses of FolkScope, the SOTA E-Commerce Intent Knowledge Graph, that limit\nits capacity to reason about user intents and to recommend diverse useful\nproducts. Following these observations, we introduce a Product Recovery\nBenchmark including a novel evaluation framework and an example dataset. We\nfurther validate the above FolkScope weaknesses on this benchmark.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14901v1",
    "authors": ["Wendi Zhou", "Tianyi Li", "Pavlos Vougiouklis", "Mark Steedman", "Jeff Z. Pan"]
  },
  {
    "id": "2402.14922",
    "title": "Practical Insights into Knowledge Distillation for Pre-Trained Models",
    "abstract": "  This research investigates the enhancement of knowledge distillation (KD)\nprocesses in pre-trained models, an emerging field in knowledge transfer with\nsignificant implications for distributed training and federated learning\nenvironments. These environments benefit from reduced communication demands and\naccommodate various model architectures. Despite the adoption of numerous KD\napproaches for transferring knowledge among pre-trained models, a comprehensive\nunderstanding of KD's application in these scenarios is lacking. Our study\nconducts an extensive comparison of multiple KD techniques, including standard\nKD, tuned KD (via optimized temperature and weight parameters), deep mutual\nlearning, and data partitioning KD. We assess these methods across various data\ndistribution strategies to identify the most effective contexts for each.\nThrough detailed examination of hyperparameter tuning, informed by extensive\ngrid search evaluations, we pinpoint when adjustments are crucial to enhance\nmodel performance. This paper sheds light on optimal hyperparameter settings\nfor distinct data partitioning scenarios and investigates KD's role in\nimproving federated learning by minimizing communication rounds and expediting\nthe training process. By filling a notable void in current research, our\nfindings serve as a practical framework for leveraging KD in pre-trained models\nwithin collaborative and federated learning frameworks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14922v1",
    "authors": ["Norah Alballa", "Marco Canini"]
  },
  {
    "id": "2402.14933",
    "title": "Path Planning based on 2D Object Bounding-box",
    "abstract": "  The implementation of Autonomous Driving (AD) technologies within urban\nenvironments presents significant challenges. These challenges necessitate the\ndevelopment of advanced perception systems and motion planning algorithms\ncapable of managing situations of considerable complexity. Although the\nend-to-end AD method utilizing LiDAR sensors has achieved significant success\nin this scenario, we argue that its drawbacks may hinder its practical\napplication. Instead, we propose the vision-centric AD as a promising\nalternative offering a streamlined model without compromising performance. In\nthis study, we present a path planning method that utilizes 2D bounding boxes\nof objects, developed through imitation learning in urban driving scenarios.\nThis is achieved by integrating high-definition (HD) map data with images\ncaptured by surrounding cameras. Subsequent perception tasks involve\nbounding-box detection and tracking, while the planning phase employs both\nlocal embeddings via Graph Neural Network (GNN) and global embeddings via\nTransformer for temporal-spatial feature aggregation, ultimately producing\noptimal path planning information. We evaluated our model on the nuPlan\nplanning task and observed that it performs competitively in comparison to\nexisting vision-centric methods.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14933v1",
    "authors": ["Yanliang Huang", "Liguo Zhou", "Chang Liu", "Alois Knoll"]
  },
  {
    "id": "2402.14963",
    "title": "Mirror: A Multiple-perspective Self-Reflection Method for Knowledge-rich\n  Reasoning",
    "abstract": "  While Large language models (LLMs) have the capability to iteratively reflect\non their own outputs, recent studies have observed their struggles with\nknowledge-rich problems without access to external resources. In addition to\nthe inefficiency of LLMs in self-assessment, we also observe that LLMs struggle\nto revisit their predictions despite receiving explicit negative feedback.\nTherefore, We propose Mirror, a Multiple-perspective self-reflection method for\nknowledge-rich reasoning, to avoid getting stuck at a particular reflection\niteration. Mirror enables LLMs to reflect from multiple-perspective clues,\nachieved through a heuristic interaction between a Navigator and a Reasoner. It\nguides agents toward diverse yet plausibly reliable reasoning trajectory\nwithout access to ground truth by encouraging (1) diversity of directions\ngenerated by Navigator and (2) agreement among strategically induced\nperturbations in responses generated by the Reasoner. The experiments on five\nreasoning datasets demonstrate that Mirror's superiority over several\ncontemporary self-reflection approaches. Additionally, the ablation study\nstudies clearly indicate that our strategies alleviate the aforementioned\nchallenges.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14963v1",
    "authors": ["Hanqi Yan", "Qinglin Zhu", "Xinyu Wang", "Lin Gui", "Yulan He"]
  },
  {
    "id": "2402.14972",
    "title": "MultiLS: A Multi-task Lexical Simplification Framework",
    "abstract": "  Lexical Simplification (LS) automatically replaces difficult to read words\nfor easier alternatives while preserving a sentence's original meaning. LS is a\nprecursor to Text Simplification with the aim of improving text accessibility\nto various target demographics, including children, second language learners,\nindividuals with reading disabilities or low literacy. Several datasets exist\nfor LS. These LS datasets specialize on one or two sub-tasks within the LS\npipeline. However, as of this moment, no single LS dataset has been developed\nthat covers all LS sub-tasks. We present MultiLS, the first LS framework that\nallows for the creation of a multi-task LS dataset. We also present MultiLS-PT,\nthe first dataset to be created using the MultiLS framework. We demonstrate the\npotential of MultiLS-PT by carrying out all LS sub-tasks of (1). lexical\ncomplexity prediction (LCP), (2). substitute generation, and (3). substitute\nranking for Portuguese. Model performances are reported, ranging from\ntransformer-based models to more recent large language models (LLMs).\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14972v1",
    "authors": ["Kai North", "Tharindu Ranasinghe", "Matthew Shardlow", "Marcos Zampieri"]
  },
  {
    "id": "2402.14989",
    "title": "Stable Neural Stochastic Differential Equations in Analyzing Irregular\n  Time Series Data",
    "abstract": "  Irregular sampling intervals and missing values in real-world time series\ndata present challenges for conventional methods that assume consistent\nintervals and complete data. Neural Ordinary Differential Equations (Neural\nODEs) offer an alternative approach, utilizing neural networks combined with\nODE solvers to learn continuous latent representations through parameterized\nvector fields. Neural Stochastic Differential Equations (Neural SDEs) extend\nNeural ODEs by incorporating a diffusion term, although this addition is not\ntrivial, particularly when addressing irregular intervals and missing values.\nConsequently, careful design of drift and diffusion functions is crucial for\nmaintaining stability and enhancing performance, while incautious choices can\nresult in adverse properties such as the absence of strong solutions,\nstochastic destabilization, or unstable Euler discretizations, significantly\naffecting Neural SDEs' performance. In this study, we propose three stable\nclasses of Neural SDEs: Langevin-type SDE, Linear Noise SDE, and Geometric SDE.\nThen, we rigorously demonstrate their robustness in maintaining excellent\nperformance under distribution shift, while effectively preventing overfitting.\nTo assess the effectiveness of our approach, we conduct extensive experiments\non four benchmark datasets for interpolation, forecasting, and classification\ntasks, and analyze the robustness of our methods with 30 public datasets under\ndifferent missing rates. Our results demonstrate the efficacy of the proposed\nmethod in handling real-world irregular time series data.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14989v1",
    "authors": ["YongKyung Oh", "Dongyoung Lim", "Sungil Kim"]
  },
  {
    "id": "2402.15012",
    "title": "Ar-Spider: Text-to-SQL in Arabic",
    "abstract": "  In Natural Language Processing (NLP), one of the most important tasks is\ntext-to-SQL semantic parsing, which focuses on enabling users to interact with\nthe database in a more natural manner. In recent years, text-to-SQL has made\nsignificant progress, but most were English-centric. In this paper, we\nintroduce Ar-Spider 1, the first Arabic cross-domain text-to-SQL dataset. Due\nto the unique nature of the language, two major challenges have been\nencountered, namely schema linguistic and SQL structural challenges. In order\nto handle these issues and conduct the experiments, we adopt two baseline\nmodels LGESQL [4] and S2SQL [12], both of which are tested with two\ncross-lingual models to alleviate the effects of schema linguistic and SQL\nstructure linking challenges. The baselines demonstrate decent single-language\nperformance on our Arabic text-to-SQL dataset, Ar-Spider, achieving 62.48% for\nS2SQL and 65.57% for LGESQL, only 8.79% below the highest results achieved by\nthe baselines when trained in English dataset. To achieve better performance on\nArabic text-to-SQL, we propose the context similarity relationship (CSR)\napproach, which results in a significant increase in the overall performance of\nabout 1.52% for S2SQL and 1.06% for LGESQL and closes the gap between Arabic\nand English languages to 7.73%.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15012v1",
    "authors": ["Saleh Almohaimeed", "Saad Almohaimeed", "Mansour Al Ghanim", "Liqiang Wang"]
  },
  {
    "id": "2402.14187",
    "title": "From Adoption to Adaption: Tracing the Diffusion of New Emojis on\n  Twitter",
    "abstract": "  In the rapidly evolving landscape of social media, the introduction of new\nemojis in Unicode release versions presents a structured opportunity to explore\ndigital language evolution. Analyzing a large dataset of sampled English\ntweets, we examine how newly released emojis gain traction and evolve in\nmeaning. We find that community size of early adopters and emoji semantics are\ncrucial in determining their popularity. Certain emojis experienced notable\nshifts in the meanings and sentiment associations during the diffusion process.\nAdditionally, we propose a novel framework utilizing language models to extract\nwords and pre-existing emojis with semantically similar contexts, which\nenhances interpretation of new emojis. The framework demonstrates its\neffectiveness in improving sentiment classification performance by substituting\nunknown new emojis with familiar ones. This study offers a new perspective in\nunderstanding how new language units are adopted, adapted, and integrated into\nthe fabric of online communication.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14187v1",
    "authors": ["Yuhang Zhou", "Xuan Lu", "Wei Ai"]
  },
  {
    "id": "2402.14208",
    "title": "Content Conditional Debiasing for Fair Text Embedding",
    "abstract": "  Mitigating biases in machine learning models has gained increasing attention\nin Natural Language Processing (NLP). Yet, only a few studies focus on fair\ntext embeddings, which are crucial yet challenging for real-world applications.\nIn this paper, we propose a novel method for learning fair text embeddings. We\nachieve fairness while maintaining utility trade-off by ensuring conditional\nindependence between sensitive attributes and text embeddings conditioned on\nthe content. Specifically, we enforce that embeddings of texts with different\nsensitive attributes but identical content maintain the same distance toward\nthe embedding of their corresponding neutral text. Furthermore, we address the\nissue of lacking proper training data by using Large Language Models (LLMs) to\naugment texts into different sensitive groups. Our extensive evaluations\ndemonstrate that our approach effectively improves fairness while preserving\nthe utility of embeddings, representing a pioneering effort in achieving\nconditional independence for fair text embeddings.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14208v2",
    "authors": ["Wenlong Deng", "Blair Chen", "Xiaoxiao Li", "Christos Thrampoulidis"]
  },
  {
    "id": "2402.14236",
    "title": "Automated Design and Optimization of Distributed Filtering Circuits via\n  Reinforcement Learning",
    "abstract": "  Designing distributed filtering circuits (DFCs) is complex and\ntime-consuming, with the circuit performance relying heavily on the expertise\nand experience of electronics engineers. However, manual design methods tend to\nhave exceedingly low-efficiency. This study proposes a novel end-to-end\nautomated method for fabricating circuits to improve the design of DFCs. The\nproposed method harnesses reinforcement learning (RL) algorithms, eliminating\nthe dependence on the design experience of engineers. Thus, it significantly\nreduces the subjectivity and constraints associated with circuit design. The\nexperimental findings demonstrate clear improvements in both design efficiency\nand quality when comparing the proposed method with traditional engineer-driven\nmethods. In particular, the proposed method achieves superior performance when\ndesigning complex or rapidly evolving DFCs. Furthermore, compared to existing\ncircuit automation design techniques, the proposed method demonstrates superior\ndesign efficiency, highlighting the substantial potential of RL in circuit\ndesign automation.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14236v1",
    "authors": ["Peng Gao", "Tao Yu", "Fei Wang", "Ru-Yue Yuan"]
  },
  {
    "id": "2402.14244",
    "title": "MENTOR: Guiding Hierarchical Reinforcement Learning with Human Feedback\n  and Dynamic Distance Constraint",
    "abstract": "  Hierarchical reinforcement learning (HRL) provides a promising solution for\ncomplex tasks with sparse rewards of intelligent agents, which uses a\nhierarchical framework that divides tasks into subgoals and completes them\nsequentially. However, current methods struggle to find suitable subgoals for\nensuring a stable learning process. Without additional guidance, it is\nimpractical to rely solely on exploration or heuristics methods to determine\nsubgoals in a large goal space. To address the issue, We propose a general\nhierarchical reinforcement learning framework incorporating human feedback and\ndynamic distance constraints (MENTOR). MENTOR acts as a \"mentor\", incorporating\nhuman feedback into high-level policy learning, to find better subgoals. As for\nlow-level policy, MENTOR designs a dual policy for exploration-exploitation\ndecoupling respectively to stabilize the training. Furthermore, although humans\ncan simply break down tasks into subgoals to guide the right learning\ndirection, subgoals that are too difficult or too easy can still hinder\ndownstream learning efficiency. We propose the Dynamic Distance Constraint\n(DDC) mechanism dynamically adjusting the space of optional subgoals. Thus\nMENTOR can generate subgoals matching the low-level policy learning process\nfrom easy to hard. Extensive experiments demonstrate that MENTOR uses a small\namount of human feedback to achieve significant improvement in complex tasks\nwith sparse rewards.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14244v1",
    "authors": ["Xinglin Zhou", "Yifu Yuan", "Shaofu Yang", "Jianye Hao"]
  },
  {
    "id": "2402.14245",
    "title": "Enhancing Robotic Manipulation with AI Feedback from Multimodal Large\n  Language Models",
    "abstract": "  Recently, there has been considerable attention towards leveraging large\nlanguage models (LLMs) to enhance decision-making processes. However, aligning\nthe natural language text instructions generated by LLMs with the vectorized\noperations required for execution presents a significant challenge, often\nnecessitating task-specific details. To circumvent the need for such\ntask-specific granularity, inspired by preference-based policy learning\napproaches, we investigate the utilization of multimodal LLMs to provide\nautomated preference feedback solely from image inputs to guide\ndecision-making. In this study, we train a multimodal LLM, termed CriticGPT,\ncapable of understanding trajectory videos in robot manipulation tasks, serving\nas a critic to offer analysis and preference feedback. Subsequently, we\nvalidate the effectiveness of preference labels generated by CriticGPT from a\nreward modeling perspective. Experimental evaluation of the algorithm's\npreference accuracy demonstrates its effective generalization ability to new\ntasks. Furthermore, performance on Meta-World tasks reveals that CriticGPT's\nreward model efficiently guides policy learning, surpassing rewards based on\nstate-of-the-art pre-trained representation models.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14245v1",
    "authors": [
      "Jinyi Liu",
      "Yifu Yuan",
      "Jianye Hao",
      "Fei Ni",
      "Lingzhi Fu",
      "Yibin Chen",
      "Yan Zheng"
    ]
  },
  {
    "id": "2402.14259",
    "title": "Word-Sequence Entropy: Towards Uncertainty Estimation in Free-Form\n  Medical Question Answering Applications and Beyond",
    "abstract": "  Uncertainty estimation plays a pivotal role in ensuring the reliability of\nsafety-critical human-AI interaction systems, particularly in the medical\ndomain. However, a general method for quantifying the uncertainty of free-form\nanswers has yet to be established in open-ended medical question-answering (QA)\ntasks, where irrelevant words and sequences with limited semantic information\ncan be the primary source of uncertainty due to the presence of generative\ninequality. In this paper, we propose the Word-Sequence Entropy (WSE), which\ncalibrates the uncertainty proportion at both the word and sequence levels\naccording to the semantic relevance, with greater emphasis placed on keywords\nand more relevant sequences when performing uncertainty quantification. We\ncompare WSE with 6 baseline methods on 5 free-form medical QA datasets,\nutilizing 7 \"off-the-shelf\" large language models (LLMs), and show that WSE\nexhibits superior performance on accurate uncertainty measurement under two\nstandard criteria for correctness evaluation (e.g., WSE outperforms existing\nstate-of-the-art method by 3.23% AUROC on the MedQA dataset). Additionally, in\nterms of the potential for real-world medical QA applications, we achieve a\nsignificant enhancement in the performance of LLMs when employing sequences\nwith lower uncertainty, identified by WSE, as final answers (e.g., +6.36%\naccuracy improvement on the COVID-QA dataset), without requiring any additional\ntask-specific fine-tuning or architectural modifications.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14259v1",
    "authors": [
      "Zhiyuan Wang",
      "Jinhao Duan",
      "Chenxi Yuan",
      "Qingyu Chen",
      "Tianlong Chen",
      "Huaxiu Yao",
      "Yue Zhang",
      "Ren Wang",
      "Kaidi Xu",
      "Xiaoshuang Shi"
    ]
  },
  {
    "id": "2402.14268",
    "title": "Can Large Language Models Detect Misinformation in Scientific News\n  Reporting?",
    "abstract": "  Scientific facts are often spun in the popular press with the intent to\ninfluence public opinion and action, as was evidenced during the COVID-19\npandemic. Automatic detection of misinformation in the scientific domain is\nchallenging because of the distinct styles of writing in these two media types\nand is still in its nascence. Most research on the validity of scientific\nreporting treats this problem as a claim verification challenge. In doing so,\nsignificant expert human effort is required to generate appropriate claims. Our\nsolution bypasses this step and addresses a more real-world scenario where such\nexplicit, labeled claims may not be available. The central research question of\nthis paper is whether it is possible to use large language models (LLMs) to\ndetect misinformation in scientific reporting. To this end, we first present a\nnew labeled dataset SciNews, containing 2.4k scientific news stories drawn from\ntrusted and untrustworthy sources, paired with related abstracts from the\nCORD-19 database. Our dataset includes both human-written and LLM-generated\nnews articles, making it more comprehensive in terms of capturing the growing\ntrend of using LLMs to generate popular press articles. Then, we identify\ndimensions of scientific validity in science news articles and explore how this\ncan be integrated into the automated detection of scientific misinformation. We\npropose several baseline architectures using LLMs to automatically detect false\nrepresentations of scientific findings in the popular press. For each of these\narchitectures, we use several prompt engineering strategies including\nzero-shot, few-shot, and chain-of-thought prompting. We also test these\narchitectures and prompting strategies on GPT-3.5, GPT-4, and Llama2-7B,\nLlama2-13B.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14268v1",
    "authors": [
      "Yupeng Cao",
      "Aishwarya Muralidharan Nair",
      "Elyon Eyimife",
      "Nastaran Jamalipour Soofi",
      "K. P. Subbalakshmi",
      "John R. Wullert II",
      "Chumki Basu",
      "David Shallcross"
    ]
  },
  {
    "id": "2402.14304",
    "title": "Vision-Language Navigation with Embodied Intelligence: A Survey",
    "abstract": "  As a long-term vision in the field of artificial intelligence, the core goal\nof embodied intelligence is to improve the perception, understanding, and\ninteraction capabilities of agents and the environment. Vision-language\nnavigation (VLN), as a critical research path to achieve embodied intelligence,\nfocuses on exploring how agents use natural language to communicate effectively\nwith humans, receive and understand instructions, and ultimately rely on visual\ninformation to achieve accurate navigation. VLN integrates artificial\nintelligence, natural language processing, computer vision, and robotics. This\nfield faces technical challenges but shows potential for application such as\nhuman-computer interaction. However, due to the complex process involved from\nlanguage understanding to action execution, VLN faces the problem of aligning\nvisual information and language instructions, improving generalization ability,\nand many other challenges. This survey systematically reviews the research\nprogress of VLN and details the research direction of VLN with embodied\nintelligence. After a detailed summary of its system architecture and research\nbased on methods and commonly used benchmark datasets, we comprehensively\nanalyze the problems and challenges faced by current research and explore the\nfuture development direction of this field, aiming to provide a practical\nreference for researchers.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14304v1",
    "authors": ["Peng Gao", "Peng Wang", "Feng Gao", "Fei Wang", "Ruyue Yuan"]
  },
  {
    "id": "2402.14335",
    "title": "HyperFast: Instant Classification for Tabular Data",
    "abstract": "  Training deep learning models and performing hyperparameter tuning can be\ncomputationally demanding and time-consuming. Meanwhile, traditional machine\nlearning methods like gradient-boosting algorithms remain the preferred choice\nfor most tabular data applications, while neural network alternatives require\nextensive hyperparameter tuning or work only in toy datasets under limited\nsettings. In this paper, we introduce HyperFast, a meta-trained hypernetwork\ndesigned for instant classification of tabular data in a single forward pass.\nHyperFast generates a task-specific neural network tailored to an unseen\ndataset that can be directly used for classification inference, removing the\nneed for training a model. We report extensive experiments with OpenML and\ngenomic data, comparing HyperFast to competing tabular data neural networks,\ntraditional ML methods, AutoML systems, and boosting machines. HyperFast shows\nhighly competitive results, while being significantly faster. Additionally, our\napproach demonstrates robust adaptability across a variety of classification\ntasks with little to no fine-tuning, positioning HyperFast as a strong solution\nfor numerous applications and rapid model deployment. HyperFast introduces a\npromising paradigm for fast classification, with the potential to substantially\ndecrease the computational burden of deep learning. Our code, which offers a\nscikit-learn-like interface, along with the trained HyperFast model, can be\nfound at https://github.com/AI-sandbox/HyperFast.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14335v1",
    "authors": [
      "David Bonet",
      "Daniel Mas Montserrat",
      "Xavier Giró-i-Nieto",
      "Alexander G. Ioannidis"
    ]
  },
  {
    "id": "2402.14409",
    "title": "Tug-of-War Between Knowledge: Exploring and Resolving Knowledge\n  Conflicts in Retrieval-Augmented Language Models",
    "abstract": "  Retrieval-augmented language models (RALMs) have demonstrated significant\npotential in refining and expanding their internal memory by retrieving\nevidence from external sources. However, RALMs will inevitably encounter\nknowledge conflicts when integrating their internal memory with external\nsources. Knowledge conflicts can ensnare RALMs in a tug-of-war between\nknowledge, limiting their practical applicability. In this paper, we focus on\nexploring and resolving knowledge conflicts in RALMs. First, we present an\nevaluation framework for assessing knowledge conflicts across various\ndimensions. Then, we investigate the behavior and preference of RALMs from the\nfollowing two perspectives: (1) Conflicts between internal memory and external\nsources: We find that stronger RALMs emerge with the Dunning-Kruger effect,\npersistently favoring their faulty internal memory even when correct evidence\nis provided. Besides, RALMs exhibit an availability bias towards common\nknowledge; (2) Conflicts between truthful, irrelevant and misleading evidence:\nWe reveal that RALMs follow the principle of majority rule, leaning towards\nplacing trust in evidence that appears more frequently. Moreover, we find that\nRALMs exhibit confirmation bias, and are more willing to choose evidence that\nis consistent with their internal memory. To solve the challenge of knowledge\nconflicts, we propose a method called Conflict-Disentangle Contrastive Decoding\n(CD2) to better calibrate the model's confidence. Experimental results\ndemonstrate that our CD2 can effectively resolve knowledge conflicts in RALMs.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14409v1",
    "authors": [
      "Zhuoran Jin",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Xiaojian Jiang",
      "Jiexin Xu",
      "Qiuxia Li",
      "Jun Zhao"
    ]
  },
  {
    "id": "2402.14486",
    "title": "Are Bounded Contracts Learnable and Approximately Optimal?",
    "abstract": "  This paper considers the hidden-action model of the principal-agent problem,\nin which a principal incentivizes an agent to work on a project using a\ncontract. We investigate whether contracts with bounded payments are learnable\nand approximately optimal. Our main results are two learning algorithms that\ncan find a nearly optimal bounded contract using a polynomial number of\nqueries, under two standard assumptions in the literature: a costlier action\nfor the agent leads to a better outcome distribution for the principal, and the\nagent's cost/effort has diminishing returns. Our polynomial query complexity\nupper bound shows that standard assumptions are sufficient for achieving an\nexponential improvement upon the known lower bound for general instances.\nUnlike the existing algorithms, which relied on discretizing the contract\nspace, our algorithms directly learn the underlying outcome distributions. As\nfor the approximate optimality of bounded contracts, we find that they could be\nfar from optimal in terms of multiplicative or additive approximation, but\nsatisfy a notion of mixed approximation.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14486v1",
    "authors": ["Yurong Chen", "Zhaohua Chen", "Xiaotie Deng", "Zhiyi Huang"]
  },
  {
    "id": "2402.14547",
    "title": "OmniPred: Language Models as Universal Regressors",
    "abstract": "  Over the broad landscape of experimental design, regression has been a\npowerful tool to accurately predict the outcome metrics of a system or model\ngiven a set of parameters, but has been traditionally restricted to methods\nwhich are only applicable to a specific task. In this paper, we propose\nOmniPred, a framework for training language models as universal end-to-end\nregressors over $(x,y)$ evaluation data from diverse real world experiments.\nUsing data sourced from Google Vizier, one of the largest blackbox optimization\ndatabases in the world, our extensive experiments demonstrate that through only\ntextual representations of mathematical parameters and values, language models\nare capable of very precise numerical regression, and if given the opportunity\nto train over multiple tasks, can significantly outperform traditional\nregression models.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14547v2",
    "authors": [
      "Xingyou Song",
      "Oscar Li",
      "Chansoo Lee",
      "Bangding Yang",
      "Daiyi Peng",
      "Sagi Perel",
      "Yutian Chen"
    ]
  },
  {
    "id": "2402.14551",
    "title": "CLCE: An Approach to Refining Cross-Entropy and Contrastive Learning for\n  Optimized Learning Fusion",
    "abstract": "  State-of-the-art pre-trained image models predominantly adopt a two-stage\napproach: initial unsupervised pre-training on large-scale datasets followed by\ntask-specific fine-tuning using Cross-Entropy loss~(CE). However, it has been\ndemonstrated that CE can compromise model generalization and stability. While\nrecent works employing contrastive learning address some of these limitations\nby enhancing the quality of embeddings and producing better decision\nboundaries, they often overlook the importance of hard negative mining and rely\non resource intensive and slow training using large sample batches. To counter\nthese issues, we introduce a novel approach named CLCE, which integrates\nLabel-Aware Contrastive Learning with CE. Our approach not only maintains the\nstrengths of both loss functions but also leverages hard negative mining in a\nsynergistic way to enhance performance. Experimental results demonstrate that\nCLCE significantly outperforms CE in Top-1 accuracy across twelve benchmarks,\nachieving gains of up to 3.52% in few-shot learning scenarios and 3.41% in\ntransfer learning settings with the BEiT-3 model. Importantly, our proposed\nCLCE approach effectively mitigates the dependency of contrastive learning on\nlarge batch sizes such as 4096 samples per batch, a limitation that has\npreviously constrained the application of contrastive learning in\nbudget-limited hardware environments.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14551v1",
    "authors": [
      "Zijun Long",
      "George Killick",
      "Lipeng Zhuang",
      "Gerardo Aragon-Camarasa",
      "Zaiqiao Meng",
      "Richard Mccreadie"
    ]
  },
  {
    "id": "2402.14609",
    "title": "FedCQA: Answering Complex Queries on Multi-Source Knowledge Graphs via\n  Federated Learning",
    "abstract": "  Complex logical query answering is a challenging task in knowledge graphs\n(KGs) that has been widely studied. The ability to perform complex logical\nreasoning is essential and supports various graph reasoning-based downstream\ntasks, such as search engines. Recent approaches are proposed to represent KG\nentities and logical queries into embedding vectors and find answers to logical\nqueries from the KGs. However, existing proposed methods mainly focus on\nquerying a single KG and cannot be applied to multiple graphs. In addition,\ndirectly sharing KGs with sensitive information may incur privacy risks, making\nit impractical to share and construct an aggregated KG for reasoning to\nretrieve query answers. Thus, it remains unknown how to answer queries on\nmulti-source KGs. An entity can be involved in various knowledge graphs and\nreasoning on multiple KGs and answering complex queries on multi-source KGs is\nimportant in discovering knowledge cross graphs. Fortunately, federated\nlearning is utilized in knowledge graphs to collaboratively learn\nrepresentations with privacy preserved. Federated knowledge graph embeddings\nenrich the relations in knowledge graphs to improve the representation quality.\nHowever, these methods only focus on one-hop relations and cannot perform\ncomplex reasoning tasks. In this paper, we apply federated learning to complex\nquery-answering tasks to reason over multi-source knowledge graphs while\npreserving privacy. We propose a Federated Complex Query Answering framework\n(FedCQA), to reason over multi-source KGs avoiding sensitive raw data\ntransmission to protect privacy. We conduct extensive experiments on three\nreal-world datasets and evaluate retrieval performance on various types of\ncomplex queries.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14609v2",
    "authors": [
      "Qi Hu",
      "Weifeng Jiang",
      "Haoran Li",
      "Zihao Wang",
      "Jiaxin Bai",
      "Qianren Mao",
      "Yangqiu Song",
      "Lixin Fan",
      "Jianxin Li"
    ]
  },
  {
    "id": "2402.14622",
    "title": "From Keywords to Structured Summaries: Streamlining Scholarly Knowledge\n  Access",
    "abstract": "  This short paper highlights the growing importance of information retrieval\n(IR) engines in the scientific community, addressing the inefficiency of\ntraditional keyword-based search engines due to the rising volume of\npublications. The proposed solution involves structured records, underpinning\nadvanced information technology (IT) tools, including visualization dashboards,\nto revolutionize how researchers access and filter articles, replacing the\ntraditional text-heavy approach. This vision is exemplified through a proof of\nconcept centered on the ``reproductive number estimate of infectious diseases''\nresearch theme, using a fine-tuned large language model (LLM) to automate the\ncreation of structured records to populate a backend database that now goes\nbeyond keywords. The result is a next-generation IR method accessible at\nhttps://orkg.org/usecases/r0-estimates.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14622v1",
    "authors": ["Mahsa Shamsabadi", "Jennifer D'Souza"]
  },
  {
    "id": "2402.14623",
    "title": "RoboScript: Code Generation for Free-Form Manipulation Tasks across Real\n  and Simulation",
    "abstract": "  Rapid progress in high-level task planning and code generation for open-world\nrobot manipulation has been witnessed in Embodied AI. However, previous studies\nput much effort into general common sense reasoning and task planning\ncapabilities of large-scale language or multi-modal models, relatively little\neffort on ensuring the deployability of generated code on real robots, and\nother fundamental components of autonomous robot systems including robot\nperception, motion planning, and control. To bridge this ``ideal-to-real'' gap,\nthis paper presents \\textbf{RobotScript}, a platform for 1) a deployable robot\nmanipulation pipeline powered by code generation; and 2) a code generation\nbenchmark for robot manipulation tasks in free-form natural language. The\nRobotScript platform addresses this gap by emphasizing the unified interface\nwith both simulation and real robots, based on abstraction from the Robot\nOperating System (ROS), ensuring syntax compliance and simulation validation\nwith Gazebo. We demonstrate the adaptability of our code generation framework\nacross multiple robot embodiments, including the Franka and UR5 robot arms, and\nmultiple grippers. Additionally, our benchmark assesses reasoning abilities for\nphysical space and constraints, highlighting the differences between GPT-3.5,\nGPT-4, and Gemini in handling complex physical interactions. Finally, we\npresent a thorough evaluation on the whole system, exploring how each module in\nthe pipeline: code generation, perception, motion planning, and even object\ngeometric properties, impact the overall performance of the system.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14623v1",
    "authors": [
      "Junting Chen",
      "Yao Mu",
      "Qiaojun Yu",
      "Tianming Wei",
      "Silang Wu",
      "Zhecheng Yuan",
      "Zhixuan Liang",
      "Chao Yang",
      "Kaipeng Zhang",
      "Wenqi Shao",
      "Yu Qiao",
      "Huazhe Xu",
      "Mingyu Ding",
      "Ping Luo"
    ]
  },
  {
    "id": "2402.14658",
    "title": "OpenCodeInterpreter: Integrating Code Generation with Execution and\n  Refinement",
    "abstract": "  The introduction of large language models has significantly advanced code\ngeneration. However, open-source models often lack the execution capabilities\nand iterative refinement of advanced systems like the GPT-4 Code Interpreter.\nTo address this, we introduce OpenCodeInterpreter, a family of open-source code\nsystems designed for generating, executing, and iteratively refining code.\nSupported by Code-Feedback, a dataset featuring 68K multi-turn interactions,\nOpenCodeInterpreter integrates execution and human feedback for dynamic code\nrefinement. Our comprehensive evaluation of OpenCodeInterpreter across key\nbenchmarks such as HumanEval, MBPP, and their enhanced versions from EvalPlus\nreveals its exceptional performance. Notably, OpenCodeInterpreter-33B achieves\nan accuracy of 83.2 (76.4) on the average (and plus versions) of HumanEval and\nMBPP, closely rivaling GPT-4's 84.2 (76.2) and further elevates to 91.6 (84.6)\nwith synthesized human feedback from GPT-4. OpenCodeInterpreter brings the gap\nbetween open-source code generation models and proprietary systems like GPT-4\nCode Interpreter.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14658v2",
    "authors": [
      "Tianyu Zheng",
      "Ge Zhang",
      "Tianhao Shen",
      "Xueling Liu",
      "Bill Yuchen Lin",
      "Jie Fu",
      "Wenhu Chen",
      "Xiang Yue"
    ]
  },
  {
    "id": "2402.14664",
    "title": "Bayesian Off-Policy Evaluation and Learning for Large Action Spaces",
    "abstract": "  In interactive systems, actions are often correlated, presenting an\nopportunity for more sample-efficient off-policy evaluation (OPE) and learning\n(OPL) in large action spaces. We introduce a unified Bayesian framework to\ncapture these correlations through structured and informative priors. In this\nframework, we propose sDM, a generic Bayesian approach designed for OPE and\nOPL, grounded in both algorithmic and theoretical foundations. Notably, sDM\nleverages action correlations without compromising computational efficiency.\nMoreover, inspired by online Bayesian bandits, we introduce Bayesian metrics\nthat assess the average performance of algorithms across multiple problem\ninstances, deviating from the conventional worst-case assessments. We analyze\nsDM in OPE and OPL, highlighting the benefits of leveraging action\ncorrelations. Empirical evidence showcases the strong performance of sDM.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14664v1",
    "authors": ["Imad Aouali", "Victor-Emmanuel Brunel", "David Rohde", "Anna Korba"]
  },
  {
    "id": "2402.14683",
    "title": "Visual Hallucinations of Multi-modal Large Language Models",
    "abstract": "  Visual hallucination (VH) means that a multi-modal LLM (MLLM) imagines\nincorrect details about an image in visual question answering. Existing studies\nfind VH instances only in existing image datasets, which results in biased\nunderstanding of MLLMs' performance under VH due to limited diversity of such\nVH instances. In this work, we propose a tool called VHTest to generate a\ndiverse set of VH instances. Specifically, VHTest finds some initial VH\ninstances in existing image datasets (e.g., COCO), generates a text description\nfor each VH mode, and uses a text-to-image generative model (e.g., DALL-E-3) to\ngenerate VH images based on the text descriptions. We collect a benchmark\ndataset with 1,200 VH instances in 8 VH modes using VHTest. We find that\nexisting MLLMs such as GPT-4V, LLaVA-1.5, and MiniGPT-v2 hallucinate for a\nlarge fraction of the instances in our benchmark. Moreover, we find that\nfine-tuning an MLLM using our benchmark dataset reduces its likelihood to\nhallucinate without sacrificing its performance on other benchmarks. Our\nbenchmarks are publicly available: https://github.com/wenhuang2000/VHTest.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14683v1",
    "authors": ["Wen Huang", "Hongbin Liu", "Minxin Guo", "Neil Zhenqiang Gong"]
  },
  {
    "id": "2402.14703",
    "title": "On the Curses of Future and History in Future-dependent Value Functions\n  for Off-policy Evaluation",
    "abstract": "  We study off-policy evaluation (OPE) in partially observable environments\nwith complex observations, with the goal of developing estimators whose\nguarantee avoids exponential dependence on the horizon. While such estimators\nexist for MDPs and POMDPs can be converted to history-based MDPs, their\nestimation errors depend on the state-density ratio for MDPs which becomes\nhistory ratios after conversion, an exponential object. Recently, Uehara et al.\n(2022) proposed future-dependent value functions as a promising framework to\naddress this issue, where the guarantee for memoryless policies depends on the\ndensity ratio over the latent state space. However, it also depends on the\nboundedness of the future-dependent value function and other related\nquantities, which we show could be exponential-in-length and thus erasing the\nadvantage of the method. In this paper, we discover novel coverage assumptions\ntailored to the structure of POMDPs, such as outcome coverage and belief\ncoverage. These assumptions not only enable polynomial bounds on the\naforementioned quantities, but also lead to the discovery of new algorithms\nwith complementary properties.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14703v1",
    "authors": ["Yuheng Zhang", "Nan Jiang"]
  },
  {
    "id": "2402.14708",
    "title": "CaT-GNN: Enhancing Credit Card Fraud Detection via Causal Temporal Graph\n  Neural Networks",
    "abstract": "  Credit card fraud poses a significant threat to the economy. While Graph\nNeural Network (GNN)-based fraud detection methods perform well, they often\noverlook the causal effect of a node's local structure on predictions. This\npaper introduces a novel method for credit card fraud detection, the\n\\textbf{\\underline{Ca}}usal \\textbf{\\underline{T}}emporal\n\\textbf{\\underline{G}}raph \\textbf{\\underline{N}}eural \\textbf{N}etwork\n(CaT-GNN), which leverages causal invariant learning to reveal inherent\ncorrelations within transaction data. By decomposing the problem into discovery\nand intervention phases, CaT-GNN identifies causal nodes within the transaction\ngraph and applies a causal mixup strategy to enhance the model's robustness and\ninterpretability. CaT-GNN consists of two key components: Causal-Inspector and\nCausal-Intervener. The Causal-Inspector utilizes attention weights in the\ntemporal attention mechanism to identify causal and environment nodes without\nintroducing additional parameters. Subsequently, the Causal-Intervener performs\na causal mixup enhancement on environment nodes based on the set of nodes.\nEvaluated on three datasets, including a private financial dataset and two\npublic datasets, CaT-GNN demonstrates superior performance over existing\nstate-of-the-art methods. Our findings highlight the potential of integrating\ncausal reasoning with graph neural networks to improve fraud detection\ncapabilities in financial transactions.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14708v1",
    "authors": [
      "Yifan Duan",
      "Guibin Zhang",
      "Shilong Wang",
      "Xiaojiang Peng",
      "Wang Ziqi",
      "Junyuan Mao",
      "Hao Wu",
      "Xinke Jiang",
      "Kun Wang"
    ]
  },
  {
    "id": "2402.14726",
    "title": "Incorporating Expert Rules into Neural Networks in the Framework of\n  Concept-Based Learning",
    "abstract": "  A problem of incorporating the expert rules into machine learning models for\nextending the concept-based learning is formulated in the paper. It is proposed\nhow to combine logical rules and neural networks predicting the concept\nprobabilities. The first idea behind the combination is to form constraints for\na joint probability distribution over all combinations of concept values to\nsatisfy the expert rules. The second idea is to represent a feasible set of\nprobability distributions in the form of a convex polytope and to use its\nvertices or faces. We provide several approaches for solving the stated problem\nand for training neural networks which guarantee that the output probabilities\nof concepts would not violate the expert rules. The solution of the problem can\nbe viewed as a way for combining the inductive and deductive learning. Expert\nrules are used in a broader sense when any logical function that connects\nconcepts and class labels or just concepts with each other can be regarded as a\nrule. This feature significantly expands the class of the proposed results.\nNumerical examples illustrate the approaches. The code of proposed algorithms\nis publicly available.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14726v1",
    "authors": ["Andrei V. Konstantinov", "Lev V. Utkin"]
  },
  {
    "id": "2402.14744",
    "title": "Large Language Models as Urban Residents: An LLM Agent Framework for\n  Personal Mobility Generation",
    "abstract": "  This paper introduces a novel approach using Large Language Models (LLMs)\nintegrated into an agent framework for flexible and efficient personal mobility\ngeneration. LLMs overcome the limitations of previous models by efficiently\nprocessing semantic data and offering versatility in modeling various tasks.\nOur approach addresses the critical need to align LLMs with real-world urban\nmobility data, focusing on three research questions: aligning LLMs with rich\nactivity data, developing reliable activity generation strategies, and\nexploring LLM applications in urban mobility. The key technical contribution is\na novel LLM agent framework that accounts for individual activity patterns and\nmotivations, including a self-consistency approach to align LLMs with\nreal-world activity data and a retrieval-augmented strategy for interpretable\nactivity generation. In experimental studies, comprehensive validation is\nperformed using real-world data. This research marks the pioneering work of\ndesigning an LLM agent framework for activity generation based on real-world\nhuman activity data, offering a promising tool for urban mobility analysis.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14744v1",
    "authors": [
      "Jiawei Wang",
      "Renhe Jiang",
      "Chuang Yang",
      "Zengqing Wu",
      "Makoto Onizuka",
      "Ryosuke Shibasaki",
      "Chuan Xiao"
    ]
  },
  {
    "id": "2402.14753",
    "title": "Prompting a Pretrained Transformer Can Be a Universal Approximator",
    "abstract": "  Despite the widespread adoption of prompting, prompt tuning and prefix-tuning\nof transformer models, our theoretical understanding of these fine-tuning\nmethods remains limited. A key question is whether one can arbitrarily modify\nthe behavior of pretrained model by prompting or prefix-tuning it. Formally,\nwhether prompting and prefix-tuning a pretrained model can universally\napproximate sequence-to-sequence functions. This paper answers in the\naffirmative and demonstrates that much smaller pretrained models than\npreviously thought can be universal approximators when prefixed. In fact, the\nattention mechanism is uniquely suited for universal approximation with\nprefix-tuning a single attention head being sufficient to approximate any\ncontinuous function. Moreover, any sequence-to-sequence function can be\napproximated by prefixing a transformer with depth linear in the sequence\nlength. Beyond these density-type results, we also offer Jackson-type bounds on\nthe length of the prefix needed to approximate a function to a desired\nprecision.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14753v1",
    "authors": ["Aleksandar Petrov", "Philip H. S. Torr", "Adel Bibi"]
  },
  {
    "id": "2402.14758",
    "title": "Batch and match: black-box variational inference with a score-based\n  divergence",
    "abstract": "  Most leading implementations of black-box variational inference (BBVI) are\nbased on optimizing a stochastic evidence lower bound (ELBO). But such\napproaches to BBVI often converge slowly due to the high variance of their\ngradient estimates. In this work, we propose batch and match (BaM), an\nalternative approach to BBVI based on a score-based divergence. Notably, this\nscore-based divergence can be optimized by a closed-form proximal update for\nGaussian variational families with full covariance matrices. We analyze the\nconvergence of BaM when the target distribution is Gaussian, and we prove that\nin the limit of infinite batch size the variational parameter updates converge\nexponentially quickly to the target mean and covariance. We also evaluate the\nperformance of BaM on Gaussian and non-Gaussian target distributions that arise\nfrom posterior inference in hierarchical and deep generative models. In these\nexperiments, we find that BaM typically converges in fewer (and sometimes\nsignificantly fewer) gradient evaluations than leading implementations of BBVI\nbased on ELBO maximization.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14758v1",
    "authors": [
      "Diana Cai",
      "Chirag Modi",
      "Loucas Pillaud-Vivien",
      "Charles C. Margossian",
      "Robert M. Gower",
      "David M. Blei",
      "Lawrence K. Saul"
    ]
  },
  {
    "id": "2402.14759",
    "title": "Generalising realisability in statistical learning theory under\n  epistemic uncertainty",
    "abstract": "  The purpose of this paper is to look into how central notions in statistical\nlearning theory, such as realisability, generalise under the assumption that\ntrain and test distribution are issued from the same credal set, i.e., a convex\nset of probability distributions. This can be considered as a first step\ntowards a more general treatment of statistical learning under epistemic\nuncertainty.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14759v1",
    "authors": ["Fabio Cuzzolin"]
  },
  {
    "id": "2402.14781",
    "title": "Rao-Blackwellising Bayesian Causal Inference",
    "abstract": "  Bayesian causal inference, i.e., inferring a posterior over causal models for\nthe use in downstream causal reasoning tasks, poses a hard computational\ninference problem that is little explored in literature. In this work, we\ncombine techniques from order-based MCMC structure learning with recent\nadvances in gradient-based graph learning into an effective Bayesian causal\ninference framework. Specifically, we decompose the problem of inferring the\ncausal structure into (i) inferring a topological order over variables and (ii)\ninferring the parent sets for each variable. When limiting the number of\nparents per variable, we can exactly marginalise over the parent sets in\npolynomial time. We further use Gaussian processes to model the unknown causal\nmechanisms, which also allows their exact marginalisation. This introduces a\nRao-Blackwellization scheme, where all components are eliminated from the\nmodel, except for the causal order, for which we learn a distribution via\ngradient-based optimisation. The combination of Rao-Blackwellization with our\nsequential inference procedure for causal orders yields state-of-the-art on\nlinear and non-linear additive noise benchmarks with scale-free and Erdos-Renyi\ngraph structures.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14781v1",
    "authors": ["Christian Toth", "Christian Knoll", "Franz Pernkopf", "Robert Peharz"]
  },
  {
    "id": "2402.14800",
    "title": "Not All Experts are Equal: Efficient Expert Pruning and Skipping for\n  Mixture-of-Experts Large Language Models",
    "abstract": "  A pivotal advancement in the progress of large language models (LLMs) is the\nemergence of the Mixture-of-Experts (MoE) LLMs. Compared to traditional LLMs,\nMoE LLMs can achieve higher performance with fewer parameters, but it is still\nhard to deploy them due to their immense parameter sizes. Different from\nprevious weight pruning methods that rely on specifically designed hardware,\nthis paper mainly aims to enhance the deployment efficiency of MoE LLMs by\nintroducing plug-and-play expert-level sparsification techniques. Specifically,\nwe propose, for the first time to our best knowledge, post-training approaches\nfor task-agnostic and task-specific expert pruning and skipping of MoE LLMs,\ntailored to improve deployment efficiency while maintaining model performance\nacross a wide range of tasks. Extensive experiments show that our proposed\nmethods can simultaneously reduce model sizes and increase the inference speed,\nwhile maintaining satisfactory performance. Data and code will be available at\nhttps://github.com/Lucky-Lance/Expert_Sparsity.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14800v1",
    "authors": [
      "Xudong Lu",
      "Qi Liu",
      "Yuhui Xu",
      "Aojun Zhou",
      "Siyuan Huang",
      "Bo Zhang",
      "Junchi Yan",
      "Hongsheng Li"
    ]
  },
  {
    "id": "2402.14807",
    "title": "A Decision-Language Model (DLM) for Dynamic Restless Multi-Armed Bandit\n  Tasks in Public Health",
    "abstract": "  Efforts to reduce maternal mortality rate, a key UN Sustainable Development\ntarget (SDG Target 3.1), rely largely on preventative care programs to spread\ncritical health information to high-risk populations. These programs face two\nimportant challenges: efficiently allocating limited health resources to large\nbeneficiary populations, and adapting to evolving policy priorities. While\nprior works in restless multi-armed bandit (RMAB) demonstrated success in\npublic health allocation tasks, they lack flexibility to adapt to evolving\npolicy priorities. Concurrently, Large Language Models (LLMs) have emerged as\nadept, automated planners in various domains, including robotic control and\nnavigation. In this paper, we propose DLM: a Decision Language Model for RMABs.\nTo enable dynamic fine-tuning of RMAB policies for challenging public health\nsettings using human-language commands, we propose using LLMs as automated\nplanners to (1) interpret human policy preference prompts, (2) propose code\nreward functions for a multi-agent RL environment for RMABs, and (3) iterate on\nthe generated reward using feedback from RMAB simulations to effectively adapt\npolicy outcomes. In collaboration with ARMMAN, an India-based public health\norganization promoting preventative care for pregnant mothers, we conduct a\nsimulation study, showing DLM can dynamically shape policy outcomes using only\nhuman language commands as input.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14807v2",
    "authors": [
      "Nikhil Behari",
      "Edwin Zhang",
      "Yunfan Zhao",
      "Aparna Taneja",
      "Dheeraj Nagaraj",
      "Milind Tambe"
    ]
  },
  {
    "id": "2402.14809",
    "title": "CriticBench: Benchmarking LLMs for Critique-Correct Reasoning",
    "abstract": "  The ability of Large Language Models (LLMs) to critique and refine their\nreasoning is crucial for their application in evaluation, feedback provision,\nand self-improvement. This paper introduces CriticBench, a comprehensive\nbenchmark designed to assess LLMs' abilities to critique and rectify their\nreasoning across a variety of tasks. CriticBench encompasses five reasoning\ndomains: mathematical, commonsense, symbolic, coding, and algorithmic. It\ncompiles 15 datasets and incorporates responses from three LLM families.\nUtilizing CriticBench, we evaluate and dissect the performance of 17 LLMs in\ngeneration, critique, and correction reasoning, i.e., GQC reasoning. Our\nfindings reveal: (1) a linear relationship in GQC capabilities, with\ncritique-focused training markedly enhancing performance; (2) a task-dependent\nvariation in correction effectiveness, with logic-oriented tasks being more\namenable to correction; (3) GQC knowledge inconsistencies that decrease as\nmodel size increases; and (4) an intriguing inter-model critiquing dynamic,\nwhere stronger models are better at critiquing weaker ones, while weaker models\ncan surprisingly surpass stronger ones in their self-critique. We hope these\ninsights into the nuanced critique-correct reasoning of LLMs will foster\nfurther research in LLM critique and self-improvement.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14809v1",
    "authors": ["Zicheng Lin", "Zhibin Gou", "Tian Liang", "Ruilin Luo", "Haowei Liu", "Yujiu Yang"]
  },
  {
    "id": "2402.14810",
    "title": "GeneOH Diffusion: Towards Generalizable Hand-Object Interaction\n  Denoising via Denoising Diffusion",
    "abstract": "  In this work, we tackle the challenging problem of denoising hand-object\ninteractions (HOI). Given an erroneous interaction sequence, the objective is\nto refine the incorrect hand trajectory to remove interaction artifacts for a\nperceptually realistic sequence. This challenge involves intricate interaction\nnoise, including unnatural hand poses and incorrect hand-object relations,\nalongside the necessity for robust generalization to new interactions and\ndiverse noise patterns. We tackle those challenges through a novel approach,\nGeneOH Diffusion, incorporating two key designs: an innovative contact-centric\nHOI representation named GeneOH and a new domain-generalizable denoising\nscheme. The contact-centric representation GeneOH informatively parameterizes\nthe HOI process, facilitating enhanced generalization across various HOI\nscenarios. The new denoising scheme consists of a canonical denoising model\ntrained to project noisy data samples from a whitened noise space to a clean\ndata manifold and a \"denoising via diffusion\" strategy which can handle input\ntrajectories with various noise patterns by first diffusing them to align with\nthe whitened noise space and cleaning via the canonical denoiser. Extensive\nexperiments on four benchmarks with significant domain variations demonstrate\nthe superior effectiveness of our method. GeneOH Diffusion also shows promise\nfor various downstream applications. Project website:\nhttps://meowuu7.github.io/GeneOH-Diffusion/.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14810v1",
    "authors": ["Xueyi Liu", "Li Yi"]
  },
  {
    "id": "2402.14815",
    "title": "Demographic Bias of Expert-Level Vision-Language Foundation Models in\n  Medical Imaging",
    "abstract": "  Advances in artificial intelligence (AI) have achieved expert-level\nperformance in medical imaging applications. Notably, self-supervised\nvision-language foundation models can detect a broad spectrum of pathologies\nwithout relying on explicit training annotations. However, it is crucial to\nensure that these AI models do not mirror or amplify human biases, thereby\ndisadvantaging historically marginalized groups such as females or Black\npatients. The manifestation of such biases could systematically delay essential\nmedical care for certain patient subgroups. In this study, we investigate the\nalgorithmic fairness of state-of-the-art vision-language foundation models in\nchest X-ray diagnosis across five globally-sourced datasets. Our findings\nreveal that compared to board-certified radiologists, these foundation models\nconsistently underdiagnose marginalized groups, with even higher rates seen in\nintersectional subgroups, such as Black female patients. Such demographic\nbiases present over a wide range of pathologies and demographic attributes.\nFurther analysis of the model embedding uncovers its significant encoding of\ndemographic information. Deploying AI systems with these biases in medical\nimaging can intensify pre-existing care disparities, posing potential\nchallenges to equitable healthcare access and raising ethical questions about\ntheir clinical application.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14815v1",
    "authors": [
      "Yuzhe Yang",
      "Yujia Liu",
      "Xin Liu",
      "Avanti Gulhane",
      "Domenico Mastrodicasa",
      "Wei Wu",
      "Edward J Wang",
      "Dushyant W Sahani",
      "Shwetak Patel"
    ]
  },
  {
    "id": "2402.14882",
    "title": "Deep Generative Model-based Synthesis of Four-bar Linkage Mechanisms\n  with Target Conditions",
    "abstract": "  Mechanisms are essential components designed to perform specific tasks in\nvarious mechanical systems. However, designing a mechanism that satisfies\ncertain kinematic or quasi-static requirements is a challenging task. The\nkinematic requirements may include the workspace of a mechanism, while the\nquasi-static requirements of a mechanism may include its torque transmission,\nwhich refers to the ability of the mechanism to transfer power and torque\neffectively. In this paper, we propose a deep learning-based generative model\nfor generating multiple crank-rocker four-bar linkage mechanisms that satisfy\nboth the kinematic and quasi-static requirements aforementioned. The proposed\nmodel is based on a conditional generative adversarial network (cGAN) with\nmodifications for mechanism synthesis, which is trained to learn the\nrelationship between the requirements of a mechanism with respect to linkage\nlengths. The results demonstrate that the proposed model successfully generates\nmultiple distinct mechanisms that satisfy specific kinematic and quasi-static\nrequirements. To evaluate the novelty of our approach, we provide a comparison\nof the samples synthesized by the proposed cGAN, traditional cVAE and NSGA-II.\nOur approach has several advantages over traditional design methods. It enables\ndesigners to efficiently generate multiple diverse and feasible design\ncandidates while exploring a large design space. Also, the proposed model\nconsiders both the kinematic and quasi-static requirements, which can lead to\nmore efficient and effective mechanisms for real-world use, making it a\npromising tool for linkage mechanism design.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14882v1",
    "authors": ["Sumin Lee", "Jihoon Kim", "Namwoo Kang"]
  },
  {
    "id": "2402.14883",
    "title": "Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning",
    "abstract": "  To support various applications, business owners often seek the customized\nmodels that are obtained by fine-tuning a pre-trained LLM through the API\nprovided by LLM owners or cloud servers. However, this process carries a\nsubstantial risk of model misuse, potentially resulting in severe economic\nconsequences for business owners. Thus, safeguarding the copyright of these\ncustomized models during LLM fine-tuning has become an urgent practical\nrequirement, but there are limited existing solutions to provide such\nprotection. To tackle this pressing issue, we propose a novel watermarking\napproach named \"Double-I watermark\". Specifically, based on the instruct-tuning\ndata, two types of backdoor data paradigms are introduced with trigger in the\ninstruction and the input, respectively. By leveraging LLM's learning\ncapability to incorporate customized backdoor samples into the dataset, the\nproposed approach effectively injects specific watermarking information into\nthe customized model during fine-tuning, which makes it easy to inject and\nverify watermarks in commercial scenarios. We evaluate the proposed \"Double-I\nwatermark\" under various fine-tuning methods, demonstrating its harmlessness,\nrobustness, uniqueness, imperceptibility, and validity through both theoretical\nanalysis and experimental verification.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14883v1",
    "authors": ["Shen Li", "Liuyi Yao", "Jinyang Gao", "Lan Zhang", "Yaliang Li"]
  },
  {
    "id": "2402.14888",
    "title": "Efficient data selection employing Semantic Similarity-based Graph\n  Structures for model training",
    "abstract": "  Recent developments in natural language processing (NLP) have highlighted the\nneed for substantial amounts of data for models to capture textual information\naccurately. This raises concerns regarding the computational resources and time\nrequired for training such models. This paper introduces Semantics for data\nSAliency in Model performance Estimation (SeSaME). It is an efficient data\nsampling mechanism solely based on textual information without passing the data\nthrough a compute-heavy model or other intensive pre-processing\ntransformations. The application of this approach is demonstrated in the use\ncase of low-resource automated speech recognition (ASR) models, which\nexcessively rely on text-to-speech (TTS) calls when using augmented data.\nSeSaME learns to categorize new incoming data points into speech recognition\ndifficulty buckets by employing semantic similarity-based graph structures and\ndiscrete ASR information from homophilous neighbourhoods through message\npassing. The results indicate reliable projections of ASR performance, with a\n93% accuracy increase when using the proposed method compared to random\npredictions, bringing non-trivial information on the impact of textual\nrepresentations in speech models. Furthermore, a series of experiments show\nboth the benefits and challenges of using the ASR information on incoming data\nto fine-tune the model. We report a 7% drop in validation loss compared to\nrandom sampling, 7% WER drop with non-local aggregation when evaluating against\na highly difficult dataset, and 1.8% WER drop with local aggregation and high\nsemantic similarity between datasets.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14888v1",
    "authors": ["Roxana Petcu", "Subhadeep Maji"]
  },
  {
    "id": "2402.14890",
    "title": "Vygotsky Distance: Measure for Benchmark Task Similarity",
    "abstract": "  Evaluation plays a significant role in modern natural language processing.\nMost modern NLP benchmarks consist of arbitrary sets of tasks that neither\nguarantee any generalization potential for the model once applied outside the\ntest set nor try to minimize the resource consumption needed for model\nevaluation. This paper presents a theoretical instrument and a practical\nalgorithm to calculate similarity between benchmark tasks, we call this\nsimilarity measure \"Vygotsky distance\". The core idea of this similarity\nmeasure is that it is based on relative performance of the \"students\" on a\ngiven task, rather that on the properties of the task itself. If two tasks are\nclose to each other in terms of Vygotsky distance the models tend to have\nsimilar relative performance on them. Thus knowing Vygotsky distance between\ntasks one can significantly reduce the number of evaluation tasks while\nmaintaining a high validation quality. Experiments on various benchmarks,\nincluding GLUE, SuperGLUE, CLUE, and RussianSuperGLUE, demonstrate that a vast\nmajority of NLP benchmarks could be at least 40% smaller in terms of the tasks\nincluded. Most importantly, Vygotsky distance could also be used for the\nvalidation of new tasks thus increasing the generalization potential of the\nfuture NLP models.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14890v2",
    "authors": ["Maxim K. Surkov", "Ivan P. Yamshchikov"]
  },
  {
    "id": "2402.14895",
    "title": "Data Augmentation is Dead, Long Live Data Augmentation",
    "abstract": "  Textual data augmentation (DA) is a prolific field of study where novel\ntechniques to create artificial data are regularly proposed, and that has\ndemonstrated great efficiency on small data settings, at least for text\nclassification tasks. In this paper, we challenge those results, showing that\nclassical data augmentation is simply a way of performing better fine-tuning,\nand that spending more time fine-tuning before applying data augmentation\nnegates its effect. This is a significant contribution as it answers several\nquestions that were left open in recent years, namely~: which DA technique\nperforms best (all of them as long as they generate data close enough to the\ntraining set as to not impair training) and why did DA show positive results\n(facilitates training of network). We furthermore show that zero and few-shot\ndata generation via conversational agents such as ChatGPT or LLama2 can\nincrease performances, concluding that this form of data augmentation does\nstill work, even if classical methods do not.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14895v1",
    "authors": ["Frédéric Piedboeuf", "Philippe Langlais"]
  },
  {
    "id": "2402.14897",
    "title": "Chain-of-Thought Unfaithfulness as Disguised Accuracy",
    "abstract": "  Understanding the extent to which Chain-of-Thought (CoT) generations align\nwith a large language model's (LLM) internal computations is critical for\ndeciding whether to trust an LLM's output. As a proxy for CoT faithfulness,\narXiv:2307.13702 propose a metric that measures a model's dependence on its CoT\nfor producing an answer. Within a single family of proprietary models, they\nfind that LLMs exhibit a scaling-then-inverse-scaling relationship between\nmodel size and their measure of faithfulness, and that a 13 billion parameter\nmodel exhibits increased faithfulness compared to models ranging from 810\nmillion to 175 billion parameters in size. We evaluate whether these results\ngeneralize as a property of all LLMs. We replicate their experimental setup\nwith three different families of models and, under specific conditions,\nsuccessfully reproduce the scaling trends for CoT faithfulness they report.\nHowever, we discover that simply changing the order of answer choices in the\nprompt can reduce the metric by 73 percentage points. The faithfulness metric\nis also highly correlated ($R^2$ = 0.91) with accuracy, raising doubts about\nits validity as a construct for evaluating faithfulness.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14897v1",
    "authors": ["Oliver Bentham", "Nathan Stringham", "Ana Marasović"]
  },
  {
    "id": "2402.14899",
    "title": "Stop Reasoning! When Multimodal LLMs with Chain-of-Thought Reasoning\n  Meets Adversarial Images",
    "abstract": "  Recently, Multimodal LLMs (MLLMs) have shown a great ability to understand\nimages. However, like traditional vision models, they are still vulnerable to\nadversarial images. Meanwhile, Chain-of-Thought (CoT) reasoning has been widely\nexplored on MLLMs, which not only improves model's performance, but also\nenhances model's explainability by giving intermediate reasoning steps.\nNevertheless, there is still a lack of study regarding MLLMs' adversarial\nrobustness with CoT and an understanding of what the rationale looks like when\nMLLMs infer wrong answers with adversarial images. Our research evaluates the\nadversarial robustness of MLLMs when employing CoT reasoning, finding that CoT\nmarginally improves adversarial robustness against existing attack methods.\nMoreover, we introduce a novel stop-reasoning attack technique that effectively\nbypasses the CoT-induced robustness enhancements. Finally, we demonstrate the\nalterations in CoT reasoning when MLLMs confront adversarial images, shedding\nlight on their reasoning process under adversarial attacks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14899v1",
    "authors": [
      "Zefeng Wang",
      "Zhen Han",
      "Shuo Chen",
      "Fan Xue",
      "Zifeng Ding",
      "Xun Xiao",
      "Volker Tresp",
      "Philip Torr",
      "Jindong Gu"
    ]
  },
  {
    "id": "2402.14904",
    "title": "Watermarking Makes Language Models Radioactive",
    "abstract": "  This paper investigates the radioactivity of LLM-generated texts, i.e.\nwhether it is possible to detect that such input was used as training data.\nConventional methods like membership inference can carry out this detection\nwith some level of accuracy. We show that watermarked training data leaves\ntraces easier to detect and much more reliable than membership inference. We\nlink the contamination level to the watermark robustness, its proportion in the\ntraining set, and the fine-tuning process. We notably demonstrate that training\non watermarked synthetic instructions can be detected with high confidence\n(p-value < 1e-5) even when as little as 5% of training text is watermarked.\nThus, LLM watermarking, originally designed for detecting machine-generated\ntext, gives the ability to easily identify if the outputs of a watermarked LLM\nwere used to fine-tune another LLM.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14904v1",
    "authors": ["Tom Sander", "Pierre Fernandez", "Alain Durmus", "Matthijs Douze", "Teddy Furon"]
  },
  {
    "id": "2402.14905",
    "title": "MobileLLM: Optimizing Sub-billion Parameter Language Models for\n  On-Device Use Cases",
    "abstract": "  This paper addresses the growing need for efficient large language models\n(LLMs) on mobile devices, driven by increasing cloud costs and latency\nconcerns. We focus on designing top-quality LLMs with fewer than a billion\nparameters, a practical choice for mobile deployment. Contrary to prevailing\nbelief emphasizing the pivotal role of data and parameter quantity in\ndetermining model quality, our investigation underscores the significance of\nmodel architecture for sub-billion scale LLMs. Leveraging deep and thin\narchitectures, coupled with embedding sharing and grouped-query attention\nmechanisms, we establish a strong baseline network denoted as MobileLLM, which\nattains a remarkable 2.7%/4.3% accuracy boost over preceding 125M/350M\nstate-of-the-art models. Additionally, we propose an immediate block-wise\nweight sharing approach with no increase in model size and only marginal\nlatency overhead. The resultant models, denoted as MobileLLM-LS, demonstrate a\nfurther accuracy enhancement of 0.7%/0.8% than MobileLLM 125M/350M. Moreover,\nMobileLLM model family shows significant improvements compared to previous\nsub-billion models on chat benchmarks, and demonstrates close correctness to\nLLaMA-v2 7B in API calling tasks, highlighting the capability of small models\nfor common on-device use cases.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14905v1",
    "authors": [
      "Zechun Liu",
      "Changsheng Zhao",
      "Forrest Iandola",
      "Chen Lai",
      "Yuandong Tian",
      "Igor Fedorov",
      "Yunyang Xiong",
      "Ernie Chang",
      "Yangyang Shi",
      "Raghuraman Krishnamoorthi",
      "Liangzhen Lai",
      "Vikas Chandra"
    ]
  },
  {
    "id": "2402.14928",
    "title": "Learning Inverse Kinodynamics for Autonomous Vehicle Drifting",
    "abstract": "  In this work, we explore a data-driven learning-based approach to learning\nthe kinodynamic model of a small autonomous vehicle, and observe the effect it\nhas on motion planning, specifically autonomous drifting. When executing a\nmotion plan in the real world, there are numerous causes for error, and what is\nplanned is often not what is executed on the actual car. Learning a kinodynamic\nplanner based off of inertial measurements and executed commands can help us\nlearn the world state. In our case, we look towards the realm of drifting; it\nis a complex maneuver that requires a smooth enough surface, high enough speed,\nand a drastic change in velocity. We attempt to learn the kinodynamic model for\nthese drifting maneuvers, and attempt to tighten the slip of the car. Our\napproach is able to learn a kinodynamic model for high-speed circular\nnavigation, and is able to avoid obstacles on an autonomous drift at high speed\nby correcting an executed curvature for loose drifts. We seek to adjust our\nkinodynamic model for success in tighter drifts in future work.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14928v1",
    "authors": ["M. Suvarna", "O. Tehrani"]
  },
  {
    "id": "2402.14929",
    "title": "Federated Fairness without Access to Sensitive Groups",
    "abstract": "  Current approaches to group fairness in federated learning assume the\nexistence of predefined and labeled sensitive groups during training. However,\ndue to factors ranging from emerging regulations to dynamics and\nlocation-dependency of protected groups, this assumption may be unsuitable in\nmany real-world scenarios. In this work, we propose a new approach to guarantee\ngroup fairness that does not rely on any predefined definition of sensitive\ngroups or additional labels. Our objective allows the federation to learn a\nPareto efficient global model ensuring worst-case group fairness and it\nenables, via a single hyper-parameter, trade-offs between fairness and utility,\nsubject only to a group size constraint. This implies that any sufficiently\nlarge subset of the population is guaranteed to receive at least a minimum\nlevel of utility performance from the model. The proposed objective encompasses\nexisting approaches as special cases, such as empirical risk minimization and\nsubgroup robustness objectives from centralized machine learning. We provide an\nalgorithm to solve this problem in federation that enjoys convergence and\nexcess risk guarantees. Our empirical results indicate that the proposed\napproach can effectively improve the worst-performing group that may be present\nwithout unnecessarily hurting the average performance, exhibits superior or\ncomparable performance to relevant baselines, and achieves a large set of\nsolutions with different fairness-utility trade-offs.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14929v1",
    "authors": [
      "Afroditi Papadaki",
      "Natalia Martinez",
      "Martin Bertran",
      "Guillermo Sapiro",
      "Miguel Rodrigues"
    ]
  },
  {
    "id": "2402.14973",
    "title": "GenCeption: Evaluate Multimodal LLMs with Unlabeled Unimodal Data",
    "abstract": "  Multimodal Large Language Models (MLLMs) are commonly evaluated using costly\nannotated multimodal benchmarks. However, these benchmarks often struggle to\nkeep pace with the rapidly advancing requirements of MLLM evaluation. We\npropose GenCeption, a novel and annotation-free MLLM evaluation framework that\nmerely requires unimodal data to assess inter-modality semantic coherence and\ninversely reflects the models' inclination to hallucinate. Analogous to the\npopular DrawCeption game, GenCeption initiates with a non-textual sample and\nundergoes a series of iterative description and generation steps. Semantic\ndrift across iterations is quantified using the GC@T metric. Our empirical\nfindings validate GenCeption's efficacy, showing strong correlations with\npopular MLLM benchmarking results. GenCeption may be extended to mitigate\ntraining data contamination by utilizing ubiquitous, previously unseen unimodal\ndata.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14973v1",
    "authors": ["Lele Cao", "Valentin Buchner", "Zineb Senane", "Fangkai Yang"]
  },
  {
    "id": "2402.14974",
    "title": "Towards Spatially-Lucid AI Classification in Non-Euclidean Space: An\n  Application for MxIF Oncology Data",
    "abstract": "  Given multi-category point sets from different place-types, our goal is to\ndevelop a spatially-lucid classifier that can distinguish between two classes\nbased on the arrangements of their points. This problem is important for many\napplications, such as oncology, for analyzing immune-tumor relationships and\ndesigning new immunotherapies. It is challenging due to spatial variability and\ninterpretability needs. Previously proposed techniques require dense training\ndata or have limited ability to handle significant spatial variability within a\nsingle place-type. Most importantly, these deep neural network (DNN) approaches\nare not designed to work in non-Euclidean space, particularly point sets.\nExisting non-Euclidean DNN methods are limited to one-size-fits-all approaches.\nWe explore a spatial ensemble framework that explicitly uses different training\nstrategies, including weighted-distance learning rate and spatial domain\nadaptation, on various place-types for spatially-lucid classification.\nExperimental results on real-world datasets (e.g., MxIF oncology data) show\nthat the proposed framework provides higher prediction accuracy than baseline\nmethods.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14974v1",
    "authors": [
      "Majid Farhadloo",
      "Arun Sharma",
      "Jayant Gupta",
      "Alexey Leontovich",
      "Svetomir N. Markovic",
      "Shashi Shekhar"
    ]
  },
  {
    "id": "2402.14976",
    "title": "Unsupervised Domain Adaptation within Deep Foundation Latent Spaces",
    "abstract": "  The vision transformer-based foundation models, such as ViT or Dino-V2, are\naimed at solving problems with little or no finetuning of features. Using a\nsetting of prototypical networks, we analyse to what extent such foundation\nmodels can solve unsupervised domain adaptation without finetuning over the\nsource or target domain. Through quantitative analysis, as well as qualitative\ninterpretations of decision making, we demonstrate that the suggested method\ncan improve upon existing baselines, as well as showcase the limitations of\nsuch approach yet to be solved.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14976v1",
    "authors": ["Dmitry Kangin", "Plamen Angelov"]
  },
  {
    "id": "2402.14978",
    "title": "AI-Augmented Brainwriting: Investigating the use of LLMs in group\n  ideation",
    "abstract": "  The growing availability of generative AI technologies such as large language\nmodels (LLMs) has significant implications for creative work. This paper\nexplores twofold aspects of integrating LLMs into the creative process - the\ndivergence stage of idea generation, and the convergence stage of evaluation\nand selection of ideas. We devised a collaborative group-AI Brainwriting\nideation framework, which incorporated an LLM as an enhancement into the group\nideation process, and evaluated the idea generation process and the resulted\nsolution space. To assess the potential of using LLMs in the idea evaluation\nprocess, we design an evaluation engine and compared it to idea ratings\nassigned by three expert and six novice evaluators. Our findings suggest that\nintegrating LLM in Brainwriting could enhance both the ideation process and its\noutcome. We also provide evidence that LLMs can support idea evaluation. We\nconclude by discussing implications for HCI education and practice.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14978v2",
    "authors": [
      "Orit Shaer",
      "Angelora Cooper",
      "Osnat Mokryn",
      "Andrew L. Kun",
      "Hagit Ben Shoshan"
    ]
  },
  {
    "id": "2402.14992",
    "title": "tinyBenchmarks: evaluating LLMs with fewer examples",
    "abstract": "  The versatility of large language models (LLMs) led to the creation of\ndiverse benchmarks that thoroughly test a variety of language models'\nabilities. These benchmarks consist of tens of thousands of examples making\nevaluation of LLMs very expensive. In this paper, we investigate strategies to\nreduce the number of evaluations needed to assess the performance of an LLM on\nseveral key benchmarks. For example, we show that to accurately estimate the\nperformance of an LLM on MMLU, a popular multiple-choice QA benchmark\nconsisting of 14K examples, it is sufficient to evaluate this LLM on 100\ncurated examples. We release evaluation tools and tiny versions of popular\nbenchmarks: Open LLM Leaderboard, MMLU, HELM, and AlpacaEval 2.0. Our empirical\nanalysis demonstrates that these tools and tiny benchmarks are sufficient to\nreliably and efficiently reproduce the original evaluation results.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14992v1",
    "authors": [
      "Felipe Maia Polo",
      "Lucas Weber",
      "Leshem Choshen",
      "Yuekai Sun",
      "Gongjun Xu",
      "Mikhail Yurochkin"
    ]
  },
  {
    "id": "2402.15010",
    "title": "How Important Is Tokenization in French Medical Masked Language Models?",
    "abstract": "  Subword tokenization has become the prevailing standard in the field of\nnatural language processing (NLP) over recent years, primarily due to the\nwidespread utilization of pre-trained language models. This shift began with\nByte-Pair Encoding (BPE) and was later followed by the adoption of\nSentencePiece and WordPiece. While subword tokenization consistently\noutperforms character and word-level tokenization, the precise factors\ncontributing to its success remain unclear. Key aspects such as the optimal\nsegmentation granularity for diverse tasks and languages, the influence of data\nsources on tokenizers, and the role of morphological information in\nIndo-European languages remain insufficiently explored. This is particularly\npertinent for biomedical terminology, characterized by specific rules governing\nmorpheme combinations. Despite the agglutinative nature of biomedical\nterminology, existing language models do not explicitly incorporate this\nknowledge, leading to inconsistent tokenization strategies for common terms. In\nthis paper, we seek to delve into the complexities of subword tokenization in\nFrench biomedical domain across a variety of NLP tasks and pinpoint areas where\nfurther enhancements can be made. We analyze classical tokenization algorithms,\nincluding BPE and SentencePiece, and introduce an original tokenization\nstrategy that integrates morpheme-enriched word segmentation into existing\ntokenization methods.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15010v1",
    "authors": [
      "Yanis Labrak",
      "Adrien Bazoge",
      "Beatrice Daille",
      "Mickael Rouvier",
      "Richard Dufour"
    ]
  },
  {
    "id": "2402.15011",
    "title": "A Conversational Brain-Artificial Intelligence Interface",
    "abstract": "  We introduce Brain-Artificial Intelligence Interfaces (BAIs) as a new class\nof Brain-Computer Interfaces (BCIs). Unlike conventional BCIs, which rely on\nintact cognitive capabilities, BAIs leverage the power of artificial\nintelligence to replace parts of the neuro-cognitive processing pipeline. BAIs\nallow users to accomplish complex tasks by providing high-level intentions,\nwhile a pre-trained AI agent determines low-level details. This approach\nenlarges the target audience of BCIs to individuals with cognitive impairments,\na population often excluded from the benefits of conventional BCIs. We present\nthe general concept of BAIs and illustrate the potential of this new approach\nwith a Conversational BAI based on EEG. In particular, we show in an experiment\nwith simulated phone conversations that the Conversational BAI enables complex\ncommunication without the need to generate language. Our work thus\ndemonstrates, for the first time, the ability of a speech neuroprosthesis to\nenable fluent communication in realistic scenarios with non-invasive\ntechnologies.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15011v1",
    "authors": [
      "Anja Meunier",
      "Michal Robert Žák",
      "Lucas Munz",
      "Sofiya Garkot",
      "Manuel Eder",
      "Jiachen Xu",
      "Moritz Grosse-Wentrup"
    ]
  },
  {
    "id": "2402.15017",
    "title": "Towards Few-Shot Adaptation of Foundation Models via Multitask\n  Finetuning",
    "abstract": "  Foundation models have emerged as a powerful tool for many AI problems.\nDespite the tremendous success of foundation models, effective adaptation to\nnew tasks, particularly those with limited labels, remains an open question and\nlacks theoretical understanding. An emerging solution with recent success in\nvision and NLP involves finetuning a foundation model on a selection of\nrelevant tasks, before its adaptation to a target task with limited labeled\nsamples. In this paper, we study the theoretical justification of this\nmultitask finetuning approach. Our theoretical analysis reveals that with a\ndiverse set of related tasks, this multitask finetuning leads to reduced error\nin the target task, in comparison to directly adapting the same pretrained\nmodel. We quantify the relationship between finetuning tasks and target tasks\nby diversity and consistency metrics, and further propose a practical task\nselection algorithm. We substantiate our theoretical claims with extensive\nempirical evidence. Further, we present results affirming our task selection\nalgorithm adeptly chooses related finetuning tasks, providing advantages to the\nmodel performance on target tasks. We believe our study shed new light on the\neffective adaptation of foundation models to new tasks that lack abundant\nlabels. Our code is available at\nhttps://github.com/OliverXUZY/Foudation-Model_Multitask.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15017v1",
    "authors": ["Zhuoyan Xu", "Zhenmei Shi", "Junyi Wei", "Fangzhou Mu", "Yin Li", "Yingyu Liang"]
  },
  {
    "id": "2402.15019",
    "title": "Consistency-Guided Temperature Scaling Using Style and Content\n  Information for Out-of-Domain Calibration",
    "abstract": "  Research interests in the robustness of deep neural networks against domain\nshifts have been rapidly increasing in recent years. Most existing works,\nhowever, focus on improving the accuracy of the model, not the calibration\nperformance which is another important requirement for trustworthy AI systems.\nTemperature scaling (TS), an accuracy-preserving post-hoc calibration method,\nhas been proven to be effective in in-domain settings, but not in out-of-domain\n(OOD) due to the difficulty in obtaining a validation set for the unseen domain\nbeforehand. In this paper, we propose consistency-guided temperature scaling\n(CTS), a new temperature scaling strategy that can significantly enhance the\nOOD calibration performance by providing mutual supervision among data samples\nin the source domains. Motivated by our observation that over-confidence\nstemming from inconsistent sample predictions is the main obstacle to OOD\ncalibration, we propose to guide the scaling process by taking consistencies\ninto account in terms of two different aspects -- style and content -- which\nare the key components that can well-represent data samples in multi-domain\nsettings. Experimental results demonstrate that our proposed strategy\noutperforms existing works, achieving superior OOD calibration performance on\nvarious datasets. This can be accomplished by employing only the source domains\nwithout compromising accuracy, making our scheme directly applicable to various\ntrustworthy AI systems.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15019v1",
    "authors": ["Wonjeong Choi", "Jungwuk Park", "Dong-Jun Han", "Younghyun Park", "Jaekyun Moon"]
  },
  {
    "id": "2402.15444",
    "title": "Unleashing the Power of Imbalanced Modality Information for Multi-modal\n  Knowledge Graph Completion",
    "abstract": "  Multi-modal knowledge graph completion (MMKGC) aims to predict the missing\ntriples in the multi-modal knowledge graphs by incorporating structural,\nvisual, and textual information of entities into the discriminant models. The\ninformation from different modalities will work together to measure the triple\nplausibility. Existing MMKGC methods overlook the imbalance problem of modality\ninformation among entities, resulting in inadequate modal fusion and\ninefficient utilization of the raw modality information. To address the\nmentioned problems, we propose Adaptive Multi-modal Fusion and Modality\nAdversarial Training (AdaMF-MAT) to unleash the power of imbalanced modality\ninformation for MMKGC. AdaMF-MAT achieves multi-modal fusion with adaptive\nmodality weights and further generates adversarial samples by\nmodality-adversarial training to enhance the imbalanced modality information.\nOur approach is a co-design of the MMKGC model and training strategy which can\noutperform 19 recent MMKGC methods and achieve new state-of-the-art results on\nthree public MMKGC benchmarks. Our code and data have been released at\nhttps://github.com/zjukg/AdaMF-MAT.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15444v1",
    "authors": ["Yichi Zhang", "Zhuo Chen", "Lei Liang", "Huajun Chen", "Wen Zhang"]
  },
  {
    "id": "2402.17778",
    "title": "Dynamic Anchor Selection and Real-Time Pose Prediction for\n  Ultra-wideband Tagless Gate",
    "abstract": "  Ultra-wideband (UWB) is emerging as a promising solution that can realize\nproximity services, such as UWB tagless gate (UTG), thanks to centimeter-level\nlocalization accuracy based on two different ranging methods such as downlink\ntime-difference of arrival (DL-TDoA) and double-sided two-way ranging (DS-TWR).\nThe UTG is a UWB-based proximity service that provides a seamless gate pass\nsystem without requiring real-time mobile device (MD) tapping. The location of\nMD is calculated using DL-TDoA, and the MD communicates with the nearest UTG\nusing DS-TWR to open the gate. Therefore, the knowledge about the exact\nlocation of MD is the main challenge of UTG, and hence we provide the solutions\nfor both DL-TDoA and DS-TWR. In this paper, we propose dynamic anchor selection\nfor extremely accurate DL-TDoA localization and pose prediction for DS-TWR,\ncalled DynaPose. The pose is defined as the actual location of MD on the human\nbody, which affects the localization accuracy. DynaPose is based on\nline-of-sight (LOS) and non-LOS (NLOS) classification using deep learning for\nanchor selection and pose prediction. Deep learning models use the UWB channel\nimpulse response and the inertial measurement unit embedded in the smartphone.\nDynaPose is implemented on Samsung Galaxy Note20 Ultra and Qorvo UWB board to\nshow the feasibility and applicability. DynaPose achieves a LOS/NLOS\nclassification accuracy of 0.984, 62% higher DL-TDoA localization accuracy, and\nultimately detects four different poses with an accuracy of 0.961 in real-time.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.17778v1",
    "authors": ["Junyoung Choi", "Sagnik Bhattacharya", "Joohyun Lee"]
  },
  {
    "id": "2402.14701",
    "title": "COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies\n  with Language Modeling",
    "abstract": "  The therapeutic working alliance is a critical factor in predicting the\nsuccess of psychotherapy treatment. Traditionally, working alliance assessment\nrelies on questionnaires completed by both therapists and patients. In this\npaper, we present COMPASS, a novel framework to directly infer the therapeutic\nworking alliance from the natural language used in psychotherapy sessions. Our\napproach utilizes advanced large language models to analyze transcripts of\npsychotherapy sessions and compare them with distributed representations of\nstatements in the working alliance inventory. Analyzing a dataset of over 950\nsessions covering diverse psychiatric conditions, we demonstrate the\neffectiveness of our method in microscopically mapping patient-therapist\nalignment trajectories and providing interpretability for clinical psychiatry\nand in identifying emerging patterns related to the condition being treated. By\nemploying various neural topic modeling techniques in combination with\ngenerative language prompting, we analyze the topical characteristics of\ndifferent psychiatric conditions and incorporate temporal modeling to capture\nthe evolution of topics at a turn-level resolution. This combined framework\nenhances the understanding of therapeutic interactions, enabling timely\nfeedback for therapists regarding conversation quality and providing\ninterpretable insights to improve the effectiveness of psychotherapy.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14701v1",
    "authors": [
      "Baihan Lin",
      "Djallel Bouneffouf",
      "Yulia Landa",
      "Rachel Jespersen",
      "Cheryl Corcoran",
      "Guillermo Cecchi"
    ]
  },
  {
    "id": "2402.14710",
    "title": "IEPile: Unearthing Large-Scale Schema-Based Information Extraction\n  Corpus",
    "abstract": "  Large Language Models (LLMs) demonstrate remarkable potential across various\ndomains; however, they exhibit a significant performance gap in Information\nExtraction (IE). Note that high-quality instruction data is the vital key for\nenhancing the specific capabilities of LLMs, while current IE datasets tend to\nbe small in scale, fragmented, and lack standardized schema. To this end, we\nintroduce IEPile, a comprehensive bilingual (English and Chinese) IE\ninstruction corpus, which contains approximately 0.32B tokens. We construct\nIEPile by collecting and cleaning 33 existing IE datasets, and introduce\nschema-based instruction generation to unearth a large-scale corpus.\nExperimental results on LLaMA and Baichuan demonstrate that using IEPile can\nenhance the performance of LLMs for IE, especially the zero-shot\ngeneralization. We open-source the resource and pre-trained models, hoping to\nprovide valuable support to the NLP community.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14710v1",
    "authors": [
      "Honghao Gui",
      "Hongbin Ye",
      "Lin Yuan",
      "Ningyu Zhang",
      "Mengshu Sun",
      "Lei Liang",
      "Huajun Chen"
    ]
  },
  {
    "id": "2402.14804",
    "title": "Measuring Multimodal Mathematical Reasoning with MATH-Vision Dataset",
    "abstract": "  Recent advancements in Large Multimodal Models (LMMs) have shown promising\nresults in mathematical reasoning within visual contexts, with models\napproaching human-level performance on existing benchmarks such as MathVista.\nHowever, we observe significant limitations in the diversity of questions and\nbreadth of subjects covered by these benchmarks. To address this issue, we\npresent the MATH-Vision (MATH-V) dataset, a meticulously curated collection of\n3,040 high-quality mathematical problems with visual contexts sourced from real\nmath competitions. Spanning 16 distinct mathematical disciplines and graded\nacross 5 levels of difficulty, our dataset provides a comprehensive and diverse\nset of challenges for evaluating the mathematical reasoning abilities of LMMs.\nThrough extensive experimentation, we unveil a notable performance gap between\ncurrent LMMs and human performance on MATH-V, underscoring the imperative for\nfurther advancements in LMMs. Moreover, our detailed categorization allows for\na thorough error analysis of LMMs, offering valuable insights to guide future\nresearch and development. The project is available at\nhttps://mathvision-cuhk.github.io\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14804v1",
    "authors": ["Ke Wang", "Junting Pan", "Weikang Shi", "Zimu Lu", "Mingjie Zhan", "Hongsheng Li"]
  },
  {
    "id": "2402.14894",
    "title": "Data-Driven Ground-Fault Location Method in Distribution Power System\n  With Distributed Generation",
    "abstract": "  The recent increase in renewable energy penetration at the distribution level\nintroduces a multi-directional power flow that outdated traditional fault\nlocation techniques. To this extent, the development of new methods is needed\nto ensure fast and accurate fault localization and, hence, strengthen power\nsystem reliability. This paper proposes a data-driven ground fault location\nmethod for the power distribution system. An 11-bus 20 kV power system is\nmodeled in Matlab/Simulink to simulate ground faults. The faults are generated\nat different locations and under various system operational states. Time-domain\nfaulted three-phase voltages at the system substation are then analyzed with\ndiscrete wavelet transform. Statistical quantities of the processed data are\neventually used to train an Artificial Neural Network (ANN) to find a mapping\nbetween computed voltage features and faults. Specifically, three ANNs allow\nthe prediction of faulted phase, faulted branch, and fault distance from the\nsystem substation separately. According to the results, the method shows good\npotential, with a total relative error of 0,4% for fault distance prediction.\nThe method is applied to datasets with unknown system states to test\nrobustness.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.14894v1",
    "authors": ["Mauro Caporuscio", "Antoine Dupuis", "Welf Löwe"]
  }
]
