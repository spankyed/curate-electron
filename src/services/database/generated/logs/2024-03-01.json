[
  {
    "id": "2403.00685",
    "title": "Know your exceptions: Towards an Ontology of Exceptions in Knowledge\n  Representation",
    "abstract": "  Defeasible reasoning is a kind of reasoning where some generalisations may\nnot be valid in all circumstances, that is general conclusions may fail in some\ncases. Various formalisms have been developed to model this kind of reasoning,\nwhich is characteristic of common-sense contexts. However, it is not easy for a\nmodeller to choose among these systems the one that better fits its domain from\nan ontological point of view. In this paper we first propose a framework based\non the notions of exceptionality and defeasibility in order to be able to\ncompare formalisms and reveal their ontological commitments. Then, we apply\nthis framework to compare four systems, showing the differences that may occur\nfrom an ontological perspective.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00685v2",
    "authors": ["Gabriele Sacco", "Loris Bozzato", "Oliver Kutz"]
  },
  {
    "id": "2403.00690",
    "title": "Playing NetHack with LLMs: Potential & Limitations as Zero-Shot Agents",
    "abstract": "  Large Language Models (LLMs) have shown great success as high-level planners\nfor zero-shot game-playing agents. However, these agents are primarily\nevaluated on Minecraft, where long-term planning is relatively straightforward.\nIn contrast, agents tested in dynamic robot environments face limitations due\nto simplistic environments with only a few objects and interactions. To fill\nthis gap in the literature, we present NetPlay, the first LLM-powered zero-shot\nagent for the challenging roguelike NetHack. NetHack is a particularly\nchallenging environment due to its diverse set of items and monsters, complex\ninteractions, and many ways to die.\n  NetPlay uses an architecture designed for dynamic robot environments,\nmodified for NetHack. Like previous approaches, it prompts the LLM to choose\nfrom predefined skills and tracks past interactions to enhance decision-making.\nGiven NetHack's unpredictable nature, NetPlay detects important game events to\ninterrupt running skills, enabling it to react to unforeseen circumstances.\nWhile NetPlay demonstrates considerable flexibility and proficiency in\ninteracting with NetHack's mechanics, it struggles with ambiguous task\ndescriptions and a lack of explicit feedback. Our findings demonstrate that\nNetPlay performs best with detailed context information, indicating the\nnecessity for dynamic methods in supplying context information for complex\ngames such as NetHack.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00690v1",
    "authors": [
      "Dominik Jeurissen",
      "Diego Perez-Liebana",
      "Jeremy Gow",
      "Duygu Cakmak",
      "James Kwan"
    ]
  },
  {
    "id": "2403.00980",
    "title": "Even-Ifs From If-Onlys: Are the Best Semi-Factual Explanations Found\n  Using Counterfactuals As Guides?",
    "abstract": "  Recently, counterfactuals using \"if-only\" explanations have become very\npopular in eXplainable AI (XAI), as they describe which changes to\nfeature-inputs of a black-box AI system result in changes to a (usually\nnegative) decision-outcome. Even more recently, semi-factuals using \"even-if\"\nexplanations have gained more attention. They elucidate the feature-input\nchanges that do \\textit{not} change the decision-outcome of the AI system, with\na potential to suggest more beneficial recourses. Some semi-factual methods use\ncounterfactuals to the query-instance to guide semi-factual production\n(so-called counterfactual-guided methods), whereas others do not (so-called\ncounterfactual-free methods). In this work, we perform comprehensive tests of 8\nsemi-factual methods on 7 datasets using 5 key metrics, to determine whether\ncounterfactual guidance is necessary to find the best semi-factuals. The\nresults of these tests suggests not, but rather that computing other aspects of\nthe decision space lead to better semi-factual XAI.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00980v1",
    "authors": ["Saugat Aryal", "Mark T. Keane"]
  },
  {
    "id": "2403.00250",
    "title": "Rethinking Classifier Re-Training in Long-Tailed Recognition: A Simple\n  Logits Retargeting Approach",
    "abstract": "  In the long-tailed recognition field, the Decoupled Training paradigm has\ndemonstrated remarkable capabilities among various methods. This paradigm\ndecouples the training process into separate representation learning and\nclassifier re-training. Previous works have attempted to improve both stages\nsimultaneously, making it difficult to isolate the effect of classifier\nre-training. Furthermore, recent empirical studies have demonstrated that\nsimple regularization can yield strong feature representations, emphasizing the\nneed to reassess existing classifier re-training methods. In this study, we\nrevisit classifier re-training methods based on a unified feature\nrepresentation and re-evaluate their performances. We propose a new metric\ncalled Logits Magnitude as a superior measure of model performance, replacing\nthe commonly used Weight Norm. However, since it is hard to directly optimize\nthe new metric during training, we introduce a suitable approximate invariant\ncalled Regularized Standard Deviation. Based on the two newly proposed metrics,\nwe prove that reducing the absolute value of Logits Magnitude when it is nearly\nbalanced can effectively decrease errors and disturbances during training,\nleading to better model performance. Motivated by these findings, we develop a\nsimple logits retargeting approach (LORT) without the requirement of prior\nknowledge of the number of samples per class. LORT divides the original one-hot\nlabel into small true label probabilities and large negative label\nprobabilities distributed across each class. Our method achieves\nstate-of-the-art performance on various imbalanced datasets, including\nCIFAR100-LT, ImageNet-LT, and iNaturalist2018.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00250v1",
    "authors": ["Han Lu", "Siyu Sun", "Yichen Xie", "Liqing Zhang", "Xiaokang Yang", "Junchi Yan"]
  },
  {
    "id": "2403.00284",
    "title": "A Survey of Route Recommendations: Methods, Applications, and\n  Opportunities",
    "abstract": "  Nowadays, with advanced information technologies deployed citywide, large\ndata volumes and powerful computational resources are intelligentizing modern\ncity development. As an important part of intelligent transportation, route\nrecommendation and its applications are widely used, directly influencing\ncitizens` travel habits. Developing smart and efficient travel routes based on\nbig data (possibly multi-modal) has become a central challenge in route\nrecommendation research. Our survey offers a comprehensive review of route\nrecommendation work based on urban computing. It is organized by the following\nthree parts: 1) Methodology-wise. We categorize a large volume of traditional\nmachine learning and modern deep learning methods. Also, we discuss their\nhistorical relations and reveal the edge-cutting progress. 2)\nApplication\\-wise. We present numerous novel applications related to route\ncommendation within urban computing scenarios. 3) We discuss current problems\nand challenges and envision several promising research directions. We believe\nthat this survey can help relevant researchers quickly familiarize themselves\nwith the current state of route recommendation research and then direct them to\nfuture research trends.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00284v1",
    "authors": ["Shiming Zhang", "Zhipeng Luo", "Li Yang", "Fei Teng", "Tianrui Li"]
  },
  {
    "id": "2403.00307",
    "title": "Embedded Multi-label Feature Selection via Orthogonal Regression",
    "abstract": "  In the last decade, embedded multi-label feature selection methods,\nincorporating the search for feature subsets into model optimization, have\nattracted considerable attention in accurately evaluating the importance of\nfeatures in multi-label classification tasks. Nevertheless, the\nstate-of-the-art embedded multi-label feature selection algorithms based on\nleast square regression usually cannot preserve sufficient discriminative\ninformation in multi-label data. To tackle the aforementioned challenge, a\nnovel embedded multi-label feature selection method, termed global redundancy\nand relevance optimization in orthogonal regression (GRROOR), is proposed to\nfacilitate the multi-label feature selection. The method employs orthogonal\nregression with feature weighting to retain sufficient statistical and\nstructural information related to local label correlations of the multi-label\ndata in the feature learning process. Additionally, both global feature\nredundancy and global label relevancy information have been considered in the\northogonal regression model, which could contribute to the search for\ndiscriminative and non-redundant feature subsets in the multi-label data. The\ncost function of GRROOR is an unbalanced orthogonal Procrustes problem on the\nStiefel manifold. A simple yet effective scheme is utilized to obtain an\noptimal solution. Extensive experimental results on ten multi-label data sets\ndemonstrate the effectiveness of GRROOR.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00307v1",
    "authors": ["Xueyuan Xu", "Fulin Wei", "Tianyuan Jia", "Li Zhuo", "Feiping Nie", "Xia Wu"]
  },
  {
    "id": "2403.00315",
    "title": "Axe the X in XAI: A Plea for Understandable AI",
    "abstract": "  In a recent paper, Erasmus et al. (2021) defend the idea that the ambiguity\nof the term \"explanation\" in explainable AI (XAI) can be solved by adopting any\nof four different extant accounts of explanation in the philosophy of science:\nthe Deductive Nomological, Inductive Statistical, Causal Mechanical, and New\nMechanist models. In this chapter, I show that the authors' claim that these\naccounts can be applied to deep neural networks as they would to any natural\nphenomenon is mistaken. I also provide a more general argument as to why the\nnotion of explainability as it is currently used in the XAI literature bears\nlittle resemblance to the traditional concept of scientific explanation. It\nwould be more fruitful to use the label \"understandable AI\" to avoid the\nconfusion that surrounds the goal and purposes of XAI. In the second half of\nthe chapter, I argue for a pragmatic conception of understanding that is better\nsuited to play the central role attributed to explanation in XAI. Following\nKuorikoski & Ylikoski (2015), the conditions of satisfaction for understanding\nan ML system are fleshed out in terms of an agent's success in using the\nsystem, in drawing correct inferences from it.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00315v1",
    "authors": ["Andrés Páez"]
  },
  {
    "id": "2403.00318",
    "title": "Deep Reinforcement Learning for Solving Management Problems: Towards A\n  Large Management Mode",
    "abstract": "  We introduce a deep reinforcement learning (DRL) approach for solving\nmanagement problems including inventory management, dynamic pricing, and\nrecommendation. This DRL approach has the potential to lead to a large\nmanagement model based on certain transformer neural network structures,\nresulting in an artificial general intelligence paradigm for various management\ntasks. Traditional methods have limitations for solving complex real-world\nproblems, and we demonstrate how DRL can surpass existing heuristic approaches\nfor solving management tasks. We aim to solve the problems in a unified\nframework, considering the interconnections between different tasks. Central to\nour methodology is the development of a foundational decision model\ncoordinating decisions across the different domains through generative\ndecision-making. Our experimental results affirm the effectiveness of our\nDRL-based framework in complex and dynamic business environments. This work\nopens new pathways for the application of DRL in management problems,\nhighlighting its potential to revolutionize traditional business management.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00318v1",
    "authors": [
      "Jinyang Jiang",
      "Xiaotian Liu",
      "Tao Ren",
      "Qinghao Wang",
      "Yi Zheng",
      "Yufu Du",
      "Yijie Peng",
      "Cheng Zhang"
    ]
  },
  {
    "id": "2403.00323",
    "title": "Softened Symbol Grounding for Neuro-symbolic Systems",
    "abstract": "  Neuro-symbolic learning generally consists of two separated worlds, i.e.,\nneural network training and symbolic constraint solving, whose success hinges\non symbol grounding, a fundamental problem in AI. This paper presents a novel,\nsoftened symbol grounding process, bridging the gap between the two worlds, and\nresulting in an effective and efficient neuro-symbolic learning framework.\nTechnically, the framework features (1) modeling of symbol solution states as a\nBoltzmann distribution, which avoids expensive state searching and facilitates\nmutually beneficial interactions between network training and symbolic\nreasoning;(2) a new MCMC technique leveraging projection and SMT solvers, which\nefficiently samples from disconnected symbol solution spaces; (3) an annealing\nmechanism that can escape from %being trapped into sub-optimal symbol\ngroundings. Experiments with three representative neuro symbolic learning tasks\ndemonstrate that, owining to its superior symbol grounding capability, our\nframework successfully solves problems well beyond the frontier of the existing\nproposals.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00323v1",
    "authors": [
      "Zenan Li",
      "Yuan Yao",
      "Taolue Chen",
      "Jingwei Xu",
      "Chun Cao",
      "Xiaoxing Ma",
      "Jian Lü"
    ]
  },
  {
    "id": "2403.00329",
    "title": "Learning with Logical Constraints but without Shortcut Satisfaction",
    "abstract": "  Recent studies in neuro-symbolic learning have explored the integration of\nlogical knowledge into deep learning via encoding logical constraints as an\nadditional loss function. However, existing approaches tend to vacuously\nsatisfy logical constraints through shortcuts, failing to fully exploit the\nknowledge. In this paper, we present a new framework for learning with logical\nconstraints. Specifically, we address the shortcut satisfaction issue by\nintroducing dual variables for logical connectives, encoding how the constraint\nis satisfied. We further propose a variational framework where the encoded\nlogical constraint is expressed as a distributional loss that is compatible\nwith the model's original training loss. The theoretical analysis shows that\nthe proposed approach bears salient properties, and the experimental\nevaluations demonstrate its superior performance in both model generalizability\nand constraint satisfaction.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00329v1",
    "authors": [
      "Zenan Li",
      "Zehua Liu",
      "Yuan Yao",
      "Jingwei Xu",
      "Taolue Chen",
      "Xiaoxing Ma",
      "Jian Lü"
    ]
  },
  {
    "id": "2403.00336",
    "title": "Never-Ending Embodied Robot Learning",
    "abstract": "  Relying on large language models (LLMs), embodied robots could perform\ncomplex multimodal robot manipulation tasks from visual observations with\npowerful generalization ability. However, most visual behavior-cloning agents\nsuffer from manipulation performance degradation and skill knowledge forgetting\nwhen adapting into a series of challenging unseen tasks. We here investigate\nthe above challenge with NBCagent in embodied robots, a pioneering\nlanguage-conditioned Never-ending Behavior-Cloning agent, which can continually\nlearn observation knowledge of novel robot manipulation skills from\nskill-specific and skill-shared attributes. Specifically, we establish a\nskill-specific evolving planner to perform knowledge decoupling, which can\ncontinually embed novel skill-specific knowledge in our NBCagent agent from\nlatent and low-rank space. Meanwhile, we propose a skill-shared semantics\nrendering module and a skill-shared representation distillation module to\neffectively transfer anti-forgetting skill-shared knowledge, further tackling\ncatastrophic forgetting on old skills from semantics and representation\naspects. Finally, we design a continual embodied robot manipulation benchmark,\nand several expensive experiments demonstrate the significant performance of\nour method. Visual results, code, and dataset are provided at:\nhttps://neragent.github.io.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00336v1",
    "authors": ["Wenqi Liang", "Gan Sun", "Qian He", "Yu Ren", "Jiahua Dong", "Yang Cong"]
  },
  {
    "id": "2403.00396",
    "title": "GLFNET: Global-Local (frequency) Filter Networks for efficient medical\n  image segmentation",
    "abstract": "  We propose a novel transformer-style architecture called Global-Local Filter\nNetwork (GLFNet) for medical image segmentation and demonstrate its\nstate-of-the-art performance. We replace the self-attention mechanism with a\ncombination of global-local filter blocks to optimize model efficiency. The\nglobal filters extract features from the whole feature map whereas the local\nfilters are being adaptively created as 4x4 patches of the same feature map and\nadd restricted scale information. In particular, the feature extraction takes\nplace in the frequency domain rather than the commonly used spatial (image)\ndomain to facilitate faster computations. The fusion of information from both\nspatial and frequency spaces creates an efficient model with regards to\ncomplexity, required data and performance. We test GLFNet on three benchmark\ndatasets achieving state-of-the-art performance on all of them while being\nalmost twice as efficient in terms of GFLOP operations.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00396v1",
    "authors": [
      "Athanasios Tragakis",
      "Qianying Liu",
      "Chaitanya Kaul",
      "Swalpa Kumar Roy",
      "Hang Dai",
      "Fani Deligianni",
      "Roderick Murray-Smith",
      "Daniele Faccio"
    ]
  },
  {
    "id": "2403.00420",
    "title": "Robust Deep Reinforcement Learning Through Adversarial Attacks and\n  Training : A Survey",
    "abstract": "  Deep Reinforcement Learning (DRL) is an approach for training autonomous\nagents across various complex environments. Despite its significant performance\nin well known environments, it remains susceptible to minor conditions\nvariations, raising concerns about its reliability in real-world applications.\nTo improve usability, DRL must demonstrate trustworthiness and robustness. A\nway to improve robustness of DRL to unknown changes in the conditions is\nthrough Adversarial Training, by training the agent against well suited\nadversarial attacks on the dynamics of the environment. Addressing this\ncritical issue, our work presents an in-depth analysis of contemporary\nadversarial attack methodologies, systematically categorizing them and\ncomparing their objectives and operational mechanisms. This classification\noffers a detailed insight into how adversarial attacks effectively act for\nevaluating the resilience of DRL agents, thereby paving the way for enhancing\ntheir robustness.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00420v1",
    "authors": [
      "Lucas Schott",
      "Josephine Delas",
      "Hatem Hajri",
      "Elies Gherbi",
      "Reda Yaich",
      "Nora Boulahia-Cuppens",
      "Frederic Cuppens",
      "Sylvain Lamprier"
    ]
  },
  {
    "id": "2403.00436",
    "title": "Abductive Ego-View Accident Video Understanding for Safe Driving\n  Perception",
    "abstract": "  We present MM-AU, a novel dataset for Multi-Modal Accident video\nUnderstanding. MM-AU contains 11,727 in-the-wild ego-view accident videos, each\nwith temporally aligned text descriptions. We annotate over 2.23 million object\nboxes and 58,650 pairs of video-based accident reasons, covering 58 accident\ncategories. MM-AU supports various accident understanding tasks, particularly\nmultimodal video diffusion to understand accident cause-effect chains for safe\ndriving. With MM-AU, we present an Abductive accident Video understanding\nframework for Safe Driving perception (AdVersa-SD). AdVersa-SD performs video\ndiffusion via an Object-Centric Video Diffusion (OAVD) method which is driven\nby an abductive CLIP model. This model involves a contrastive interaction loss\nto learn the pair co-occurrence of normal, near-accident, accident frames with\nthe corresponding text descriptions, such as accident reasons, prevention\nadvice, and accident categories. OAVD enforces the causal region learning while\nfixing the content of the original frame background in video generation, to\nfind the dominant cause-effect chain for certain accidents. Extensive\nexperiments verify the abductive ability of AdVersa-SD and the superiority of\nOAVD against the state-of-the-art diffusion models. Additionally, we provide\ncareful benchmark evaluations for object detection and accident reason\nanswering since AdVersa-SD relies on precise object and accident reason\ninformation.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00436v1",
    "authors": [
      "Jianwu Fang",
      "Lei-lei Li",
      "Junfei Zhou",
      "Junbin Xiao",
      "Hongkai Yu",
      "Chen Lv",
      "Jianru Xue",
      "Tat-Seng Chua"
    ]
  },
  {
    "id": "2403.00439",
    "title": "Authors' Values and Attitudes Towards AI-bridged Scalable\n  Personalization of Creative Language Arts",
    "abstract": "  Generative AI has the potential to create a new form of interactive media:\nAI-bridged creative language arts (CLA), which bridge the author and audience\nby personalizing the author's vision to the audience's context and taste at\nscale. However, it is unclear what the authors' values and attitudes would be\nregarding AI-bridged CLA. To identify these values and attitudes, we conducted\nan interview study with 18 authors across eight genres (e.g., poetry, comics)\nby presenting speculative but realistic AI-bridged CLA scenarios. We identified\nthree benefits derived from the dynamics between author, artifact, and\naudience: those that 1) authors get from the process, 2) audiences get from the\nartifact, and 3) authors get from the audience. We found how AI-bridged CLA\nwould either promote or reduce these benefits, along with authors' concerns. We\nhope our investigation hints at how AI can provide intriguing experiences to\nCLA audiences while promoting authors' values.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00439v1",
    "authors": ["Taewook Kim", "Hyomin Han", "Eytan Adar", "Matthew Kay", "John Joon Young Chung"]
  },
  {
    "id": "2403.00450",
    "title": "Parallel Hyperparameter Optimization Of Spiking Neural Network",
    "abstract": "  Spiking Neural Networks (SNN). SNNs are based on a more biologically inspired\napproach than usual artificial neural networks. Such models are characterized\nby complex dynamics between neurons and spikes. These are very sensitive to the\nhyperparameters, making their optimization challenging. To tackle\nhyperparameter optimization of SNNs, we initially extended the signal loss\nissue of SNNs to what we call silent networks. These networks fail to emit\nenough spikes at their outputs due to mistuned hyperparameters or architecture.\nGenerally, search spaces are heavily restrained, sometimes even discretized, to\nprevent the sampling of such networks. By defining an early stopping criterion\ndetecting silent networks and by designing specific constraints, we were able\nto instantiate larger and more flexible search spaces. We applied a constrained\nBayesian optimization technique, which was asynchronously parallelized, as the\nevaluation time of a SNN is highly stochastic. Large-scale experiments were\ncarried-out on a multi-GPU Petascale architecture. By leveraging silent\nnetworks, results show an acceleration of the search, while maintaining good\nperformances of both the optimization algorithm and the best solution obtained.\nWe were able to apply our methodology to two popular training algorithms, known\nas spike timing dependent plasticity and surrogate gradient. Early detection\nallowed us to prevent worthless and costly computation, directing the search\ntoward promising hyperparameter combinations. Our methodology could be applied\nto multi-objective problems, where the spiking activity is often minimized to\nreduce the energy consumption. In this scenario, it becomes essential to find\nthe delicate frontier between low-spiking and silent networks. Finally, our\napproach may have implications for neural architecture search, particularly in\ndefining suitable spiking architectures.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00450v1",
    "authors": ["Thomas Firmin", "Pierre Boulet", "El-Ghazali Talbi"]
  },
  {
    "id": "2403.00510",
    "title": "ROME: Memorization Insights from Text, Probability and Hidden State in\n  Large Language Models",
    "abstract": "  Probing the memorization of large language models holds significant\nimportance. Previous works have established metrics for quantifying\nmemorization, explored various influencing factors, such as data duplication,\nmodel size, and prompt length, and evaluated memorization by comparing model\noutputs with training corpora. However, the training corpora are of enormous\nscale and its pre-processing is time-consuming. To explore memorization without\naccessing training data, we propose a novel approach, named ROME, wherein\nmemorization is explored by comparing disparities across memorized and\nnon-memorized. Specifically, models firstly categorize the selected samples\ninto memorized and non-memorized groups, and then comparing the demonstrations\nin the two groups from the insights of text, probability, and hidden state.\nExperimental findings show the disparities in factors including word length,\npart-of-speech, word frequency, mean and variance, just to name a few.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00510v2",
    "authors": ["Bo Li", "Qinghua Zhao", "Lijie Wen"]
  },
  {
    "id": "2403.00550",
    "title": "Imitation Learning Datasets: A Toolkit For Creating Datasets, Training\n  Agents and Benchmarking",
    "abstract": "  Imitation learning field requires expert data to train agents in a task. Most\noften, this learning approach suffers from the absence of available data, which\nresults in techniques being tested on its dataset. Creating datasets is a\ncumbersome process requiring researchers to train expert agents from scratch,\nrecord their interactions and test each benchmark method with newly created\ndata. Moreover, creating new datasets for each new technique results in a lack\nof consistency in the evaluation process since each dataset can drastically\nvary in state and action distribution. In response, this work aims to address\nthese issues by creating Imitation Learning Datasets, a toolkit that allows\nfor: (i) curated expert policies with multithreaded support for faster dataset\ncreation; (ii) readily available datasets and techniques with precise\nmeasurements; and (iii) sharing implementations of common imitation learning\ntechniques. Demonstration link:\nhttps://nathangavenski.github.io/#/il-datasets-video\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00550v1",
    "authors": ["Nathan Gavenski", "Michael Luck", "Odinaldo Rodrigues"]
  },
  {
    "id": "2403.00561",
    "title": "Multi-Task Learning Using Uncertainty to Weigh Losses for Heterogeneous\n  Face Attribute Estimation",
    "abstract": "  Face images contain a wide variety of attribute information. In this paper,\nwe propose a generalized framework for joint estimation of ordinal and nominal\nattributes based on information sharing. We tackle the correlation problem\nbetween heterogeneous attributes using hard parameter sharing of shallow\nfeatures, and trade-off multiple loss functions by considering homoskedastic\nuncertainty for each attribute estimation task. This leads to optimal\nestimation of multiple attributes of the face and reduces the training cost of\nmultitask learning. Experimental results on benchmarks with multiple face\nattributes show that the proposed approach has superior performance compared to\nstate of the art. Finally, we discuss the bias issues arising from the proposed\napproach in face attribute estimation and validate its feasibility on edge\nsystems.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00561v1",
    "authors": ["Huaqing Yuan", "Yi He", "Peng Du", "Lu Song"]
  },
  {
    "id": "2403.00565",
    "title": "Predicting UAV Type: An Exploration of Sampling and Data Augmentation\n  for Time Series Classification",
    "abstract": "  Unmanned aerial vehicles are becoming common and have many productive uses.\nHowever, their increased prevalence raises safety concerns -- how can we\nprotect restricted airspace? Knowing the type of unmanned aerial vehicle can go\na long way in determining any potential risks it carries. For instance,\nfixed-wing craft can carry more weight over longer distances, thus potentially\nposing a more significant threat. This paper presents a machine learning model\nfor classifying unmanned aerial vehicles as quadrotor, hexarotor, or\nfixed-wing. Our approach effectively applies a Long-Short Term Memory (LSTM)\nneural network for the purpose of time series classification. We performed\nexperiments to test the effects of changing the timestamp sampling method and\naddressing the imbalance in the class distribution. Through these experiments,\nwe identified the top-performing sampling and class imbalance fixing methods.\nAveraging the macro f-scores across 10 folds of data, we found that the\nmajority quadrotor class was predicted well (98.16%), and, despite an extreme\nclass imbalance, the model could also predicted a majority of fixed-wing\nflights correctly (73.15%). Hexarotor instances were often misclassified as\nquadrotors due to the similarity of multirotors in general (42.15%). However,\nresults remained relatively stable across certain methods, which prompted us to\nanalyze and report on their tradeoffs. The supplemental material for this\npaper, including the code and data for running all the experiments and\ngenerating the results tables, is available at https://osf.io/mnsgk/.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00565v1",
    "authors": ["Tarik Crnovrsanin", "Calvin Yu", "Dane Hankamer", "Cody Dunne"]
  },
  {
    "id": "2403.00567",
    "title": "Flatten Long-Range Loss Landscapes for Cross-Domain Few-Shot Learning",
    "abstract": "  Cross-domain few-shot learning (CDFSL) aims to acquire knowledge from limited\ntraining data in the target domain by leveraging prior knowledge transferred\nfrom source domains with abundant training samples. CDFSL faces challenges in\ntransferring knowledge across dissimilar domains and fine-tuning models with\nlimited training data. To address these challenges, we initially extend the\nanalysis of loss landscapes from the parameter space to the representation\nspace, which allows us to simultaneously interpret the transferring and\nfine-tuning difficulties of CDFSL models. We observe that sharp minima in the\nloss landscapes of the representation space result in representations that are\nhard to transfer and fine-tune. Moreover, existing flatness-based methods have\nlimited generalization ability due to their short-range flatness. To enhance\nthe transferability and facilitate fine-tuning, we introduce a simple yet\neffective approach to achieve long-range flattening of the minima in the loss\nlandscape. This approach considers representations that are differently\nnormalized as minima in the loss landscape and flattens the high-loss region in\nthe middle by randomly sampling interpolated representations. We implement this\nmethod as a new normalization layer that replaces the original one in both CNNs\nand ViTs. This layer is simple and lightweight, introducing only a minimal\nnumber of additional parameters. Experimental results on 8 datasets demonstrate\nthat our approach outperforms state-of-the-art methods in terms of average\naccuracy. Moreover, our method achieves performance improvements of up to 9\\%\ncompared to the current best approaches on individual datasets. Our code will\nbe released.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00567v1",
    "authors": ["Yixiong Zou", "Yicong Liu", "Yiman Hu", "Yuhua Li", "Ruixuan Li"]
  },
  {
    "id": "2403.00587",
    "title": "Improving Explicit Spatial Relationships in Text-to-Image Generation\n  through an Automatically Derived Dataset",
    "abstract": "  Existing work has observed that current text-to-image systems do not\naccurately reflect explicit spatial relations between objects such as 'left of'\nor 'below'. We hypothesize that this is because explicit spatial relations\nrarely appear in the image captions used to train these models. We propose an\nautomatic method that, given existing images, generates synthetic captions that\ncontain 14 explicit spatial relations. We introduce the Spatial Relation for\nGeneration (SR4G) dataset, which contains 9.9 millions image-caption pairs for\ntraining, and more than 60 thousand captions for evaluation. In order to test\ngeneralization we also provide an 'unseen' split, where the set of objects in\nthe train and test captions are disjoint. SR4G is the first dataset that can be\nused to spatially fine-tune text-to-image systems. We show that fine-tuning two\ndifferent Stable Diffusion models (denoted as SD$_{SR4G}$) yields up to 9\npoints improvements in the VISOR metric. The improvement holds in the 'unseen'\nsplit, showing that SD$_{SR4G}$ is able to generalize to unseen objects.\nSD$_{SR4G}$ improves the state-of-the-art with fewer parameters, and avoids\ncomplex architectures. Our analysis shows that improvement is consistent for\nall relations. The dataset and the code will be publicly available.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00587v1",
    "authors": [
      "Ander Salaberria",
      "Gorka Azkune",
      "Oier Lopez de Lacalle",
      "Aitor Soroa",
      "Eneko Agirre",
      "Frank Keller"
    ]
  },
  {
    "id": "2403.00691",
    "title": "Tri-Modal Motion Retrieval by Learning a Joint Embedding Space",
    "abstract": "  Information retrieval is an ever-evolving and crucial research domain. The\nsubstantial demand for high-quality human motion data especially in online\nacquirement has led to a surge in human motion research works. Prior works have\nmainly concentrated on dual-modality learning, such as text and motion tasks,\nbut three-modality learning has been rarely explored. Intuitively, an extra\nintroduced modality can enrich a model's application scenario, and more\nimportantly, an adequate choice of the extra modality can also act as an\nintermediary and enhance the alignment between the other two disparate\nmodalities. In this work, we introduce LAVIMO (LAnguage-VIdeo-MOtion\nalignment), a novel framework for three-modality learning integrating\nhuman-centric videos as an additional modality, thereby effectively bridging\nthe gap between text and motion. Moreover, our approach leverages a specially\ndesigned attention mechanism to foster enhanced alignment and synergistic\neffects among text, video, and motion modalities. Empirically, our results on\nthe HumanML3D and KIT-ML datasets show that LAVIMO achieves state-of-the-art\nperformance in various motion-related cross-modal retrieval tasks, including\ntext-to-motion, motion-to-text, video-to-motion and motion-to-video.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00691v1",
    "authors": ["Kangning Yin", "Shihao Zou", "Yuxuan Ge", "Zheng Tian"]
  },
  {
    "id": "2403.00868",
    "title": "SoftTiger: A Clinical Foundation Model for Healthcare Workflows",
    "abstract": "  We release and introduce SoftTiger, a clinical large language model (CLaM)\ndesigned as a foundation model for healthcare workflows. The narrative and\nunstructured nature of clinical notes is a major obstacle for healthcare\nintelligentization. We address a critical problem of structuring clinical notes\ninto clinical data, according to international interoperability standards. We\ncollect and annotate data for three critical subtasks, namely, international\npatient summary, clinical impression and medical encounter. We then supervised\nfine-tuned a state-of-the-art LLM using public and credentialed clinical data.\nThe training is orchestrated in a way that the target model can first support\nbasic clinical tasks such as abbreviation expansion and temporal information\nextraction, and then learn to perform more complex downstream clinical tasks\nsuch as impression and encounter summary. Moreover, we address, several\nmodeling challenges in the healthcare context, e.g., extra long context window.\nOur blind pairwise evaluation shows that SoftTiger outperforms other popular\nopen-source models and GPT-3.5, comparable to Gemini-pro, and only has a mild\ngap from GPT-4. We believe that LLMs may become a step-stone towards healthcare\ndigitalization and democratization. Therefore, we publicly release SoftTiger\nmodels at scales of 13 billion and 70 billion parameters, as well as datasets\nand code for our innovative scalable evaluation, hopefully, making a\nsignificant contribution to the healthcare industry.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00868v1",
    "authors": ["Ye Chen", "Igor Couto", "Wei Cai", "Cong Fu", "Bruno Dorneles"]
  },
  {
    "id": "2403.00872",
    "title": "DFIN-SQL: Integrating Focused Schema with DIN-SQL for Superior Accuracy\n  in Large-Scale Databases",
    "abstract": "  The task of converting natural language queries into SQL queries is\nintricate, necessitating a blend of precise techniques for an accurate\ntranslation. The DIN-SQL (Decomposed-In-Context SQL) methodology represents a\nsignificant development in this domain. This paper introduces DFIN (Decomposed\nFocused-In-Context), an innovative extension of DIN-SQL that enhances\nText-to-SQL conversion by addressing schema linking errors, which are a major\nsource of inaccuracies. DFIN uniquely alternates between prompting techniques\nand Retrieval-Augmented Generation (RAG), adapting to the size and complexity\nof the database schema. A preprocessing phase embeds database definitions and\nleverages annotated files, akin to those in the BIRD dataset, facilitating the\nruntime retrieval of pertinent schema information. This strategy significantly\nreduces the token count for schema linking prompts, enabling the use of a\nstandard GPT-4 model over its larger context variant, thus handling large-scale\ndatabases more effectively and economically. Our evaluation on the BIRD\ndataset, a challenging real-world benchmark, demonstrates that DFIN not only\nscales efficiently but also improves accuracy, achieving a score of 51.69. This\nimprovement surpasses DIN-SQL method (the current third-place), which is the\nhighest-ranked model employing in-context learning rather than fine-tuning,\npreviously scoring 50.72. The advancement of DFIN underscores the evolving\ncapabilities of in-context learning methodologies combined with advanced\nlanguage models, offering a promising avenue for future research in complex\nText-to-SQL conversion tasks.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00872v1",
    "authors": ["Shai Volvovsky", "Marco Marcassa", "Mustafa Panbiharwala"]
  },
  {
    "id": "2403.00876",
    "title": "Word Order and World Knowledge",
    "abstract": "  Word order is an important concept in natural language, and in this work, we\nstudy how word order affects the induction of world knowledge from raw text\nusing language models. We use word analogies to probe for such knowledge.\nSpecifically, in addition to the natural word order, we first respectively\nextract texts of six fixed word orders from five languages and then pretrain\nthe language models on these texts. Finally, we analyze the experimental\nresults of the fixed word orders on word analogies and show that i) certain\nfixed word orders consistently outperform or underperform others, though the\nspecifics vary across languages, and ii) the Wov2Lex hypothesis is not hold in\npre-trained language models, and the natural word order typically yields\nmediocre results. The source code will be made publicly available at\nhttps://github.com/lshowway/probing_by_analogy.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00876v1",
    "authors": ["Qinghua Zhao", "Vinit Ravishankar", "Nicolas Garneau", "Anders Søgaard"]
  },
  {
    "id": "2403.00878",
    "title": "Crimson: Empowering Strategic Reasoning in Cybersecurity through Large\n  Language Models",
    "abstract": "  We introduces Crimson, a system that enhances the strategic reasoning\ncapabilities of Large Language Models (LLMs) within the realm of cybersecurity.\nBy correlating CVEs with MITRE ATT&CK techniques, Crimson advances threat\nanticipation and strategic defense efforts. Our approach includes defining and\nevaluating cybersecurity strategic tasks, alongside implementing a\ncomprehensive human-in-the-loop data-synthetic workflow to develop the\nCVE-to-ATT&CK Mapping (CVEM) dataset. We further enhance LLMs' reasoning\nabilities through a novel Retrieval-Aware Training (RAT) process and its\nrefined iteration, RAT-R.\n  Our findings demonstrate that an LLM fine-tuned with our techniques,\npossessing 7 billion parameters, approaches the performance level of GPT-4,\nshowing markedly lower rates of hallucination and errors, and surpassing other\nmodels in strategic reasoning tasks. Moreover, domain-specific fine-tuning of\nembedding models significantly improves performance within cybersecurity\ncontexts, underscoring the efficacy of our methodology. By leveraging Crimson\nto convert raw vulnerability data into structured and actionable insights, we\nbolster proactive cybersecurity defenses.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00878v1",
    "authors": [
      "Jiandong Jin",
      "Bowen Tang",
      "Mingxuan Ma",
      "Xiao Liu",
      "Yunfei Wang",
      "Qingnan Lai",
      "Jia Yang",
      "Changling Zhou"
    ]
  },
  {
    "id": "2403.00880",
    "title": "Dual-Granularity Medication Recommendation Based on Causal Inference",
    "abstract": "  As medical demands grow and machine learning technology advances, AI-based\ndiagnostic and treatment systems are garnering increasing attention. Medication\nrecommendation aims to integrate patients' long-term health records with\nmedical knowledge, recommending accuracy and safe medication combinations for\nspecific conditions. However, most existing researches treat medication\nrecommendation systems merely as variants of traditional recommendation\nsystems, overlooking the heterogeneity between medications and diseases. To\naddress this challenge, we propose DGMed, a framework for medication\nrecommendation. DGMed utilizes causal inference to uncover the connections\namong medical entities and presents an innovative feature alignment method to\ntackle heterogeneity issues. Specifically, this study first applies causal\ninference to analyze the quantified therapeutic effects of medications on\nspecific diseases from historical records, uncovering potential links between\nmedical entities. Subsequently, we integrate molecular-level knowledge,\naligning the embeddings of medications and diseases within the molecular space\nto effectively tackle their heterogeneity. Ultimately, based on relationships\nat the entity level, we adaptively adjust the recommendation probabilities of\nmedication and recommend medication combinations according to the patient's\ncurrent health condition. Experimental results on a real-world dataset show\nthat our method surpasses existing state-of-the-art baselines in four\nevaluation metrics, demonstrating superior performance in both accuracy and\nsafety aspects. Compared to the sub-optimal model, our approach improved\naccuracy by 4.40%, reduced the risk of side effects by 6.14%, and increased\ntime efficiency by 47.15%.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00880v1",
    "authors": [
      "Shunpan Liang",
      "Xiang Li",
      "Xiang Li",
      "Chen Li",
      "Yu Lei",
      "Yulei Hou",
      "Tengfei Ma"
    ]
  },
  {
    "id": "2403.00890",
    "title": "Improving Android Malware Detection Through Data Augmentation Using\n  Wasserstein Generative Adversarial Networks",
    "abstract": "  Generative Adversarial Networks (GANs) have demonstrated their versatility\nacross various applications, including data augmentation and malware detection.\nThis research explores the effectiveness of utilizing GAN-generated data to\ntrain a model for the detection of Android malware. Given the considerable\nstorage requirements of Android applications, the study proposes a method to\nsynthetically represent data using GANs, thereby reducing storage demands. The\nproposed methodology involves creating image representations of features\nextracted from an existing dataset. A GAN model is then employed to generate a\nmore extensive dataset consisting of realistic synthetic grayscale images.\nSubsequently, this synthetic dataset is utilized to train a Convolutional\nNeural Network (CNN) designed to identify previously unseen Android malware\napplications. The study includes a comparative analysis of the CNN's\nperformance when trained on real images versus synthetic images generated by\nthe GAN. Furthermore, the research explores variations in performance between\nthe Wasserstein Generative Adversarial Network (WGAN) and the Deep\nConvolutional Generative Adversarial Network (DCGAN). The investigation extends\nto studying the impact of image size and malware obfuscation on the\nclassification model's effectiveness. The data augmentation approach\nimplemented in this study resulted in a notable performance enhancement of the\nclassification model, ranging from 1.5% to 7%, depending on the dataset. The\nhighest achieved F1 score reached 0.975.\n  Keywords--Generative Adversarial Networks, Android Malware, Data\nAugmentation, Wasserstein Generative Adversarial Network\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00890v2",
    "authors": ["Kawana Stalin", "Mikias Berhanu Mekoya"]
  },
  {
    "id": "2403.00896",
    "title": "DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large\n  Language Models",
    "abstract": "  Since large language models (LLMs) achieve significant success in recent\nyears, the hallucination issue remains a challenge, numerous benchmarks are\nproposed to detect the hallucination. Nevertheless, some of these benchmarks\nare not naturally generated by LLMs but are intentionally induced. Also, many\nmerely focus on the factuality hallucination while ignoring the faithfulness\nhallucination. Additionally, although dialogue pattern is more widely utilized\nin the era of LLMs, current benchmarks only concentrate on sentence-level and\npassage-level hallucination. In this study, we propose DiaHalu, the first\ndialogue-level hallucination evaluation benchmark to our knowledge. Initially,\nwe integrate the collected topics into system prompts and facilitate a dialogue\nbetween two ChatGPT3.5. Subsequently, we manually modify the contents that do\nnot adhere to human language conventions and then have LLMs re-generate,\nsimulating authentic human-machine interaction scenarios. Finally, professional\nscholars annotate all the samples in the dataset. DiaHalu covers four common\nmulti-turn dialogue domains and five hallucination subtypes, extended from\nfactuality and faithfulness hallucination. Experiments through some well-known\nLLMs and detection methods on the dataset show that DiaHalu is a challenging\nbenchmark, holding significant value for further research.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00896v1",
    "authors": ["Kedi Chen", "Qin Chen", "Jie Zhou", "Yishen He", "Liang He"]
  },
  {
    "id": "2403.00930",
    "title": "Scale-free Adversarial Reinforcement Learning",
    "abstract": "  This paper initiates the study of scale-free learning in Markov Decision\nProcesses (MDPs), where the scale of rewards/losses is unknown to the learner.\nWe design a generic algorithmic framework, \\underline{S}cale\n\\underline{C}lipping \\underline{B}ound (\\texttt{SCB}), and instantiate this\nframework in both the adversarial Multi-armed Bandit (MAB) setting and the\nadversarial MDP setting. Through this framework, we achieve the first minimax\noptimal expected regret bound and the first high-probability regret bound in\nscale-free adversarial MABs, resolving an open problem raised in\n\\cite{hadiji2023adaptation}. On adversarial MDPs, our framework also give birth\nto the first scale-free RL algorithm with a $\\tilde{\\mathcal{O}}(\\sqrt{T})$\nhigh-probability regret guarantee.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00930v1",
    "authors": ["Mingyu Chen", "Xuezhou Zhang"]
  },
  {
    "id": "2403.00953",
    "title": "AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge\n  Graph Construction Based on Ontologies-enhanced Large Language Models",
    "abstract": "  Objectives: Our objective is to create an end-to-end system called AutoRD,\nwhich automates extracting information from clinical text about rare diseases.\nWe have conducted various tests to evaluate the performance of AutoRD and\nhighlighted its strengths and limitations in this paper.\n  Materials and Methods: Our system, AutoRD, is a software pipeline involving\ndata preprocessing, entity extraction, relation extraction, entity calibration,\nand knowledge graph construction. We implement this using large language models\nand medical knowledge graphs developed from open-source medical ontologies. We\nquantitatively evaluate our system on entity extraction, relation extraction,\nand the performance of knowledge graph construction.\n  Results: AutoRD achieves an overall F1 score of 47.3%, a 14.4% improvement\ncompared to the base LLM. In detail, AutoRD achieves an overall entity\nextraction F1 score of 56.1% (rare_disease: 83.5%, disease: 35.8%,\nsymptom_and_sign: 46.1%, anaphor: 67.5%) and an overall relation extraction F1\nscore of 38.6% (produces: 34.7%, increases_risk_of: 12.4%, is_a: 37.4%,\nis_acronym: 44.1%, is_synonym: 16.3%, anaphora: 57.5%). Our qualitative\nexperiment also demonstrates that the performance in constructing the knowledge\ngraph is commendable.\n  Discussion: AutoRD demonstrates the potential of LLM applications in rare\ndisease detection. This improvement is attributed to several design, including\nthe integration of ontologies-enhanced LLMs.\n  Conclusion: AutoRD is an automated end-to-end system for extracting rare\ndisease information from text to build knowledge graphs. It uses\nontologies-enhanced LLMs for a robust medical knowledge base. The superior\nperformance of AutoRD is validated by experimental evaluations, demonstrating\nthe potential of LLMs in healthcare.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00953v1",
    "authors": ["Lang Cao", "Jimeng Sun", "Adam Cross"]
  },
  {
    "id": "2403.01002",
    "title": "Attribute Structuring Improves LLM-Based Evaluation of Clinical Text\n  Summaries",
    "abstract": "  Summarizing clinical text is crucial in health decision-support and clinical\nresearch. Large language models (LLMs) have shown the potential to generate\naccurate clinical text summaries, but still struggle with issues regarding\ngrounding and evaluation, especially in safety-critical domains such as health.\nHolistically evaluating text summaries is challenging because they may contain\nunsubstantiated information. Here, we explore a general mitigation framework\nusing Attribute Structuring (AS), which structures the summary evaluation\nprocess. It decomposes the evaluation process into a grounded procedure that\nuses an LLM for relatively simple structuring and scoring tasks, rather than\nthe full task of holistic summary evaluation. Experiments show that AS\nconsistently improves the correspondence between human annotations and\nautomated metrics in clinical text summarization. Additionally, AS yields\ninterpretations in the form of a short text span corresponding to each output,\nwhich enables efficient human auditing, paving the way towards trustworthy\nevaluation of clinical information in resource-constrained scenarios. We\nrelease our code, prompts, and an open-source benchmark at\nhttps://github.com/microsoft/attribute-structuring.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.01002v1",
    "authors": [
      "Zelalem Gero",
      "Chandan Singh",
      "Yiqing Xie",
      "Sheng Zhang",
      "Tristan Naumann",
      "Jianfeng Gao",
      "Hoifung Poon"
    ]
  },
  {
    "id": "2403.01003",
    "title": "FlaKat: A Machine Learning-Based Categorization Framework for Flaky\n  Tests",
    "abstract": "  Flaky tests can pass or fail non-deterministically, without alterations to a\nsoftware system. Such tests are frequently encountered by developers and hinder\nthe credibility of test suites. State-of-the-art research incorporates machine\nlearning solutions into flaky test detection and achieves reasonably good\naccuracy. Moreover, the majority of automated flaky test repair solutions are\ndesigned for specific types of flaky tests. This research work proposes a novel\ncategorization framework, called FlaKat, which uses machine-learning\nclassifiers for fast and accurate prediction of the category of a given flaky\ntest that reflects its root cause. Sampling techniques are applied to address\nthe imbalance between flaky test categories in the International Dataset of\nFlaky Test (IDoFT). A new evaluation metric, called Flakiness Detection\nCapacity (FDC), is proposed for measuring the accuracy of classifiers from the\nperspective of information theory and provides proof for its effectiveness. The\nfinal FDC results are also in agreement with F1 score regarding which\nclassifier yields the best flakiness classification.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.01003v1",
    "authors": ["Shizhe Lin", "Ryan Zheng He Liu", "Ladan Tahvildari"]
  },
  {
    "id": "2403.01031",
    "title": "Peacock: A Family of Arabic Multimodal Large Language Models and\n  Benchmarks",
    "abstract": "  Multimodal large language models (MLLMs) have proven effective in a wide\nrange of tasks requiring complex reasoning and linguistic comprehension.\nHowever, due to a lack of high-quality multimodal resources in languages other\nthan English, success of MLLMs remains relatively limited to English-based\nsettings. This poses significant challenges in developing comparable models for\nother languages, including even those with large speaker populations such as\nArabic. To alleviate this challenge, we introduce a comprehensive family of\nArabic MLLMs, dubbed \\textit{Peacock}, with strong vision and language\ncapabilities. Through comprehensive qualitative and quantitative analysis, we\ndemonstrate the solid performance of our models on various visual reasoning\ntasks and further show their emerging dialectal potential. Additionally, we\nintroduce ~\\textit{Henna}, a new benchmark specifically designed for assessing\nMLLMs on aspects related to Arabic culture, setting the first stone for\nculturally-aware Arabic MLLMs.The GitHub repository for the \\textit{Peacock}\nproject is available at \\url{https://github.com/UBC-NLP/peacock}.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.01031v1",
    "authors": [
      "Fakhraddin Alwajih",
      "El Moatez Billah Nagoudi",
      "Gagan Bhatia",
      "Abdelrahman Mohamed",
      "Muhammad Abdul-Mageed"
    ]
  },
  {
    "id": "2403.02352",
    "title": "ATP: Enabling Fast LLM Serving via Attention on Top Principal Keys",
    "abstract": "  We propose a new attention mechanism with linear complexity, ATP, that\nfixates \\textbf{A}ttention on \\textbf{T}op \\textbf{P}rincipal keys, rather than\non each individual token. Particularly, ATP is driven by an important\nobservation that input sequences are typically low-rank, i.e., input sequences\ncan be represented by a few principal bases. Therefore, instead of directly\niterating over all the input tokens, ATP transforms inputs into an orthogonal\nspace and computes attention only on the top principal bases (keys). Owing to\nthe observed low-rank structure in input sequences, ATP is able to capture\nsemantic relationships in input sequences with a few principal keys.\nFurthermore, the attention complexity is reduced from \\emph{quadratic} to\n\\emph{linear} without incurring a noticeable performance drop. ATP further\nreduces complexity for other linear layers with low-rank inputs, leading to\nmore speedup compared to prior works that solely target the attention module.\nOur evaluations on various models (e.g., BERT and Llama) demonstrate that ATP\nachieves comparable accuracy with much lower computation and memory complexity\nthan the standard attention mechanism. In particular, ATP barely loses accuracy\nwith only $1/2$ principal keys, and only incurs around $2\\%$ accuracy drops\nwith $1/4$ principal keys.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.02352v1",
    "authors": ["Yue Niu", "Saurav Prakash", "Salman Avestimehr"]
  },
  {
    "id": "2403.00198",
    "title": "AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language\n  Model Outputs",
    "abstract": "  Pre-trained Large Language Models (LLMs) have significantly advanced natural\nlanguage processing capabilities but are susceptible to biases present in their\ntraining data, leading to unfair outcomes in various applications. While\nnumerous strategies have been proposed to mitigate bias, they often require\nextensive computational resources and may compromise model performance. In this\nwork, we introduce AXOLOTL, a novel post-processing framework, which operates\nagnostically across tasks and models, leveraging public APIs to interact with\nLLMs without direct access to internal parameters. Through a three-step process\nresembling zero-shot learning, AXOLOTL identifies biases, proposes resolutions,\nand guides the model to self-debias its outputs. This approach minimizes\ncomputational costs and preserves model performance, making AXOLOTL a promising\ntool for debiasing LLM outputs with broad applicability and ease of use.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00198v1",
    "authors": ["Sana Ebrahimi", "Kaiwen Chen", "Abolfazl Asudeh", "Gautam Das", "Nick Koudas"]
  },
  {
    "id": "2403.00236",
    "title": "Benchmarking zero-shot stance detection with FlanT5-XXL: Insights from\n  training data, prompting, and decoding strategies into its near-SoTA\n  performance",
    "abstract": "  We investigate the performance of LLM-based zero-shot stance detection on\ntweets. Using FlanT5-XXL, an instruction-tuned open-source LLM, with the\nSemEval 2016 Tasks 6A, 6B, and P-Stance datasets, we study the performance and\nits variations under different prompts and decoding strategies, as well as the\npotential biases of the model. We show that the zero-shot approach can match or\noutperform state-of-the-art benchmarks, including fine-tuned models. We provide\nvarious insights into its performance including the sensitivity to instructions\nand prompts, the decoding strategies, the perplexity of the prompts, and to\nnegations and oppositions present in prompts. Finally, we ensure that the LLM\nhas not been trained on test datasets, and identify a positivity bias which may\npartially explain the performance differences across decoding strategie\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00236v1",
    "authors": [
      "Rachith Aiyappa",
      "Shruthi Senthilmani",
      "Jisun An",
      "Haewoon Kwak",
      "Yong-Yeol Ahn"
    ]
  },
  {
    "id": "2403.00252",
    "title": "EUROPA: A Legal Multilingual Keyphrase Generation Dataset",
    "abstract": "  Keyphrase generation has primarily been explored within the context of\nacademic research articles, with a particular focus on scientific domains and\nthe English language. In this work, we present EUROPA, a dataset for\nmultilingual keyphrase generation in the legal domain. It is derived from legal\njudgments from the Court of Justice of the European Union (EU), and contains\ninstances in all 24 EU official languages. We run multilingual models on our\ncorpus and analyze the results, showing room for improvement on a\ndomain-specific multilingual corpus such as the one we present.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00252v1",
    "authors": [
      "Olivier Salaün",
      "Frédéric Piedboeuf",
      "Guillaume Le Berre",
      "David Alfonso Hermelo",
      "Philippe Langlais"
    ]
  },
  {
    "id": "2403.00254",
    "title": "Cloud-based Federated Learning Framework for MRI Segmentation",
    "abstract": "  In contemporary rural healthcare settings, the principal challenge in\ndiagnosing brain images is the scarcity of available data, given that most of\nthe existing deep learning models demand extensive training data to optimize\ntheir performance, necessitating centralized processing methods that\npotentially compromise data privacy. This paper proposes a novel framework\ntailored for brain tissue segmentation in rural healthcare facilities. The\nframework employs a deep reinforcement learning (DRL) environment in tandem\nwith a refinement model (RM) deployed locally at rural healthcare sites. The\nproposed DRL model has a reduced parameter count and practicality for\nimplementation across distributed rural sites. To uphold data privacy and\nenhance model generalization without transgressing privacy constraints, we\nemploy federated learning (FL) for cooperative model training. We demonstrate\nthe efficacy of our approach by training the network with a limited data set\nand observing a substantial performance enhancement, mitigating inaccuracies\nand irregularities in segmentation across diverse sites. Remarkably, the DRL\nmodel attains an accuracy of up to 80%, surpassing the capabilities of\nconventional convolutional neural networks when confronted with data\ninsufficiency. Incorporating our RM results in an additional accuracy\nimprovement of at least 10%, while FL contributes to a further accuracy\nenhancement of up to 5%. Collectively, the framework achieves an average 92%\naccuracy rate within rural healthcare settings characterized by data\nconstraints.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00254v1",
    "authors": ["Rukesh Prajapati", "Amr S. El-Wakeel"]
  },
  {
    "id": "2403.00290",
    "title": "Semantic Text Transmission via Prediction with Small Language Models:\n  Cost-Similarity Trade-off",
    "abstract": "  We consider the communication of natural language text from a source to a\ndestination over noiseless and character-erasure channels. We exploit\nlanguage's inherent correlations and predictability to constrain transmission\ncosts by allowing the destination to predict or complete words with potential\ndissimilarity with the source text. Concretely, our objective is to obtain\nachievable $(\\bar{c}, \\bar{s})$ pairs, where $\\bar{c}$ is the average\ntransmission cost at the source and $\\bar{s}$ is the average semantic\nsimilarity measured via cosine similarity between vector embedding of words at\nthe source and those predicted/completed at the destination. We obtain\n$(\\bar{c}, \\bar{s})$ pairs for neural language and first-order Markov\nchain-based small language models (SLM) for prediction, using both a threshold\npolicy that transmits a word if its cosine similarity with that\npredicted/completed at the destination is below a threshold, and a periodic\npolicy, which transmits words after a specific interval and predicts/completes\nthe words in between, at the destination. We adopt an SLM for word completion.\nWe demonstrate that, when communication occurs over a noiseless channel, the\nthreshold policy achieves a higher $\\bar{s}$ for a given $\\bar{c}$ than the\nperiodic policy and that the $\\bar{s}$ achieved with the neural SLM is greater\nthan or equal to that of the Markov chain-based algorithm for the same\n$\\bar{c}$. The improved performance comes with a higher complexity in terms of\ntime and computing requirements. However, when communication occurs over a\ncharacter-erasure channel, all prediction algorithms and scheduling policies\nperform poorly. Furthermore, if character-level Huffman coding is used, the\nrequired $\\bar{c}$ to achieve a given $\\bar{s}$ is reduced, but the above\nobservations still apply.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00290v1",
    "authors": [
      "Bhavani A Madhabhavi",
      "Gangadhar Karevvanavar",
      "Rajshekhar V Bhat",
      "Nikolaos Pappas"
    ]
  },
  {
    "id": "2403.00353",
    "title": "MS-Net: A Multi-Path Sparse Model for Motion Prediction in Multi-Scenes",
    "abstract": "  The multi-modality and stochastic characteristics of human behavior make\nmotion prediction a highly challenging task, which is critical for autonomous\ndriving. While deep learning approaches have demonstrated their great potential\nin this area, it still remains unsolved to establish a connection between\nmultiple driving scenes (e.g., merging, roundabout, intersection) and the\ndesign of deep learning models. Current learning-based methods typically use\none unified model to predict trajectories in different scenarios, which may\nresult in sub-optimal results for one individual scene. To address this issue,\nwe propose Multi-Scenes Network (aka. MS-Net), which is a multi-path sparse\nmodel trained by an evolutionary process. MS-Net selectively activates a subset\nof its parameters during the inference stage to produce prediction results for\neach scene. In the training stage, the motion prediction task under\ndifferentiated scenes is abstracted as a multi-task learning problem, an\nevolutionary algorithm is designed to encourage the network search of the\noptimal parameters for each scene while sharing common knowledge between\ndifferent scenes. Our experiment results show that with substantially reduced\nparameters, MS-Net outperforms existing state-of-the-art methods on\nwell-established pedestrian motion prediction datasets, e.g., ETH and UCY, and\nranks the 2nd place on the INTERACTION challenge.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00353v1",
    "authors": ["Xiaqiang Tang", "Weigao Sun", "Siyuan Hu", "Yiyang Sun", "Yafeng Guo"]
  },
  {
    "id": "2403.00376",
    "title": "Invariant Test-Time Adaptation for Vision-Language Model Generalization",
    "abstract": "  Vision-language foundation models have exhibited remarkable success across a\nmultitude of downstream tasks due to their scalability on extensive image-text\npaired datasets. However, these models display significant limitations when\napplied to long-tail tasks, such as fine-grained image classification, as a\nresult of \"decision shortcuts\" that hinders their generalization capabilities.\nIn this work, we find that the CLIP model possesses a rich set of features,\nencompassing both \\textit{desired invariant causal features} and\n\\textit{undesired decision shortcuts}. Moreover, the underperformance of CLIP\non downstream tasks originates from its inability to effectively utilize\npre-trained features in accordance with specific task requirements. To address\nthis challenge, this paper introduces a test-time prompt tuning paradigm that\noptimizes a learnable prompt, thereby compelling the model to exploit genuine\ncausal invariant features while disregarding decision shortcuts during the\ninference phase. The proposed method effectively alleviates excessive\ndependence on potentially misleading, task-irrelevant contextual information,\nwhile concurrently emphasizing critical, task-related visual cues. We conduct\ncomparative analysis of the proposed method against various approaches which\nvalidates its effectiveness.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00376v1",
    "authors": [
      "Huan Ma",
      "Yan Zhu",
      "Changqing Zhang",
      "Peilin Zhao",
      "Baoyuan Wu",
      "Long-Kai Huang",
      "Qinghua Hu",
      "Bingzhe Wu"
    ]
  },
  {
    "id": "2403.00425",
    "title": "HALC: Object Hallucination Reduction via Adaptive Focal-Contrast\n  Decoding",
    "abstract": "  While large vision-language models (LVLMs) have demonstrated impressive\ncapabilities in interpreting multi-modal contexts, they invariably suffer from\nobject hallucinations (OH). We introduce HALC, a novel decoding algorithm\ndesigned to mitigate OH in LVLMs. HALC leverages distinct fine-grained optimal\nvisual information in vision-language tasks and operates on both local and\nglobal contexts simultaneously. Specifically, HALC integrates a robust\nauto-focal grounding mechanism (locally) to correct hallucinated tokens on the\nfly, and a specialized beam search algorithm (globally) to significantly reduce\nOH while preserving text generation quality. Additionally, HALC can be\nintegrated into any LVLMs as a plug-and-play module without extra training.\nExtensive experimental studies demonstrate the effectiveness of HALC in\nreducing OH, outperforming state-of-the-arts across four benchmarks.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00425v1",
    "authors": ["Zhaorun Chen", "Zhuokai Zhao", "Hongyin Luo", "Huaxiu Yao", "Bo Li", "Jiawei Zhou"]
  },
  {
    "id": "2403.00437",
    "title": "LoMOE: Localized Multi-Object Editing via Multi-Diffusion",
    "abstract": "  Recent developments in the field of diffusion models have demonstrated an\nexceptional capacity to generate high-quality prompt-conditioned image edits.\nNevertheless, previous approaches have primarily relied on textual prompts for\nimage editing, which tend to be less effective when making precise edits to\nspecific objects or fine-grained regions within a scene containing\nsingle/multiple objects. We introduce a novel framework for zero-shot localized\nmulti-object editing through a multi-diffusion process to overcome this\nchallenge. This framework empowers users to perform various operations on\nobjects within an image, such as adding, replacing, or editing $\\textbf{many}$\nobjects in a complex scene $\\textbf{in one pass}$. Our approach leverages\nforeground masks and corresponding simple text prompts that exert localized\ninfluences on the target regions resulting in high-fidelity image editing. A\ncombination of cross-attention and background preservation losses within the\nlatent space ensures that the characteristics of the object being edited are\npreserved while simultaneously achieving a high-quality, seamless\nreconstruction of the background with fewer artifacts compared to the current\nmethods. We also curate and release a dataset dedicated to multi-object\nediting, named $\\texttt{LoMOE}$-Bench. Our experiments against existing\nstate-of-the-art methods demonstrate the improved effectiveness of our approach\nin terms of both image editing quality and inference speed.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00437v1",
    "authors": ["Goirik Chakrabarty", "Aditya Chandrasekar", "Ramya Hebbalaguppe", "Prathosh AP"]
  },
  {
    "id": "2403.00504",
    "title": "Learning and Leveraging World Models in Visual Representation Learning",
    "abstract": "  Joint-Embedding Predictive Architecture (JEPA) has emerged as a promising\nself-supervised approach that learns by leveraging a world model. While\npreviously limited to predicting missing parts of an input, we explore how to\ngeneralize the JEPA prediction task to a broader set of corruptions. We\nintroduce Image World Models, an approach that goes beyond masked image\nmodeling and learns to predict the effect of global photometric transformations\nin latent space. We study the recipe of learning performant IWMs and show that\nit relies on three key aspects: conditioning, prediction difficulty, and\ncapacity. Additionally, we show that the predictive world model learned by IWM\ncan be adapted through finetuning to solve diverse tasks; a fine-tuned IWM\nworld model matches or surpasses the performance of previous self-supervised\nmethods. Finally, we show that learning with an IWM allows one to control the\nabstraction level of the learned representations, learning invariant\nrepresentations such as contrastive methods, or equivariant representations\nsuch as masked image modelling.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00504v1",
    "authors": [
      "Quentin Garrido",
      "Mahmoud Assran",
      "Nicolas Ballas",
      "Adrien Bardes",
      "Laurent Najman",
      "Yann LeCun"
    ]
  },
  {
    "id": "2403.00509",
    "title": "Surveying the Dead Minds: Historical-Psychological Text Analysis with\n  Contextualized Construct Representation (CCR) for Classical Chinese",
    "abstract": "  In this work, we develop a pipeline for historical-psychological text\nanalysis in classical Chinese. Humans have produced texts in various languages\nfor thousands of years; however, most of the computational literature is\nfocused on contemporary languages and corpora. The emerging field of historical\npsychology relies on computational techniques to extract aspects of psychology\nfrom historical corpora using new methods developed in natural language\nprocessing (NLP). The present pipeline, called Contextualized Construct\nRepresentations (CCR), combines expert knowledge in psychometrics (i.e.,\npsychological surveys) with text representations generated via\ntransformer-based language models to measure psychological constructs such as\ntraditionalism, norm strength, and collectivism in classical Chinese corpora.\nConsidering the scarcity of available data, we propose an indirect supervised\ncontrastive learning approach and build the first Chinese historical psychology\ncorpus (C-HI-PSY) to fine-tune pre-trained models. We evaluate the pipeline to\ndemonstrate its superior performance compared with other approaches. The CCR\nmethod outperforms word-embedding-based approaches across all of our tasks and\nexceeds prompting with GPT-4 in most tasks. Finally, we benchmark the pipeline\nagainst objective, external data to further verify its validity.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00509v1",
    "authors": ["Yuqi Chen", "Sixuan Li", "Ying Li", "Mohammad Atari"]
  },
  {
    "id": "2403.00564",
    "title": "EfficientZero V2: Mastering Discrete and Continuous Control with Limited\n  Data",
    "abstract": "  Sample efficiency remains a crucial challenge in applying Reinforcement\nLearning (RL) to real-world tasks. While recent algorithms have made\nsignificant strides in improving sample efficiency, none have achieved\nconsistently superior performance across diverse domains. In this paper, we\nintroduce EfficientZero V2, a general framework designed for sample-efficient\nRL algorithms. We have expanded the performance of EfficientZero to multiple\ndomains, encompassing both continuous and discrete actions, as well as visual\nand low-dimensional inputs. With a series of improvements we propose,\nEfficientZero V2 outperforms the current state-of-the-art (SOTA) by a\nsignificant margin in diverse tasks under the limited data setting.\nEfficientZero V2 exhibits a notable advancement over the prevailing general\nalgorithm, DreamerV3, achieving superior outcomes in 50 of 66 evaluated tasks\nacross diverse benchmarks, such as Atari 100k, Proprio Control, and Vision\nControl.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00564v1",
    "authors": ["Shengjie Wang", "Shaohuai Liu", "Weirui Ye", "Jiacheng You", "Yang Gao"]
  },
  {
    "id": "2403.00570",
    "title": "Rethinking cluster-conditioned diffusion models",
    "abstract": "  We present a comprehensive experimental study on image-level conditioning for\ndiffusion models using cluster assignments. We elucidate how individual\ncomponents regarding image clustering impact image synthesis across three\ndatasets. By combining recent advancements from image clustering and diffusion\nmodels, we show that, given the optimal cluster granularity with respect to\nimage synthesis (visual groups), cluster-conditioning can achieve\nstate-of-the-art FID (i.e. 1.67, 2.17 on CIFAR10 and CIFAR100 respectively),\nwhile attaining a strong training sample efficiency. Finally, we propose a\nnovel method to derive an upper cluster bound that reduces the search space of\nthe visual groups using solely feature-based clustering. Unlike existing\napproaches, we find no significant connection between clustering and\ncluster-conditional image generation. The code and cluster assignments will be\nreleased.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00570v1",
    "authors": ["Nikolas Adaloglou", "Tim Kaiser", "Felix Michels", "Markus Kollmann"]
  },
  {
    "id": "2403.00632",
    "title": "Metamorpheus: Interactive, Affective, and Creative Dream Narration\n  Through Metaphorical Visual Storytelling",
    "abstract": "  Human emotions are essentially molded by lived experiences, from which we\nconstruct personalised meaning. The engagement in such meaning-making process\nhas been practiced as an intervention in various psychotherapies to promote\nwellness. Nevertheless, to support recollecting and recounting lived\nexperiences in everyday life remains under explored in HCI. It also remains\nunknown how technologies such as generative AI models can facilitate the\nmeaning making process, and ultimately support affective mindfulness. In this\npaper we present Metamorpheus, an affective interface that engages users in a\ncreative visual storytelling of emotional experiences during dreams.\nMetamorpheus arranges the storyline based on a dream's emotional arc, and\nprovokes self-reflection through the creation of metaphorical images and text\ndepictions. The system provides metaphor suggestions, and generates visual\nmetaphors and text depictions using generative AI models, while users can apply\ngenerations to recolour and re-arrange the interface to be visually affective.\nOur experience-centred evaluation manifests that, by interacting with\nMetamorpheus, users can recall their dreams in vivid detail, through which they\nrelive and reflect upon their experiences in a meaningful way.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00632v1",
    "authors": ["Qian Wan", "Xin Feng", "Yining Bei", "Zhiqi Gao", "Zhicong Lu"]
  },
  {
    "id": "2403.00642",
    "title": "Rethinking The Uniformity Metric in Self-Supervised Learning",
    "abstract": "  Uniformity plays a crucial role in the assessment of learned representations,\ncontributing to a deeper comprehension of self-supervised learning. The seminal\nwork by \\citet{Wang2020UnderstandingCR} introduced a uniformity metric that\nquantitatively measures the collapse degree of learned representations.\nDirectly optimizing this metric together with alignment proves to be effective\nin preventing constant collapse. However, we present both theoretical and\nempirical evidence revealing that this metric lacks sensitivity to dimensional\ncollapse, highlighting its limitations. To address this limitation and design a\nmore effective uniformity metric, this paper identifies five fundamental\nproperties, some of which the existing uniformity metric fails to meet. We\nsubsequently introduce a novel uniformity metric that satisfies all of these\ndesiderata and exhibits sensitivity to dimensional collapse. When applied as an\nauxiliary loss in various established self-supervised methods, our proposed\nuniformity metric consistently enhances their performance in downstream\ntasks.Our code was released at\nhttps://github.com/sunset-clouds/WassersteinUniformityMetric.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00642v1",
    "authors": ["Xianghong Fang", "Jian Li", "Qiang Sun", "Benyou Wang"]
  },
  {
    "id": "2403.00692",
    "title": "Toward Autonomous Cooperation in Heterogeneous Nanosatellite\n  Constellations Using Dynamic Graph Neural Networks",
    "abstract": "  The upcoming landscape of Earth Observation missions will defined by\nnetworked heterogeneous nanosatellite constellations required to meet strict\nmission requirements, such as revisit times and spatial resolution. However,\nscheduling satellite communications in these satellite networks through\nefficiently creating a global satellite Contact Plan (CP) is a complex task,\nwith current solutions requiring ground-based coordination or being limited by\nonboard computational resources. The paper proposes a novel approach to\novercome these challenges by modeling the constellations and CP as dynamic\nnetworks and employing graph-based techniques. The proposed method utilizes a\nstate-of-the-art dynamic graph neural network to evaluate the performance of a\ngiven CP and update it using a heuristic algorithm based on simulated\nannealing. The trained neural network can predict the network delay with a mean\nabsolute error of 3.6 minutes. Simulation results show that the proposed method\ncan successfully design a contact plan for large satellite networks, improving\nthe delay by 29.1%, similar to a traditional approach, while performing the\nobjective evaluations 20x faster.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00692v2",
    "authors": ["Guillem Casadesus-Vila", "Joan-Adria Ruiz-de-Azua", "Eduard Alarcon"]
  },
  {
    "id": "2403.00694",
    "title": "Defining Expertise: Applications to Treatment Effect Estimation",
    "abstract": "  Decision-makers are often experts of their domain and take actions based on\ntheir domain knowledge. Doctors, for instance, may prescribe treatments by\npredicting the likely outcome of each available treatment. Actions of an expert\nthus naturally encode part of their domain knowledge, and can help make\ninferences within the same domain: Knowing doctors try to prescribe the best\ntreatment for their patients, we can tell treatments prescribed more frequently\nare likely to be more effective. Yet in machine learning, the fact that most\ndecision-makers are experts is often overlooked, and \"expertise\" is seldom\nleveraged as an inductive bias. This is especially true for the literature on\ntreatment effect estimation, where often the only assumption made about actions\nis that of overlap. In this paper, we argue that expertise - particularly the\ntype of expertise the decision-makers of a domain are likely to have - can be\ninformative in designing and selecting methods for treatment effect estimation.\nWe formally define two types of expertise, predictive and prognostic, and\ndemonstrate empirically that: (i) the prominent type of expertise in a domain\nsignificantly influences the performance of different methods in treatment\neffect estimation, and (ii) it is possible to predict the type of expertise\npresent in a dataset, which can provide a quantitative basis for model\nselection.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00694v1",
    "authors": ["Alihan Hüyük", "Qiyao Wei", "Alicia Curth", "Mihaela van der Schaar"]
  },
  {
    "id": "2403.00742",
    "title": "Dialect prejudice predicts AI decisions about people's character,\n  employability, and criminality",
    "abstract": "  Hundreds of millions of people now interact with language models, with uses\nranging from serving as a writing aid to informing hiring decisions. Yet these\nlanguage models are known to perpetuate systematic racial prejudices, making\ntheir judgments biased in problematic ways about groups like African Americans.\nWhile prior research has focused on overt racism in language models, social\nscientists have argued that racism with a more subtle character has developed\nover time. It is unknown whether this covert racism manifests in language\nmodels. Here, we demonstrate that language models embody covert racism in the\nform of dialect prejudice: we extend research showing that Americans hold\nraciolinguistic stereotypes about speakers of African American English and find\nthat language models have the same prejudice, exhibiting covert stereotypes\nthat are more negative than any human stereotypes about African Americans ever\nexperimentally recorded, although closest to the ones from before the civil\nrights movement. By contrast, the language models' overt stereotypes about\nAfrican Americans are much more positive. We demonstrate that dialect prejudice\nhas the potential for harmful consequences by asking language models to make\nhypothetical decisions about people, based only on how they speak. Language\nmodels are more likely to suggest that speakers of African American English be\nassigned less prestigious jobs, be convicted of crimes, and be sentenced to\ndeath. Finally, we show that existing methods for alleviating racial bias in\nlanguage models such as human feedback training do not mitigate the dialect\nprejudice, but can exacerbate the discrepancy between covert and overt\nstereotypes, by teaching language models to superficially conceal the racism\nthat they maintain on a deeper level. Our findings have far-reaching\nimplications for the fair and safe employment of language technology.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00742v1",
    "authors": ["Valentin Hofmann", "Pratyusha Ria Kalluri", "Dan Jurafsky", "Sharese King"]
  },
  {
    "id": "2403.00758",
    "title": "Mitigating Reversal Curse via Semantic-aware Permutation Training",
    "abstract": "  While large language models (LLMs) have achieved impressive performance\nacross diverse tasks, recent studies showcase that causal LLMs suffer from the\n\"reversal curse\". It is a typical example that the model knows \"A's father is\nB\", but is unable to reason \"B's child is A\". This limitation poses a challenge\nto the advancement of artificial general intelligence (AGI), as it suggests a\ngap in the models' ability to comprehend and apply bidirectional reasoning. In\nthis paper, we first conduct substantial evaluation and identify that the root\ncause of the reversal curse lies in the different word order between the\ntraining and inference stage, namely, the poor ability of causal language\nmodels to predict antecedent words within the training data. Accordingly,\npermutation on the training data is considered as a potential solution, since\nthis can make the model predict antecedent words or tokens. However, previous\npermutation methods may disrupt complete phrases or entities, thereby posing\nchallenges for the model to comprehend and learn from training data. To address\nthis issue, we propose Semantic-aware Permutation Training (SPT), which\naddresses this issue by segmenting the training sentences into semantic units\n(i.e., entities or phrases) with an assistant language model and permuting\nthese units before feeding into the model. Extensive experiments demonstrate\nthat SPT effectively mitigates the reversal curse since the performance on\nreversed questions approximates that on the forward ones, and significantly\nadvances the performance of existing works.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00758v1",
    "authors": ["Qingyan Guo", "Rui Wang", "Junliang Guo", "Xu Tan", "Jiang Bian", "Yujiu Yang"]
  },
  {
    "id": "2403.00865",
    "title": "Fast and Efficient Local Search for Genetic Programming Based Loss\n  Function Learning",
    "abstract": "  In this paper, we develop upon the topic of loss function learning, an\nemergent meta-learning paradigm that aims to learn loss functions that\nsignificantly improve the performance of the models trained under them.\nSpecifically, we propose a new meta-learning framework for task and\nmodel-agnostic loss function learning via a hybrid search approach. The\nframework first uses genetic programming to find a set of symbolic loss\nfunctions. Second, the set of learned loss functions is subsequently\nparameterized and optimized via unrolled differentiation. The versatility and\nperformance of the proposed framework are empirically validated on a diverse\nset of supervised learning tasks. Results show that the learned loss functions\nbring improved convergence, sample efficiency, and inference performance on\ntabulated, computer vision, and natural language processing problems, using a\nvariety of task-specific neural network architectures.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00865v1",
    "authors": ["Christian Raymond", "Qi Chen", "Bing Xue", "Mengjie Zhang"]
  },
  {
    "id": "2403.00867",
    "title": "Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by\n  Exploring Refusal Loss Landscapes",
    "abstract": "  Large Language Models (LLMs) are becoming a prominent generative AI tool,\nwhere the user enters a query and the LLM generates an answer. To reduce harm\nand misuse, efforts have been made to align these LLMs to human values using\nadvanced training techniques such as Reinforcement Learning from Human Feedback\n(RLHF). However, recent studies have highlighted the vulnerability of LLMs to\nadversarial jailbreak attempts aiming at subverting the embedded safety\nguardrails. To address this challenge, this paper defines and investigates the\nRefusal Loss of LLMs and then proposes a method called Gradient Cuff to detect\njailbreak attempts. Gradient Cuff exploits the unique properties observed in\nthe refusal loss landscape, including functional values and its smoothness, to\ndesign an effective two-step detection strategy. Experimental results on two\naligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak\nattacks (GCG, AutoDAN, PAIR, TAP, Base64, and LRL) show that Gradient Cuff can\nsignificantly improve the LLM's rejection capability for malicious jailbreak\nqueries, while maintaining the model's performance for benign user queries by\nadjusting the detection threshold.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00867v2",
    "authors": ["Xiaomeng Hu", "Pin-Yu Chen", "Tsung-Yi Ho"]
  },
  {
    "id": "2403.00871",
    "title": "Teach LLMs to Phish: Stealing Private Information from Language Models",
    "abstract": "  When large language models are trained on private data, it can be a\nsignificant privacy risk for them to memorize and regurgitate sensitive\ninformation. In this work, we propose a new practical data extraction attack\nthat we call \"neural phishing\". This attack enables an adversary to target and\nextract sensitive or personally identifiable information (PII), e.g., credit\ncard numbers, from a model trained on user data with upwards of 10% attack\nsuccess rates, at times, as high as 50%. Our attack assumes only that an\nadversary can insert as few as 10s of benign-appearing sentences into the\ntraining dataset using only vague priors on the structure of the user data.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00871v1",
    "authors": [
      "Ashwinee Panda",
      "Christopher A. Choquette-Choo",
      "Zhengming Zhang",
      "Yaoqing Yang",
      "Prateek Mittal"
    ]
  },
  {
    "id": "2403.00875",
    "title": "Enhancing Protein Predictive Models via Proteins Data Augmentation: A\n  Benchmark and New Directions",
    "abstract": "  Augmentation is an effective alternative to utilize the small amount of\nlabeled protein data. However, most of the existing work focuses on design-ing\nnew architectures or pre-training tasks, and relatively little work has studied\ndata augmentation for proteins. This paper extends data augmentation techniques\npreviously used for images and texts to proteins and then benchmarks these\ntechniques on a variety of protein-related tasks, providing the first\ncomprehensive evaluation of protein augmentation. Furthermore, we propose two\nnovel semantic-level protein augmentation methods, namely Integrated Gradients\nSubstitution and Back Translation Substitution, which enable protein\nsemantic-aware augmentation through saliency detection and biological\nknowledge. Finally, we integrate extended and proposed augmentations into an\naugmentation pool and propose a simple but effective framework, namely\nAutomated Protein Augmentation (APA), which can adaptively select the most\nsuitable augmentation combinations for different tasks. Extensive experiments\nhave shown that APA enhances the performance of five protein related tasks by\nan average of 10.55% across three architectures compared to vanilla\nimplementations without augmentation, highlighting its potential to make a\ngreat impact on the field.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00875v1",
    "authors": ["Rui Sun", "Lirong Wu", "Haitao Lin", "Yufei Huang", "Stan Z. Li"]
  },
  {
    "id": "2403.00884",
    "title": "Text classification of column headers with a controlled vocabulary:\n  leveraging LLMs for metadata enrichment",
    "abstract": "  Traditional dataset retrieval systems index on metadata information rather\nthan on the data values. Thus relying primarily on manual annotations and\nhigh-quality metadata, processes known to be labour-intensive and challenging\nto automate. We propose a method to support metadata enrichment with topic\nannotations of column headers using three Large Language Models (LLMs):\nChatGPT-3.5, GoogleBard and GoogleGemini. We investigate the LLMs ability to\nclassify column headers based on domain-specific topics from a controlled\nvocabulary. We evaluate our approach by assessing the internal consistency of\nthe LLMs, the inter-machine alignment, and the human-machine agreement for the\ntopic classification task. Additionally, we investigate the impact of\ncontextual information (i.e. dataset description) on the classification\noutcomes. Our results suggest that ChatGPT and GoogleGemini outperform\nGoogleBard for internal consistency as well as LLM-human-alignment.\nInterestingly, we found that context had no impact on the LLMs performances.\nThis work proposes a novel approach that leverages LLMs for text classification\nusing a controlled topic vocabulary, which has the potential to facilitate\nautomated metadata enrichment, thereby enhancing dataset retrieval and the\nFindability, Accessibility, Interoperability and Reusability (FAIR) of research\ndata on the Web.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00884v2",
    "authors": ["Margherita Martorana", "Tobias Kuhn", "Lise Stork", "Jacco van Ossenbruggen"]
  },
  {
    "id": "2403.00891",
    "title": "A Regularization-based Transfer Learning Method for Information\n  Extraction via Instructed Graph Decoder",
    "abstract": "  Information extraction (IE) aims to extract complex structured information\nfrom the text. Numerous datasets have been constructed for various IE tasks,\nleading to time-consuming and labor-intensive data annotations. Nevertheless,\nmost prevailing methods focus on training task-specific models, while the\ncommon knowledge among different IE tasks is not explicitly modeled. Moreover,\nthe same phrase may have inconsistent labels in different tasks, which poses a\nbig challenge for knowledge transfer using a unified model. In this study, we\npropose a regularization-based transfer learning method for IE (TIE) via an\ninstructed graph decoder. Specifically, we first construct an instruction pool\nfor datasets from all well-known IE tasks, and then present an instructed graph\ndecoder, which decodes various complex structures into a graph uniformly based\non corresponding instructions. In this way, the common knowledge shared with\nexisting datasets can be learned and transferred to a new dataset with new\nlabels. Furthermore, to alleviate the label inconsistency problem among various\nIE tasks, we introduce a task-specific regularization strategy, which does not\nupdate the gradients of two tasks with 'opposite direction'. We conduct\nextensive experiments on 12 datasets spanning four IE tasks, and the results\ndemonstrate the great advantages of our proposed method\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00891v1",
    "authors": ["Kedi Chen", "Jie Zhou", "Qin Chen", "Shunyu Liu", "Liang He"]
  },
  {
    "id": "2403.00894",
    "title": "A systematic evaluation of large language models for generating\n  programming code",
    "abstract": "  We systematically evaluated the performance of seven large language models in\ngenerating programming code using various prompt strategies, programming\nlanguages, and task difficulties. GPT-4 substantially outperforms other large\nlanguage models, including Gemini Ultra and Claude 2. The coding performance of\nGPT-4 varies considerably with different prompt strategies. In most LeetCode\nand GeeksforGeeks coding contests evaluated in this study, GPT-4 employing the\noptimal prompt strategy outperforms 85 percent of human participants.\nAdditionally, GPT-4 demonstrates strong capabilities in translating code\nbetween different programming languages and in learning from past errors. The\ncomputational efficiency of the code generated by GPT-4 is comparable to that\nof human programmers. These results suggest that GPT-4 has the potential to\nserve as a reliable assistant in programming code generation and software\ndevelopment.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00894v1",
    "authors": ["Wenpin Hou", "Zhicheng Ji"]
  },
  {
    "id": "2403.00895",
    "title": "End-to-end Graph-Sequential Representation Learning for Accurate\n  Recommendations",
    "abstract": "  Many recent advancements in recommender systems have focused on developing\nsequence-based and graph-based approaches. Both approaches proved useful in\nmodeling intricate relationships within behavioral data, leading to promising\noutcomes in personalized ranking and next-item recommendation tasks while\nmaintaining good scalability. However, they capture very different signals from\ndata. While the former approach represents users directly through ordered\ninteractions with recent items, the latter one aims to capture indirect\ndependencies across the interactions graph. This paper presents a novel\nmulti-representational learning framework that exploits the synergies between\nthese two paradigms. Our empirical evaluation on several datasets demonstrates\nthat mutual training of sequential and graph components with the proposed\nframework significantly improves recommendations performance.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00895v1",
    "authors": ["Vladimir Baikalov", "Evgeny Frolov"]
  },
  {
    "id": "2403.00898",
    "title": "The Algorithm Configuration Problem",
    "abstract": "  The field of algorithmic optimization has significantly advanced with the\ndevelopment of methods for the automatic configuration of algorithmic\nparameters. This article delves into the Algorithm Configuration Problem,\nfocused on optimizing parametrized algorithms for solving specific instances of\ndecision/optimization problems. We present a comprehensive framework that not\nonly formalizes the Algorithm Configuration Problem, but also outlines\ndifferent approaches for its resolution, leveraging machine learning models and\nheuristic strategies. The article categorizes existing methodologies into\nper-instance and per-problem approaches, distinguishing between offline and\nonline strategies for model construction and deployment. By synthesizing these\napproaches, we aim to provide a clear pathway for both understanding and\naddressing the complexities inherent in algorithm configuration.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00898v1",
    "authors": ["Gabriele Iommazzo", "Claudia D'Ambrosio", "Antonio Frangioni", "Leo Liberti"]
  },
  {
    "id": "2403.00929",
    "title": "PRIME: Scaffolding Manipulation Tasks with Behavior Primitives for\n  Data-Efficient Imitation Learning",
    "abstract": "  Imitation learning has shown great potential for enabling robots to acquire\ncomplex manipulation behaviors. However, these algorithms suffer from high\nsample complexity in long-horizon tasks, where compounding errors accumulate\nover the task horizons. We present PRIME (PRimitive-based IMitation with data\nEfficiency), a behavior primitive-based framework designed for improving the\ndata efficiency of imitation learning. PRIME scaffolds robot tasks by\ndecomposing task demonstrations into primitive sequences, followed by learning\na high-level control policy to sequence primitives through imitation learning.\nOur experiments demonstrate that PRIME achieves a significant performance\nimprovement in multi-stage manipulation tasks, with 10-34% higher success rates\nin simulation over state-of-the-art baselines and 20-48% on physical hardware.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00929v1",
    "authors": ["Tian Gao", "Soroush Nasiriany", "Huihan Liu", "Quantao Yang", "Yuke Zhu"]
  },
  {
    "id": "2403.00942",
    "title": "Resilience of Entropy Model in Distributed Neural Networks",
    "abstract": "  Distributed deep neural networks (DNNs) have emerged as a key technique to\nreduce communication overhead without sacrificing performance in edge computing\nsystems. Recently, entropy coding has been introduced to further reduce the\ncommunication overhead. The key idea is to train the distributed DNN jointly\nwith an entropy model, which is used as side information during inference time\nto adaptively encode latent representations into bit streams with variable\nlength. To the best of our knowledge, the resilience of entropy models is yet\nto be investigated. As such, in this paper we formulate and investigate the\nresilience of entropy models to intentional interference (e.g., adversarial\nattacks) and unintentional interference (e.g., weather changes and motion\nblur). Through an extensive experimental campaign with 3 different DNN\narchitectures, 2 entropy models and 4 rate-distortion trade-off factors, we\ndemonstrate that the entropy attacks can increase the communication overhead by\nup to 95%. By separating compression features in frequency and spatial domain,\nwe propose a new defense mechanism that can reduce the transmission overhead of\nthe attacked input by about 9% compared to unperturbed data, with only about 2%\naccuracy loss. Importantly, the proposed defense mechanism is a standalone\napproach which can be applied in conjunction with approaches such as\nadversarial training to further improve robustness. Code will be shared for\nreproducibility.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00942v1",
    "authors": ["Milin Zhang", "Mohammad Abdi", "Shahriar Rifat", "Francesco Restuccia"]
  },
  {
    "id": "2403.00965",
    "title": "Binary Gaussian Copula Synthesis: A Novel Data Augmentation Technique to\n  Advance ML-based Clinical Decision Support Systems for Early Prediction of\n  Dialysis Among CKD Patients",
    "abstract": "  The Center for Disease Control estimates that over 37 million US adults\nsuffer from chronic kidney disease (CKD), yet 9 out of 10 of these individuals\nare unaware of their condition due to the absence of symptoms in the early\nstages. It has a significant impact on patients' quality of life, particularly\nwhen it progresses to the need for dialysis. Early prediction of dialysis is\ncrucial as it can significantly improve patient outcomes and assist healthcare\nproviders in making timely and informed decisions. However, developing an\neffective machine learning (ML)-based Clinical Decision Support System (CDSS)\nfor early dialysis prediction poses a key challenge due to the imbalanced\nnature of data. To address this challenge, this study evaluates various data\naugmentation techniques to understand their effectiveness on real-world\ndatasets. We propose a new approach named Binary Gaussian Copula Synthesis\n(BGCS). BGCS is tailored for binary medical datasets and excels in generating\nsynthetic minority data that mirrors the distribution of the original data.\nBGCS enhances early dialysis prediction by outperforming traditional methods in\ndetecting dialysis patients. For the best ML model, Random Forest, BCGS\nachieved a 72% improvement, surpassing the state-of-the-art augmentation\napproaches. Also, we present a ML-based CDSS, designed to aid clinicians in\nmaking informed decisions. CDSS, which utilizes decision tree models, is\ndeveloped to improve patient outcomes, identify critical variables, and thereby\nenable clinicians to make proactive decisions, and strategize treatment plans\neffectively for CKD patients who are more likely to require dialysis in the\nnear future. Through comprehensive feature analysis and meticulous data\npreparation, we ensure that the CDSS's dialysis predictions are not only\naccurate but also actionable, providing a valuable tool in the management and\ntreatment of CKD.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00965v1",
    "authors": ["Hamed Khosravi", "Srinjoy Das", "Abdullah Al-Mamun", "Imtiaz Ahmed"]
  },
  {
    "id": "2403.00975",
    "title": "Equipment Health Assessment: Time Series Analysis for Wind Turbine\n  Performance",
    "abstract": "  In this study, we leverage SCADA data from diverse wind turbines to predict\npower output, employing advanced time series methods, specifically Functional\nNeural Networks (FNN) and Long Short-Term Memory (LSTM) networks. A key\ninnovation lies in the ensemble of FNN and LSTM models, capitalizing on their\ncollective learning. This ensemble approach outperforms individual models,\nensuring stable and accurate power output predictions. Additionally, machine\nlearning techniques are applied to detect wind turbine performance\ndeterioration, enabling proactive maintenance strategies and health assessment.\nCrucially, our analysis reveals the uniqueness of each wind turbine,\nnecessitating tailored models for optimal predictions. These insight\nunderscores the importance of providing automatized customization for different\nturbines to keep human modeling effort low. Importantly, the methodologies\ndeveloped in this analysis are not limited to wind turbines; they can be\nextended to predict and optimize performance in various machinery, highlighting\nthe versatility and applicability of our research across diverse industrial\ncontexts.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00975v1",
    "authors": [
      "Jana Backhus",
      "Aniruddha Rajendra Rao",
      "Chandrasekar Venkatraman",
      "Abhishek Padmanabhan",
      "A. Vinoth Kumar",
      "Chetan Gupta"
    ]
  },
  {
    "id": "2403.00986",
    "title": "Merging Text Transformer Models from Different Initializations",
    "abstract": "  Recent work on one-shot permutation-based model merging has shown impressive\nlow- or zero-barrier mode connectivity between models from completely different\ninitializations. However, this line of work has not yet extended to the\nTransformer architecture, despite its dominant popularity in the language\ndomain. Therefore, in this work, we investigate the extent to which separate\nTransformer minima learn similar features, and propose a model merging\ntechnique to investigate the relationship between these minima in the loss\nlandscape. The specifics of the architecture, like its residual connections,\nmulti-headed attention, and discrete, sequential input, require specific\ninterventions in order to compute model permutations that remain within the\nsame functional equivalence class. In merging these models with our method, we\nconsistently find lower loss barriers between minima compared to model\naveraging for several models trained on a masked-language modeling task or\nfine-tuned on a language understanding benchmark. Our results show that the\nminima of these models are less sharp and isolated than previously understood,\nand provide a basis for future work on merging separately trained Transformer\nmodels.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00986v1",
    "authors": ["Neha Verma", "Maha Elbayad"]
  },
  {
    "id": "2403.00993",
    "title": "On the Role of Information Structure in Reinforcement Learning for\n  Partially-Observable Sequential Teams and Games",
    "abstract": "  In a sequential decision-making problem, the information structure is the\ndescription of how events in the system occurring at different points in time\naffect each other. Classical models of reinforcement learning (e.g., MDPs,\nPOMDPs, Dec-POMDPs, and POMGs) assume a very simple and highly regular\ninformation structure, while more general models like predictive state\nrepresentations do not explicitly model the information structure. By contrast,\nreal-world sequential decision-making problems typically involve a complex and\ntime-varying interdependence of system variables, requiring a rich and flexible\nrepresentation of information structure.\n  In this paper, we argue for the perspective that explicit representation of\ninformation structures is an important component of analyzing and solving\nreinforcement learning problems. We propose novel reinforcement learning models\nwith an explicit representation of information structure, capturing classical\nmodels as special cases. We show that this leads to a richer analysis of\nsequential decision-making problems and enables more tailored algorithm design.\nIn particular, we characterize the \"complexity\" of the observable dynamics of\nany sequential decision-making problem through a graph-theoretic analysis of\nthe DAG representation of its information structure. The central quantity in\nthis analysis is the minimal set of variables that $d$-separates the past\nobservations from future observations. Furthermore, through constructing a\ngeneralization of predictive state representations, we propose tailored\nreinforcement learning algorithms and prove that the sample complexity is in\npart determined by the information structure. This recovers known tractability\nresults and gives a novel perspective on reinforcement learning in general\nsequential decision-making problems, providing a systematic way of identifying\nnew tractable classes of problems.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00993v1",
    "authors": ["Awni Altabaa", "Zhuoran Yang"]
  },
  {
    "id": "2403.00994",
    "title": "Leveraging Prompt-Based Large Language Models: Predicting Pandemic\n  Health Decisions and Outcomes Through Social Media Language",
    "abstract": "  We introduce a multi-step reasoning framework using prompt-based LLMs to\nexamine the relationship between social media language patterns and trends in\nnational health outcomes. Grounded in fuzzy-trace theory, which emphasizes the\nimportance of gists of causal coherence in effective health communication, we\nintroduce Role-Based Incremental Coaching (RBIC), a prompt-based LLM framework,\nto identify gists at-scale. Using RBIC, we systematically extract gists from\nsubreddit discussions opposing COVID-19 health measures (Study 1). We then\ntrack how these gists evolve across key events (Study 2) and assess their\ninfluence on online engagement (Study 3). Finally, we investigate how the\nvolume of gists is associated with national health trends like vaccine uptake\nand hospitalizations (Study 4). Our work is the first to empirically link\nsocial media linguistic patterns to real-world public health trends,\nhighlighting the potential of prompt-based LLMs in identifying critical online\ndiscussion patterns that can form the basis of public health communication\nstrategies.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00994v1",
    "authors": [
      "Xiaohan Ding",
      "Buse Carik",
      "Uma Sushmitha Gunturi",
      "Valerie Reyna",
      "Eugenia H. Rho"
    ]
  },
  {
    "id": "2403.01005",
    "title": "Policy Optimization for PDE Control with a Warm Start",
    "abstract": "  Dimensionality reduction is crucial for controlling nonlinear partial\ndifferential equations (PDE) through a \"reduce-then-design\" strategy, which\nidentifies a reduced-order model and then implements model-based control\nsolutions. However, inaccuracies in the reduced-order modeling can\nsubstantially degrade controller performance, especially in PDEs with chaotic\nbehavior. To address this issue, we augment the reduce-then-design procedure\nwith a policy optimization (PO) step. The PO step fine-tunes the model-based\ncontroller to compensate for the modeling error from dimensionality reduction.\nThis augmentation shifts the overall strategy into\nreduce-then-design-then-adapt, where the model-based controller serves as a\nwarm start for PO. Specifically, we study the state-feedback tracking control\nof PDEs that aims to align the PDE state with a specific constant target\nsubject to a linear-quadratic cost. Through extensive experiments, we show that\na few iterations of PO can significantly improve the model-based controller\nperformance. Our approach offers a cost-effective alternative to PDE control\nusing end-to-end reinforcement learning.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.01005v1",
    "authors": ["Xiangyuan Zhang", "Saviz Mowlavi", "Mouhacine Benosman", "Tamer Başar"]
  },
  {
    "id": "2403.01024",
    "title": "Reservoir Computing Using Measurement-Controlled Quantum Dynamics",
    "abstract": "  Physical reservoir computing (RC) is a machine learning algorithm that\nemploys the dynamics of a physical system to forecast highly nonlinear and\nchaotic phenomena. In this paper, we introduce a quantum RC system that employs\nthe dynamics of a probed atom in a cavity. The atom experiences coherent\ndriving at a particular rate, leading to a measurement-controlled quantum\nevolution. The proposed quantum reservoir can make fast and reliable forecasts\nusing a small number of artificial neurons compared with the traditional RC\nalgorithm. We theoretically validate the operation of the reservoir,\ndemonstrating its potential to be used in error-tolerant applications, where\napproximate computing approaches may be used to make feasible forecasts in\nconditions of limited computational and energy resources.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.01024v1",
    "authors": ["A. H. Abbas", "Ivan S. Maksymov"]
  },
  {
    "id": "2403.00299",
    "title": "Universal Auto-encoder Framework for MIMO CSI Feedback",
    "abstract": "  Existing auto-encoder (AE)-based channel state information (CSI) frameworks\nhave focused on a specific configuration of user equipment (UE) and base\nstation (BS), and thus the input and output sizes of the AE are fixed. However,\nin the real-world scenario, the input and output sizes may vary depending on\nthe number of antennas of the BS and UE and the allocated resource block in the\nfrequency dimension. A naive approach to support the different input and output\nsizes is to use multiple AE models, which is impractical for the UE due to the\nlimited HW resources. In this paper, we propose a universal AE framework that\ncan support different input sizes and multiple compression ratios. The proposed\nAE framework significantly reduces the HW complexity while providing comparable\nperformance in terms of compression ratio-distortion trade-off compared to the\nnaive and state-of-the-art approaches.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00299v1",
    "authors": ["Jinhyun So", "Hyukjoon Kwon"]
  },
  {
    "id": "2403.00887",
    "title": "SEGAA: A Unified Approach to Predicting Age, Gender, and Emotion in\n  Speech",
    "abstract": "  The interpretation of human voices holds importance across various\napplications. This study ventures into predicting age, gender, and emotion from\nvocal cues, a field with vast applications. Voice analysis tech advancements\nspan domains, from improving customer interactions to enhancing healthcare and\nretail experiences. Discerning emotions aids mental health, while age and\ngender detection are vital in various contexts. Exploring deep learning models\nfor these predictions involves comparing single, multi-output, and sequential\nmodels highlighted in this paper. Sourcing suitable data posed challenges,\nresulting in the amalgamation of the CREMA-D and EMO-DB datasets. Prior work\nshowed promise in individual predictions, but limited research considered all\nthree variables simultaneously. This paper identifies flaws in an individual\nmodel approach and advocates for our novel multi-output learning architecture\nSpeech-based Emotion Gender and Age Analysis (SEGAA) model. The experiments\nsuggest that Multi-output models perform comparably to individual models,\nefficiently capturing the intricate relationships between variables and speech\ninputs, all while achieving improved runtime.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00887v1",
    "authors": [
      "Aron R",
      "Indra Sigicharla",
      "Chirag Periwal",
      "Mohanaprasad K",
      "Nithya Darisini P S",
      "Sourabh Tiwari",
      "Shivani Arora"
    ]
  },
  {
    "id": "2403.00897",
    "title": "VisRec: A Semi-Supervised Approach to Radio Interferometric Data\n  Reconstruction",
    "abstract": "  Radio telescopes produce visibility data about celestial objects, but these\ndata are sparse and noisy. As a result, images created on raw visibility data\nare of low quality. Recent studies have used deep learning models to\nreconstruct visibility data to get cleaner images. However, these methods rely\non a substantial amount of labeled training data, which requires significant\nlabeling effort from radio astronomers. Addressing this challenge, we propose\nVisRec, a model-agnostic semi-supervised learning approach to the\nreconstruction of visibility data. Specifically, VisRec consists of both a\nsupervised learning module and an unsupervised learning module. In the\nsupervised learning module, we introduce a set of data augmentation functions\nto produce diverse training examples. In comparison, the unsupervised learning\nmodule in VisRec augments unlabeled data and uses reconstructions from\nnon-augmented visibility data as pseudo-labels for training. This hybrid\napproach allows VisRec to effectively leverage both labeled and unlabeled data.\nThis way, VisRec performs well even when labeled data is scarce. Our evaluation\nresults show that VisRec outperforms all baseline methods in reconstruction\nquality, robustness against common observation perturbation, and\ngeneralizability to different telescope configurations.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00897v1",
    "authors": ["Ruoqi Wang", "Haitao Wang", "Qiong Luo", "Feng Wang", "Hejun Wu"]
  },
  {
    "id": "2403.00957",
    "title": "Resolution of Simpson's paradox via the common cause principle",
    "abstract": "  Simpson's paradox is an obstacle to establishing a probabilistic association\nbetween two events $a_1$ and $a_2$, given the third (lurking) random variable\n$B$. We focus on scenarios when the random variables $A$ (which combines $a_1$,\n$a_2$, and their complements) and $B$ have a common cause $C$ that need not be\nobserved. Alternatively, we can assume that $C$ screens out $A$ from $B$. For\nsuch cases, the correct association between $a_1$ and $a_2$ is to be defined\nvia conditioning over $C$. This set-up generalizes the original Simpson's\nparadox. Now its two contradicting options simply refer to two particular and\ndifferent causes $C$. We show that if $B$ and $C$ are binary and $A$ is\nquaternary (the minimal and the most widespread situation for valid Simpson's\nparadox), the conditioning over any binary common cause $C$ establishes the\nsame direction of the association between $a_1$ and $a_2$ as the conditioning\nover $B$ in the original formulation of the paradox. Thus, for the minimal\ncommon cause, one should choose the option of Simpson's paradox that assumes\nconditioning over $B$ and not its marginalization. For tertiary (unobserved)\ncommon causes $C$ all three options of Simpson's paradox become possible (i.e.\nmarginalized, conditional, and none of them), and one needs prior information\non $C$ to choose the right option.\n",
    "pdfLink": "http://arxiv.org/pdf/2403.00957v1",
    "authors": ["A. Hovhannisyan", "A. E. Allahverdyan"]
  }
]
