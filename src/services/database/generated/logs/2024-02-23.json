[
  {
    "id": "2402.15075",
    "title": "Stacking Factorizing Partitioned Expressions in Hybrid Bayesian Network\n  Models",
    "abstract": "  Hybrid Bayesian networks (HBN) contain complex conditional probabilistic\ndistributions (CPD) specified as partitioned expressions over discrete and\ncontinuous variables. The size of these CPDs grows exponentially with the\nnumber of parent nodes when using discrete inference, resulting in significant\ninefficiency. Normally, an effective way to reduce the CPD size is to use a\nbinary factorization (BF) algorithm to decompose the statistical or arithmetic\nfunctions in the CPD by factorizing the number of connected parent nodes to\nsets of size two. However, the BF algorithm was not designed to handle\npartitioned expressions. Hence, we propose a new algorithm called stacking\nfactorization (SF) to decompose the partitioned expressions. The SF algorithm\ncreates intermediate nodes to incrementally reconstruct the densities in the\noriginal partitioned expression, allowing no more than two continuous parent\nnodes to be connected to each child node in the resulting HBN. SF can be either\nused independently or combined with the BF algorithm. We show that the SF+BF\nalgorithm significantly reduces the CPD size and contributes to lowering the\ntree-width of a model, thus improving efficiency.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15075v1",
    "authors": ["Peng Lin", "Martin Neil", "Norman Fenton"]
  },
  {
    "id": "2402.15140",
    "title": "A Relation-Interactive Approach for Message Passing in Hyper-relational\n  Knowledge Graphs",
    "abstract": "  Hyper-relational knowledge graphs (KGs) contain additional key-value pairs,\nproviding more information about the relations. In many scenarios, the same\nrelation can have distinct key-value pairs, making the original triple fact\nmore recognizable and specific. Prior studies on hyper-relational KGs have\nestablished a solid standard method for hyper-relational graph encoding. In\nthis work, we propose a message-passing-based graph encoder with global\nrelation structure awareness ability, which we call ReSaE. Compared to the\nprior state-of-the-art approach, ReSaE emphasizes the interaction of relations\nduring message passing process and optimizes the readout structure for link\nprediction tasks. Overall, ReSaE gives a encoding solution for hyper-relational\nKGs and ensures stronger performance on downstream link prediction tasks. Our\nexperiments demonstrate that ReSaE achieves state-of-the-art performance on\nmultiple link prediction benchmarks. Furthermore, we also analyze the influence\nof different model structures on model performance.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15140v1",
    "authors": ["Yonglin Jing"]
  },
  {
    "id": "2402.15445",
    "title": "Can we forget how we learned? Doxastic redundancy in iterated belief\n  revision",
    "abstract": "  How information was acquired may become irrelevant. An obvious case is when\nsomething is confirmed many times. In terms of iterated belief revision, a\nspecific revision may become irrelevant in presence of others. Simple\nrepetitions are an example, but not the only case when this happens. Sometimes,\na revision becomes redundant even in presence of none equal, or even no else\nimplying it. A necessary and sufficient condition for the redundancy of the\nfirst of a sequence of lexicographic revisions is given. The problem is\ncoNP-complete even with two propositional revisions only. Complexity is the\nsame in the Horn case but only with an unbounded number of revisions: it\nbecomes polynomial with two revisions. Lexicographic revisions are not only\nrelevant by themselves, but also because sequences of them are the most compact\nof the common mechanisms used to represent the state of an iterated revision\nprocess. Shortening sequences of lexicographic revisions is shortening the most\ncompact representations of iterated belief revision states.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15445v1",
    "authors": ["Paolo Liberatore"]
  },
  {
    "id": "2402.15048",
    "title": "Unlocking the Power of Large Language Models for Entity Alignment",
    "abstract": "  Entity Alignment (EA) is vital for integrating diverse knowledge graph (KG)\ndata, playing a crucial role in data-driven AI applications. Traditional EA\nmethods primarily rely on comparing entity embeddings, but their effectiveness\nis constrained by the limited input KG data and the capabilities of the\nrepresentation learning techniques. Against this backdrop, we introduce ChatEA,\nan innovative framework that incorporates large language models (LLMs) to\nimprove EA. To address the constraints of limited input KG data, ChatEA\nintroduces a KG-code translation module that translates KG structures into a\nformat understandable by LLMs, thereby allowing LLMs to utilize their extensive\nbackground knowledge to improve EA accuracy. To overcome the over-reliance on\nentity embedding comparisons, ChatEA implements a two-stage EA strategy that\ncapitalizes on LLMs' capability for multi-step reasoning in a dialogue format,\nthereby enhancing accuracy while preserving efficiency. Our experimental\nresults affirm ChatEA's superior performance, highlighting LLMs' potential in\nfacilitating EA tasks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15048v1",
    "authors": [
      "Xuhui Jiang",
      "Yinghan Shen",
      "Zhichao Shi",
      "Chengjin Xu",
      "Wei Li",
      "Zixuan Li",
      "Jian Guo",
      "Huawei Shen",
      "Yuanzhuo Wang"
    ]
  },
  {
    "id": "2402.15052",
    "title": "ToMBench: Benchmarking Theory of Mind in Large Language Models",
    "abstract": "  Theory of Mind (ToM) is the cognitive capability to perceive and ascribe\nmental states to oneself and others. Recent research has sparked a debate over\nwhether large language models (LLMs) exhibit a form of ToM. However, existing\nToM evaluations are hindered by challenges such as constrained scope,\nsubjective judgment, and unintended contamination, yielding inadequate\nassessments. To address this gap, we introduce ToMBench with three key\ncharacteristics: a systematic evaluation framework encompassing 8 tasks and 31\nabilities in social cognition, a multiple-choice question format to support\nautomated and unbiased evaluation, and a build-from-scratch bilingual inventory\nto strictly avoid data leakage. Based on ToMBench, we conduct extensive\nexperiments to evaluate the ToM performance of 10 popular LLMs across tasks and\nabilities. We find that even the most advanced LLMs like GPT-4 lag behind human\nperformance by over 10% points, indicating that LLMs have not achieved a\nhuman-level theory of mind yet. Our aim with ToMBench is to enable an efficient\nand effective evaluation of LLMs' ToM capabilities, thereby facilitating the\ndevelopment of LLMs with inherent social intelligence.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15052v1",
    "authors": [
      "Zhuang Chen",
      "Jincenzi Wu",
      "Jinfeng Zhou",
      "Bosi Wen",
      "Guanqun Bi",
      "Gongyao Jiang",
      "Yaru Cao",
      "Mengting Hu",
      "Yunghwei Lai",
      "Zexuan Xiong",
      "Minlie Huang"
    ]
  },
  {
    "id": "2402.15057",
    "title": "On the Multi-turn Instruction Following for Conversational Web Agents",
    "abstract": "  Web agents powered by Large Language Models (LLMs) have demonstrated\nremarkable abilities in planning and executing multi-step interactions within\ncomplex web-based environments, fulfilling a wide range of web navigation\ntasks. Despite these advancements, the potential for LLM-powered agents to\neffectively engage with sequential user instructions in real-world scenarios\nhas not been fully explored. In this work, we introduce a new task of\nConversational Web Navigation, which necessitates sophisticated interactions\nthat span multiple turns with both the users and the environment, supported by\na specially developed dataset named Multi-Turn Mind2Web (MT-Mind2Web). To\ntackle the limited context length of LLMs and the context-dependency issue of\nthe conversational tasks, we further propose a novel framework, named\nself-reflective memory-augmented planning (Self-MAP), which employs memory\nutilization and self-reflection techniques. Extensive experiments are conducted\nto benchmark the MT-Mind2Web dataset, and validate the effectiveness of the\nproposed method.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15057v1",
    "authors": [
      "Yang Deng",
      "Xuan Zhang",
      "Wenxuan Zhang",
      "Yifei Yuan",
      "See-Kiong Ng",
      "Tat-Seng Chua"
    ]
  },
  {
    "id": "2402.15131",
    "title": "Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question\n  Answering with Large Language Models",
    "abstract": "  This study explores the realm of knowledge-base question answering (KBQA).\nKBQA is considered a challenging task, particularly in parsing intricate\nquestions into executable logical forms. Traditional semantic parsing\n(SP)-based methods require extensive data annotations, which result in\nsignificant costs. Recently, the advent of few-shot in-context learning,\npowered by large language models (LLMs), has showcased promising capabilities.\nYet, fully leveraging LLMs to parse questions into logical forms in\nlow-resource scenarios poses a substantial challenge. To tackle these hurdles,\nwe introduce Interactive-KBQA, a framework designed to generate logical forms\nthrough direct interaction with knowledge bases (KBs). Within this framework,\nwe have developed three generic APIs for KB interaction. For each category of\ncomplex question, we devised exemplars to guide LLMs through the reasoning\nprocesses. Our method achieves competitive results on the WebQuestionsSP,\nComplexWebQuestions, KQA Pro, and MetaQA datasets with a minimal number of\nexamples (shots). Importantly, our approach supports manual intervention,\nallowing for the iterative refinement of LLM outputs. By annotating a dataset\nwith step-wise reasoning processes, we showcase our model's adaptability and\nhighlight its potential for contributing significant enhancements to the field.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15131v1",
    "authors": ["Guanming Xiong", "Junwei Bao", "Wen Zhao"]
  },
  {
    "id": "2402.15134",
    "title": "Deep Coupling Network For Multivariate Time Series Forecasting",
    "abstract": "  Multivariate time series (MTS) forecasting is crucial in many real-world\napplications. To achieve accurate MTS forecasting, it is essential to\nsimultaneously consider both intra- and inter-series relationships among time\nseries data. However, previous work has typically modeled intra- and\ninter-series relationships separately and has disregarded multi-order\ninteractions present within and between time series data, which can seriously\ndegrade forecasting accuracy. In this paper, we reexamine intra- and\ninter-series relationships from the perspective of mutual information and\naccordingly construct a comprehensive relationship learning mechanism tailored\nto simultaneously capture the intricate multi-order intra- and inter-series\ncouplings. Based on the mechanism, we propose a novel deep coupling network for\nMTS forecasting, named DeepCN, which consists of a coupling mechanism dedicated\nto explicitly exploring the multi-order intra- and inter-series relationships\namong time series data concurrently, a coupled variable representation module\naimed at encoding diverse variable patterns, and an inference module\nfacilitating predictions through one forward step. Extensive experiments\nconducted on seven real-world datasets demonstrate that our proposed DeepCN\nachieves superior performance compared with the state-of-the-art baselines.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15134v1",
    "authors": ["Kun Yi", "Qi Zhang", "Hui He", "Kaize Shi", "Liang Hu", "Ning An", "Zhendong Niu"]
  },
  {
    "id": "2402.15135",
    "title": "Modified CycleGAN for the synthesization of samples for wheat head\n  segmentation",
    "abstract": "  Deep learning models have been used for a variety of image processing tasks.\nHowever, most of these models are developed through supervised learning\napproaches, which rely heavily on the availability of large-scale annotated\ndatasets. Developing such datasets is tedious and expensive. In the absence of\nan annotated dataset, synthetic data can be used for model development;\nhowever, due to the substantial differences between simulated and real data, a\nphenomenon referred to as domain gap, the resulting models often underperform\nwhen applied to real data. In this research, we aim to address this challenge\nby first computationally simulating a large-scale annotated dataset and then\nusing a generative adversarial network (GAN) to fill the gap between simulated\nand real images. This approach results in a synthetic dataset that can be\neffectively utilized to train a deep-learning model. Using this approach, we\ndeveloped a realistic annotated synthetic dataset for wheat head segmentation.\nThis dataset was then used to develop a deep-learning model for semantic\nsegmentation. The resulting model achieved a Dice score of 83.4\\% on an\ninternal dataset and Dice scores of 79.6% and 83.6% on two external Global\nWheat Head Detection datasets. While we proposed this approach in the context\nof wheat head segmentation, it can be generalized to other crop types or, more\nbroadly, to images with dense, repeated patterns such as those found in\ncellular imagery.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15135v1",
    "authors": ["Jaden Myers", "Keyhan Najafian", "Farhad Maleki", "Katie Ovens"]
  },
  {
    "id": "2402.15160",
    "title": "Spatially-Aware Transformer Memory for Embodied Agents",
    "abstract": "  Episodic memory plays a crucial role in various cognitive processes, such as\nthe ability to mentally recall past events. While cognitive science emphasizes\nthe significance of spatial context in the formation and retrieval of episodic\nmemory, the current primary approach to implementing episodic memory in AI\nsystems is through transformers that store temporally ordered experiences,\nwhich overlooks the spatial dimension. As a result, it is unclear how the\nunderlying structure could be extended to incorporate the spatial axis beyond\ntemporal order alone and thereby what benefits can be obtained. To address\nthis, this paper explores the use of Spatially-Aware Transformer models that\nincorporate spatial information. These models enable the creation of\nplace-centric episodic memory that considers both temporal and spatial\ndimensions. Adopting this approach, we demonstrate that memory utilization\nefficiency can be improved, leading to enhanced accuracy in various\nplace-centric downstream tasks. Additionally, we propose the Adaptive Memory\nAllocator, a memory management method based on reinforcement learning that aims\nto optimize efficiency of memory utilization. Our experiments demonstrate the\nadvantages of our proposed model in various environments and across multiple\ndownstream tasks, including prediction, generation, reasoning, and\nreinforcement learning. The source code for our models and experiments will be\navailable at https://github.com/junmokane/spatially-aware-transformer.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15160v2",
    "authors": ["Junmo Cho", "Jaesik Yoon", "Sungjin Ahn"]
  },
  {
    "id": "2402.15163",
    "title": "Studying the Impact of Stochasticity on the Evaluation of Deep Neural\n  Networks for Forest-Fire Prediction",
    "abstract": "  This paper presents the first systematic study of the evaluation of Deep\nNeural Networks (DNNs) for discrete dynamical systems under stochastic\nassumptions, with a focus on wildfire prediction. We develop a framework to\nstudy the impact of stochasticity on two classes of evaluation metrics:\nclassification-based metrics, which assess fidelity to observed ground truth\n(GT), and proper scoring rules, which test fidelity-to-statistic. Our findings\nreveal that evaluating for fidelity-to-statistic is a reliable alternative in\nhighly stochastic scenarios. We extend our analysis to real-world wildfire\ndata, highlighting limitations in traditional wildfire prediction evaluation\nmethods, and suggest interpretable stochasticity-compatible alternatives.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15163v1",
    "authors": ["Harshit Kumar", "Biswadeep Chakraborty", "Beomseok Kang", "Saibal Mukhopadhyay"]
  },
  {
    "id": "2402.15170",
    "title": "The Surprising Effectiveness of Skip-Tuning in Diffusion Sampling",
    "abstract": "  With the incorporation of the UNet architecture, diffusion probabilistic\nmodels have become a dominant force in image generation tasks. One key design\nin UNet is the skip connections between the encoder and decoder blocks.\nAlthough skip connections have been shown to improve training stability and\nmodel performance, we reveal that such shortcuts can be a limiting factor for\nthe complexity of the transformation. As the sampling steps decrease, the\ngeneration process and the role of the UNet get closer to the push-forward\ntransformations from Gaussian distribution to the target, posing a challenge\nfor the network's complexity. To address this challenge, we propose\nSkip-Tuning, a simple yet surprisingly effective training-free tuning method on\nthe skip connections. Our method can achieve 100% FID improvement for\npretrained EDM on ImageNet 64 with only 19 NFEs (1.75), breaking the limit of\nODE samplers regardless of sampling steps. Surprisingly, the improvement\npersists when we increase the number of sampling steps and can even surpass the\nbest result from EDM-2 (1.58) with only 39 NFEs (1.57). Comprehensive\nexploratory experiments are conducted to shed light on the surprising\neffectiveness. We observe that while Skip-Tuning increases the score-matching\nlosses in the pixel space, the losses in the feature space are reduced,\nparticularly at intermediate noise levels, which coincide with the most\neffective range accounting for image quality improvement.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15170v1",
    "authors": [
      "Jiajun Ma",
      "Shuchen Xue",
      "Tianyang Hu",
      "Wenjia Wang",
      "Zhaoqiang Liu",
      "Zhenguo Li",
      "Zhi-Ming Ma",
      "Kenji Kawaguchi"
    ]
  },
  {
    "id": "2402.15183",
    "title": "GraphEdit: Large Language Models for Graph Structure Learning",
    "abstract": "  Graph Structure Learning (GSL) focuses on capturing intrinsic dependencies\nand interactions among nodes in graph-structured data by generating novel graph\nstructures. Graph Neural Networks (GNNs) have emerged as promising GSL\nsolutions, utilizing recursive message passing to encode node-wise\ninter-dependencies. However, many existing GSL methods heavily depend on\nexplicit graph structural information as supervision signals, leaving them\nsusceptible to challenges such as data noise and sparsity. In this work, we\npropose GraphEdit, an approach that leverages large language models (LLMs) to\nlearn complex node relationships in graph-structured data. By enhancing the\nreasoning capabilities of LLMs through instruction-tuning over graph\nstructures, we aim to overcome the limitations associated with explicit graph\nstructural information and enhance the reliability of graph structure learning.\nOur approach not only effectively denoises noisy connections but also\nidentifies node-wise dependencies from a global perspective, providing a\ncomprehensive understanding of the graph structure. We conduct extensive\nexperiments on multiple benchmark datasets to demonstrate the effectiveness and\nrobustness of GraphEdit across various settings.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15183v2",
    "authors": [
      "Zirui Guo",
      "Lianghao Xia",
      "Yanhua Yu",
      "Yuling Wang",
      "Zixuan Yang",
      "Wei Wei",
      "Liang Pang",
      "Tat-Seng Chua",
      "Chao Huang"
    ]
  },
  {
    "id": "2402.15205",
    "title": "Enhancing ICU Patient Recovery: Using LLMs to Assist Nurses in Diary\n  Writing",
    "abstract": "  Intensive care unit (ICU) patients often develop new health-related problems\nin their long-term recovery. Health care professionals keeping a diary of a\npatient's stay is a proven strategy to tackle this but faces several adoption\nbarriers, such as lack of time and difficulty in knowing what to write. Large\nlanguage models (LLMs), with their ability to generate human-like text and\nadaptability, could solve these challenges. However, realizing this vision\ninvolves addressing several socio-technical and practical research challenges.\nThis paper discusses these challenges and proposes future research directions\nto utilize the potential of LLMs in ICU diary writing, ultimately improving the\nlong-term recovery outcomes for ICU patients.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15205v1",
    "authors": ["Samuel Kernan Freire", "Margo MC van Mol", "Carola Schol", "Elif Ã–zcan Vieira"]
  },
  {
    "id": "2402.15227",
    "title": "Fixed Random Classifier Rearrangement for Continual Learning",
    "abstract": "  With the explosive growth of data, continual learning capability is\nincreasingly important for neural networks. Due to catastrophic forgetting,\nneural networks inevitably forget the knowledge of old tasks after learning new\nones. In visual classification scenario, a common practice of alleviating the\nforgetting is to constrain the backbone. However, the impact of classifiers is\nunderestimated. In this paper, we analyze the variation of model predictions in\nsequential binary classification tasks and find that the norm of the equivalent\none-class classifiers significantly affects the forgetting level. Based on this\nconclusion, we propose a two-stage continual learning algorithm named Fixed\nRandom Classifier Rearrangement (FRCR). In first stage, FRCR replaces the\nlearnable classifiers with fixed random classifiers, constraining the norm of\nthe equivalent one-class classifiers without affecting the performance of the\nnetwork. In second stage, FRCR rearranges the entries of new classifiers to\nimplicitly reduce the drift of old latent representations. The experimental\nresults on multiple datasets show that FRCR significantly mitigates the model\nforgetting; subsequent experimental analyses further validate the effectiveness\nof the algorithm.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15227v1",
    "authors": ["Shengyang Huang", "Jianwen Mo"]
  },
  {
    "id": "2402.15255",
    "title": "Optimal Transport for Structure Learning Under Missing Data",
    "abstract": "  Causal discovery in the presence of missing data introduces a chicken-and-egg\ndilemma. While the goal is to recover the true causal structure, robust\nimputation requires considering the dependencies or preferably causal relations\namong variables. Merely filling in missing values with existing imputation\nmethods and subsequently applying structure learning on the complete data is\nempirical shown to be sub-optimal. To this end, we propose in this paper a\nscore-based algorithm, based on optimal transport, for learning causal\nstructure from missing data. This optimal transport viewpoint diverges from\nexisting score-based approaches that are dominantly based on EM. We project\nstructure learning as a density fitting problem, where the goal is to find the\ncausal model that induces a distribution of minimum Wasserstein distance with\nthe distribution over the observed data. Through extensive simulations and\nreal-data experiments, our framework is shown to recover the true causal graphs\nmore effectively than the baselines in various simulations and real-data\nexperiments. Empirical evidences also demonstrate the superior scalability of\nour approach, along with the flexibility to incorporate any off-the-shelf\ncausal discovery methods for complete data.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15255v1",
    "authors": ["Vy Vo", "He Zhao", "Trung Le", "Edwin V. Bonilla", "Dinh Phung"]
  },
  {
    "id": "2402.15267",
    "title": "A Robust Defense against Adversarial Attacks on Deep Learning-based\n  Malware Detectors via (De)Randomized Smoothing",
    "abstract": "  Deep learning-based malware detectors have been shown to be susceptible to\nadversarial malware examples, i.e. malware examples that have been deliberately\nmanipulated in order to avoid detection. In light of the vulnerability of deep\nlearning detectors to subtle input file modifications, we propose a practical\ndefense against adversarial malware examples inspired by (de)randomized\nsmoothing. In this work, we reduce the chances of sampling adversarial content\ninjected by malware authors by selecting correlated subsets of bytes, rather\nthan using Gaussian noise to randomize inputs like in the Computer Vision (CV)\ndomain. During training, our ablation-based smoothing scheme trains a base\nclassifier to make classifications on a subset of contiguous bytes or chunk of\nbytes. At test time, a large number of chunks are then classified by a base\nclassifier and the consensus among these classifications is then reported as\nthe final prediction. We propose two strategies to determine the location of\nthe chunks used for classification: (1) randomly selecting the locations of the\nchunks and (2) selecting contiguous adjacent chunks. To showcase the\neffectiveness of our approach, we have trained two classifiers with our\nchunk-based ablation schemes on the BODMAS dataset. Our findings reveal that\nthe chunk-based smoothing classifiers exhibit greater resilience against\nadversarial malware examples generated with state-of-the-are evasion attacks,\noutperforming a non-smoothed classifier and a randomized smoothing-based\nclassifier by a great margin.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15267v2",
    "authors": ["Daniel Gibert", "Giulio Zizzo", "Quan Le", "Jordi Planes"]
  },
  {
    "id": "2402.15270",
    "title": "Smoothed Graph Contrastive Learning via Seamless Proximity Integration",
    "abstract": "  Graph contrastive learning (GCL) aligns node representations by classifying\nnode pairs into positives and negatives using a selection process that\ntypically relies on establishing correspondences within two augmented graphs.\nThe conventional GCL approaches incorporate negative samples uniformly in the\ncontrastive loss, resulting in the equal treatment negative nodes, regardless\nof their proximity to the true positive. In this paper, we present a Smoothed\nGraph Contrastive Learning model (SGCL), which leverages the geometric\nstructure of augmented graphs to inject proximity information associated with\npositive/negative pairs in the contrastive loss, thus significantly\nregularizing the learning process. The proposed SGCL adjusts the penalties\nassociated with node pairs in the contrastive loss by incorporating three\ndistinct smoothing techniques that result in proximity aware positives and\nnegatives. To enhance scalability for large-scale graphs, the proposed\nframework incorporates a graph batch-generating strategy that partitions the\ngiven graphs into multiple subgraphs, facilitating efficient training in\nseparate batches. Through extensive experimentation in the unsupervised setting\non various benchmarks, particularly those of large scale, we demonstrate the\nsuperiority of our proposed framework against recent baselines.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15270v1",
    "authors": ["Maysam Behmanesh", "Maks Ovsjanikov"]
  },
  {
    "id": "2402.15272",
    "title": "EMIFF: Enhanced Multi-scale Image Feature Fusion for\n  Vehicle-Infrastructure Cooperative 3D Object Detection",
    "abstract": "  In autonomous driving, cooperative perception makes use of multi-view cameras\nfrom both vehicles and infrastructure, providing a global vantage point with\nrich semantic context of road conditions beyond a single vehicle viewpoint.\nCurrently, two major challenges persist in vehicle-infrastructure cooperative\n3D (VIC3D) object detection: $1)$ inherent pose errors when fusing multi-view\nimages, caused by time asynchrony across cameras; $2)$ information loss in\ntransmission process resulted from limited communication bandwidth. To address\nthese issues, we propose a novel camera-based 3D detection framework for VIC3D\ntask, Enhanced Multi-scale Image Feature Fusion (EMIFF). To fully exploit\nholistic perspectives from both vehicles and infrastructure, we propose\nMulti-scale Cross Attention (MCA) and Camera-aware Channel Masking (CCM)\nmodules to enhance infrastructure and vehicle features at scale, spatial, and\nchannel levels to correct the pose error introduced by camera asynchrony. We\nalso introduce a Feature Compression (FC) module with channel and spatial\ncompression blocks for transmission efficiency. Experiments show that EMIFF\nachieves SOTA on DAIR-V2X-C datasets, significantly outperforming previous\nearly-fusion and late-fusion methods with comparable transmission costs.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15272v1",
    "authors": [
      "Zhe Wang",
      "Siqi Fan",
      "Xiaoliang Huo",
      "Tongda Xu",
      "Yan Wang",
      "Jingjing Liu",
      "Yilun Chen",
      "Ya-Qin Zhang"
    ]
  },
  {
    "id": "2402.15283",
    "title": "When in Doubt, Think Slow: Iterative Reasoning with Latent Imagination",
    "abstract": "  In an unfamiliar setting, a model-based reinforcement learning agent can be\nlimited by the accuracy of its world model. In this work, we present a novel,\ntraining-free approach to improving the performance of such agents separately\nfrom planning and learning. We do so by applying iterative inference at\ndecision-time, to fine-tune the inferred agent states based on the coherence of\nfuture state representations. Our approach achieves a consistent improvement in\nboth reconstruction accuracy and task performance when applied to visual 3D\nnavigation tasks. We go on to show that considering more future states further\nimproves the performance of the agent in partially-observable environments, but\nnot in a fully-observable one. Finally, we demonstrate that agents with less\ntraining pre-evaluation benefit most from our approach.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15283v1",
    "authors": ["Martin Benfeghoul", "Umais Zahid", "Qinghai Guo", "Zafeirios Fountas"]
  },
  {
    "id": "2402.15290",
    "title": "Linear Dynamics-embedded Neural Network for Long-Sequence Modeling",
    "abstract": "  The trade-off between performance and computational efficiency in\nlong-sequence modeling becomes a bottleneck for existing models. Inspired by\nthe continuous state space models (SSMs) with multi-input and multi-output in\ncontrol theory, we propose a new neural network called Linear Dynamics-embedded\nNeural Network (LDNN). SSMs' continuous, discrete, and convolutional properties\nenable LDNN to have few parameters, flexible inference, and efficient training\nin long-sequence tasks. Two efficient strategies, diagonalization and\n$'\\text{Disentanglement then Fast Fourier Transform (FFT)}'$, are developed to\nreduce the time complexity of convolution from $O(LNH\\max\\{L, N\\})$ to\n$O(LN\\max \\{H, \\log L\\})$. We further improve LDNN through bidirectional\nnoncausal and multi-head settings to accommodate a broader range of\napplications. Extensive experiments on the Long Range Arena (LRA) demonstrate\nthe effectiveness and state-of-the-art performance of LDNN.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15290v1",
    "authors": ["Tongyi Liang", "Han-Xiong Li"]
  },
  {
    "id": "2402.15333",
    "title": "A Quantum-Classical Collaborative Training Architecture Based on Quantum\n  State Fidelity",
    "abstract": "  Recent advancements have highlighted the limitations of current quantum\nsystems, particularly the restricted number of qubits available on near-term\nquantum devices. This constraint greatly inhibits the range of applications\nthat can leverage quantum computers. Moreover, as the available qubits\nincrease, the computational complexity grows exponentially, posing additional\nchallenges. Consequently, there is an urgent need to use qubits efficiently and\nmitigate both present limitations and future complexities. To address this,\nexisting quantum applications attempt to integrate classical and quantum\nsystems in a hybrid framework. In this study, we concentrate on quantum deep\nlearning and introduce a collaborative classical-quantum architecture called\nco-TenQu. The classical component employs a tensor network for compression and\nfeature extraction, enabling higher-dimensional data to be encoded onto logical\nquantum circuits with limited qubits. On the quantum side, we propose a\nquantum-state-fidelity-based evaluation function to iteratively train the\nnetwork through a feedback loop between the two sides. co-TenQu has been\nimplemented and evaluated with both simulators and the IBM-Q platform. Compared\nto state-of-the-art approaches, co-TenQu enhances a classical deep neural\nnetwork by up to 41.72% in a fair setting. Additionally, it outperforms other\nquantum-based methods by up to 1.9 times and achieves similar accuracy while\nutilizing 70.59% fewer qubits.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15333v1",
    "authors": [
      "Ryan L'Abbate",
      "Anthony D'Onofrio Jr.",
      "Samuel Stein",
      "Samuel Yen-Chi Chen",
      "Ang Li",
      "Pin-Yu Chen",
      "Juntao Chen",
      "Ying Mao"
    ]
  },
  {
    "id": "2402.15368",
    "title": "Safe Task Planning for Language-Instructed Multi-Robot Systems using\n  Conformal Prediction",
    "abstract": "  This paper addresses task planning problems for language-instructed robot\nteams. Tasks are expressed in natural language (NL), requiring the robots to\napply their capabilities (e.g., mobility, manipulation, and sensing) at various\nlocations and semantic objects. Several recent works have addressed similar\nplanning problems by leveraging pre-trained Large Language Models (LLMs) to\ndesign effective multi-robot plans. However, these approaches lack mission\nperformance and safety guarantees. To address this challenge, we introduce a\nnew decentralized LLM-based planner that is capable of achieving high mission\nsuccess rates. This is accomplished by leveraging conformal prediction (CP), a\ndistribution-free uncertainty quantification tool in black-box models. CP\nallows the proposed multi-robot planner to reason about its inherent\nuncertainty in a decentralized fashion, enabling robots to make individual\ndecisions when they are sufficiently certain and seek help otherwise. We show,\nboth theoretically and empirically, that the proposed planner can achieve\nuser-specified task success rates while minimizing the overall number of help\nrequests. We demonstrate the performance of our approach on multi-robot home\nservice applications. We also show through comparative experiments, that our\nmethod outperforms recent centralized and decentralized multi-robot LLM-based\nplanners in terms of in terms of its ability to design correct plans. The\nadvantage of our algorithm over baselines becomes more pronounced with\nincreasing mission complexity and robot team size.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15368v1",
    "authors": ["Jun Wang", "Guocheng He", "Yiannis Kantaros"]
  },
  {
    "id": "2402.15393",
    "title": "NeuralThink: Algorithm Synthesis that Extrapolates in General Tasks",
    "abstract": "  While machine learning methods excel at pattern recognition, they struggle\nwith complex reasoning tasks in a scalable, algorithmic manner. Recent Deep\nThinking methods show promise in learning algorithms that extrapolate: learning\nin smaller environments and executing the learned algorithm in larger\nenvironments. However, these works are limited to symmetrical tasks, where the\ninput and output dimensionalities are the same. To address this gap, we propose\nNeuralThink, a new recurrent architecture that can consistently extrapolate to\nboth symmetrical and asymmetrical tasks, where the dimensionality of the input\nand output are different. We contribute with a novel benchmark of asymmetrical\ntasks for extrapolation. We show that NeuralThink consistently outperforms the\nprior state-of-the-art Deep Thinking architectures, in regards to stable\nextrapolation to large observations from smaller training sizes.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15393v1",
    "authors": ["Bernardo Esteves", "Miguel Vasco", "Francisco S. Melo"]
  },
  {
    "id": "2402.15491",
    "title": "API-BLEND: A Comprehensive Corpora for Training and Benchmarking API\n  LLMs",
    "abstract": "  There is a growing need for Large Language Models (LLMs) to effectively use\ntools and external Application Programming Interfaces (APIs) to plan and\ncomplete tasks. As such, there is tremendous interest in methods that can\nacquire sufficient quantities of train and test data that involve calls to\ntools / APIs. Two lines of research have emerged as the predominant strategies\nfor addressing this challenge. The first has focused on synthetic data\ngeneration techniques, while the second has involved curating task-adjacent\ndatasets which can be transformed into API / Tool-based tasks. In this paper,\nwe focus on the task of identifying, curating, and transforming existing\ndatasets and, in turn, introduce API-BLEND, a large corpora for training and\nsystematic testing of tool-augmented LLMs. The datasets mimic real-world\nscenarios involving API-tasks such as API / tool detection, slot filling, and\nsequencing of the detected APIs. We demonstrate the utility of the API-BLEND\ndataset for both training and benchmarking purposes.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15491v1",
    "authors": [
      "Kinjal Basu",
      "Ibrahim Abdelaziz",
      "Subhajit Chaudhury",
      "Soham Dan",
      "Maxwell Crouse",
      "Asim Munawar",
      "Sadhana Kumaravel",
      "Vinod Muthusamy",
      "Pavan Kapanipathi",
      "Luis A. Lastras"
    ]
  },
  {
    "id": "2402.15504",
    "title": "Gen4Gen: Generative Data Pipeline for Generative Multi-Concept\n  Composition",
    "abstract": "  Recent text-to-image diffusion models are able to learn and synthesize images\ncontaining novel, personalized concepts (e.g., their own pets or specific\nitems) with just a few examples for training. This paper tackles two\ninterconnected issues within this realm of personalizing text-to-image\ndiffusion models. First, current personalization techniques fail to reliably\nextend to multiple concepts -- we hypothesize this to be due to the mismatch\nbetween complex scenes and simple text descriptions in the pre-training dataset\n(e.g., LAION). Second, given an image containing multiple personalized\nconcepts, there lacks a holistic metric that evaluates performance on not just\nthe degree of resemblance of personalized concepts, but also whether all\nconcepts are present in the image and whether the image accurately reflects the\noverall text description. To address these issues, we introduce Gen4Gen, a\nsemi-automated dataset creation pipeline utilizing generative models to combine\npersonalized concepts into complex compositions along with text-descriptions.\nUsing this, we create a dataset called MyCanvas, that can be used to benchmark\nthe task of multi-concept personalization. In addition, we design a\ncomprehensive metric comprising two scores (CP-CLIP and TI-CLIP) for better\nquantifying the performance of multi-concept, personalized text-to-image\ndiffusion methods. We provide a simple baseline built on top of Custom\nDiffusion with empirical prompting strategies for future researchers to\nevaluate on MyCanvas. We show that by improving data quality and prompting\nstrategies, we can significantly increase multi-concept personalized image\ngeneration quality, without requiring any modifications to model architecture\nor training algorithms.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15504v1",
    "authors": [
      "Chun-Hsiao Yeh",
      "Ta-Ying Cheng",
      "He-Yen Hsieh",
      "Chuan-En Lin",
      "Yi Ma",
      "Andrew Markham",
      "Niki Trigoni",
      "H. T. Kung",
      "Yubei Chen"
    ]
  },
  {
    "id": "2402.15538",
    "title": "AgentLite: A Lightweight Library for Building and Advancing\n  Task-Oriented LLM Agent System",
    "abstract": "  The booming success of LLMs initiates rapid development in LLM agents. Though\nthe foundation of an LLM agent is the generative model, it is critical to\ndevise the optimal reasoning strategies and agent architectures. Accordingly,\nLLM agent research advances from the simple chain-of-thought prompting to more\ncomplex ReAct and Reflection reasoning strategy; agent architecture also\nevolves from single agent generation to multi-agent conversation, as well as\nmulti-LLM multi-agent group chat. However, with the existing intricate\nframeworks and libraries, creating and evaluating new reasoning strategies and\nagent architectures has become a complex challenge, which hinders research\ninvestigation into LLM agents. Thus, we open-source a new AI agent library,\nAgentLite, which simplifies this process by offering a lightweight,\nuser-friendly platform for innovating LLM agent reasoning, architectures, and\napplications with ease. AgentLite is a task-oriented framework designed to\nenhance the ability of agents to break down tasks and facilitate the\ndevelopment of multi-agent systems. Furthermore, we introduce multiple\npractical applications developed with AgentLite to demonstrate its convenience\nand flexibility. Get started now at:\n\\url{https://github.com/SalesforceAIResearch/AgentLite}.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15538v1",
    "authors": [
      "Zhiwei Liu",
      "Weiran Yao",
      "Jianguo Zhang",
      "Liangwei Yang",
      "Zuxin Liu",
      "Juntao Tan",
      "Prafulla K. Choubey",
      "Tian Lan",
      "Jason Wu",
      "Huan Wang",
      "Shelby Heinecke",
      "Caiming Xiong",
      "Silvio Savarese"
    ]
  },
  {
    "id": "2402.15591",
    "title": "RecWizard: A Toolkit for Conversational Recommendation with Modular,\n  Portable Models and Interactive User Interface",
    "abstract": "  We present a new Python toolkit called RecWizard for Conversational\nRecommender Systems (CRS). RecWizard offers support for development of models\nand interactive user interface, drawing from the best practices of the\nHuggingface ecosystems. CRS with RecWizard are modular, portable, interactive\nand Large Language Models (LLMs)-friendly, to streamline the learning process\nand reduce the additional effort for CRS research. For more comprehensive\ninformation about RecWizard, please check our GitHub\nhttps://github.com/McAuley-Lab/RecWizard.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15591v1",
    "authors": [
      "Zeyuan Zhang",
      "Tanmay Laud",
      "Zihang He",
      "Xiaojie Chen",
      "Xinshuang Liu",
      "Zhouhang Xie",
      "Julian McAuley",
      "Zhankui He"
    ]
  },
  {
    "id": "2402.15631",
    "title": "Fine-Grained Self-Endorsement Improves Factuality and Reasoning",
    "abstract": "  This work studies improving large language model (LLM) generations at\ninference time by mitigating fact-conflicting hallucinations. Particularly, we\npropose a self-endorsement framework that leverages the fine-grained fact-level\ncomparisons across multiple sampled responses. Compared with prior ensemble\nmethods (Wang et al., 2022;Chen et al., 2023)) that perform response-level\nselection, our approach can better alleviate hallucinations, especially for\nlongform generation tasks. Our approach can broadly benefit smaller and\nopen-source LLMs as it mainly conducts simple content-based comparisons.\nExperiments on Biographies show that our method can effectively improve the\nfactuality of generations with simple and intuitive prompts across different\nscales of LLMs. Besides, comprehensive analyses on TriviaQA and GSM8K\ndemonstrate the potential of self-endorsement for broader application.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15631v1",
    "authors": [
      "Ante Wang",
      "Linfeng Song",
      "Baolin Peng",
      "Ye Tian",
      "Lifeng Jin",
      "Haitao Mi",
      "Jinsong Su",
      "Dong Yu"
    ]
  },
  {
    "id": "2402.15650",
    "title": "Multi-Constraint Safe RL with Objective Suppression for Safety-Critical\n  Applications",
    "abstract": "  Safe reinforcement learning tasks with multiple constraints are a challenging\ndomain despite being very common in the real world. To address this challenge,\nwe propose Objective Suppression, a novel method that adaptively suppresses the\ntask reward maximizing objectives according to a safety critic. We benchmark\nObjective Suppression in two multi-constraint safety domains, including an\nautonomous driving domain where any incorrect behavior can lead to disastrous\nconsequences. Empirically, we demonstrate that our proposed method, when\ncombined with existing safe RL algorithms, can match the task reward achieved\nby our baselines with significantly fewer constraint violations.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15650v1",
    "authors": ["Zihan Zhou", "Jonathan Booher", "Wei Liu", "Aleksandr Petiushko", "Animesh Garg"]
  },
  {
    "id": "2402.16891",
    "title": "Multi-Task Learning for Routing Problem with Cross-Problem Zero-Shot\n  Generalization",
    "abstract": "  Vehicle routing problems (VRPs), which can be found in numerous real-world\napplications, have been an important research topic for several decades.\nRecently, the neural combinatorial optimization (NCO) approach that leverages a\nlearning-based model to solve VRPs without manual algorithm design has gained\nsubstantial attention. However, current NCO methods typically require building\none model for each routing problem, which significantly hinders their practical\napplication for real-world industry problems with diverse attributes. In this\nwork, we make the first attempt to tackle the crucial challenge of\ncross-problem generalization. In particular, we formulate VRPs as different\ncombinations of a set of shared underlying attributes and solve them\nsimultaneously via a single model through attribute composition. In this way,\nour proposed model can successfully solve VRPs with unseen attribute\ncombinations in a zero-shot generalization manner. Extensive experiments are\nconducted on eleven VRP variants, benchmark datasets, and industry logistic\nscenarios. The results show that the unified model demonstrates superior\nperformance in the eleven VRPs, reducing the average gap to around 5% from over\n20% in the existing approach and achieving a significant performance boost on\nbenchmark datasets as well as a real-world logistics application.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.16891v1",
    "authors": ["Fei Liu", "Xi Lin", "Qingfu Zhang", "Xialiang Tong", "Mingxuan Yuan"]
  },
  {
    "id": "2402.16893",
    "title": "The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented\n  Generation (RAG)",
    "abstract": "  Retrieval-augmented generation (RAG) is a powerful technique to facilitate\nlanguage model with proprietary and private data, where data privacy is a\npivotal concern. Whereas extensive research has demonstrated the privacy risks\nof large language models (LLMs), the RAG technique could potentially reshape\nthe inherent behaviors of LLM generation, posing new privacy issues that are\ncurrently under-explored. In this work, we conduct extensive empirical studies\nwith novel attack methods, which demonstrate the vulnerability of RAG systems\non leaking the private retrieval database. Despite the new risk brought by RAG\non the retrieval data, we further reveal that RAG can mitigate the leakage of\nthe LLMs' training data. Overall, we provide new insights in this paper for\nprivacy protection of retrieval-augmented LLMs, which benefit both LLMs and RAG\nsystems builders. Our code is available at\nhttps://github.com/phycholosogy/RAG-privacy.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.16893v1",
    "authors": [
      "Shenglai Zeng",
      "Jiankun Zhang",
      "Pengfei He",
      "Yue Xing",
      "Yiding Liu",
      "Han Xu",
      "Jie Ren",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Yi Chang",
      "Jiliang Tang"
    ]
  },
  {
    "id": "2402.15038",
    "title": "Dynamics-Guided Diffusion Model for Robot Manipulator Design",
    "abstract": "  We present Dynamics-Guided Diffusion Model, a data-driven framework for\ngenerating manipulator geometry designs for a given manipulation task. Instead\nof training different design models for each task, our approach employs a\nlearned dynamics network shared across tasks. For a new manipulation task, we\nfirst decompose it into a collection of individual motion targets which we call\ntarget interaction profile, where each individual motion can be modeled by the\nshared dynamics network. The design objective constructed from the target and\npredicted interaction profiles provides a gradient to guide the refinement of\nfinger geometry for the task. This refinement process is executed as a\nclassifier-guided diffusion process, where the design objective acts as the\nclassifier guidance. We evaluate our framework on various manipulation tasks,\nunder the sensor-less setting using only an open-loop parallel jaw motion. Our\ngenerated designs outperform optimization-based and unguided diffusion\nbaselines relatively by 31.5% and 45.3% on average manipulation success rate.\nWith the ability to generate a design within 0.8 seconds, our framework could\nfacilitate rapid design iteration and enhance the adoption of data-driven\napproaches for robotic mechanism design.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15038v1",
    "authors": ["Xiaomeng Xu", "Huy Ha", "Shuran Song"]
  },
  {
    "id": "2402.15043",
    "title": "KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large\n  Language Models",
    "abstract": "  Automatic evaluation methods for large language models (LLMs) are hindered by\ndata contamination, leading to inflated assessments of their effectiveness.\nExisting strategies, which aim to detect contaminated texts, focus on\nquantifying contamination status instead of accurately gauging model\nperformance. In this paper, we introduce KIEval, a Knowledge-grounded\nInteractive Evaluation framework, which incorporates an LLM-powered\n\"interactor\" role for the first time to accomplish a dynamic\ncontamination-resilient evaluation. Starting with a question in a conventional\nLLM benchmark involving domain-specific knowledge, KIEval utilizes dynamically\ngenerated, multi-round, and knowledge-focused dialogues to determine whether a\nmodel's response is merely a recall of benchmark answers or demonstrates a deep\ncomprehension to apply knowledge in more complex conversations. Extensive\nexperiments on seven leading LLMs across five datasets validate KIEval's\neffectiveness and generalization. We also reveal that data contamination brings\nno contribution or even negative effect to models' real-world applicability and\nunderstanding, and existing contamination detection methods for LLMs can only\nidentify contamination in pre-training but not during supervised fine-tuning.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15043v1",
    "authors": [
      "Zhuohao Yu",
      "Chang Gao",
      "Wenjin Yao",
      "Yidong Wang",
      "Wei Ye",
      "Jindong Wang",
      "Xing Xie",
      "Yue Zhang",
      "Shikun Zhang"
    ]
  },
  {
    "id": "2402.15055",
    "title": "Interpreting Context Look-ups in Transformers: Investigating\n  Attention-MLP Interactions",
    "abstract": "  In this paper, we investigate the interplay between attention heads and\nspecialized \"next-token\" neurons in the Multilayer Perceptron that predict\nspecific tokens. By prompting an LLM like GPT-4 to explain these model\ninternals, we can elucidate attention mechanisms that activate certain\nnext-token neurons. Our analysis identifies attention heads that recognize\ncontexts relevant to predicting a particular token, activating the associated\nneuron through the residual connection. We focus specifically on heads in\nearlier layers consistently activating the same next-token neuron across\nsimilar prompts. Exploring these differential activation patterns reveals that\nheads that specialize for distinct linguistic contexts are tied to generating\ncertain tokens. Overall, our method combines neural explanations and probing\nisolated components to illuminate how attention enables context-dependent,\nspecialized processing in LLMs.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15055v1",
    "authors": ["Clement Neo", "Shay B. Cohen", "Fazl Barez"]
  },
  {
    "id": "2402.15083",
    "title": "Hands-Free VR",
    "abstract": "  The paper introduces Hands-Free VR, a voice-based natural-language interface\nfor VR. The user gives a command using their voice, the speech audio data is\nconverted to text using a speech-to-text deep learning model that is fine-tuned\nfor robustness to word phonetic similarity and to spoken English accents, and\nthe text is mapped to an executable VR command using a large language model\nthat is robust to natural language diversity. Hands-Free VR was evaluated in a\ncontrolled within-subjects study (N = 22) that asked participants to find\nspecific objects and to place them in various configurations. In the control\ncondition participants used a conventional VR user interface to grab, carry,\nand position the objects using the handheld controllers. In the experimental\ncondition participants used Hands-Free VR. The results confirm that: (1)\nHands-Free VR is robust to spoken English accents, as for 20 of our\nparticipants English was not their first language, and to word phonetic\nsimilarity, correctly transcribing the voice command 96.71% of the time; (2)\nHands-Free VR is robust to natural language diversity, correctly mapping the\ntranscribed command to an executable command in 97.83% of the time; (3)\nHands-Free VR had a significant efficiency advantage over the conventional VR\ninterface in terms of task completion time, total viewpoint translation, total\nview direction rotation, and total left and right hand translations; (4)\nHands-Free VR received high user preference ratings in terms of ease of use,\nintuitiveness, ergonomics, reliability, and desirability.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15083v1",
    "authors": [
      "Jorge Askur Vazquez Fernandez",
      "Jae Joong Lee",
      "Santiago AndrÃ©s Serrano Vacca",
      "Alejandra Magana",
      "Bedrich Benes",
      "Voicu Popescu"
    ]
  },
  {
    "id": "2402.15089",
    "title": "AttributionBench: How Hard is Automatic Attribution Evaluation?",
    "abstract": "  Modern generative search engines enhance the reliability of large language\nmodel (LLM) responses by providing cited evidence. However, evaluating the\nanswer's attribution, i.e., whether every claim within the generated responses\nis fully supported by its cited evidence, remains an open problem. This\nverification, traditionally dependent on costly human evaluation, underscores\nthe urgent need for automatic attribution evaluation methods. To bridge the gap\nin the absence of standardized benchmarks for these methods, we present\nAttributionBench, a comprehensive benchmark compiled from various existing\nattribution datasets. Our extensive experiments on AttributionBench reveal the\nchallenges of automatic attribution evaluation, even for state-of-the-art LLMs.\nSpecifically, our findings show that even a fine-tuned GPT-3.5 only achieves\naround 80% macro-F1 under a binary classification formulation. A detailed\nanalysis of more than 300 error cases indicates that a majority of failures\nstem from the model's inability to process nuanced information, and the\ndiscrepancy between the information the model has access to and that human\nannotators do.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15089v1",
    "authors": ["Yifei Li", "Xiang Yue", "Zeyi Liao", "Huan Sun"]
  },
  {
    "id": "2402.15102",
    "title": "Trajectory-wise Iterative Reinforcement Learning Framework for\n  Auto-bidding",
    "abstract": "  In online advertising, advertisers participate in ad auctions to acquire ad\nopportunities, often by utilizing auto-bidding tools provided by demand-side\nplatforms (DSPs). The current auto-bidding algorithms typically employ\nreinforcement learning (RL). However, due to safety concerns, most RL-based\nauto-bidding policies are trained in simulation, leading to a performance\ndegradation when deployed in online environments. To narrow this gap, we can\ndeploy multiple auto-bidding agents in parallel to collect a large interaction\ndataset. Offline RL algorithms can then be utilized to train a new policy. The\ntrained policy can subsequently be deployed for further data collection,\nresulting in an iterative training framework, which we refer to as iterative\noffline RL. In this work, we identify the performance bottleneck of this\niterative offline RL framework, which originates from the ineffective\nexploration and exploitation caused by the inherent conservatism of offline RL\nalgorithms. To overcome this bottleneck, we propose Trajectory-wise Exploration\nand Exploitation (TEE), which introduces a novel data collecting and data\nutilization method for iterative offline RL from a trajectory perspective.\nFurthermore, to ensure the safety of online exploration while preserving the\ndataset quality for TEE, we propose Safe Exploration by Adaptive Action\nSelection (SEAS). Both offline experiments and real-world experiments on\nAlibaba display advertising platform demonstrate the effectiveness of our\nproposed method.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15102v1",
    "authors": [
      "Haoming Li",
      "Yusen Huo",
      "Shuai Dou",
      "Zhenzhe Zheng",
      "Zhilin Zhang",
      "Chuan Yu",
      "Jian Xu",
      "Fan Wu"
    ]
  },
  {
    "id": "2402.15116",
    "title": "Large Multimodal Agents: A Survey",
    "abstract": "  Large language models (LLMs) have achieved superior performance in powering\ntext-based AI agents, endowing them with decision-making and reasoning\nabilities akin to humans. Concurrently, there is an emerging research trend\nfocused on extending these LLM-powered AI agents into the multimodal domain.\nThis extension enables AI agents to interpret and respond to diverse multimodal\nuser queries, thereby handling more intricate and nuanced tasks. In this paper,\nwe conduct a systematic review of LLM-driven multimodal agents, which we refer\nto as large multimodal agents ( LMAs for short). First, we introduce the\nessential components involved in developing LMAs and categorize the current\nbody of research into four distinct types. Subsequently, we review the\ncollaborative frameworks integrating multiple LMAs , enhancing collective\nefficacy. One of the critical challenges in this field is the diverse\nevaluation methods used across existing studies, hindering effective comparison\namong different LMAs . Therefore, we compile these evaluation methodologies and\nestablish a comprehensive framework to bridge the gaps. This framework aims to\nstandardize evaluations, facilitating more meaningful comparisons. Concluding\nour review, we highlight the extensive applications of LMAs and propose\npossible future research directions. Our discussion aims to provide valuable\ninsights and guidelines for future research in this rapidly evolving field. An\nup-to-date resource list is available at\nhttps://github.com/jun0wanan/awesome-large-multimodal-agents.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15116v1",
    "authors": ["Junlin Xie", "Zhihong Chen", "Ruifei Zhang", "Xiang Wan", "Guanbin Li"]
  },
  {
    "id": "2402.15120",
    "title": "Fine-tuning CLIP Text Encoders with Two-step Paraphrasing",
    "abstract": "  Contrastive language-image pre-training (CLIP) models have demonstrated\nconsiderable success across various vision-language tasks, such as\ntext-to-image retrieval, where the model is required to effectively process\nnatural language input to produce an accurate visual output. However, current\nmodels still face limitations in dealing with linguistic variations in input\nqueries, such as paraphrases, making it challenging to handle a broad range of\nuser queries in real-world applications. In this study, we introduce a\nstraightforward fine-tuning approach to enhance the representations of CLIP\nmodels for paraphrases. Our approach involves a two-step paraphrase generation\nprocess, where we automatically create two categories of paraphrases from\nweb-scale image captions by leveraging large language models. Subsequently, we\nfine-tune the CLIP text encoder using these generated paraphrases while\nfreezing the image encoder. Our resulting model, which we call ParaCLIP,\nexhibits significant improvements over baseline CLIP models across various\ntasks, including paraphrased retrieval (with rank similarity scores improved by\nup to 2.0% and 5.6%), Visual Genome Relation and Attribution, as well as seven\nsemantic textual similarity tasks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15120v1",
    "authors": [
      "Hyunjae Kim",
      "Seunghyun Yoon",
      "Trung Bui",
      "Handong Zhao",
      "Quan Tran",
      "Franck Dernoncourt",
      "Jaewoo Kang"
    ]
  },
  {
    "id": "2402.15152",
    "title": "On the Duality Between Sharpness-Aware Minimization and Adversarial\n  Training",
    "abstract": "  Adversarial Training (AT), which adversarially perturb the input samples\nduring training, has been acknowledged as one of the most effective defenses\nagainst adversarial attacks, yet suffers from a fundamental tradeoff that\ninevitably decreases clean accuracy. Instead of perturbing the samples,\nSharpness-Aware Minimization (SAM) perturbs the model weights during training\nto find a more flat loss landscape and improve generalization. However, as SAM\nis designed for better clean accuracy, its effectiveness in enhancing\nadversarial robustness remains unexplored. In this work, considering the\nduality between SAM and AT, we investigate the adversarial robustness derived\nfrom SAM. Intriguingly, we find that using SAM alone can improve adversarial\nrobustness. To understand this unexpected property of SAM, we first provide\nempirical and theoretical insights into how SAM can implicitly learn more\nrobust features, and conduct comprehensive experiments to show that SAM can\nimprove adversarial robustness notably without sacrificing any clean accuracy,\nshedding light on the potential of SAM to be a substitute for AT when accuracy\ncomes at a higher priority. Code is available at\nhttps://github.com/weizeming/SAM_AT.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15152v1",
    "authors": [
      "Yihao Zhang",
      "Hangzhou He",
      "Jingyu Zhu",
      "Huanran Chen",
      "Yifei Wang",
      "Zeming Wei"
    ]
  },
  {
    "id": "2402.15159",
    "title": "Machine Unlearning of Pre-trained Large Language Models",
    "abstract": "  This study investigates the concept of the `right to be forgotten' within the\ncontext of large language models (LLMs). We explore machine unlearning as a\npivotal solution, with a focus on pre-trained models--a notably\nunder-researched area. Our research delineates a comprehensive framework for\nmachine unlearning in pre-trained LLMs, encompassing a critical analysis of\nseven diverse unlearning methods. Through rigorous evaluation using curated\ndatasets from arXiv, books, and GitHub, we establish a robust benchmark for\nunlearning performance, demonstrating that these methods are over $10^5$ times\nmore computationally efficient than retraining. Our results show that\nintegrating gradient ascent with gradient descent on in-distribution data\nimproves hyperparameter robustness. We also provide detailed guidelines for\nefficient hyperparameter tuning in the unlearning process. Our findings advance\nthe discourse on ethical AI practices, offering substantive insights into the\nmechanics of machine unlearning for pre-trained LLMs and underscoring the\npotential for responsible AI development.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15159v2",
    "authors": [
      "Jin Yao",
      "Eli Chien",
      "Minxin Du",
      "Xinyao Niu",
      "Tianhao Wang",
      "Zezhou Cheng",
      "Xiang Yue"
    ]
  },
  {
    "id": "2402.15162",
    "title": "Entity-level Factual Adaptiveness of Fine-tuning based Abstractive\n  Summarization Models",
    "abstract": "  Abstractive summarization models often generate factually inconsistent\ncontent particularly when the parametric knowledge of the model conflicts with\nthe knowledge in the input document. In this paper, we analyze the robustness\nof fine-tuning based summarization models to the knowledge conflict, which we\ncall factual adaptiveness. We utilize pre-trained language models to construct\nevaluation sets and find that factual adaptiveness is not strongly correlated\nwith factual consistency on original datasets. Furthermore, we introduce a\ncontrollable counterfactual data augmentation method where the degree of\nknowledge conflict within the augmented data can be adjustable. Our\nexperimental results on two pre-trained language models (PEGASUS and BART) and\ntwo fine-tuning datasets (XSum and CNN/DailyMail) demonstrate that our method\nenhances factual adaptiveness while achieving factual consistency on original\ndatasets on par with the contrastive learning baseline.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15162v1",
    "authors": [
      "Jongyoon Song",
      "Nohil Park",
      "Bongkyu Hwang",
      "Jaewoong Yun",
      "Seongho Joe",
      "Youngjune L. Gwon",
      "Sungroh Yoon"
    ]
  },
  {
    "id": "2402.15189",
    "title": "Biomedical Entity Linking as Multiple Choice Question Answering",
    "abstract": "  Although biomedical entity linking (BioEL) has made significant progress with\npre-trained language models, challenges still exist for fine-grained and\nlong-tailed entities. To address these challenges, we present BioELQA, a novel\nmodel that treats Biomedical Entity Linking as Multiple Choice Question\nAnswering. BioELQA first obtains candidate entities with a fast retriever,\njointly presents the mention and candidate entities to a generator, and then\noutputs the predicted symbol associated with its chosen entity. This\nformulation enables explicit comparison of different candidate entities, thus\ncapturing fine-grained interactions between mentions and entities, as well as\namong entities themselves. To improve generalization for long-tailed entities,\nwe retrieve similar labeled training instances as clues and concatenate the\ninput with retrieved instances for the generator. Extensive experimental\nresults show that BioELQA outperforms state-of-the-art baselines on several\ndatasets.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15189v1",
    "authors": ["Zhenxi Lin", "Ziheng Zhang", "Xian Wu", "Yefeng Zheng"]
  },
  {
    "id": "2402.15194",
    "title": "Fine-Tuning of Continuous-Time Diffusion Models as Entropy-Regularized\n  Control",
    "abstract": "  Diffusion models excel at capturing complex data distributions, such as those\nof natural images and proteins. While diffusion models are trained to represent\nthe distribution in the training dataset, we often are more concerned with\nother properties, such as the aesthetic quality of the generated images or the\nfunctional properties of generated proteins. Diffusion models can be finetuned\nin a goal-directed way by maximizing the value of some reward function (e.g.,\nthe aesthetic quality of an image). However, these approaches may lead to\nreduced sample diversity, significant deviations from the training data\ndistribution, and even poor sample quality due to the exploitation of an\nimperfect reward function. The last issue often occurs when the reward function\nis a learned model meant to approximate a ground-truth \"genuine\" reward, as is\nthe case in many practical applications. These challenges, collectively termed\n\"reward collapse,\" pose a substantial obstacle. To address this reward\ncollapse, we frame the finetuning problem as entropy-regularized control\nagainst the pretrained diffusion model, i.e., directly optimizing\nentropy-enhanced rewards with neural SDEs. We present theoretical and empirical\nevidence that demonstrates our framework is capable of efficiently generating\ndiverse samples with high genuine rewards, mitigating the overoptimization of\nimperfect reward models.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15194v2",
    "authors": [
      "Masatoshi Uehara",
      "Yulai Zhao",
      "Kevin Black",
      "Ehsan Hajiramezanali",
      "Gabriele Scalia",
      "Nathaniel Lee Diamant",
      "Alex M Tseng",
      "Tommaso Biancalani",
      "Sergey Levine"
    ]
  },
  {
    "id": "2402.15195",
    "title": "The AffectToolbox: Affect Analysis for Everyone",
    "abstract": "  In the field of affective computing, where research continually advances at a\nrapid pace, the demand for user-friendly tools has become increasingly\napparent. In this paper, we present the AffectToolbox, a novel software system\nthat aims to support researchers in developing affect-sensitive studies and\nprototypes. The proposed system addresses the challenges posed by existing\nframeworks, which often require profound programming knowledge and cater\nprimarily to power-users or skilled developers. Aiming to facilitate ease of\nuse, the AffectToolbox requires no programming knowledge and offers its\nfunctionality to reliably analyze the affective state of users through an\naccessible graphical user interface. The architecture encompasses a variety of\nmodels for emotion recognition on multiple affective channels and modalities,\nas well as an elaborate fusion system to merge multi-modal assessments into a\nunified result. The entire system is open-sourced and will be publicly\navailable to ensure easy integration into more complex applications through a\nwell-structured, Python-based code base - therefore marking a substantial\ncontribution toward advancing affective computing research and fostering a more\ncollaborative and inclusive environment within this interdisciplinary field.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15195v1",
    "authors": [
      "Silvan Mertes",
      "Dominik Schiller",
      "Michael Dietz",
      "Elisabeth AndrÃ©",
      "Florian Lingenfelser"
    ]
  },
  {
    "id": "2402.15246",
    "title": "Artificial Bee Colony optimization of Deep Convolutional Neural Networks\n  in the context of Biomedical Imaging",
    "abstract": "  Most efforts in Computer Vision focus on natural images or artwork, which\ndiffer significantly both in size and contents from the kind of data biomedical\nimage processing deals with. Thus, Transfer Learning models often prove\nthemselves suboptimal for these tasks, even after manual finetuning. The\ndevelopment of architectures from scratch is oftentimes unfeasible due to the\nvastness of the hyperparameter space and a shortage of time, computational\nresources and Deep Learning experts in most biomedical research laboratories.\nAn alternative to manually defining the models is the use of Neuroevolution,\nwhich employs metaheuristic techniques to optimize Deep Learning architectures.\nHowever, many algorithms proposed in the neuroevolutive literature are either\ntoo unreliable or limited to a small, predefined region of the hyperparameter\nspace. To overcome these shortcomings, we propose the Chimera Algorithm, a\nnovel, hybrid neuroevolutive algorithm that integrates the Artificial Bee\nColony Algorithm with Evolutionary Computation tools to generate models from\nscratch, as well as to refine a given previous architecture to better fit the\ntask at hand. The Chimera Algorithm has been validated with two datasets of\nnatural and medical images, producing models that surpassed the performance of\nthose coming from Transfer Learning.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15246v1",
    "authors": [
      "Adri Gomez Martin",
      "Carlos Fernandez del Cerro",
      "Monica Abella Garcia",
      "Manuel Desco Menendez"
    ]
  },
  {
    "id": "2402.15247",
    "title": "A Bargaining-based Approach for Feature Trading in Vertical Federated\n  Learning",
    "abstract": "  Vertical Federated Learning (VFL) has emerged as a popular machine learning\nparadigm, enabling model training across the data and the task parties with\ndifferent features about the same user set while preserving data privacy. In\nproduction environment, VFL usually involves one task party and one data party.\nFair and economically efficient feature trading is crucial to the\ncommercialization of VFL, where the task party is considered as the data\nconsumer who buys the data party's features. However, current VFL feature\ntrading practices often price the data party's data as a whole and assume\ntransactions occur prior to the performing VFL. Neglecting the performance\ngains resulting from traded features may lead to underpayment and overpayment\nissues. In this study, we propose a bargaining-based feature trading approach\nin VFL to encourage economically efficient transactions. Our model incorporates\nperformance gain-based pricing, taking into account the revenue-based\noptimization objectives of both parties. We analyze the proposed bargaining\nmodel under perfect and imperfect performance information settings, proving the\nexistence of an equilibrium that optimizes the parties' objectives. Moreover,\nwe develop performance gain estimation-based bargaining strategies for\nimperfect performance information scenarios and discuss potential security\nissues and solutions. Experiments on three real-world datasets demonstrate the\neffectiveness of the proposed bargaining model.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15247v1",
    "authors": ["Yue Cui", "Liuyi Yao", "Zitao Li", "Yaliang Li", "Bolin Ding", "Xiaofang Zhou"]
  },
  {
    "id": "2402.15262",
    "title": "Dynamic Memory Based Adaptive Optimization",
    "abstract": "  Define an optimizer as having memory $k$ if it stores $k$ dynamically\nchanging vectors in the parameter space. Classical SGD has memory $0$, momentum\nSGD optimizer has $1$ and Adam optimizer has $2$. We address the following\nquestions: How can optimizers make use of more memory units? What information\nshould be stored in them? How to use them for the learning steps? As an\napproach to the last question, we introduce a general method called\n\"Retrospective Learning Law Correction\" or shortly RLLC. This method is\ndesigned to calculate a dynamically varying linear combination (called learning\nlaw) of memory units, which themselves may evolve arbitrarily. We demonstrate\nRLLC on optimizers whose memory units have linear update rules and small memory\n($\\leq 4$ memory units). Our experiments show that in a variety of standard\nproblems, these optimizers outperform the above mentioned three classical\noptimizers. We conclude that RLLC is a promising framework for boosting the\nperformance of known optimizers by adding more memory units and by making them\nmore adaptive.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15262v1",
    "authors": ["BalÃ¡zs Szegedy", "Domonkos Czifra", "PÃ©ter KÅ‘rÃ¶si-SzabÃ³"]
  },
  {
    "id": "2402.15266",
    "title": "Calibration of Deep Learning Classification Models in fNIRS",
    "abstract": "  Functional near-infrared spectroscopy (fNIRS) is a valuable non-invasive tool\nfor monitoring brain activity. The classification of fNIRS data in relation to\nconscious activity holds significance for advancing our understanding of the\nbrain and facilitating the development of brain-computer interfaces (BCI). Many\nresearchers have turned to deep learning to tackle the classification\nchallenges inherent in fNIRS data due to its strong generalization and\nrobustness. In the application of fNIRS, reliability is really important, and\none mathematical formulation of the reliability of confidence is calibration.\nHowever, many researchers overlook the important issue of calibration. To\naddress this gap, we propose integrating calibration into fNIRS field and\nassess the reliability of existing models. Surprisingly, our results indicate\npoor calibration performance in many proposed models. To advance calibration\ndevelopment in the fNIRS field, we summarize three practical tips. Through this\nletter, we hope to emphasize the critical role of calibration in fNIRS research\nand argue for enhancing the reliability of deep learning-based predictions in\nfNIRS classification tasks. All data from our experimental process are openly\navailable on GitHub.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15266v1",
    "authors": ["Zhihao Cao", "Zizhou Luo"]
  },
  {
    "id": "2402.15268",
    "title": "MemoryPrompt: A Light Wrapper to Improve Context Tracking in Pre-trained\n  Language Models",
    "abstract": "  Transformer-based language models (LMs) track contextual information through\nlarge, hard-coded input windows. We introduce MemoryPrompt, a leaner approach\nin which the LM is complemented by a small auxiliary recurrent network that\npasses information to the LM by prefixing its regular input with a sequence of\nvectors, akin to soft prompts, without requiring LM finetuning. Tested on a\ntask designed to probe a LM's ability to keep track of multiple fact updates, a\nMemoryPrompt-augmented LM outperforms much larger LMs that have access to the\nfull input history. We also test MemoryPrompt on a long-distance dialogue\ndataset, where its performance is comparable to that of a model conditioned on\nthe entire conversation history. In both experiments we also observe that,\nunlike full-finetuning approaches, MemoryPrompt does not suffer from\ncatastrophic forgetting when adapted to new tasks, thus not disrupting the\ngeneralist capabilities of the underlying LM.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15268v1",
    "authors": ["NathanaÃ«l Carraz Rakotonirina", "Marco Baroni"]
  },
  {
    "id": "2402.15276",
    "title": "Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale\n  Libraries",
    "abstract": "  Text-to-image retrieval plays a crucial role across various applications,\nincluding digital libraries, e-commerce platforms, and multimedia databases, by\nenabling the search for images using text queries. Despite the advancements in\nMultimodal Large Language Models (MLLMs), which offer leading-edge performance,\ntheir applicability in large-scale, varied, and ambiguous retrieval scenarios\nis constrained by significant computational demands and the generation of\ninjective embeddings. This paper introduces the Text2Pic Swift framework,\ntailored for efficient and robust retrieval of images corresponding to\nextensive textual descriptions in sizable datasets. The framework employs a\ntwo-tier approach: the initial Entity-based Ranking (ER) stage addresses the\nambiguity inherent in lengthy text queries through a\nmultiple-queries-to-multiple-targets strategy, effectively narrowing down\npotential candidates for subsequent analysis. Following this, the Summary-based\nRe-ranking (SR) stage further refines these selections based on concise query\nsummaries. Additionally, we present a novel Decoupling-BEiT-3 encoder,\nspecifically designed to tackle the challenges of ambiguous queries and to\nfacilitate both stages of the retrieval process, thereby significantly\nimproving computational efficiency via vector-based similarity assessments. Our\nevaluation, conducted on the AToMiC dataset, demonstrates that Text2Pic Swift\noutperforms current MLLMs by achieving up to an 11.06% increase in Recall@1000,\nalongside reductions in training and retrieval durations by 68.75% and 99.79%,\nrespectively.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15276v2",
    "authors": ["Zijun Long", "Xuri Ge", "Richard Mccreadie", "Joemon Jose"]
  },
  {
    "id": "2402.15284",
    "title": "Spatiotemporal Observer Design for Predictive Learning of\n  High-Dimensional Data",
    "abstract": "  Although deep learning-based methods have shown great success in\nspatiotemporal predictive learning, the framework of those models is designed\nmainly by intuition. How to make spatiotemporal forecasting with theoretical\nguarantees is still a challenging issue. In this work, we tackle this problem\nby applying domain knowledge from the dynamical system to the framework design\nof deep learning models. An observer theory-guided deep learning architecture,\ncalled Spatiotemporal Observer, is designed for predictive learning of high\ndimensional data. The characteristics of the proposed framework are twofold:\nfirstly, it provides the generalization error bound and convergence guarantee\nfor spatiotemporal prediction; secondly, dynamical regularization is introduced\nto enable the model to learn system dynamics better during training. Further\nexperimental results show that this framework could capture the spatiotemporal\ndynamics and make accurate predictions in both one-step-ahead and\nmulti-step-ahead forecasting scenarios.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15284v1",
    "authors": ["Tongyi Liang", "Han-Xiong Li"]
  },
  {
    "id": "2402.15294",
    "title": "A Survey of Music Generation in the Context of Interaction",
    "abstract": "  In recent years, machine learning, and in particular generative adversarial\nneural networks (GANs) and attention-based neural networks (transformers), have\nbeen successfully used to compose and generate music, both melodies and\npolyphonic pieces. Current research focuses foremost on style replication (eg.\ngenerating a Bach-style chorale) or style transfer (eg. classical to jazz)\nbased on large amounts of recorded or transcribed music, which in turn also\nallows for fairly straight-forward \"performance\" evaluation. However, most of\nthese models are not suitable for human-machine co-creation through live\ninteraction, neither is clear, how such models and resulting creations would be\nevaluated. This article presents a thorough review of music representation,\nfeature analysis, heuristic algorithms, statistical and parametric modelling,\nand human and automatic evaluation measures, along with a discussion of which\napproaches and models seem most suitable for live interaction.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15294v1",
    "authors": [
      "Ismael Agchar",
      "Ilja Baumann",
      "Franziska Braun",
      "Paula Andrea Perez-Toro",
      "Korbinian Riedhammer",
      "Sebastian Trump",
      "Martin Ullrich"
    ]
  },
  {
    "id": "2402.15307",
    "title": "Representing Online Handwriting for Recognition in Large Vision-Language\n  Models",
    "abstract": "  The adoption of tablets with touchscreens and styluses is increasing, and a\nkey feature is converting handwriting to text, enabling search, indexing, and\nAI assistance. Meanwhile, vision-language models (VLMs) are now the go-to\nsolution for image understanding, thanks to both their state-of-the-art\nperformance across a variety of tasks and the simplicity of a unified approach\nto training, fine-tuning, and inference. While VLMs obtain high performance on\nimage-based tasks, they perform poorly on handwriting recognition when applied\nnaively, i.e., by rendering handwriting as an image and performing optical\ncharacter recognition (OCR). In this paper, we study online handwriting\nrecognition with VLMs, going beyond naive OCR. We propose a novel tokenized\nrepresentation of digital ink (online handwriting) that includes both a\ntime-ordered sequence of strokes as text, and as image. We show that this\nrepresentation yields results comparable to or better than state-of-the-art\nonline handwriting recognizers. Wide applicability is shown through results\nwith two different VLM families, on multiple public datasets. Our approach can\nbe applied to off-the-shelf VLMs, does not require any changes in their\narchitecture, and can be used in both fine-tuning and parameter-efficient\ntuning. We perform a detailed ablation study to identify the key elements of\nthe proposed representation.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15307v1",
    "authors": [
      "Anastasiia Fadeeva",
      "Philippe Schlattner",
      "Andrii Maksai",
      "Mark Collier",
      "Efi Kokiopoulou",
      "Jesse Berent",
      "Claudiu Musat"
    ]
  },
  {
    "id": "2402.15313",
    "title": "ArabianGPT: Native Arabic GPT-based Large Language Model",
    "abstract": "  The predominance of English and Latin-based large language models (LLMs) has\nled to a notable deficit in native Arabic LLMs. This discrepancy is accentuated\nby the prevalent inclusion of English tokens in existing Arabic models,\ndetracting from their efficacy in processing native Arabic's intricate\nmorphology and syntax. Consequently, there is a theoretical and practical\nimperative for developing LLMs predominantly focused on Arabic linguistic\nelements. To address this gap, this paper proposes ArabianGPT, a series of\ntransformer-based models within the ArabianLLM suite designed explicitly for\nArabic. These models, including ArabianGPT-0.1B and ArabianGPT-0.3B, vary in\nsize and complexity, aligning with the nuanced linguistic characteristics of\nArabic. The AraNizer tokenizer, integral to these models, addresses the unique\nmorphological aspects of Arabic script, ensuring more accurate text processing.\nEmpirical results from fine-tuning the models on tasks like sentiment analysis\nand summarization demonstrate significant improvements. For sentiment analysis,\nthe fine-tuned ArabianGPT-0.1B model achieved a remarkable accuracy of 95%, a\nsubstantial increase from the base model's 56%. Similarly, in summarization\ntasks, fine-tuned models showed enhanced F1 scores, indicating improved\nprecision and recall in generating concise summaries. Comparative analysis of\nfine-tuned ArabianGPT models against their base versions across various\nbenchmarks reveals nuanced differences in performance, with fine-tuning\npositively impacting specific tasks like question answering and summarization.\nThese findings underscore the efficacy of fine-tuning in aligning ArabianGPT\nmodels more closely with specific NLP tasks, highlighting the potential of\ntailored transformer architectures in advancing Arabic NLP.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15313v2",
    "authors": ["Anis Koubaa", "Adel Ammar", "Lahouari Ghouti", "Omar Najar", "Serry Sibaee"]
  },
  {
    "id": "2402.15321",
    "title": "OpenSUN3D: 1st Workshop Challenge on Open-Vocabulary 3D Scene\n  Understanding",
    "abstract": "  This report provides an overview of the challenge hosted at the OpenSUN3D\nWorkshop on Open-Vocabulary 3D Scene Understanding held in conjunction with\nICCV 2023. The goal of this workshop series is to provide a platform for\nexploration and discussion of open-vocabulary 3D scene understanding tasks,\nincluding but not limited to segmentation, detection and mapping. We provide an\noverview of the challenge hosted at the workshop, present the challenge\ndataset, the evaluation methodology, and brief descriptions of the winning\nmethods. For additional details, please see\nhttps://opensun3d.github.io/index_iccv23.html.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15321v1",
    "authors": [
      "Francis Engelmann",
      "Ayca Takmaz",
      "Jonas Schult",
      "Elisabetta Fedele",
      "Johanna Wald",
      "Songyou Peng",
      "Xi Wang",
      "Or Litany",
      "Siyu Tang",
      "Federico Tombari",
      "Marc Pollefeys",
      "Leonidas Guibas",
      "Hongbo Tian",
      "Chunjie Wang",
      "Xiaosheng Yan",
      "Bingwen Wang",
      "Xuanyang Zhang",
      "Xiao Liu",
      "Phuc Nguyen",
      "Khoi Nguyen",
      "Anh Tran",
      "Cuong Pham",
      "Zhening Huang",
      "Xiaoyang Wu",
      "Xi Chen",
      "Hengshuang Zhao",
      "Lei Zhu",
      "Joan Lasenby"
    ]
  },
  {
    "id": "2402.15343",
    "title": "NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data",
    "abstract": "  Large Language Models (LLMs) have shown impressive abilities in data\nannotation, opening the way for new approaches to solve classic NLP problems.\nIn this paper, we show how to use LLMs to create NuNER, a compact language\nrepresentation model specialized in the Named Entity Recognition (NER) task.\nNuNER can be fine-tuned to solve downstream NER problems in a data-efficient\nway, outperforming similar-sized foundation models in the few-shot regime and\ncompeting with much larger LLMs. We find that the size and entity-type\ndiversity of the pre-training dataset are key to achieving good performance. We\nview NuNER as a member of the broader family of task-specific foundation\nmodels, recently unlocked by LLMs.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15343v1",
    "authors": [
      "Sergei Bogdanov",
      "Alexandre Constantin",
      "TimothÃ©e Bernard",
      "Benoit CrabbÃ©",
      "Etienne Bernard"
    ]
  },
  {
    "id": "2402.15347",
    "title": "Information-Theoretic Safe Bayesian Optimization",
    "abstract": "  We consider a sequential decision making task, where the goal is to optimize\nan unknown function without evaluating parameters that violate an a~priori\nunknown (safety) constraint. A common approach is to place a Gaussian process\nprior on the unknown functions and allow evaluations only in regions that are\nsafe with high probability. Most current methods rely on a discretization of\nthe domain and cannot be directly extended to the continuous case. Moreover,\nthe way in which they exploit regularity assumptions about the constraint\nintroduces an additional critical hyperparameter. In this paper, we propose an\ninformation-theoretic safe exploration criterion that directly exploits the GP\nposterior to identify the most informative safe parameters to evaluate. The\ncombination of this exploration criterion with a well known Bayesian\noptimization acquisition function yields a novel safe Bayesian optimization\nselection criterion. Our approach is naturally applicable to continuous domains\nand does not require additional explicit hyperparameters. We theoretically\nanalyze the method and show that we do not violate the safety constraint with\nhigh probability and that we learn about the value of the safe optimum up to\narbitrary precision. Empirical evaluations demonstrate improved data-efficiency\nand scalability.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15347v1",
    "authors": [
      "Alessandro G. Bottero",
      "Carlos E. Luis",
      "Julia Vinogradska",
      "Felix Berkenkamp",
      "Jan Peters"
    ]
  },
  {
    "id": "2402.15350",
    "title": "Farsight: Fostering Responsible AI Awareness During AI Application\n  Prototyping",
    "abstract": "  Prompt-based interfaces for Large Language Models (LLMs) have made\nprototyping and building AI-powered applications easier than ever before.\nHowever, identifying potential harms that may arise from AI applications\nremains a challenge, particularly during prompt-based prototyping. To address\nthis, we present Farsight, a novel in situ interactive tool that helps people\nidentify potential harms from the AI applications they are prototyping. Based\non a user's prompt, Farsight highlights news articles about relevant AI\nincidents and allows users to explore and edit LLM-generated use cases,\nstakeholders, and harms. We report design insights from a co-design study with\n10 AI prototypers and findings from a user study with 42 AI prototypers. After\nusing Farsight, AI prototypers in our user study are better able to\nindependently identify potential harms associated with a prompt and find our\ntool more useful and usable than existing resources. Their qualitative feedback\nalso highlights that Farsight encourages them to focus on end-users and think\nbeyond immediate harms. We discuss these findings and reflect on their\nimplications for designing AI prototyping experiences that meaningfully engage\nwith AI harms. Farsight is publicly accessible at:\nhttps://PAIR-code.github.io/farsight.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15350v1",
    "authors": [
      "Zijie J. Wang",
      "Chinmay Kulkarni",
      "Lauren Wilcox",
      "Michael Terry",
      "Michael Madaio"
    ]
  },
  {
    "id": "2402.15370",
    "title": "Dual Encoder: Exploiting the Potential of Syntactic and Semantic for\n  Aspect Sentiment Triplet Extraction",
    "abstract": "  Aspect Sentiment Triple Extraction (ASTE) is an emerging task in fine-grained\nsentiment analysis. Recent studies have employed Graph Neural Networks (GNN) to\nmodel the syntax-semantic relationships inherent in triplet elements. However,\nthey have yet to fully tap into the vast potential of syntactic and semantic\ninformation within the ASTE task. In this work, we propose a \\emph{Dual\nEncoder: Exploiting the potential of Syntactic and Semantic} model (D2E2S),\nwhich maximizes the syntactic and semantic relationships among words.\nSpecifically, our model utilizes a dual-channel encoder with a BERT channel to\ncapture semantic information, and an enhanced LSTM channel for comprehensive\nsyntactic information capture. Subsequently, we introduce the heterogeneous\nfeature interaction module to capture intricate interactions between dependency\nsyntax and attention semantics, and to dynamically select vital nodes. We\nleverage the synergy of these modules to harness the significant potential of\nsyntactic and semantic information in ASTE tasks. Testing on public benchmarks,\nour D2E2S model surpasses the current state-of-the-art(SOTA), demonstrating its\neffectiveness.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15370v1",
    "authors": ["Xiaowei Zhao", "Yong Zhou", "Xiujuan Xu"]
  },
  {
    "id": "2402.15384",
    "title": "Homeostatic motion planning with innate physics knowledge",
    "abstract": "  Living organisms interact with their surroundings in a closed-loop fashion,\nwhere sensory inputs dictate the initiation and termination of behaviours. Even\nsimple animals are able to develop and execute complex plans, which has not yet\nbeen replicated in robotics using pure closed-loop input control. We propose a\nsolution to this problem by defining a set of discrete and temporary\nclosed-loop controllers, called \"tasks\", each representing a closed-loop\nbehaviour. We further introduce a supervisory module which has an innate\nunderstanding of physics and causality, through which it can simulate the\nexecution of task sequences over time and store the results in a model of the\nenvironment. On the basis of this model, plans can be made by chaining\ntemporary closed-loop controllers. The proposed framework was implemented for a\nreal robot and tested in two scenarios as proof of concept.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15384v1",
    "authors": ["Giulia Lafratta", "Bernd Porr", "Christopher Chandler", "Alice Miller"]
  },
  {
    "id": "2402.15390",
    "title": "Explorations of Self-Repair in Language Models",
    "abstract": "  Prior interpretability research studying narrow distributions has\npreliminarily identified self-repair, a phenomena where if components in large\nlanguage models are ablated, later components will change their behavior to\ncompensate. Our work builds off this past literature, demonstrating that\nself-repair exists on a variety of models families and sizes when ablating\nindividual attention heads on the full training distribution. We further show\nthat on the full training distribution self-repair is imperfect, as the\noriginal direct effect of the head is not fully restored, and noisy, since the\ndegree of self-repair varies significantly across different prompts (sometimes\novercorrecting beyond the original effect). We highlight two different\nmechanisms that contribute to self-repair, including changes in the final\nLayerNorm scaling factor (which can repair up to 30% of the direct effect) and\nsparse sets of neurons implementing Anti-Erasure. We additionally discuss the\nimplications of these results for interpretability practitioners and close with\na more speculative discussion on the mystery of why self-repair occurs in these\nmodels at all, highlighting evidence for the Iterative Inference hypothesis in\nlanguage models, a framework that predicts self-repair.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15390v1",
    "authors": ["Cody Rushing", "Neel Nanda"]
  },
  {
    "id": "2402.15391",
    "title": "Genie: Generative Interactive Environments",
    "abstract": "  We introduce Genie, the first generative interactive environment trained in\nan unsupervised manner from unlabelled Internet videos. The model can be\nprompted to generate an endless variety of action-controllable virtual worlds\ndescribed through text, synthetic images, photographs, and even sketches. At\n11B parameters, Genie can be considered a foundation world model. It is\ncomprised of a spatiotemporal video tokenizer, an autoregressive dynamics\nmodel, and a simple and scalable latent action model. Genie enables users to\nact in the generated environments on a frame-by-frame basis despite training\nwithout any ground-truth action labels or other domain-specific requirements\ntypically found in the world model literature. Further the resulting learned\nlatent action space facilitates training agents to imitate behaviors from\nunseen videos, opening the path for training generalist agents of the future.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15391v1",
    "authors": [
      "Jake Bruce",
      "Michael Dennis",
      "Ashley Edwards",
      "Jack Parker-Holder",
      "Yuge Shi",
      "Edward Hughes",
      "Matthew Lai",
      "Aditi Mavalankar",
      "Richie Steigerwald",
      "Chris Apps",
      "Yusuf Aytar",
      "Sarah Bechtle",
      "Feryal Behbahani",
      "Stephanie Chan",
      "Nicolas Heess",
      "Lucy Gonzalez",
      "Simon Osindero",
      "Sherjil Ozair",
      "Scott Reed",
      "Jingwei Zhang",
      "Konrad Zolna",
      "Jeff Clune",
      "Nando de Freitas",
      "Satinder Singh",
      "Tim RocktÃ¤schel"
    ]
  },
  {
    "id": "2402.15398",
    "title": "TransFlower: An Explainable Transformer-Based Model with Flow-to-Flow\n  Attention for Commuting Flow Prediction",
    "abstract": "  Understanding the link between urban planning and commuting flows is crucial\nfor guiding urban development and policymaking. This research, bridging\ncomputer science and urban studies, addresses the challenge of integrating\nthese fields with their distinct focuses. Traditional urban studies methods,\nlike the gravity and radiation models, often underperform in complex scenarios\ndue to their limited handling of multiple variables and reliance on overly\nsimplistic and unrealistic assumptions, such as spatial isotropy. While deep\nlearning models offer improved accuracy, their black-box nature poses a\ntrade-off between performance and explainability -- both vital for analyzing\ncomplex societal phenomena like commuting flows. To address this, we introduce\nTransFlower, an explainable, transformer-based model employing flow-to-flow\nattention to predict urban commuting patterns. It features a geospatial encoder\nwith an anisotropy-aware relative location encoder for nuanced flow\nrepresentation. Following this, the transformer-based flow predictor enhances\nthis by leveraging attention mechanisms to efficiently capture flow\ninteractions. Our model outperforms existing methods by up to 30.8% Common Part\nof Commuters, offering insights into mobility dynamics crucial for urban\nplanning and policy decisions.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15398v1",
    "authors": [
      "Yan Luo",
      "Zhuoyue Wan",
      "Yuzhong Chen",
      "Gengchen Mai",
      "Fu-lai Chung",
      "Kent Larson"
    ]
  },
  {
    "id": "2402.15418",
    "title": "Reputational Algorithm Aversion",
    "abstract": "  People are often reluctant to incorporate information produced by algorithms\ninto their decisions, a phenomenon called \"algorithm aversion\". This paper\nshows how algorithm aversion arises when the choice to follow an algorithm\nconveys information about a human's ability. I develop a model in which workers\nmake forecasts of a random outcome based on their own private information and\nan algorithm's signal. Low-skill workers receive worse information than the\nalgorithm and hence should always follow the algorithm's signal, while\nhigh-skill workers receive better information than the algorithm and should\nsometimes override it. However, due to reputational concerns, low-skill workers\ninefficiently override the algorithm to increase the likelihood they are\nperceived as high-skill. The model provides a fully rational microfoundation\nfor algorithm aversion that aligns with the broad concern that AI systems will\ndisplace many types of workers.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15418v1",
    "authors": ["Gregory Weitzner"]
  },
  {
    "id": "2402.15422",
    "title": "A Data-Centric Approach To Generate Faithful and High Quality Patient\n  Summaries with Large Language Models",
    "abstract": "  Patients often face difficulties in understanding their hospitalizations,\nwhile healthcare workers have limited resources to provide explanations. In\nthis work, we investigate the potential of large language models to generate\npatient summaries based on doctors' notes and study the effect of training data\non the faithfulness and quality of the generated summaries. To this end, we\ndevelop a rigorous labeling protocol for hallucinations, and have two medical\nexperts annotate 100 real-world summaries and 100 generated summaries. We show\nthat fine-tuning on hallucination-free data effectively reduces hallucinations\nfrom 2.60 to 1.55 per summary for Llama 2, while preserving relevant\ninformation. Although the effect is still present, it is much smaller for GPT-4\nwhen prompted with five examples (0.70 to 0.40). We also conduct a qualitative\nevaluation using hallucination-free and improved training data. GPT-4 shows\nvery good results even in the zero-shot setting. We find that common\nquantitative metrics do not correlate well with faithfulness and quality.\nFinally, we test GPT-4 for automatic hallucination detection, which yields\npromising results.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15422v1",
    "authors": [
      "Stefan Hegselmann",
      "Shannon Zejiang Shen",
      "Florian Gierse",
      "Monica Agrawal",
      "David Sontag",
      "Xiaoyi Jiang"
    ]
  },
  {
    "id": "2402.15427",
    "title": "Understanding Entrainment in Human Groups: Optimising Human-Robot\n  Collaboration from Lessons Learned during Human-Human Collaboration",
    "abstract": "  Successful entrainment during collaboration positively affects trust,\nwillingness to collaborate, and likeability towards collaborators. In this\npaper, we present a mixed-method study to investigate characteristics of\nsuccessful entrainment leading to pair and group-based synchronisation. Drawing\ninspiration from industrial settings, we designed a fast-paced, short-cycle\nrepetitive task. Using motion tracking, we investigated entrainment in both\ndyadic and triadic task completion. Furthermore, we utilise audio-video\nrecordings and semi-structured interviews to contextualise participants'\nexperiences. This paper contributes to the Human-Computer/Robot Interaction\n(HCI/HRI) literature using a human-centred approach to identify characteristics\nof entrainment during pair- and group-based collaboration. We present five\ncharacteristics related to successful entrainment. These are related to the\noccurrence of entrainment, leader-follower patterns, interpersonal\ncommunication, the importance of the point-of-assembly, and the value of\nacoustic feedback. Finally, we present three design considerations for future\nresearch and design on collaboration with robots.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15427v1",
    "authors": [
      "Eike Schneiders",
      "Christopher Fourie",
      "Stanley Celestin",
      "Julie Shah",
      "Malte Jung"
    ]
  },
  {
    "id": "2402.15429",
    "title": "ProTIP: Probabilistic Robustness Verification on Text-to-Image Diffusion\n  Models against Stochastic Perturbation",
    "abstract": "  Text-to-Image (T2I) Diffusion Models (DMs) have shown impressive abilities in\ngenerating high-quality images based on simple text descriptions. However, as\nis common with many Deep Learning (DL) models, DMs are subject to a lack of\nrobustness. While there are attempts to evaluate the robustness of T2I DMs as a\nbinary or worst-case problem, they cannot answer how robust in general the\nmodel is whenever an adversarial example (AE) can be found. In this study, we\nfirst introduce a probabilistic notion of T2I DMs' robustness; and then\nestablish an efficient framework, ProTIP, to evaluate it with statistical\nguarantees. The main challenges stem from: i) the high computational cost of\nthe generation process; and ii) determining if a perturbed input is an AE\ninvolves comparing two output distributions, which is fundamentally harder\ncompared to other DL tasks like classification where an AE is identified upon\nmisprediction of labels. To tackle the challenges, we employ sequential\nanalysis with efficacy and futility early stopping rules in the statistical\ntesting for identifying AEs, and adaptive concentration inequalities to\ndynamically determine the \"just-right\" number of stochastic perturbations\nwhenever the verification target is met. Empirical experiments validate the\neffectiveness and efficiency of ProTIP over common T2I DMs. Finally, we\ndemonstrate an application of ProTIP to rank commonly used defence methods.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15429v1",
    "authors": [
      "Yi Zhang",
      "Yun Tang",
      "Wenjie Ruan",
      "Xiaowei Huang",
      "Siddartha Khastgir",
      "Paul Jennings",
      "Xingyu Zhao"
    ]
  },
  {
    "id": "2402.15448",
    "title": "Computer Vision for Multimedia Geolocation in Human Trafficking\n  Investigation: A Systematic Literature Review",
    "abstract": "  The task of multimedia geolocation is becoming an increasingly essential\ncomponent of the digital forensics toolkit to effectively combat human\ntrafficking, child sexual exploitation, and other illegal acts. Typically,\nmetadata-based geolocation information is stripped when multimedia content is\nshared via instant messaging and social media. The intricacy of geolocating,\ngeotagging, or finding geographical clues in this content is often overly\nburdensome for investigators. Recent research has shown that contemporary\nadvancements in artificial intelligence, specifically computer vision and deep\nlearning, show significant promise towards expediting the multimedia\ngeolocation task. This systematic literature review thoroughly examines the\nstate-of-the-art leveraging computer vision techniques for multimedia\ngeolocation and assesses their potential to expedite human trafficking\ninvestigation. This includes a comprehensive overview of the application of\ncomputer vision-based approaches to multimedia geolocation, identifies their\napplicability in combating human trafficking, and highlights the potential\nimplications of enhanced multimedia geolocation for prosecuting human\ntrafficking. 123 articles inform this systematic literature review. The\nfindings suggest numerous potential paths for future impactful research on the\nsubject.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15448v1",
    "authors": ["Opeyemi Bamigbade", "John Sheppard", "Mark Scanlon"]
  },
  {
    "id": "2402.15487",
    "title": "RoboEXP: Action-Conditioned Scene Graph via Interactive Exploration for\n  Robotic Manipulation",
    "abstract": "  Robots need to explore their surroundings to adapt to and tackle tasks in\nunknown environments. Prior work has proposed building scene graphs of the\nenvironment but typically assumes that the environment is static, omitting\nregions that require active interactions. This severely limits their ability to\nhandle more complex tasks in household and office environments: before setting\nup a table, robots must explore drawers and cabinets to locate all utensils and\ncondiments. In this work, we introduce the novel task of interactive scene\nexploration, wherein robots autonomously explore environments and produce an\naction-conditioned scene graph (ACSG) that captures the structure of the\nunderlying environment. The ACSG accounts for both low-level information, such\nas geometry and semantics, and high-level information, such as the\naction-conditioned relationships between different entities in the scene. To\nthis end, we present the Robotic Exploration (RoboEXP) system, which\nincorporates the Large Multimodal Model (LMM) and an explicit memory design to\nenhance our system's capabilities. The robot reasons about what and how to\nexplore an object, accumulating new information through the interaction process\nand incrementally constructing the ACSG. We apply our system across various\nreal-world settings in a zero-shot manner, demonstrating its effectiveness in\nexploring and modeling environments it has never seen before. Leveraging the\nconstructed ACSG, we illustrate the effectiveness and efficiency of our RoboEXP\nsystem in facilitating a wide range of real-world manipulation tasks involving\nrigid, articulated objects, nested objects like Matryoshka dolls, and\ndeformable objects like cloth.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15487v1",
    "authors": [
      "Hanxiao Jiang",
      "Binghao Huang",
      "Ruihai Wu",
      "Zhuoran Li",
      "Shubham Garg",
      "Hooshang Nayyeri",
      "Shenlong Wang",
      "Yunzhu Li"
    ]
  },
  {
    "id": "2402.15505",
    "title": "Co-Supervised Learning: Improving Weak-to-Strong Generalization with\n  Hierarchical Mixture of Experts",
    "abstract": "  Steering the behavior of a strong model pre-trained on internet-scale data\ncan be difficult due to the scarcity of competent supervisors. Recent studies\nreveal that, despite supervisory noises, a strong student model may surpass its\nweak teacher when fine-tuned on specific objectives. Yet, the effectiveness of\nsuch weak-to-strong generalization remains limited, especially in the presence\nof large capability gaps. In this paper, we propose to address this challenge\nby harnessing a diverse set of specialized teachers, instead of a single\ngeneralist one, that collectively supervises the strong student. Our approach\nresembles the classical hierarchical mixture of experts, with two components\ntailored for co-supervision: (i) we progressively alternate student training\nand teacher assignment, leveraging the growth of the strong student to identify\nplausible supervisions; (ii) we conservatively enforce teacher-student and\nlocal-global consistency, leveraging their dependencies to reject potential\nannotation noises. We validate the proposed method through visual recognition\ntasks on the OpenAI weak-to-strong benchmark and additional multi-domain\ndatasets. Our code is available at \\url{https://github.com/yuejiangliu/csl}.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15505v1",
    "authors": ["Yuejiang Liu", "Alexandre Alahi"]
  },
  {
    "id": "2402.15506",
    "title": "AgentOhana: Design Unified Data and Training Pipeline for Effective\n  Agent Learning",
    "abstract": "  Autonomous agents powered by large language models (LLMs) have garnered\nsignificant research attention. However, fully harnessing the potential of LLMs\nfor agent-based tasks presents inherent challenges due to the heterogeneous\nnature of diverse data sources featuring multi-turn trajectories. In this\npaper, we introduce \\textbf{AgentOhana} as a comprehensive solution to address\nthese challenges. \\textit{AgentOhana} aggregates agent trajectories from\ndistinct environments, spanning a wide array of scenarios. It meticulously\nstandardizes and unifies these trajectories into a consistent format,\nstreamlining the creation of a generic data loader optimized for agent\ntraining. Leveraging the data unification, our training pipeline maintains\nequilibrium across different data sources and preserves independent randomness\nacross devices during dataset partitioning and model training. Additionally, we\npresent \\textbf{xLAM-v0.1}, a large action model tailored for AI agents, which\ndemonstrates exceptional performance across various benchmarks.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15506v2",
    "authors": [
      "Jianguo Zhang",
      "Tian Lan",
      "Rithesh Murthy",
      "Zhiwei Liu",
      "Weiran Yao",
      "Juntao Tan",
      "Thai Hoang",
      "Liangwei Yang",
      "Yihao Feng",
      "Zuxin Liu",
      "Tulika Awalgaonkar",
      "Juan Carlos Niebles",
      "Silvio Savarese",
      "Shelby Heinecke",
      "Huan Wang",
      "Caiming Xiong"
    ]
  },
  {
    "id": "2402.15537",
    "title": "Evaluating the Performance of ChatGPT for Spam Email Detection",
    "abstract": "  Email continues to be a pivotal and extensively utilized communication medium\nwithin professional and commercial domains. Nonetheless, the prevalence of spam\nemails poses a significant challenge for users, disrupting their daily routines\nand diminishing productivity. Consequently, accurately identifying and\nfiltering spam based on content has become crucial for cybersecurity. Recent\nadvancements in natural language processing, particularly with large language\nmodels like ChatGPT, have shown remarkable performance in tasks such as\nquestion answering and text generation. However, its potential in spam\nidentification remains underexplored. To fill in the gap, this study attempts\nto evaluate ChatGPT's capabilities for spam identification in both English and\nChinese email datasets. We employ ChatGPT for spam email detection using\nin-context learning, which requires a prompt instruction and a few\ndemonstrations. We also investigate how the training example size affects the\nperformance of ChatGPT. For comparison, we also implement five popular\nbenchmark methods, including naive Bayes, support vector machines (SVM),\nlogistic regression (LR), feedforward dense neural networks (DNN), and BERT\nclassifiers. Though extensive experiments, the performance of ChatGPT is\nsignificantly worse than deep supervised learning methods in the large English\ndataset, while it presents superior performance on the low-resourced Chinese\ndataset, even outperforming BERT in this case.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15537v1",
    "authors": ["Yuwei Wu", "Shijing Si", "Yugui Zhang", "Jiawen Gu", "Jedrek Wosik"]
  },
  {
    "id": "2402.15546",
    "title": "HiMAP: Learning Heuristics-Informed Policies for Large-Scale Multi-Agent\n  Pathfinding",
    "abstract": "  Large-scale multi-agent pathfinding (MAPF) presents significant challenges in\nseveral areas. As systems grow in complexity with a multitude of autonomous\nagents operating simultaneously, efficient and collision-free coordination\nbecomes paramount. Traditional algorithms often fall short in scalability,\nespecially in intricate scenarios. Reinforcement Learning (RL) has shown\npotential to address the intricacies of MAPF; however, it has also been shown\nto struggle with scalability, demanding intricate implementation, lengthy\ntraining, and often exhibiting unstable convergence, limiting its practical\napplication. In this paper, we introduce Heuristics-Informed Multi-Agent\nPathfinding (HiMAP), a novel scalable approach that employs imitation learning\nwith heuristic guidance in a decentralized manner. We train on small-scale\ninstances using a heuristic policy as a teacher that maps each single agent\nobservation information to an action probability distribution. During\npathfinding, we adopt several inference techniques to improve performance. With\na simple training scheme and implementation, HiMAP demonstrates competitive\nresults in terms of success rate and scalability in the field of\nimitation-learning-only MAPF, showing the potential of imitation-learning-only\nMAPF equipped with inference techniques.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15546v1",
    "authors": [
      "Huijie Tang",
      "Federico Berto",
      "Zihan Ma",
      "Chuanbo Hua",
      "Kyuree Ahn",
      "Jinkyoo Park"
    ]
  },
  {
    "id": "2402.15552",
    "title": "Morphological Symmetries in Robotics",
    "abstract": "  We present a comprehensive framework for studying and leveraging\nmorphological symmetries in robotic systems. These are intrinsic properties of\nthe robot's morphology, frequently observed in animal biology and robotics,\nwhich stem from the replication of kinematic structures and the symmetrical\ndistribution of mass. We illustrate how these symmetries extend to the robot's\nstate space and both proprioceptive and exteroceptive sensor measurements,\nresulting in the equivariance of the robot's equations of motion and optimal\ncontrol policies. Thus, we recognize morphological symmetries as a relevant and\npreviously unexplored physics-informed geometric prior, with significant\nimplications for both data-driven and analytical methods used in modeling,\ncontrol, estimation and design in robotics. For data-driven methods, we\ndemonstrate that morphological symmetries can enhance the sample efficiency and\ngeneralization of machine learning models through data augmentation, or by\napplying equivariant/invariant constraints on the model's architecture. In the\ncontext of analytical methods, we employ abstract harmonic analysis to\ndecompose the robot's dynamics into a superposition of lower-dimensional,\nindependent dynamics. We substantiate our claims with both synthetic and\nreal-world experiments conducted on bipedal and quadrupedal robots. Lastly, we\nintroduce the repository MorphoSymm to facilitate the practical use of the\ntheory and applications outlined in this work.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15552v1",
    "authors": [
      "Daniel OrdoÃ±ez-Apraez",
      "Giulio Turrisi",
      "Vladimir Kostic",
      "Mario Martin",
      "Antonio Agudo",
      "Francesc Moreno-Noguer",
      "Massimiliano Pontil",
      "Claudio Semini",
      "Carlos Mastalli"
    ]
  },
  {
    "id": "2402.15555",
    "title": "Deep Networks Always Grok and Here is Why",
    "abstract": "  Grokking, or delayed generalization, is a phenomenon where generalization in\na deep neural network (DNN) occurs long after achieving near zero training\nerror. Previous studies have reported the occurrence of grokking in specific\ncontrolled settings, such as DNNs initialized with large-norm parameters or\ntransformers trained on algorithmic datasets. We demonstrate that grokking is\nactually much more widespread and materializes in a wide range of practical\nsettings, such as training of a convolutional neural network (CNN) on CIFAR10\nor a Resnet on Imagenette. We introduce the new concept of delayed robustness,\nwhereby a DNN groks adversarial examples and becomes robust, long after\ninterpolation and/or generalization. We develop an analytical explanation for\nthe emergence of both delayed generalization and delayed robustness based on a\nnew measure of the local complexity of a DNN's input-output mapping. Our local\ncomplexity measures the density of the so-called 'linear regions' (aka, spline\npartition regions) that tile the DNN input space, and serves as a utile\nprogress measure for training. We provide the first evidence that for\nclassification problems, the linear regions undergo a phase transition during\ntraining whereafter they migrate away from the training samples (making the DNN\nmapping smoother there) and towards the decision boundary (making the DNN\nmapping less smooth there). Grokking occurs post phase transition as a robust\npartition of the input space emerges thanks to the linearization of the DNN\nmapping around the training points. Website: https://bit.ly/grok-adversarial\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15555v1",
    "authors": ["Ahmed Imtiaz Humayun", "Randall Balestriero", "Richard Baraniuk"]
  },
  {
    "id": "2402.15567",
    "title": "Foundation Policies with Hilbert Representations",
    "abstract": "  Unsupervised and self-supervised objectives, such as next token prediction,\nhave enabled pre-training generalist models from large amounts of unlabeled\ndata. In reinforcement learning (RL), however, finding a truly general and\nscalable unsupervised pre-training objective for generalist policies from\noffline data remains a major open question. While a number of methods have been\nproposed to enable generic self-supervised RL, based on principles such as\ngoal-conditioned RL, behavioral cloning, and unsupervised skill learning, such\nmethods remain limited in terms of either the diversity of the discovered\nbehaviors, the need for high-quality demonstration data, or the lack of a clear\nprompting or adaptation mechanism for downstream tasks. In this work, we\npropose a novel unsupervised framework to pre-train generalist policies that\ncapture diverse, optimal, long-horizon behaviors from unlabeled offline data\nsuch that they can be quickly adapted to any arbitrary new tasks in a zero-shot\nmanner. Our key insight is to learn a structured representation that preserves\nthe temporal structure of the underlying environment, and then to span this\nlearned latent space with directional movements, which enables various\nzero-shot policy \"prompting\" schemes for downstream tasks. Through our\nexperiments on simulated robotic locomotion and manipulation benchmarks, we\nshow that our unsupervised policies can solve goal-conditioned and general RL\ntasks in a zero-shot fashion, even often outperforming prior methods designed\nspecifically for each setting. Our code and videos are available at\nhttps://seohong.me/projects/hilp/\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15567v1",
    "authors": ["Seohong Park", "Tobias Kreiman", "Sergey Levine"]
  },
  {
    "id": "2402.15570",
    "title": "Fast Adversarial Attacks on Language Models In One GPU Minute",
    "abstract": "  In this paper, we introduce a novel class of fast, beam search-based\nadversarial attack (BEAST) for Language Models (LMs). BEAST employs\ninterpretable parameters, enabling attackers to balance between attack speed,\nsuccess rate, and the readability of adversarial prompts. The computational\nefficiency of BEAST facilitates us to investigate its applications on LMs for\njailbreaking, eliciting hallucinations, and privacy attacks. Our gradient-free\ntargeted attack can jailbreak aligned LMs with high attack success rates within\none minute. For instance, BEAST can jailbreak Vicuna-7B-v1.5 under one minute\nwith a success rate of 89% when compared to a gradient-based baseline that\ntakes over an hour to achieve 70% success rate using a single Nvidia RTX A6000\n48GB GPU. Additionally, we discover a unique outcome wherein our untargeted\nattack induces hallucinations in LM chatbots. Through human evaluations, we\nfind that our untargeted attack causes Vicuna-7B-v1.5 to produce ~15% more\nincorrect outputs when compared to LM outputs in the absence of our attack. We\nalso learn that 22% of the time, BEAST causes Vicuna to generate outputs that\nare not relevant to the original prompt. Further, we use BEAST to generate\nadversarial prompts in a few seconds that can boost the performance of existing\nmembership inference attacks for LMs. We believe that our fast attack, BEAST,\nhas the potential to accelerate research in LM security and privacy. Our\ncodebase is publicly available at https://github.com/vinusankars/BEAST.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15570v1",
    "authors": [
      "Vinu Sankar Sadasivan",
      "Shoumik Saha",
      "Gaurang Sriramanan",
      "Priyatham Kattakinda",
      "Atoosa Chegini",
      "Soheil Feizi"
    ]
  },
  {
    "id": "2402.15572",
    "title": "Improving Explainable Object-induced Model through Uncertainty for\n  Automated Vehicles",
    "abstract": "  The rapid evolution of automated vehicles (AVs) has the potential to provide\nsafer, more efficient, and comfortable travel options. However, these systems\nface challenges regarding reliability in complex driving scenarios. Recent\nexplainable AV architectures neglect crucial information related to inherent\nuncertainties while providing explanations for actions. To overcome such\nchallenges, our study builds upon the \"object-induced\" model approach that\nprioritizes the role of objects in scenes for decision-making and integrates\nuncertainty assessment into the decision-making process using an evidential\ndeep learning paradigm with a Beta prior. Additionally, we explore several\nadvanced training strategies guided by uncertainty, including\nuncertainty-guided data reweighting and augmentation. Leveraging the BDD-OIA\ndataset, our findings underscore that the model, through these enhancements,\nnot only offers a clearer comprehension of AV decisions and their underlying\nreasoning but also surpasses existing baselines across a broad range of\nscenarios.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15572v1",
    "authors": ["Shihong Ling", "Yue Wan", "Xiaowei Jia", "Na Du"]
  },
  {
    "id": "2402.15589",
    "title": "Prompting LLMs to Compose Meta-Review Drafts from Peer-Review Narratives\n  of Scholarly Manuscripts",
    "abstract": "  One of the most important yet onerous tasks in the academic peer-reviewing\nprocess is composing meta-reviews, which involves understanding the core\ncontributions, strengths, and weaknesses of a scholarly manuscript based on\npeer-review narratives from multiple experts and then summarizing those\nmultiple experts' perspectives into a concise holistic overview. Given the\nlatest major developments in generative AI, especially Large Language Models\n(LLMs), it is very compelling to rigorously study the utility of LLMs in\ngenerating such meta-reviews in an academic peer-review setting. In this paper,\nwe perform a case study with three popular LLMs, i.e., GPT-3.5, LLaMA2, and\nPaLM2, to automatically generate meta-reviews by prompting them with different\ntypes/levels of prompts based on the recently proposed TELeR taxonomy. Finally,\nwe perform a detailed qualitative study of the meta-reviews generated by the\nLLMs and summarize our findings and recommendations for prompting LLMs for this\ncomplex task.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15589v1",
    "authors": [
      "Shubhra Kanti Karmaker Santu",
      "Sanjeev Kumar Sinha",
      "Naman Bansal",
      "Alex Knipper",
      "Souvika Sarkar",
      "John Salvador",
      "Yash Mahajan",
      "Sri Guttikonda",
      "Mousumi Akter",
      "Matthew Freestone",
      "Matthew C. Williams Jr"
    ]
  },
  {
    "id": "2402.15625",
    "title": "Learning Cyclic Causal Models from Incomplete Data",
    "abstract": "  Causal learning is a fundamental problem in statistics and science, offering\ninsights into predicting the effects of unseen treatments on a system. Despite\nrecent advances in this topic, most existing causal discovery algorithms\noperate under two key assumptions: (i) the underlying graph is acyclic, and\n(ii) the available data is complete. These assumptions can be problematic as\nmany real-world systems contain feedback loops (e.g., biological systems), and\npractical scenarios frequently involve missing data. In this work, we propose a\nnovel framework, named MissNODAGS, for learning cyclic causal graphs from\npartially missing data. Under the additive noise model, MissNODAGS learns the\ncausal graph by alternating between imputing the missing data and maximizing\nthe expected log-likelihood of the visible part of the data in each training\nstep, following the principles of the expectation-maximization (EM) framework.\nThrough synthetic experiments and real-world single-cell perturbation data, we\ndemonstrate improved performance when compared to using state-of-the-art\nimputation techniques followed by causal learning on partially missing\ninterventional data.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15625v1",
    "authors": ["Muralikrishnna G. Sethuraman", "Faramarz Fekri"]
  },
  {
    "id": "2402.16887",
    "title": "Artificial Intelligence for Complex Network: Potential, Methodology and\n  Application",
    "abstract": "  Complex networks pervade various real-world systems, from the natural\nenvironment to human societies. The essence of these networks is in their\nability to transition and evolve from microscopic disorder-where network\ntopology and node dynamics intertwine-to a macroscopic order characterized by\ncertain collective behaviors. Over the past two decades, complex network\nscience has significantly enhanced our understanding of the statistical\nmechanics, structures, and dynamics underlying real-world networks. Despite\nthese advancements, there remain considerable challenges in exploring more\nrealistic systems and enhancing practical applications. The emergence of\nartificial intelligence (AI) technologies, coupled with the abundance of\ndiverse real-world network data, has heralded a new era in complex network\nscience research. This survey aims to systematically address the potential\nadvantages of AI in overcoming the lingering challenges of complex network\nresearch. It endeavors to summarize the pivotal research problems and provide\nan exhaustive review of the corresponding methodologies and applications.\nThrough this comprehensive survey-the first of its kind on AI for complex\nnetworks-we expect to provide valuable insights that will drive further\nresearch and advancement in this interdisciplinary field.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.16887v1",
    "authors": [
      "Jingtao Ding",
      "Chang Liu",
      "Yu Zheng",
      "Yunke Zhang",
      "Zihan Yu",
      "Ruikun Li",
      "Hongyi Chen",
      "Jinghua Piao",
      "Huandong Wang",
      "Jiazhen Liu",
      "Yong Li"
    ]
  },
  {
    "id": "2402.16889",
    "title": "Generative Models are Self-Watermarked: Declaring Model Authentication\n  through Re-Generation",
    "abstract": "  As machine- and AI-generated content proliferates, protecting the\nintellectual property of generative models has become imperative, yet verifying\ndata ownership poses formidable challenges, particularly in cases of\nunauthorized reuse of generated data. The challenge of verifying data ownership\nis further amplified by using Machine Learning as a Service (MLaaS), which\noften functions as a black-box system.\n  Our work is dedicated to detecting data reuse from even an individual sample.\nTraditionally, watermarking has been leveraged to detect AI-generated content.\nHowever, unlike watermarking techniques that embed additional information as\ntriggers into models or generated content, potentially compromising output\nquality, our approach identifies latent fingerprints inherently present within\nthe outputs through re-generation. We propose an explainable verification\nprocedure that attributes data ownership through re-generation, and further\namplifies these fingerprints in the generative models through iterative data\nre-generation. This methodology is theoretically grounded and demonstrates\nviability and robustness using recent advanced text and image generative\nmodels. Our methodology is significant as it goes beyond protecting the\nintellectual property of APIs and addresses important issues such as the spread\nof misinformation and academic misconduct. It provides a useful tool to ensure\nthe integrity of sources and authorship, expanding its application in different\nscenarios where authenticity and ownership verification are essential.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.16889v1",
    "authors": ["Aditya Desu", "Xuanli He", "Qiongkai Xu", "Wei Lu"]
  },
  {
    "id": "2402.15197",
    "title": "Safety Optimized Reinforcement Learning via Multi-Objective Policy\n  Optimization",
    "abstract": "  Safe reinforcement learning (Safe RL) refers to a class of techniques that\naim to prevent RL algorithms from violating constraints in the process of\ndecision-making and exploration during trial and error. In this paper, a novel\nmodel-free Safe RL algorithm, formulated based on the multi-objective policy\noptimization framework is introduced where the policy is optimized towards\noptimality and safety, simultaneously. The optimality is achieved by the\nenvironment reward function that is subsequently shaped using a safety critic.\nThe advantage of the Safety Optimized RL (SORL) algorithm compared to the\ntraditional Safe RL algorithms is that it omits the need to constrain the\npolicy search space. This allows SORL to find a natural tradeoff between safety\nand optimality without compromising the performance in terms of either safety\nor optimality due to strict search space constraints. Through our theoretical\nanalysis of SORL, we propose a condition for SORL's converged policy to\nguarantee safety and then use it to introduce an aggressiveness parameter that\nallows for fine-tuning the mentioned tradeoff. The experimental results\nobtained in seven different robotic environments indicate a considerable\nreduction in the number of safety violations along with higher, or competitive,\npolicy returns, in comparison to six different state-of-the-art Safe RL\nmethods. The results demonstrate the significant superiority of the proposed\nSORL algorithm in safety-critical applications.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15197v1",
    "authors": ["Homayoun Honari", "Mehran Ghafarian Tamizi", "Homayoun Najjaran"]
  },
  {
    "id": "2402.15300",
    "title": "Seeing is Believing: Mitigating Hallucination in Large Vision-Language\n  Models via CLIP-Guided Decoding",
    "abstract": "  Large Vision-Language Models (LVLMs) are susceptible to object\nhallucinations, an issue in which their generated text contains non-existent\nobjects, greatly limiting their reliability and practicality. Current\napproaches often rely on the model's token likelihoods or other internal\ninformation, instruction tuning on additional datasets, or incorporating\ncomplex external tools. We first perform empirical analysis on sentence-level\nLVLM hallucination, finding that CLIP similarity to the image acts as a\nstronger and more robust indicator of hallucination compared to token\nlikelihoods. Motivated by this, we introduce our CLIP-Guided Decoding (CGD)\napproach, a straightforward but effective training-free approach to reduce\nobject hallucination at decoding time. CGD uses CLIP to guide the model's\ndecoding process by enhancing visual grounding of generated text with the\nimage. Experiments demonstrate that CGD effectively mitigates object\nhallucination across multiple LVLM families while preserving the utility of\ntext generation.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15300v1",
    "authors": ["Ailin Deng", "Zhirui Chen", "Bryan Hooi"]
  },
  {
    "id": "2402.15332",
    "title": "Categorical Deep Learning: An Algebraic Theory of Architectures",
    "abstract": "  We present our position on the elusive quest for a general-purpose framework\nfor specifying and studying deep learning architectures. Our opinion is that\nthe key attempts made so far lack a coherent bridge between specifying\nconstraints which models must satisfy and specifying their implementations.\nFocusing on building a such a bridge, we propose to apply category theory --\nprecisely, the universal algebra of monads valued in a 2-category of parametric\nmaps -- as a single theory elegantly subsuming both of these flavours of neural\nnetwork design. To defend our position, we show how this theory recovers\nconstraints induced by geometric deep learning, as well as implementations of\nmany architectures drawn from the diverse landscape of neural networks, such as\nRNNs. We also illustrate how the theory naturally encodes many standard\nconstructs in computer science and automata theory.\n",
    "pdfLink": "http://arxiv.org/pdf/2402.15332v1",
    "authors": [
      "Bruno GavranoviÄ‡",
      "Paul Lessard",
      "Andrew Dudzik",
      "Tamara von Glehn",
      "JoÃ£o G. M. AraÃºjo",
      "Petar VeliÄkoviÄ‡"
    ]
  }
]
